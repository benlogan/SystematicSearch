@inproceedings{10.1145/3583133.3590740,
author = {Tlili, Takwa and Krichen, Saoussen},
title = {Energy-Aware Metaheuristic for Virtual Machine Placement towards a Green Cloud Computing},
year = {2023},
isbn = {9798400701207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583133.3590740},
doi = {10.1145/3583133.3590740},
abstract = {Green cloud computing, an emerging computing paradigm in IT industry, is about providing efficient utilization of cloud's resources with minimal impact on the environment. The virtual machine placement has a considerable impact on a data center's energy and resource utilisation. The assignment of Virtual Machines (VMs) to Physical Machines (PMs) is an NP-hard problem to be solved using approximate algorithms at a reasonable computing time. In this paper, an energy-aware based algorithm is proposed for virtual machine placement. Our aim is to reduce the energy consumption and CO2 emission under a set of constraints. The performance and the efficiency of the proposed approach is tested on a cloud computing simulation toolkit.},
booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
pages = {779–782},
numpages = {4},
keywords = {genetic algorithm, green cloud computing, virtual machine placement, cloudSim},
location = {Lisbon, Portugal},
series = {GECCO '23 Companion}
}

@inproceedings{10.1145/3484824.3484894,
author = {Bheda, Hitesh and Thaker, Chirag and Shah, Sanjay},
title = {An Optimized VM Placement Approach to Reduce Energy Consumption in Green Cloud Computing},
year = {2022},
isbn = {9781450387637},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3484824.3484894},
doi = {10.1145/3484824.3484894},
abstract = {As a global digitization advancement, there is a massive need of cloud-based solutions and data centers. Another reason behind excessive need of data centers is because of increasing number of internet users. Increasing demand of data centers simultaneously need huge amount of energy for data center operation and on other end emit enormous amount of CO2. Several approaches have been proposed to reduce energy consumption, but major concern is by looking at one parameter or criteria they must compromise on other. Our proposed approach MIPS-Aware VM Placement in combination with searching of best capable host helps to reduce VM migration and increase mean time for better performance and save energy. Proposed approach identifies overloaded and underloaded hosts and to improve system performance algorithm does not allow to allocate additional workload, which will also help to reduce energy and get better QoS. Proposed approach significantly decreases VM migration and increase mean time before VM migration which in turns helps to reduce energy and associated cost. By using proposed MIPS-Aware VM Placement approach, we can reduce upto 25% more energy consumption compared to traditional approaches.},
booktitle = {Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence},
pages = {130–135},
numpages = {6},
keywords = {Performance improvement, Energy efficiency, MIPS-Aware VM placement, Green cloud computing},
location = {Windhoek, Namibia},
series = {DSMLAI '21'}
}

@inproceedings{10.1145/3264746.3264792,
author = {Liu, Xing and Liu, Panwen and Li, Hongjing and Li, Zheng and Zou, Chengming and Zhou, Haiying and Yan, Xin and Xia, Ruoshi},
title = {Energy-Aware Task Scheduling Strategies with QoS Constraint for Green Computing in Cloud Data Centers},
year = {2018},
isbn = {9781450358859},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3264746.3264792},
doi = {10.1145/3264746.3264792},
abstract = {Energy optimization with Quality-of-Service (QoS) constraint has become a timely and significant challenge for the cloud datacenters. In this paper, a hardware and software collaborative optimization strategy is implemented to minimize the energy cost while satisfying the time constraint of the cloud-computing datacenters. In the hardware aspect, a DVFS-capable CPU/GPU/FPGA heterogeneous cloud infrastructure is built. This infrastructure has high flexibility, and can adjust its hardware characteristics dynamically in terms of the software run-time contexts, so that a hardware platform which matches the software can be built. Based on this hardware platform, the cloud applications can be executed more efficiently with less energy cost. In the software aspect, the deadline-aware energy-efficient task scheduling algorithms are investigated. Different from the traditional approaches which search for the optimal scheduling solution by the heuristic approaches, a new scheduling approach based on the improved Mathematical Morphology (MM) algorithm is investigated in this paper. To evaluate the performance of our work, we calculated the energy cost of the Fourier transform (FT) and Gaussian elimination (GE) applications on the homogeneous and heterogeneous cloud computing platforms by applying the GA and MM algorithms, respectively. The results proved the MM algorithms running on the DVFS-capable heterogeneous cloud infrastructure could decrease the energy cost of the FT application and GE application respectively by 24.7% and 37.8%, if compared with the GA algorithm running on the DVFS-incapable homogeneous cloud infrastructure.},
booktitle = {Proceedings of the 2018 Conference on Research in Adaptive and Convergent Systems},
pages = {260–267},
numpages = {8},
keywords = {energy optimization, green cloud computing, DVFS, task scheduling},
location = {Honolulu, Hawaii},
series = {RACS '18}
}

@inproceedings{10.1145/1968613.1968651,
author = {Chu, Feng-Seng and Chen, Kwang-Cheng and Cheng, Chen-Mou},
title = {Toward Green Cloud Computing},
year = {2011},
isbn = {9781450305716},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1968613.1968651},
doi = {10.1145/1968613.1968651},
abstract = {Cloud computing is emerging as a critical information communication technology to heavily impact our daily life in the future. We systematically analyze its energy consumption based on types of services and obtain the conditions to facilitate green cloud computing to save overall energy consumption in the related information communication systems. With a tremendously increasing number of mobile devices, green mobile communications would be the foundation of green cloud computing.},
booktitle = {Proceedings of the 5th International Conference on Ubiquitous Information Management and Communication},
articleno = {31},
numpages = {5},
keywords = {energy efficiency, green communications, cloud computing, mobile internet, mobile computing},
location = {Seoul, Korea},
series = {ICUIMC '11}
}

@inproceedings{10.1109/UCC.2014.9,
author = {Rocha, Lucio A. and Cardozo, Eleri},
title = {A Hybrid Optimization Model for Green Cloud Computing},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.9},
doi = {10.1109/UCC.2014.9},
abstract = {This paper presents a hybrid optimization model that allows a cloud service provider to establish virtual machine (VM) placement strategies for its data centers in such a way that energy efficiency and network quality of service are jointly optimized. Usually, VM placement is an activity not fully integrated with network operations. As such, the VM placement strategy does not take into account the impact it produces on the network performance in terms of quality of service parameters such as packet losses and traffic delays. The proposed strategy allows cloud providers to reach a balance between the energy efficiency of their infrastructures and the network quality of service they offer to their customers. The proposed strategy has high potential for parallelism making it feasible for the energetic optimization of large cloud infrastructures. In addition, the strategy allows network operations practices such as constraint-based routing be incorporated into the VM placement process.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {11–20},
numpages = {10},
series = {UCC '14}
}

@inproceedings{10.1145/2554850.2555069,
author = {Zhan, Kelie and Lung, Chung-Horng and Srivastava, Pradeep},
title = {A Green Analysis of Mobile Cloud Computing Applications},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2555069},
doi = {10.1145/2554850.2555069},
abstract = {With the widespread of rich mobile applications, the usage of mobile devices, especially smart phones and tablets, has become popular nowadays. However, battery in the mobile devices often limits continuous usages with its small size and capacity. Therefore, power consumption of mobile devices is a critical issue, not only for extending lifetime use of mobile devices, but also for creating a green IT which is a raising concern in academic and industrial communities. The goal of this paper is to investigate the power consumption of mobile devices and resource usages for various applications. To meet the goal, we have performed a number of experiments and detailed evaluations of resource usages and power consumption for various applications using a number of tools. In addition, we have measured performance metrics for applications either using a mobile device or running in the Amazon cloud. We examine the impact of various factors and provide insights on power consumption for different mobile applications.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {357–362},
numpages = {6},
keywords = {green computing, Amazon, mobile cloud computing, power consumption, CPU},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/1687399.1687520,
author = {Shin, Donghwa and Kim, Jihun and Chang, Naehyuck and Choi, Jinhang and Chung, Sung Woo and Chung, Eui-Young},
title = {Energy-Optimal Dynamic Thermal Management for Green Computing},
year = {2009},
isbn = {9781605588001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1687399.1687520},
doi = {10.1145/1687399.1687520},
abstract = {Existing thermal management systems for microprocessors assume that the thermal resistance of the heat-sink is constant and that the objective of the cooling system is simply to avoid thermal emergencies. But in fact the thermal resistance of the usual forced-convection heat-sink is inversely proportional to the fan speed, and a more rational objective is to minimize the total power consumption of both processor and cooling system. Our new method of dynamic thermal management uses both the fan speed and the voltage/frequency of the microprocessor as control variables. Experiments show that tracking the energy-optimal steady-state temperature can saves up to 17.6% of the overall energy, when compared with a conventional approach that merely avoids over-heating.},
booktitle = {Proceedings of the 2009 International Conference on Computer-Aided Design},
pages = {652–657},
numpages = {6},
location = {San Jose, California},
series = {ICCAD '09}
}

@inproceedings{10.5555/2735522.2735547,
author = {Romansky, Stephen and Hindle, Abram},
title = {On Improving Green Mining for Energy-Aware Software Analysis},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Consumer demand for longer lasting battery life in mobile computers, as well as industry interest in energy efficient cloud infrastructure, creates a need for hardware and software energy efficiency improvements. One way to tackle this problem is from a software perspective. If it were known which software changes influenced energy consumption, then tools could be created to help software professionals create more energy efficient software. The process of extracting energy consumption information, Green Mining, is time demanding because researchers must run many tests, with sufficient coverage, on each revision in a software product multiple times. The time required for testing acts as a barrier to extracting energy consumption measurements from new software systems. Therefore, this work proposes, implements, and evaluates a search-based approximation method that trades some precision for a speed-up in the mining process. This speed-up enables researchers to study additional software systems that were too costly to investigate before.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {234–245},
numpages = {12},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1145/3230348.3230369,
author = {Fathi, Mohammad H. and Khanli, Leyli M.},
title = {Consolidating VMs in Green Cloud Computing Using Harmony Search Algorithm},
year = {2018},
isbn = {9781450363754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3230348.3230369},
doi = {10.1145/3230348.3230369},
abstract = {Throughout history, energy consumption was not a matter to humanity and mankind considered resources on earth limitless, as his knowledge grew, he found out that using so much energy and producing a lot of greenhouse gases, has endangered his life. Nowadays Cloud networks and data centers consume a lot of energy. In order to decrease energy consumption like heuristic and meta-heuristic algorithms are in wide range of use in this problem because a Virtual Machine(VM) consolidation is considered a NP-hard problem. Ant colony system, artificial bee colony, genetic algorithm and local regression are some of these heuristic methods. These mentioned algorithms tried to maintain service level agreement (SLA) while reducing energy consumption and live migrations. On the other hand, the harmony search algorithm has acceptable convergence rate compared to swarm methods, and has less computation time compared to genetic algorithm to find the optimum answer. In this paper, we are motivated to use newly presented meta-heuristic harmony search algorithm. This algorithm has proven its efficiency in power management systems. This algorithm benefits in way that other particle and genetic driven algorithms don't. Some of these benefits are faster result, no need for initial parameters, and no need for data derivation. Using this algorithm for virtual machine consolidation allows reduction in energy consumption, SLA violation, live migrations quantity and energy SLA violation multiplication (ESV), where the proposed method has proven its efficiency and offered improvement ranges from minimum of 18.56% in ESV to maximum of 1988.23% in migrations compared to previous methods.},
booktitle = {Proceedings of the 2018 1st International Conference on Internet and E-Business},
pages = {146–151},
numpages = {6},
keywords = {harmony search algorithm, VM consolidation, green computing, Cloud computing},
location = {Singapore, Singapore},
series = {ICIEB '18}
}

@inproceedings{10.5555/3233397.3233502,
author = {Bolla, R. and Sambolino, L. and Tigano, D. and Repetto, M.},
title = {Enhancing Energy-Efficient Cloud Management through Code Annotations and the Green Abstraction Layer},
year = {2015},
isbn = {9780769556970},
publisher = {IEEE Press},
abstract = {Cloud computing has emerged as a flexible and efficient paradigm to provide IT resources on-demand. However, it has also raised new challenges for infrastructure providers to manage large-scale deployments in an efficient and effective way.In this paper, we present the trade-off between energy consumption and performance. We outline a novel framework for efficient and effective resource consolidation in data centers, building on latest trends in software development practice and recent standards for energy efficiency. In particular, we consider the usage of code annotations from software developers and the adoption of a "green abstraction layer" to model the trade-off between performance and energy consumption.},
booktitle = {Proceedings of the 8th International Conference on Utility and Cloud Computing},
pages = {534–539},
numpages = {6},
location = {Limassol, Cyprus},
series = {UCC '15}
}

@inproceedings{10.1145/2905055.2905136,
author = {Patel, Mili and Patel, Hiren and Patel, Nimisha},
title = {Usage of Hybrid Mechanisms to Reduce Energy Consumption While Preserving Green SLA in Cloud Environment},
year = {2016},
isbn = {9781450339629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2905055.2905136},
doi = {10.1145/2905055.2905136},
abstract = {Cloud computing provides utility oriented services and pay-as-you-go computing model for its users. Massive adoption of Cloud services leads to build a sustainable environment and also demands for green Cloud services. With the advancement in Cloud services, the issue of carbon dioxide emission becomes significant. There is also a challenge for Cloud provider to satisfy the customer by guaranteeing the services with performance and availability in Service Level Agreement (SLA). Hence, energy consumption and SLA violation become important issues for Cloud providers. These issues can be addressed in many facets viz. efficient provisioning of resources, reducing energy consumption in datacenters, server consolidation, virtual machine (VM) migration, minimizing SLA violation or also by providing SLA with green requirements. In this paper, we survey various techniques which address green SLA with Quality of Service (QoS) requirements by using different resource management and consolidation procedures.Further, we propose our work by considering the multi-criteria method for resource management which selects the host as probable migration destination having highest predicted utilization after allocating a VM on the host. Hence, we aim to address the issue of maintaining the trade-off between energy consumption and SLA violation.},
booktitle = {Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {77},
numpages = {6},
keywords = {Service Level Agreement (SLA), Resource Allocation, Green Cloud Computing, Quality of Service (QoS), VM Consolidation, Energy efficiency},
location = {Udaipur, India},
series = {ICTCS '16}
}

@article{10.1145/3588591,
author = {Luo, Tao and Wong, Weng-Fai and Goh, Rick Siow Mong and Do, Anh Tuan and Chen, Zhixian and Li, Haizhou and Jiang, Wenyu and Yau, Weiyun},
title = {Achieving Green AI with Energy-Efficient Deep Learning Using Neuromorphic Computing},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/3588591},
doi = {10.1145/3588591},
journal = {Commun. ACM},
month = {jun},
pages = {52–57},
numpages = {6}
}

@inproceedings{10.5555/3049877.3049903,
author = {Bergen, Andreas and Taherimakhsousi, Nina},
title = {Software Energy Optimization in the Cloud},
year = {2016},
publisher = {IBM Corp.},
address = {USA},
abstract = {A promising avenue to control energy-related costs in enterprise data centers is to investigate power-aware resource management strategies. Mechanisms to accurately capture energy consumption in data centers include source and machine code instruction analysis, kernel sensors, system call monitors and per-VM metering techniques. Though very accurate, these approaches are highly invasive, requiring modifications to software or hardware, and introduce an observer effect that can adversely impact performance. Perhaps most important, results obtained from these approaches require refinement before they can actually be used for management decisions that must strike a balance between costs, SLOs and SLAs. Using existing instrumentation at a rack's PDU provides sufficient granularity to determine the true energy consumption of servers in a non-intrusive way. We show that by leveraging existing instrumentation at a rack's PDU, profiling the type of resource (e.g., CPU, memory, disk, network) a process is using on a given server is not only possible, but highly accurate despite the anticipated signal noise from other servers on a rack's power circuit. This provides a better foundation and allows us to forecast and manage energy demands in data centers.},
booktitle = {Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering},
pages = {243–249},
numpages = {7},
keywords = {ACM proceedings, LaTeX, text tagging},
location = {Toronto, Ontario, Canada},
series = {CASCON '16}
}

@inproceedings{10.1145/3255895,
author = {Malakuti, Somayeh and Lohmann, Wolfgang and Aksit, Mehmet},
title = {Session Details: Volume II: Software Development, System Software &amp; Security: Software Engineering Aspects of Green Computing Track},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3255895},
doi = {10.1145/3255895},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/2593743.2593745,
author = {Bergen, Andreas and Desmarais, Ronald and Ganti, Sudhakar and Stege, Ulrike},
title = {Towards Software-Adaptive Green Computing Based on Server Power Consumption},
year = {2014},
isbn = {9781450328449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593743.2593745},
doi = {10.1145/2593743.2593745},
abstract = {With the proliferation of virtualization and cloud comput- ing, optimizing the power usage effectiveness of enterprise data centers has become a laudable goal and a critical re- quirement in IT operations all over the world. While a sig- nificant body of research exists to measure, monitor, and control the greenness level of hardware components, signif- icant research efforts are needed to relate hardware energy consumption to energy consumption due to program exe- cution. In this paper we report on our investigations to characterize power consumption profiles for different types of compute and memory intensive software applications. In particular, we focus on studying the effects of CPU loads on the power consumption of compute servers by monitoring rack power consumption in a data center. We conducted a series of experiments with a variety of processes of differ- ent complexity to understand and characterize the effect on power consumption. Combining processes of varying com- plexity with varying resource allocations produces different energy consumption levels. The challenge is to optimize pro- cess orchestration based on a power consumption framework to accrue energy savings. Our ultimate goal is to develop smart adaptive green computing techniques, such as adap- tive job scheduling and resource provisioning, to reduce over- all power consumption in data centers or clouds.},
booktitle = {Proceedings of the 3rd International Workshop on Green and Sustainable Software},
pages = {9–16},
numpages = {8},
keywords = {self-adaptive green computing, green-aware, data centers, power application pro- files, Power consumption measurments, power consumption framework, cloud computing},
location = {Hyderabad, India},
series = {GREENS 2014}
}

@inproceedings{10.1145/3245171,
author = {Malakuti, Somayeh and Lohmann, Wolfgang and Aksit, Mehmet},
title = {Session Details: Volume II: Software Development and System Software &amp; Security: Software Engineering Aspects of Green Computing Track},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245171},
doi = {10.1145/3245171},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@inproceedings{10.1145/2627566.2627578,
author = {Sobie, Randall},
title = {Distributed Cloud Computing in High Energy Physics},
year = {2014},
isbn = {9781450329927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2627566.2627578},
doi = {10.1145/2627566.2627578},
abstract = {Cloud computing is increasingly being used for running high energy physics (HEP) applications. We review the motivation for using clouds in HEP and describe how they are gradually being integrated into our systems. In particular, we highlight our use of a distributed cloud computing system that integrates both private and public IaaS clouds into a unified infrastructure. We describe our experience using the distributed cloud and our plans to make the system context-aware in order to scale to larger workloads and run data-intensive HEP applications.},
booktitle = {Proceedings of the 2014 ACM SIGCOMM Workshop on Distributed Cloud Computing},
pages = {1–4},
numpages = {4},
keywords = {high energy physics, cloud computing},
location = {Chicago, Illinois, USA},
series = {DCC '14}
}

@inproceedings{10.5555/2346696.2346731,
author = {Kathiresan, Nagarajan and Narayanasamy, Ganesan},
title = {Implementation of Green Computing in IBM HPC Software Stack on Accelerator Based Super Computing},
year = {2012},
isbn = {9781450316446},
publisher = {A*STAR Computational Resource Centre},
address = {SGP},
abstract = {Computational requirements of the high performance computing servers and their power consumptions have increased over the period of time. The major power consumption components are processors and the main memory in the servers. The multi-core era bring the quad, hexa or an octa cores into a single socket, the total power consumption of the server is reduced by the way of various energy aware kernel implementations. I.e., the energy aware kernel will bring the processor/core into sleep modes (or) lower clock speeds during the time of CPUs are not utilized for a finite interval of time. Additionally, the green and energy-aware implementations are done by the way of (i) processor affinity or binding tools (ii) energy aware scheduling techniques (iii) case study by power and performance trade-offs (iv) On-demand compute awareness in the kernel (v) dynamic frequency scaling etc. into the software stack. Herewith, we discussed the various possibilities of energy-aware implementations in the software stack thereby the best application performance and the optimal power/energy efficiency can be obtained within a given power budget and using various user defined performance metrics &amp; constrains.},
booktitle = {Proceedings of the ATIP/A*CRC Workshop on Accelerator Technologies for High-Performance Computing: Does Asia Lead the Way?},
articleno = {30},
numpages = {2},
keywords = {green computing, power and performance trade-offs, high performance computing, energy-aware scheduling},
location = {Buona Vista, Singapore},
series = {ATIP '12}
}

@inproceedings{10.1145/2597073.2597130,
author = {Zhang, Chenlei and Hindle, Abram},
title = {A Green Miner's Dataset: Mining the Impact of Software Change on Energy Consumption},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597130},
doi = {10.1145/2597073.2597130},
abstract = {With the advent of mobile computing, the responsibility of software developers to update and ship energy efficient applications has never been more pronounced. Green mining attempts to address this responsibility by examining the impact of software change on energy consumption. One problem with green mining is that power performance data is not readily available, unlike many other forms of MSR research. Green miners have to create tests and run them across numerous versions of a software project because power performance data was either missing or never existed for that particular project. In this paper we describe multiple open green mining datasets used in prior green mining work. The dataset includes numerous power traces and parallel system call and CPU/IO/Memory traces of multiple versions of multiple products. These datasets enable those more interested in data-mining and modeling to work on green mining problems as well.},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {400–403},
numpages = {4},
keywords = {Software Energy Consumption, Software Change, Dataset},
location = {Hyderabad, India},
series = {MSR 2014}
}

@article{10.1145/2742488,
author = {Kaur, Tarandeep and Chana, Inderveer},
title = {Energy Efficiency Techniques in Cloud Computing: A Survey and Taxonomy},
year = {2015},
issue_date = {November 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2742488},
doi = {10.1145/2742488},
abstract = {The increase in energy consumption is the most critical problem worldwide. The growth and development of complex data-intensive applications have promulgated the creation of huge data centers that have heightened the energy demand. In this article, the need for energy efficiency is emphasized by discussing the dual role of cloud computing as a major contributor to increasing energy consumption and as a method to reduce energy wastage. This article comprehensively and comparatively studies existing energy efficiency techniques in cloud computing and provides the taxonomies for the classification and evaluation of the existing studies. The article concludes with a summary providing valuable suggestions for future enhancements.},
journal = {ACM Comput. Surv.},
month = {oct},
articleno = {22},
numpages = {46},
keywords = {Resource Management System (RMS), Information and Communication Technology (ICT), energy efficiency, data center, consolidation, Virtual Machines (VMs), virtualization, Cloud computing, resource scheduling, multicores}
}

@inproceedings{10.1145/2525526.2525855,
author = {Kaushik, Rini T. and Sarkar, Prasenjit and Gharaibeh, Abdullah},
title = {Greening the Compute Cloud's Pricing Plans},
year = {2013},
isbn = {9781450324588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2525526.2525855},
doi = {10.1145/2525526.2525855},
abstract = {Customers are levied a charge by the cloud service providers for using their services and the attractiveness of the offered pricing plan is one of the key determinants in the cloud adoption. The paper presents a synergistic cloud where the pricing plan, scheduler, and the charge-back model work in tandem with each other to provide green and cost-efficient computing options and incentives to the environmentally-friendly and cost-conscious end-users. The fine-grained, wholesale electricity price aware scheduler works in synergy with end-users' choices to reduce operating energy costs. The fine-grained, resource-utilization based, and spot price aware charge-back model is used to provide incentives in form of reduced usage costs. Strong evaluation results with real-world traces from Google show the feasibility of the proposed techniques.},
booktitle = {Proceedings of the Workshop on Power-Aware Computing and Systems},
articleno = {6},
numpages = {5},
location = {Farmington, Pennsylvania},
series = {HotPower '13}
}

@inproceedings{10.1145/1900008.1900122,
author = {Qian, Kai and Lo, Chia-Tien Dan},
title = {Leveraging CS Capstone Project and Green Smart Energy Computing with WSN in a Box},
year = {2010},
isbn = {9781450300643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1900008.1900122},
doi = {10.1145/1900008.1900122},
abstract = {This paper describes an innovative product-oriented and software engineering process-guided Computer Science (CS) capstone project model for green smart energy application with aportable and inexpensive Wireless Sensor Network (WSN) kit in a Box (WinBox). The project is infused with ZigBee wireless technology and requires a wide range of CS and Software Engineering knowledge elements. Students will gain experience to tie their knowledge and skills learned in the CS discipline to analyze, design, and develop deliverable real world oriented product prototypes, and will be motivated to catch up with emerging technologies in "learning by doing" and be promoted for creativity and life-long learning.},
booktitle = {Proceedings of the 48th Annual Southeast Regional Conference},
articleno = {84},
numpages = {2},
keywords = {capstone project, product-oriented, wireless sensor network, software engineering process},
location = {Oxford, Mississippi},
series = {ACM SE '10}
}

@inproceedings{10.1145/1531542.1531543,
author = {Pedram, Massoud},
title = {Green Computing: Reducing Energy Cost and Carbon Footprint of Information Processing Systems},
year = {2009},
isbn = {9781605585222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1531542.1531543},
doi = {10.1145/1531542.1531543},
abstract = {Digital information management is the key enabler for unprecedented rise in productivity and efficiency gains experienced by the world economies during the 21st century. Information processing systems have thus become essential to the functioning of business, service, academic, and governmental institutions. As institutions increase their offerings of digital information services, the demand for computation and storage capability also increases. Examples include online banking, e-filing of taxes, music and video downloads, online shipment tracking, real-time inventory/supply-chain management, electronic medical recording, insurance database management, surveillance and disaster recovery. It is estimated that, in some industries, the number of records that must be retained is growing at a CAGR of 50 percent or greater. This exponential increase in the digital intensity of human existence is driven by many factors, including ease of use and availability of a rich set of information technology (IT) devices and services. Indeed, it would be difficult to imagine how significant societal transformations that better our world could occur without the productivity and innovation enabled by the IT. Unfortunately, the energy cost and carbon footprint of the IT devices and services has become exorbitant. Moreover, current technological and digital service utilization trends result in a doubling of the energy cost of the IT infrastructure and its carbon footprint in less than five years. In an energy-constrained world, this consumption trend is unsustainable and comes at increasingly unacceptable societal and environmental costs. This presentation will first explain what is meant by green computing and how greenness of information processing may be quantified. Next, energy-efficient computing paradigms which utilize chip multi-processing, multiple-voltage domains, dynamic voltage/frequency scaling, and power/clock gating techniques will be reviewed. Finally, techniques for improving performance per Watt of large-scale information processing and storage systems (e.g., a data center), including hierarchical dynamic power management, task placement and scheduling, energy balancing, resource virtualization, and application optimizations that dynamically configure hardware for higher efficiency will be discussed.},
booktitle = {Proceedings of the 19th ACM Great Lakes Symposium on VLSI},
pages = {1–2},
numpages = {2},
keywords = {power and thermal management, data center, green computing, energy efficiency},
location = {Boston Area, MA, USA},
series = {GLSVLSI '09}
}

@inproceedings{10.1145/3297662.3365820,
author = {Khan, Naveed and Haugerud, H\r{a}rek and Shrestha, Raju and Yazidi, Anis},
title = {Optimizing Power and Energy Efficiency in Cloud Computing},
year = {2020},
isbn = {9781450362382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297662.3365820},
doi = {10.1145/3297662.3365820},
abstract = {With the exponential growth in cloud computing, the steadily increasing amount of power consumption due to the use of physical and virtual machines is becoming a serious challenge. In this context, we report a study on optimizing the power and energy efficiency of physical and virtual machines in a cloud computing environment. The energy profile of different workloads is thoroughly investigated under different configurations. This paper presents the findings from our study which provides a good understanding of how different workloads affect power and energy efficiency of both physical and virtual machines.},
booktitle = {Proceedings of the 11th International Conference on Management of Digital EcoSystems},
pages = {256–261},
numpages = {6},
keywords = {Energy Efficiency, Cloud computing, Optimization, Virtual Machines},
location = {Limassol, Cyprus},
series = {MEDES '19}
}

@inproceedings{10.1145/3387168.3387192,
author = {Jun, Liu and Jie, Zhang and DingHong, Pu},
title = {Cloud Computing Virtual Machine Migration Energy Measuring Research},
year = {2020},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387168.3387192},
doi = {10.1145/3387168.3387192},
abstract = {This paper research virtual machine migration energy measuring on IPv4/IPv6 network based on cloud computing infrastructure platform, it conducts a research on the energy measuring in IPv4/IPv6 cloud computing platform, and presents a dynamic energy measuring mathematical model based on analyzing CPU energy consumption changes brought by random assignment works. The research determines mathematical model parameter values and it completes the IPv4/IPv6 cloud computing platform virtual machine migration experimentally. This paper achieves the energy consumption of IPv4/IPv6 transition prior-period, mid-period and last-period cloud computing platform virtual machine migration, the conclusions in line with the cloud energy measurement needs, it builds the theoretical foundation for cloud computing platform energy consumption optimize.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {21},
numpages = {5},
keywords = {Cloud Computing, Migration Energy Consumption, Energy Measuring, Virtual Machine Migration},
location = {Vancouver, BC, Canada},
series = {ICVISP 2019}
}

@inproceedings{10.1145/3374587.3374594,
author = {Singh, Jyoti and Chen, Jingchao},
title = {Optimizing Energy Consumption for Cloud Computing: A Cluster and Migration Based Approach (CMBA)},
year = {2020},
isbn = {9781450376273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374587.3374594},
doi = {10.1145/3374587.3374594},
abstract = {The increased use of IT technologies and number of IT users have triggered cloud computing resource demand including the need for more data centers. Each data center consumes electricity for its un-interrupted operations and maintenance, therefore responsible for the emissions of carbon dioxide, a potent greenhouse gas causing climate change. Hence, there is a necessity to provide a solution through which energy consumption for cloud data centers can be reduced. As virtual machine located in data center are run under loaded to maintain higher performance but it causes wastage of resources and power. While, task overloading severally reduce the performance of data center. To address this issue, we propose CMBA (Cluster and Migration Based Approach) for cloud resource allocation that maps groups of tasks to customized virtual machine types based on processing, memory and network requirements. Proper placement of workload with specific VMs and dynamic migration concept reduce energy consumption for running physical machine and its respective host or data centers. Taking altogether, intelligent customization of virtual machines by adopting CMBA approach will maintain high efficiency of datacenters with reduced energy consumption.},
booktitle = {Proceedings of the 2019 3rd International Conference on Computer Science and Artificial Intelligence},
pages = {28–32},
numpages = {5},
keywords = {energy consumption, Cloud computing, virtual machine migration, virtualization},
location = {Normal, IL, USA},
series = {CSAI '19}
}

@article{10.5555/2460156.2460172,
author = {Yuan, Dongqing and Lewandowski, Cody and Cross, Brandon},
title = {Building a Green Unified Computing IT Laboratory through Virtualization},
year = {2013},
issue_date = {June 2013},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {28},
number = {6},
issn = {1937-4771},
abstract = {In this study, we share our experience how we use cluster virtualization to build a unified virtual computing environment. Virtual machines (VMs) installed in a lab environment can be used to create scalable and reliable virtual computing clusters. Virtualization provides many benefits, such as greener IT with less power consumption, easier management through central environment control and improved disaster recovery ability. This paper describes three such virtual clusters that have been used to conduct hands-on laboratory experiments in undergraduate courses and serve as a platform for student practicing hands-on skills in Server Application and Administration, IP Telephony and Unified Communication. We present the architecture and configuration of the clusters and describe how we make them available for educational use along with instructional materials, then we report on lessons we learned while developing and maintaining these clusters and using them for the coursework.},
journal = {J. Comput. Sci. Coll.},
month = {jun},
pages = {76–83},
numpages = {8}
}

@inproceedings{10.5555/2485288.3250184,
author = {Rosing, Tajana and Theocharides, Theocharis},
title = {Session Details: Energy Efficient Mobile and Cloud Computing Systems},
year = {2013},
isbn = {9781450321532},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
location = {Grenoble, France},
series = {DATE '13}
}

@inproceedings{10.5555/3398761.3398775,
author = {Antoniadis, Antonios and Cristi, Andr\'{e}s and Oosterwijk, Tim and Sgouritsa, Alkmini},
title = {A General Framework for Energy-Efficient Cloud Computing Mechanisms},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We present a general model for the operation of a cloud computing server comprised of one or more speed-scalable processors. Typically, tasks are submitted to such a cloud computing server in an online fashion, and the server operator has to schedule the tasks and decides on payments without knowledge about the tasks arriving in the future. Although very natural, this cloud computing problem on speed-scalable processors has not been studied from a mechanism design perspective in the online setting.We provide a mechanism for this setting, both for a single and multiprocessor environment, that has several desirable properties: (1) the induced game admits a subgame perfect equilibrium in pure strategies and therefore a pure Nash equilibrium, (2) the Price of Anarchy is constant, (3) the mechanism is budget balanced, i.e., the sum of the payments of the agents is equal to the total energy costs, (4) the communication complexity is low, (5) the mechanism is computationally tractable for both the service operator and the agents, and (6) the agents' payment is also intuitive and easy to communicate to them. We also provide a second mechanism with a better Price of Anarchy, which in turn is more involved to implement.We are able to extend our mechanisms and results to the Bayesian setting, where the type of each agent is drawn independently from some underlying distribution and agents are minimizing their expected costs. In this setting we also show the same approximation factor of our mechanism as in the basic online setting in both the single and the multiprocessor environment.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {70–78},
numpages = {9},
keywords = {speed scaling, price of anarchy, game theory, energy efficiency, cloud computing, scheduling, mechanism design},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@inproceedings{10.1145/2371536.2371562,
author = {Zhang, Qi and Zhani, Mohamed Faten and Zhang, Shuo and Zhu, Quanyan and Boutaba, Raouf and Hellerstein, Joseph L.},
title = {Dynamic Energy-Aware Capacity Provisioning for Cloud Computing Environments},
year = {2012},
isbn = {9781450315203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371536.2371562},
doi = {10.1145/2371536.2371562},
abstract = {Data centers have recently gained significant popularity as a cost-effective platform for hosting large-scale service applications. While large data centers enjoy economies of scale by amortizing initial capital investment over large number of machines, they also incur tremendous energy cost in terms of power distribution and cooling. An effective approach for saving energy in data centers is to adjust dynamically the data center capacity by turning off unused machines. However, this dynamic capacity provisioning problem is known to be challenging as it requires a careful understanding of the resource demand characteristics as well as considerations to various cost factors, including task scheduling delay, machine reconfiguration cost and electricity price fluctuation.In this paper, we provide a control-theoretic solution to the dynamic capacity provisioning problem that minimizes the total energy cost while meeting the performance objective in terms of task scheduling delay. Specifically, we model this problem as a constrained discrete-time optimal control problem, and use Model Predictive Control (MPC) to find the optimal control policy. Through extensive analysis and simulation using real workload traces from Google's compute clusters, we show that our proposed framework can achieve significant reduction in energy cost, while maintaining an acceptable average scheduling delay for individual tasks.},
booktitle = {Proceedings of the 9th International Conference on Autonomic Computing},
pages = {145–154},
numpages = {10},
keywords = {cloud computing, energy management, resource management, model predictive control},
location = {San Jose, California, USA},
series = {ICAC '12}
}

@inproceedings{10.1145/3284557.3284738,
author = {Atiewi, Saleh and Abuhussein, Abdullah and Saleh, Mohammad Abu},
title = {Impact of Virtualization on Cloud Computing Energy Consumption: Empirical Study},
year = {2018},
isbn = {9781450366281},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3284557.3284738},
doi = {10.1145/3284557.3284738},
abstract = {Global warming, which is currently one of the greatest environmental challenges, is caused by carbon emissions. A report from the Energy Information Administration indicates that approximately 98% of CO2 emissions can be attributed to energy consumption. The trade-off between efficient and ecologically sound operation represents a major challenge faced by many organizations at present. In addition, numerous companies are currently compelled to pay a carbon tax for the resources they use and the environmental impact of their products and services. Therefore, an energy consumption system can generate actual financial payback. Green information technology involves various approaches, including power management, recycling, telecommunications, and virtualization. This paper focuses on comparing and evaluating techniques used for reducing energy consumption in virtualized environments. We first highlight the impact of virtualization techniques on minimizing energy consumption in cloud computing. Then we present an experimental comparative study between two common energy-efficient task scheduling algorithms in cloud computing (i.e., the green scheduler, the power saver scheduler). These algorithms are discussed briefly and analyzed. The three metrics used to evaluate the task scheduling algorithms are (1) total power consumption, (2) data center load, and (3) virtual machine load. This work aims to gauge and subsequently improve energy consumption efficiency in virtualized environments.},
booktitle = {Proceedings of the 2nd International Symposium on Computer Science and Intelligent Control},
articleno = {24},
numpages = {7},
keywords = {Virtualization, Green computing, Energy, Cloud cconomics, Simulation, Green cloud, Cloud computing},
location = {Stockholm, Sweden},
series = {ISCSIC '18}
}

@article{10.1145/1400181.1400186,
author = {Kurp, Patrick},
title = {Green Computing},
year = {2008},
issue_date = {October 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/1400181.1400186},
doi = {10.1145/1400181.1400186},
abstract = {Are you ready for a personal energy meter?},
journal = {Commun. ACM},
month = {oct},
pages = {11–13},
numpages = {3}
}

@inproceedings{10.5555/2147671.2147698,
author = {Yanggratoke, Rerngvit and Wuhib, Fetahi and Stadler, Rolf},
title = {Gossip-Based Resource Allocation for Green Computing in Large Clouds},
year = {2011},
isbn = {9783901882449},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {We address the problem of resource allocation in a large-scale cloud environment, which we formalize as that of dynamically optimizing a cloud configuration for green computing objectives under CPU and memory constraints. We propose a generic gossip protocol for resource allocation, which can be instantiated for specific objectives. We develop an instantiation of this generic protocol which aims at minimizing power consumption through server consolidation, while satisfying a changing load pattern. This protocol, called GRMP-Q, provides an efficient heuristic solution that performs well in most cases---in special cases it is optimal. Under overload, the protocol gives a fair allocation of CPU resources to clients. Simulation results suggest that key performance metrics do not change with increasing system size, making the resource allocation process scalable to well above 100,000 servers. Generally, the effectiveness of the protocol in achieving its objective increases with increasing memory capacity in the servers.},
booktitle = {Proceedings of the 7th International Conference on Network and Services Management},
pages = {171–179},
numpages = {9},
keywords = {power management, server consolidation, resource allocation, gossip protocols, green computing, cloud computing, distributed management},
location = {Paris, France},
series = {CNSM '11}
}

@inproceedings{10.1145/3388333.3403035,
author = {Heinisch, Philip and Ostaszewski, Katharina and Ranocha, Hendrik},
title = {Towards Green Computing: A Survey of Performance and Energy Efficiency of Different Platforms Using OpenCL},
year = {2020},
isbn = {9781450375313},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3388333.3403035},
doi = {10.1145/3388333.3403035},
abstract = {When considering hardware platforms, not just time to solution can be of importance but also the energy necessary to reach it. This is not only the case with battery powered mobile devices but also with HPC cluster systems due to financial and practical limits on power consumption a nd cooling. With a variety of hardware options available, the question arises which combination of devices is best suited for a given problem. The answer depends not only on the runtime but also on the energy to solution and the price of the hardware. The energy required to reach a solution becomes increasingly important as battery powered systems have to handle computationally intensive tasks e.g. image processing or machine learning. Even for data centers or HPC facilities the energy cost over the lifetime of the systems can be higher than the acquisition cost. To showcase the differences and give a basic outlook on the applicability of different architectures, devices ranging from ARM systems to server CPUs and GPUs have been used with diverse benchmarking test cases taken from applied research applications.},
booktitle = {Proceedings of the International Workshop on OpenCL},
articleno = {30},
numpages = {2},
location = {Munich, Germany},
series = {IWOCL '20}
}

@inproceedings{10.1109/UCC.2014.79,
author = {Sequeira, Hugo and Carreira, Paulo and Goldschmidt, Thomas and Vorst, Philipp},
title = {Energy Cloud: Real-Time Cloud-Native Energy Management System to Monitor and Analyze Energy Consumption in Multiple Industrial Sites},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.79},
doi = {10.1109/UCC.2014.79},
abstract = {Industrial organizations use Energy Management Systems (EMS) to monitor, control, and optimize their energy consumption. Industrial EMS are complex and expensive systems due to the unique requirements of performance, reliability, and interoperability. Moreover, industry is facing challenges with current EMS implementations such as cross-site monitoring of energy consumption and CO2 emissions, integration between energy and production data, and meaningful energy efficiency benchmarking. Additionally, big data has emerged because of recent advances in field instrumentation that led to the generation of large quantities of machine data, with much more detail and higher sampling rates. This created a challenge for real-time analytics. In order to address all these needs and challenges, we propose a cloud-native industrial EMS solution with cloud computing capabilities. Through this innovative approach we expect to generate useful knowledge in a shorter time period, enabling organizations to react quicker to changes of events and detect hidden patterns that compromise efficiency.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {529–534},
numpages = {6},
keywords = {cloud computing, Energy efficiency, energy management systems, big data},
series = {UCC '14}
}

@inproceedings{10.1145/3140107.3140121,
author = {Sharma, Swati and Kaushal, Rishabh},
title = {Energy Conserving Secure VM Allocation in Untrusted Cloud Computing Environment},
year = {2017},
isbn = {9781450353236},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3140107.3140121},
doi = {10.1145/3140107.3140121},
abstract = {Cloud computing is the latest buzz in most of the IT organizations which are witnessing a a trend of migration from traditional computing to cloud computing, thereby reducing their infrastructure cost and improving efficiency and performance. Cloud computing provides services through virtualization layer, which helps to execute more than one operating systems and applications on a single machine. Being a crucial part of cloud computing, virtualization layer faces major security threats, most challenging being an insider threat wherein attacker can either compromise existing virtual machines (VMs) or create rogue VMs. The objective of this work is to propose virtual machine (VM) allocation algorithm which operates in an untrusted cloud computing environment with non-trustworthy VMs. Our approach is based on the notion of trust. Lack of trust is modeled by either introducing faults or monitoring SLAs per host on which VMs are hosted. Detailed experiments considering varying cloud infrastructure and varying workloads are conducted using CloudSim. Results show that proposed algorithm works well in untrusted environment while at the same time is energy efficient and reduces the computational costs by decreasing the number of migrations and SLA violations.},
booktitle = {Proceedings of the 10th Annual ACM India Compute Conference},
pages = {73–81},
numpages = {9},
keywords = {Green Computing, Cloud Computing, Security},
location = {Bhopal, India},
series = {Compute '17}
}

@inproceedings{10.1145/2801948.2801989,
author = {Panagiotou, Dimitra and Oikonomou, Efthymios and Rouskas, Angelos},
title = {Energy-Efficient Virtual Machine Provisioning Mechanism in Cloud Computing Environments},
year = {2015},
isbn = {9781450335515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2801948.2801989},
doi = {10.1145/2801948.2801989},
abstract = {As the increasing number of modern applications and enterprises demand more and more resources in computational power, memory and disk storage, cloud data centers are consuming huge amounts of electrical energy. The aim of cloud service providers is to reduce the operational costs by minimizing energy consumption while providing competitive services to their customers. The above, can be fulfilled by trying to reduce the number of active servers, using live VM migrations and keeping the system performance in the requested levels according to SLAs. In this paper, an efficient virtual machine allocation mechanism for cloud data center environments is proposed. We first describe the virtual machine allocation policy and then we perform a series of experiments based on CloudSim [1] 3.0.3 simulator. Experimental results have shown that the proposed scheme is very efficient in terms of energy consumption and QoS (decreased SLA violations) compared to LrMmt provisioning mechanism presented in [2].},
booktitle = {Proceedings of the 19th Panhellenic Conference on Informatics},
pages = {197–202},
numpages = {6},
keywords = {data centers, CloudSim, virtualization, quality of service, energy consumption, cloud computing, energy efficiency, VM migration, service level agreement, migration, data center, VM provisioning},
location = {Athens, Greece},
series = {PCI '15}
}

@inproceedings{10.5555/3375069.3375128,
author = {Dandres, Thomas and Farrahi Moghaddam, Reza and Nguyen, Kim Khoa and Lemieux, Yves and Samson, R\'{e}jean and Cheriet, Mohamed},
title = {The Green Sustainable Telco Cloud: Minimizing Greenhouse Gas Emissions of Server Load Migrations between Distributed Data Centres},
year = {2016},
isbn = {9783901882852},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {Among the innovative approaches to reduce the greenhouse gas (GHG) emissions of data centres during their use phase, electrical power from renewable sources appears promising. However, renewable electricity is often intermittent due to meteorological conditions. Consequently, the regional availability of renewable power varies constantly over time. This created the opportunity to deploy cloud computing systems relying on data centres located in different regions. Cloud computing technology enables real-time load migration to a data centre in the region where the GHG emissions per kWh are the lowest. While this approach is becoming popular to manage distributed data centres, there is still room for improvement in its implementation. Indeed, the consequences of data centre power demand migrations across electric networks and the resulting GHG emissions are usually neglected. In this project, we developed a novel GHG emission factor based on the sources of electricity affected by the server load migrations. Then, we used this emission factor in a simulation of distributed data centres to minimize their GHG emissions. Results show, the use of the novel emission factor enables an extra reduction of 23% of GHG emissions as compared to the usual approach.},
booktitle = {Proceedings of the 12th Conference on International Conference on Network and Service Management},
pages = {383–387},
numpages = {5},
keywords = {real-time electricity generation, Data centre network optimization, Green house gas emissions},
location = {Montreal, Quebec, Canada},
series = {CNSM 2016}
}

@inproceedings{10.1145/2479871.2479911,
author = {Chen, Feifei and Grundy, John and Yang, Yun and Schneider, Jean-Guy and He, Qiang},
title = {Experimental Analysis of Task-Based Energy Consumption in Cloud Computing Systems},
year = {2013},
isbn = {9781450316361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479871.2479911},
doi = {10.1145/2479871.2479911},
abstract = {Cloud computing delivers IT solutions as a utility to users. One consequence of this model is that large cloud data centres consume large amounts of energy and produce significant carbon footprints. A common objective of cloud providers is to develop resource provisioning and management solutions that minimise energy consumption while guaranteeing Service Level Agreements (SLAs). In order to achieve this objective, a thorough understanding of energy consumption patterns in complex cloud systems is imperative. We have developed an energy consumption model for cloud computing systems. To operationalise this model, we have conducted extensive experiments to profile the energy consumption in cloud computing systems based on three types of tasks: computation-intensive, data-intensive and communication-intensive tasks. We collected fine-grained energy consumption and performance data with varying system configurations and workloads. Our experimental results show the correlation coefficients of energy consumption, system configuration and workload, as well as system performance in cloud systems. These results can be used for designing energy consumption monitors, and static or dynamic system-level energy consumption optimisation strategies for green cloud computing systems.},
booktitle = {Proceedings of the 4th ACM/SPEC International Conference on Performance Engineering},
pages = {295–306},
numpages = {12},
keywords = {cloud computing, performance analysis, energy consumption, green cloud, energy efficiency},
location = {Prague, Czech Republic},
series = {ICPE '13}
}

@inproceedings{10.1145/3607947.3607970,
author = {Ajmera, Kashav and Tewari, Tribhuwan Kumar and Singh, Vivek Kumar and Vikash and Upadhyay, Pawan Kumar},
title = {Energy-Aware Dynamic Virtual Machine Scheduling in Cloud Computing: A Survey},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607947.3607970},
doi = {10.1145/3607947.3607970},
abstract = {Dynamic virtual machine scheduling is a crucial research area in cloud computing, to optimize resource utilization, reduce energy consumption, and ensuring performance and availability by dynamically managing and scheduling virtual machines (VMs) across servers. Effective dynamic VM scheduling can significantly impact the efficiency and sustainability of data centers by efficiently allocating resources based on workload demand. However, the dynamic nature of workload demand presents one of the primary challenges in dynamic VM scheduling. Sudden spikes or drops in server resource usage can lead to severe SLA violation concerns and energy inefficiency. To mitigate these challenges, scheduling algorithms need to balance the workload demand across servers while ensuring that servers are not overloaded or underloaded. In this work, we present a comprehensive comparison of state-of-the-art techniques for dynamic VM scheduling, evaluating their performance based on several key factors, including objective function, approach, the technique of VM scheduling, VM placement approach, VM selection approach, and server underload and overload detection techniques. Our comparison highlights the strengths and weaknesses of different approaches and provides insights into the design of efficient dynamic VM scheduling algorithms. The findings of this work can guide the development of novel techniques that address the challenges of dynamic VM scheduling and improve the efficiency and sustainability of data centers.},
booktitle = {Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
pages = {133–141},
numpages = {9},
keywords = {Green computing, Particle Swarm Optimization, Cloud computing, Virtualization, Cloud data center, Bin packing, Power consumption, Energy-efficient VM scheduling},
location = {Noida, India},
series = {IC3-2023}
}

@inproceedings{10.1145/3549206.3549225,
author = {Mishra, Manas Kumar and Panda, Sanjaya Kumar},
title = {A Cost-Variant Renewable Energy-Based Scheduling Algorithm for Cloud Computing},
year = {2022},
isbn = {9781450396752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549206.3549225},
doi = {10.1145/3549206.3549225},
abstract = {The global growth of cloud computing services is rising abruptly due to a large variety of services like computing, storage, network, etc. It expresses cloud service providers (CSPs) for better usage of existing datacenter resources, increasing agility, and reducing the need for unanticipated datacenter growth. These datacenters use a lot of energy generated from fossil fuels (i.e., non-renewable energy (NRE) sources) and omit a lot of nitrous oxide and carbon dioxide, which cause the greenhouse effect and are harmful to the environment. Moreover, NRE sources are limited in supply and cannot be sustained over a long period. As a circumstance, CSPs are moving towards renewable energy (RE) sources, such as solar, wind, hydro, and biomass, to decarbonize datacenters even though these resources are not available round the clock. Therefore, recent studies focus on using both RE and NRE sources to avoid any interruption of the datacenter services. However, these studies consider the equal cost for all the RE sources and do not consider the categorization among user requests (URs). This paper considers the different costs for RE sources and two categories of URs, namely critical and non-critical, and introduces a cost-variant RE-based scheduling (CRES) algorithm for cloud computing. Here, the critical UR does not depend on the RE resources due to the unpredictability of RE sources. On the other hand, the non-critical UR can be accommodated by both RE and NRE resources. We simulate the proposed algorithm by considering 20 to 100 URs and 5 to 25 datacenters and compare the performance with the future-aware best fit (FABEF) and highest available renewable first (HAREF) algorithms in terms of cost and usage count of RE resources to show its usefulness.},
booktitle = {Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing},
pages = {91–97},
numpages = {7},
keywords = {renewable energy, scheduling algorithm, non-renewable energy, datacenter, cloud service provider, Cloud computing},
location = {Noida, India},
series = {IC3-2022}
}

@inproceedings{10.1145/2480347.2480349,
author = {Szymanski, Ted H.},
title = {Low Latency Energy Efficient Communications in Global-Scale Cloud Computing Systems},
year = {2013},
isbn = {9781450319805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480347.2480349},
doi = {10.1145/2480347.2480349},
abstract = {This paper explores technologies to achieve low-latency energy-efficient communications in Global-Scale Cloud Computing systems. A global-scale cloud computing system linking 100 remote data-centers can interconnect potentially 5M servers, considerably larger than the size of traditional High-Performance-Computing (HPC) machines. Traditional HPC machines use tightly coupled processors and networks which rarely drop packets. In contrast, today's IP Internet is a relatively loosely-coupled Best-Effort network with poor latency and energy-efficiency guarantees, with relatively high packet loss rates. This paper explores the use of a recently-proposed Future-Internet network, which uses a QoS-aware router scheduling algorithm combined with a new IETF resource reservation signalling technology, to achieve improved latency and energy-efficiency in cloud computing systems. A Maximum-Flow Minimum-Energy routing algorithm is used to route high-capacity "trunks" between data-centers distributed over the continental USA, using a USA IP network topology. The communications between virtual machines in remote data-centers are aggregated and multiplexed onto the trunks, to achieve significantly improved energy-efficiency. According to theory and simulations, the large and variable queueing delays of traditional Best-Effort Internet links can be eliminated, and the latency over the cloud can be reduced to near-minimal values, i.e., the fiber latency. The maximum fiber latencies over the Sprint USA network are approx. 20 milliseconds, comparable to hard disk drive latencies, and multithreading in virtual machines can be used to hide these latencies. Furthermore, if existing dark-fiber over the continental network is activated, the bisection bandwidth available in a global-scale cloud computing system can rival that achievable in commercial HPC machines.},
booktitle = {Proceedings of the 2013 Workshop on Energy Efficient High Performance Parallel and Distributed Computing},
pages = {13–22},
numpages = {10},
keywords = {quality of service, cloud computing, minimum energy, internet, energy efficiency, data centers, routing, maximum flow, global scale, minimum latency, minimum cost},
location = {New York, New York, USA},
series = {EEHPDC '13}
}

@inproceedings{10.5555/2663779.2663787,
author = {Chen, FeiFei and Schneider, Jean-Guy and Yang, Yun and Grundy, John and He, Qiang},
title = {An Energy Consumption Model and Analysis Tool for Cloud Computing Environments},
year = {2012},
isbn = {9781467318327},
publisher = {IEEE Press},
abstract = {Cloud computing delivers computing as a utility to users worldwide. A consequence of this model is that cloud data centres have high deployment and operational costs, as well as significant carbon footprints for the environment. We need to develop Green Cloud Computing (GCC) solutions that reduce these deployment and operational costs and thus save energy and reduce adverse environmental impacts. In order to achieve this objective, a thorough understanding of the energy consumption patterns in complex Cloud environments is needed. We present a new energy consumption model and associated analysis tool for Cloud computing environments. We measure energy consumption in Cloud environments based on different runtime tasks. Empirical analysis of the correlation of energy consumption and Cloud data and computational tasks, as well as system performance, will be investigated based on our energy consumption model and analysis tool. Our research results can be integrated into Cloud systems to monitor energy consumption and support static or dynamic system-level optimisation.},
booktitle = {Proceedings of the First International Workshop on Green and Sustainable Software},
pages = {45–50},
numpages = {6},
keywords = {energy consumption, performance analysis, cloud computing, green computing},
location = {Zurich, Switzerland},
series = {GREENS '12}
}

@inproceedings{10.1145/3147213.3147218,
author = {Sharma, Yogesh and Javadi, Bahman and Si, Weisheng and Sun, Daniel},
title = {Reliable and Energy Efficient Resource Provisioning and Allocation in Cloud Computing},
year = {2017},
isbn = {9781450351492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147213.3147218},
doi = {10.1145/3147213.3147218},
abstract = {Reliability and Energy-efficiency is one of the biggest trade-off challenges confronting cloud service providers. This paper provides a mathematical model of both reliability and energy consumption in cloud computing systems and analyses their interplay. This paper also proposes a formal method to calculate the finishing time of tasks running in a failure prone cloud computing environment using checkpointing and without checkpointing. To achieve the objective of maximizing the reliability and minimizing the energy-consumption of cloud computing systems, three resource provisioning and virtual machine (VM) allocation policies using the aforementioned mathematical models are proposed. These three policies are named Reliability Aware Best Fit Decreasing (RABFD), Energy Aware Best Fit Decreasing (EABFD), Reliability-Energy Aware Best Fit Decreasing (REABFD). A simulation based evaluation of the proposed policies has been done by using real failure traces and workload models. The results of our experiments demonstrated that by considering both reliability and energy factors during resource provisioning and VM allocation, the reliability and energy consumption of the system can be improved by 23% and 61%, respectively.},
booktitle = {Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {57–66},
numpages = {10},
keywords = {bag of tasks, virtual machines, resource provisioning, reliability, failures, energy consumption, cloud computing, checkpointing},
location = {Austin, Texas, USA},
series = {UCC '17}
}

@inproceedings{10.1145/3021460.3021464,
author = {Marimuthu, C. and Chandrasekaran, K.},
title = {Software Engineering Aspects of Green and Sustainable Software: A Systematic Mapping Study},
year = {2017},
isbn = {9781450348560},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3021460.3021464},
doi = {10.1145/3021460.3021464},
abstract = {Green and sustainable software engineering is an emerging research field which aims at creating, using, and disposing the energy-efficient software in an environment friendly manner with less negative impacts. The research community strongly believes that the energy efficiency and sustainability of the software can be improved by modifying the existing software engineering methods. This systematic mapping study identifies and map such methods for green and sustainable software development. Especially, this study identifies the research types, research goals, software engineering research topics, accepted validation methods and publication fora that are used in the field of green and sustainable software engineering. This study was conducted with 7 research questions and analyzed 82 relevant studies. We have used snowballing reading to find out the relevant studies that were published from 2010 to May, 2016. One of the important finding of this study is, there are less number of contributions on software design and construction. In future, sufficient research works and tools support must be provided to make this research field more matured. The main contribution of this study is to summarize the body of knowledge in the field of green and sustainable software engineering and provides a platform to conduct future research.},
booktitle = {Proceedings of the 10th Innovations in Software Engineering Conference},
pages = {34–44},
numpages = {11},
keywords = {systematic mapping study, green and sustainable software engineering, green software},
location = {Jaipur, India},
series = {ISEC '17}
}

@inproceedings{10.1145/3167918.3167952,
author = {Alsadie, Deafallah and Tari, Zahir and Alzahrani, Eidah J. and Zomaya, Albert Y.},
title = {Dynamic Resource Allocation for an Energy Efficient VM Architecture for Cloud Computing},
year = {2018},
isbn = {9781450354363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167918.3167952},
doi = {10.1145/3167918.3167952},
abstract = {Minimizing power consumption is a vital consideration in the modern-day development of cloud computing. One of the major challenges reported in cloud computing is the consumption of power by computing resources due to improper allocation of resources over improperly sized virtual machines (VM). In spite of many efforts, the existing solutions are only able to meet the requirement for minimizing power consumption to a limited extent, due to their lack of optimized allocation of computing resources. The primary aim of the proposed work is to make effective use of the computing resources of the cloud for minimizing power consumption. It employs the concept of mapping appropriately sized VMs to a group of tasks in a data center, in order to reduce its power consumption. It involves the clustering of tasks on the basis of their computing requirements and finding a suitably sized VM with the required computing resources. The efficient use of computing resources on the basis of their actual requirements for a group of tasks helps to save a substantial amount of power. The proposed work is evaluated for its superiority over representational techniques using Google cloud traces as benchmark dataset. The experimental results showed an improvement of 8.42% in power consumption compared to representational techniques using fixed-sized VMs in the field. The proposed approach also achieves an improvement of 62% in the number of instances of VMs created for hosting the task workload, while maintaining a low task rejection rate.},
booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
articleno = {16},
numpages = {8},
keywords = {scheduling, cloud computing, task clustering, energy-saving, virtualization},
location = {Brisband, Queensland, Australia},
series = {ACSW '18}
}

@inproceedings{10.1145/2405136.2405141,
author = {Mukherjee, Tridib and Dasgupta, Koustuv and Gujar, Sujit and Jung, Gueyoung and Lee, Haengju},
title = {An Economic Model for Green Cloud},
year = {2012},
isbn = {9781450316088},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2405136.2405141},
doi = {10.1145/2405136.2405141},
abstract = {A novel economic model for cloud-based services is presented that: (i) transparently presents energy demands (of services) to the customers in a simple abstract form, called green point, which is understandable to any general user; (ii) provides economic incentives (through dynamic discounts) as motivations for customers to select greener configuration; and (iii) offers service prices to customers such that the profit of cloud vendor is maximized while providing the discounts. Price is differentiated for different classes of customers (e.g. gold, silver, and bronze) and dynamic based on posterior distribution on resource demand considering both current demand and willingness toward green configuration. The model enables a paradigm shift in cloud service offering that provides higher transparency and control knobs to users for greener configuration. Preliminary results indicate higher profit using the proposed model compared to static pricing in existing pay-per-use service offerings.},
booktitle = {Proceedings of the 10th International Workshop on Middleware for Grids, Clouds and e-Science},
articleno = {5},
numpages = {6},
keywords = {economic model, cloud computing, green computing},
location = {Montreal, Quebec, Canada},
series = {MGC '12}
}

@article{10.1145/2656204,
author = {Mastelic, Toni and Oleksiak, Ariel and Claussen, Holger and Brandic, Ivona and Pierson, Jean-Marc and Vasilakos, Athanasios V.},
title = {Cloud Computing: Survey on Energy Efficiency},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2656204},
doi = {10.1145/2656204},
abstract = {Cloud computing is today’s most emphasized Information and Communications Technology (ICT) paradigm that is directly or indirectly used by almost every online user. However, such great significance comes with the support of a great infrastructure that includes large data centers comprising thousands of server units and other supporting equipment. Their share in power consumption generates between 1.1% and 1.5% of the total electricity use worldwide and is projected to rise even more. Such alarming numbers demand rethinking the energy efficiency of such infrastructures. However, before making any changes to infrastructure, an analysis of the current status is required. In this article, we perform a comprehensive analysis of an infrastructure supporting the cloud computing paradigm with regards to energy efficiency. First, we define a systematic approach for analyzing the energy efficiency of most important data center domains, including server and network equipment, as well as cloud management systems and appliances consisting of a software utilized by end users. Second, we utilize this approach for analyzing available scientific and industrial literature on state-of-the-art practices in data centers and their equipment. Finally, we extract existing challenges and highlight future research directions.},
journal = {ACM Comput. Surv.},
month = {dec},
articleno = {33},
numpages = {36},
keywords = {data center, appliances, servers, cloud management system, energy efficiency, Cloud computing, network}
}

@inproceedings{10.1145/3060403.3066859,
author = {Jones, Alex K.},
title = {Green Computing: New Challenges and Opportunities},
year = {2017},
isbn = {9781450349727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3060403.3066859},
doi = {10.1145/3060403.3066859},
abstract = {As individuals and researchers approach the challenge of green computing it is natural to consider the energy consumption of computational devices and their supporting systems during their use phase (i.e., after they are deployed into service). This includes reducing energy consumption in processors, memory systems, peripheral devices, cooling systems and a host of other components that are used in deployed systems. However, for computing to be truly green, all phases of the system life-cycle, from manufacturing to disposal, must be considered. In particular there is limited awareness to the considerable fraction of the total life-cycle environmental impacts of computing systems that result from the fabrication of the integrated circuits (ICs) that are used in those devices. Studies have shown that the energy and environmental costs of IC fabrication can actually significantly outpace use-phase sustainability metrics and environmental impacts. With trends towards more exotic, thus, more environmentally unfriendly, fabrication approaches at deeply scaled nodes, life-cycle thinking for next generation computing systems that includes traditional optimization of operational energy-efficiency as well as minimizing impacts from IC fabrication is critical. In this talk I will present a new cadre of tools and methodologies to holistically evaluate energy consumption and other environmental impacts from computing. Based on these tools, I will discuss new interdisciplinary research directions and educational opportunities that emerge towards achieving more sustainable computing.},
booktitle = {Proceedings of the on Great Lakes Symposium on VLSI 2017},
pages = {3},
numpages = {1},
keywords = {dark silicon, life cycle assessment (lca), sustainability, embodied energy, indifference analysis, reliability, technology scaling, emerging memory, approximate computing},
location = {Banff, Alberta, Canada},
series = {GLSVLSI '17}
}

@inproceedings{10.1145/3443467.3443915,
author = {Wang, Yanwei and Kan, Hongwei and Su, Dongdong and Shen, Yanmei and Liu, Wei and Ou, Mingyang},
title = {Energy Efficient Computing Offloading Mechanism Based on FPGA Cluster for Edge Cloud},
year = {2021},
isbn = {9781450387811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3443467.3443915},
doi = {10.1145/3443467.3443915},
abstract = {Towards the computing overload problem in cloud data center, we propose a computing offloading mechanism based on FPGA clusters for edge cloud. Firstly, the FPGA cluster we proposed is decoupled from traditional server, and FPGA BOX is used to power batch FPGA accelerators. The network-based FPGA cluster is deployed at the edge to undertake the computing tasks of the data center. On this basis, we propose an edge cloud network model based on FPGA clusters, and study the energy consumption minimization problem. Secondly, considering the diversity of computing tasks, the MapReduce algorithm based on the numbering mechanism proposed in this paper realizes the classification of computing tasks, and converts the energy consumption minimization problem into the energy consumption minimization problem when the user's computing tasks are determined. Based on the classification results, our improved Hungary algorithm can obtain the minimum energy consumption. Meantime, the computing task results can feedback to corresponding user according to the user information in classification results. Finally, numerical calculation results show that the computing offloading mechanism proposed in this paper shows good performance in terms of energy consumption.},
booktitle = {Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1120–1125},
numpages = {6},
keywords = {Computing offloading, edge cloud, energy consumption, numbering mechanism, Hungary algorithm, FPGA},
location = {Xiamen, China},
series = {EITCE '20}
}

@inproceedings{10.1145/3291064.3291069,
author = {Liu, Jiamin and Chang, Yan and Wei, Dong and Wang, Dapeng and Zhang, Tieyan},
title = {An Information Monitoring Platform for Thermal Energy Storage Systems Using Cloud Computing},
year = {2018},
isbn = {9781450365765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3291064.3291069},
doi = {10.1145/3291064.3291069},
abstract = {Energy storage plays a key element to use new energy to replace traditional coal and petrochemical energy, and it plays an important role of shifting energy utilization ways. Nowadays energy internet is a way of renewable and sharing energy. A cloud platform for monitoring energy information of thermal storage systems is developed by using cloud computing, IoT and energy storage technologies. This platform allows a user to monitor the running conditions of regional thermal energy systems in real-time from anywhere as the condition data are synchronized to the client-side website, and data are stored into a data storage server. To quickly locate any thermal energy storage system, the geographical locations of the systems built anywhere are marked on the map of the web page. The condition data of all systems can be collected and communicated between the control unit installed in the heat system and the servers on cloud. The gathered data can be worked out for further allocating energy consumption. This platform has been launched after successfully tested on a number of practical thermal energy storage systems at different regions. This will provide a guarantee for further intelligent analysis and optimization of energy deployment.},
booktitle = {Proceedings of the 2018 International Conference on Cloud Computing and Internet of Things},
pages = {19–24},
numpages = {6},
keywords = {Monitoring, Energy internet, Cloud computing, Thermal energy storage},
location = {Singapore, Singapore},
series = {CCIOT '18}
}

@article{10.1145/1716383.1730791,
author = {Brown, David J. and Reams, Charles},
title = {Toward Energy-Efficient Computing: What Will It Take to Make Server-Side Computing More Energy Efficient?},
year = {2010},
issue_date = {February 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/1716383.1730791},
doi = {10.1145/1716383.1730791},
abstract = {By now, most everyone is aware of the energy problem at its highest level: our primary sources of energy are running out, while the demand for energy in both commercial and domestic environments is increasing, and the side effects of energy use have important global environmental considerations. The emission of greenhouse gases such as CO, now seen by most climatologists to be linked to global warming, is only one issue.},
journal = {Queue},
month = {feb},
pages = {30–43},
numpages = {14}
}

@inproceedings{10.1145/3350768.3350770,
author = {Karita, Leila and Mour\~{a}o, Brunna C. and Machado, Ivan},
title = {Software Industry Awareness on Green and Sustainable Software Engineering: A State-of-the-Practice Survey},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350770},
doi = {10.1145/3350768.3350770},
abstract = {Sustainable computing is a rapidly growing research area spanning several areas of computer science. In the software engineering field, the topic has received increasing attention in recent years, with several studies addressing a range of concerns. However, few studies have demonstrated the awareness of software practitioners about the underlying concepts of sustainability in the software development practice. In this effect, in this study, we aim to provide some evidence about the practitioners' perception about the adoption of sustainability in software development, under four main perspectives: economic, social, environmental and technical. To accomplish such a goal, we carried out a survey study with twenty-five software engineers involved in projects in different domains. The yielded results indicate an overall lack of knowledge about the topic, in particular regarding the concepts about sustainable software, although it is a common understanding that sustainability should be treated as a quality attribute and should support the interaction between sustainability and the software development life cycle phases. Among the observed perspectives, the respondents indicate that the technical dimension is the most relevant and explored so far. This study contributes to the field with initial evidence and can be seen as a first step towards establishing a common understanding about how the software industry is receptive to the use of sustainability concepts in software development practices.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {501–510},
numpages = {10},
keywords = {Survey, Empirical Study, Sustainable Software Engineering},
location = {Salvador, Brazil},
series = {SBES '19}
}

@inproceedings{10.1145/1741906.1741959,
author = {Gupta, S.},
title = {Computing with Green Responsibility},
year = {2010},
isbn = {9781605588124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1741906.1741959},
doi = {10.1145/1741906.1741959},
abstract = {The paper explains Green computing as a concept and tries to bring out an understandable concept of green computing, reasons and advantages of going green for a responsible and ecologically sustainable use of IT infrastructure.},
booktitle = {Proceedings of the International Conference and Workshop on Emerging Trends in Technology},
pages = {234–236},
numpages = {3},
keywords = {green computing, recycle, environmental change, power, efficiency},
location = {Mumbai, Maharashtra, India},
series = {ICWET '10}
}

@article{10.5555/2038772.2038782,
author = {Schaeffer, Donna and Raghavan, Srinivasan and Camerlinck, Tom and McKenzie, Walter},
title = {Going Green with Computing},
year = {2012},
issue_date = {January 2012},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {27},
number = {3},
issn = {1937-4771},
abstract = {It is imperative that we foster an environmental awareness and concern for the use of natural resources in today's students, since they are the decision-makers of the future. Green computing is a timely topic as it incorporates the triple bottom line including social responsibility, economic viability and environmental impact. Panelists will address sustainability, energy efficiency, recycling, efficient coding and the use of algorithms that minimize needed computing power.},
journal = {J. Comput. Sci. Coll.},
month = {jan},
pages = {30},
numpages = {1}
}

@inproceedings{10.1145/2556871.2556905,
author = {Han, Ke and Cai, Xiaobo},
title = {Speed-Scaling-Based Job/Tasks Deployment for Energy-Efficient Datacenters in Cloud Computing},
year = {2013},
isbn = {9781450321198},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556871.2556905},
doi = {10.1145/2556871.2556905},
abstract = {Power management is one of the most challenging problems in cloud computing. A cloud data center could save the amount of energy used from speed scaling. The traditional theoretical research for speed scaling usually assume the power function as the form Sα. Moreover, more comprehensive support for Quality of Service (QoS) is essential by cloud computing providers. Thus, how to dealing with the power/performance trade-off is a burning question. Motivated by improving energy efficiency of the data center, we study policies by setting the speed of the processor for both goals of minimizing the total energy cost and meeting the specified QoS performance well. We initiate a model of speed scaling with weighted power energy, the QoS parameters can be induced to a qualitative concept as the weighting factor of energy consumptions. Based on this model, we propose a resource allocation policy based on the cooperative game theory for energy-efficient management of clouds. The simulation results show the efficiency of the method.},
booktitle = {Proceedings of the Second International Conference on Innovative Computing and Cloud Computing},
pages = {154–157},
numpages = {4},
keywords = {QoS, Speed scaling, Cloud computing, Energy efficiency, Job/tasks deployment},
location = {Wuhan, China},
series = {ICCC '13}
}

@inproceedings{10.1145/2664591.2664609,
author = {du Buisson, Werner and Naidoo, Rennie},
title = {Exploring Factors Influencing IT Workers' Green Computing Intention at a South African Firm},
year = {2014},
isbn = {9781450332460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2664591.2664609},
doi = {10.1145/2664591.2664609},
abstract = {Given the widespread use of computer technologies and mounting concerns over its impact on climate change, energy consumption and environmental degradation, one would imagine that IT workers would be practicing and advocating green computing behaviors. Employing the Theory of Planned Behaviour (TPB), this study therefore set out to examine the influence of factors such as attitude, social influence, media influence, perceived behavioral control and environmental concern on the IT worker's green computing intention. The research model was tested using survey data collected from 149 respondents within a large financial services firm in Gauteng. Descriptive statistics suggest that personal awareness, knowledge and actual green computing behaviors are low. Regression analysis indicates that environmental concern, perceived behavioral control, attitude, and media influence are important predictors while social influence plays almost no role -- suggesting that IT workers are under no social pressure to practice green computing. The paper recommends that responsible peers, firms, higher education institutions, and media focus their attention on driving environmental awareness in order to promote green computing behaviors among seemingly unaware and disempowered IT workers.},
booktitle = {Proceedings of the Southern African Institute for Computer Scientist and Information Technologists Annual Conference 2014 on SAICSIT 2014 Empowered by Technology},
pages = {148–156},
numpages = {9},
keywords = {Social influence, Environmental Concern, Theory of Planned Behaviour, Green Computing Intentions, IT Workers, Attitude},
location = {Centurion, South Africa},
series = {SAICSIT '14}
}

@inproceedings{10.1145/2791405.2791527,
author = {Pawar, Apurva and Jagtap, Vandana and Bhamare, Mamta},
title = {Time and Energy Saving through Computation Offloading with Bandwidth Consideration for Mobile Cloud Computing},
year = {2015},
isbn = {9781450333610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791405.2791527},
doi = {10.1145/2791405.2791527},
abstract = {Smartphone applications are gaining popularity and with time many complex and computation/resource intensive applications are coming to market. These applications require more resources and consume lot of battery power, but the improvisation in battery capacity has been lagged far behind as compared to other components of mobile devices. On other hand, clouds are rich in resources and computational power. Therefore, by utilizing cloud resources for application execution we can reduce battery consumption and in turn increases battery charging intervals. This all is known as cyber foreign or computation offloading in Moble Cloud Computing. There are various factors affecting computation offloading like bandwidth. So, we had considered bandwidth as major factor in proposed offloading decision making algorithm. Our algorithm is based on divide and conquer strategy. This system focuses on time and energy saving.},
booktitle = {Proceedings of the Third International Symposium on Women in Computing and Informatics},
pages = {527–532},
numpages = {6},
keywords = {Mobile Cloud Computing, partitioning, cyber foreign, elastic applications, computation offloading, smartphone},
location = {Kochi, India},
series = {WCI '15}
}

@inproceedings{10.5555/2819009.2819240,
author = {Morisio, Maurizio and Meyer, Niklaus and M\"{u}ller, Hausi A. and Lago, Patricia and Scanniello, Giuseppe},
title = {4th International Workshop on Green and Sustainable Software (GREENS 2015)},
year = {2015},
publisher = {IEEE Press},
abstract = {Engineering green software-intensive systems is critical in our drive towards a sustainable, smarter planet. The goal of green software engineering is to apply green principles to the design and operation of software-intensive systems. Green and self-greening software systems have tremendous potential to decrease energy consumption. Moreover, enterprise software can and should be re-thought to address sustainability issues using innovative business models, processes, and incentives. Monitoring and measuring the greenness of software is critical towards the notion of sustainable and green software. Demonstrating improvement is paramount for users to achieve and affect change. Thus, the theme of GREENS 2015 is Towards a Green Software Body of Knowledge. The GREENS workshop series brings together researchers and practitioners to discuss both the state-of-the-art and state-of-the-practice in green software, including novel ideas, research challenges, methods, experiences, and tools to support the engineering of sustainable and energy efficient software systems.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {981–982},
numpages = {2},
keywords = {green IT, green design, green adaptation, key green indicators (KGIs), green monitoring, sustainability, green scheduling, self-greening, green computing, energy efficiency, smart green sensors and actuators, green software engineering},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/2486788.2487065,
author = {Lago, Patricia and Meyer, Niklaus and Morisio, Maurizio and M\"{u}ller, Hausi A. and Scanniello, Giuseppe},
title = {2nd International Workshop on Green and Sustainable Software (GREENS 2013)},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {Software can become greener by being more energy efficient, hence using less resources; or by making its supported processes more sustainable, hence decreasing the environmental impact of governments, companies and individuals using software applications and services. While research results exist in measuring and controlling the level of greenness of hardware components, major research is needed to relate energy consumption of hardware to energy consumption of its executing software. Measuring the level of greenness of software and reporting it back to the users is the focus of GREENS 2013 with special theme Leveraging Energy Efficiency to Software Users. GREENS brings together software engineering researchers and practitioners to discuss the state-of-the-art and state-of-the-practice in green software, as well as research challenges, novel ideas, methods, experiences, and tools to support the engineering of sustainable and energy efficient software systems.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {1523–1524},
numpages = {2},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/3253593,
author = {Tantar, Alexandru-Adrian and Tantar, Emilia and Bosman, Peter},
title = {Session Details: Green and Efficient Energy Applications of Genetic and Evolutionary Computation Workshop},
year = {2013},
isbn = {9781450319645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253593},
doi = {10.1145/3253593},
booktitle = {Proceedings of the 15th Annual Conference Companion on Genetic and Evolutionary Computation},
location = {Amsterdam, The Netherlands},
series = {GECCO '13 Companion}
}

@inproceedings{10.1145/2333660.2333724,
author = {Ge, Yang and Zhang, Yukan and Qiu, Qinru and Lu, Yung-Hsiang},
title = {A Game Theoretic Resource Allocation for Overall Energy Minimization in Mobile Cloud Computing System},
year = {2012},
isbn = {9781450312493},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2333660.2333724},
doi = {10.1145/2333660.2333724},
abstract = {Cloud computing and virtualization techniques provide mobile devices with battery energy saving opportunities by allowing them to offload computation and execute code remotely. When the cloud infrastructure consists of heterogeneous servers, the mapping between mobile devices and servers plays an important role in determining the energy dissipation on both sides. From an environmental impact perspective, any energy dissipation related to computation should be counted. To achieve energy sustainability, it is important reducing the overall energy consumption of the mobile systems and the cloud infrastructure. Furthermore, reducing cloud energy consumption can potentially reduce the cost of mobile cloud users because the pricing model of cloud services is pay-by-usage. In this paper, we propose a game-theoretic approach to optimize the overall energy in a mobile cloud computing system. We formulate the energy minimization problem as a congestion game, where each mobile device is a player and his strategy is to select one of the servers to offload the computation while minimizing the overall energy consumption. We prove that the Nash equilibrium always exists in this game and propose an efficient algorithm that could achieve the Nash equilibrium in polynomial time. Experimental results show that our approach is able to reduce the total energy of mobile devices and servers compared to a random approach and an approach which only tries to reduce mobile devices alone.},
booktitle = {Proceedings of the 2012 ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {279–284},
numpages = {6},
keywords = {mobile cloud computing, congestion game, power management, virtualization, game theory},
location = {Redondo Beach, California, USA},
series = {ISLPED '12}
}

@inproceedings{10.5555/2616606.2616721,
author = {Gao, Yue and Gupta, Sandeep K. and Wang, Yanzhi and Pedram, Massoud},
title = {An Energy-Aware Fault Tolerant Scheduling Framework for Soft Error Resilient Cloud Computing Systems},
year = {2014},
isbn = {9783981537024},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {For modern high performance systems, aggressive technology and voltage scaling has drastically increased their susceptibility to soft errors. At the grand scale of cloud computing, it is clear that soft error induced failures will occur far more frequently, but it is unclear as to how to effectively apply current error detection and fault tolerance techniques in scale. In this paper, we focus on energy-aware fault tolerant scheduling in public, multi-user cloud systems, and explore the three-way tradeoff between reliability (in terms of soft error resiliency), performance and energy. Through a systematically optimized resource allocation, error detection approach selection, virtual machine placement, spatial/temporal redundancy augmentation and task scheduling process, the cloud service provider can achieve high error coverage and fault tolerance confidence while minimizing global energy costs under user deadline constraints. Our scheduling algorithm includes a static scheduling phase that operates on task graph based workload inputs prior to execution, and a light-weight dynamic scheduler that migrates tasks during execution in case of excessive re-executions. All schedules are evaluated on a runtime simulation engine that (1) mimics the performance fluctuations in cloud systems, and (2) supports the injection of arbitrary fault patterns. Compared to current virtual machine or task replication techniques, we are able to reduce overall application failure rates by over 50% with approximately 76% total energy overhead.},
booktitle = {Proceedings of the Conference on Design, Automation &amp; Test in Europe},
articleno = {94},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '14}
}

@inproceedings{10.1145/3600061.3603131,
author = {Jiang, Feng and Cheng, Yongyang and Qin, Boqin and Zhang, Tao},
title = {MRP: An Energy Efficient Network Protocol That Avoids Multiple Encryption in Cloud Computing Environment},
year = {2023},
isbn = {9798400707827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600061.3603131},
doi = {10.1145/3600061.3603131},
abstract = {To ensure the security of data transmission on the Internet, users usually encrypt the data during the process of sending and receiving data. For example, the commonly used HTTPS protocol verifies the identity of servers through TLS certificates and encrypts communication between browsers and servers. However, the encrypted part of the unstructured data is still re-encrypted by TLS during HTTPS transmission, wasting computing and energy resources. In this paper, we propose an energy efficient network protocol, namely MRP, that avoids multiple encryption. MRP could carry multiple types of application layer protocols, while freely configure the location and encryption approaches of the data that needs to be encrypted. Based on our proposed, users could freely segment application layer data, achieve on-demand encryption of data, reduce encryption costs without compromising user security requirements, avoid redundant double encryption and save energy.},
booktitle = {Proceedings of the 7th Asia-Pacific Workshop on Networking},
pages = {194–195},
numpages = {2},
keywords = {MRP protocol, cloud computing, resource management},
location = {Hong Kong, China},
series = {APNET '23}
}

@inproceedings{10.1145/3250290,
author = {Bosman, Peter A.N. and Tantar, Alexandru-Adrian and Tantar, Emilia},
title = {Session Details: Workshop: Green and Efficient Energy Applications of Genetic and Evolutionary Computation},
year = {2014},
isbn = {9781450328814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3250290},
doi = {10.1145/3250290},
abstract = {We would like to express our great pleasure in welcoming you to the GECCO Workshop on Green and Efficient Energy Applications of Genetic and Evolutionary Computation (GreenGEC Workshop'14), held in conjunction with the GECCO 2014 International Conference.A main characteristic of the studies in the area of green and energy-efficient applications is the strong connection with real-world environments and constraints. As such, there is only little place for errors and leading edge algorithms alone can be used. The potential impact and outcomes are also of foremost importance. Global increases in living standards, diminishing natural resources and environmental concerns place energy amongst the most important global issues today. On the consumer side, there is an increasing need for more efficient, smart, uses of energy, be it in large-scale computing systems and data warehouses, in homes or in office buildings. On the producer side, there is a push toward the use of sustainable, green, energy sources, which often come in the form of less reliable sources such as wind energy. In addition, future energy systems are often envisioned to be "smart", consisting of massive amounts of small generators, such as solar panels, located at consumers, effectively turning consumers into potential producers whenever they have a surplus of energy. The management, control and planning of, and efficient use of energy in (future) energy systems brings about many important challenges.Energy systems are not only real-world systems, they are also one of the most important foundations of the modern world. Especially with the upcoming required changes to make more efficient use of energy and to shift towards a global use of sustainable, green energy sources, there are many challenges in mathematics and computer science. Real-world challenges, such as those arising in (future) energy systems, are typically highly complex because of the many aspects to be considered that are often disregarded in theoretical research such as dynamic changes, uncertainty and multiple objectives. In many situations therefore, problem-specific algorithms are infeasible or impractical. Instead, flexible and powerful approaches such as evolutionary algorithms (EAs) can often provide viable solutions. Typical real-world challenges that are addressed by EAs are of the optimization type. This covers the use of EAs to optimize issues ranging from energy consumption (e.g. scheduling, memory/storage management, communication protocols, smart sensors, etc.) to the planning and design of energy systems at many levels, ranging from small printed circuit boards to entire transmission networks.},
booktitle = {Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation},
location = {Vancouver, BC, Canada},
series = {GECCO Comp '14}
}

@inproceedings{10.1145/3245063,
author = {Tantar, Alexandru-Adrian and Tantar, Emilia and Bouvry, Pascal and Bosman, Peter A.N. and Dorronsoro, Bernab\'{e} and Danoy, Gr\'{e}goire and Khan, Samee U.},
title = {Session Details: Green and Efficient Energy Applications of Genetic and Evolutionary Computation (GreenGEC)},
year = {2012},
isbn = {9781450311786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3245063},
doi = {10.1145/3245063},
abstract = {Energy systems are not only real-world systems; they are also one of the most important foundations of the modern world. Especially with the upcoming required changes to make more efficient use of energy and to shift towards a global use of sustainable, green energy sources, there are many challenges in mathematics and computer science. Thus, with the current increase in living standards, diminishing natural resources and environmental concerns, the management of energy production and use became one of the most important global issues today.First, on the consumer side, there is an increasing need for more efficient, smart uses of energy, be it in large-scale computing systems and data warehouses, in homes or in office buildings. Second, on the producer side, there is a push toward the use of sustainable, green, energy sources, which are often less reliable, e.g. wind energy. In addition, future energy systems are often envisioned to be "smart", consisting of massive amounts of small generators, such as solar panels, located at consumers, effectively turning consumers into potential producers whenever they have a surplus of energy. The management, control and planning of, and efficient use of energy in (future) energy systems brings about as many important questions. Real-world challenges, such as those arising in (future) energy systems, are typically highly complex because of the many aspects to be considered that are often disregarded in theoretical research such as dynamic changes, uncertainty and multiple objectives. In many situations therefore, problem-specific algorithms are infeasible or impractical. Instead, flexible and powerful approaches such as evolutionary algorithms (EAs) can often provide viable solutions. Typical real-world challenges that are addressed by EAs are of the optimization type. This covers the use of EAs to optimize issues ranging from energy consumption (e.g. scheduling, memory/storage management, communication protocols, smart sensors, etc.) to the planning and design of energy systems at many levels, ranging from small printed circuit boards to entire transmission networks.The aim of this workshop is therefore to bring together researchers interested in addressing challenging issues related to the use of evolutionary computation for applications in (future) energy systems. The workshop is a follow up of the GreenIT Evolutionary Computation workshop held at GECCO 2011.},
booktitle = {Proceedings of the 14th Annual Conference Companion on Genetic and Evolutionary Computation},
location = {Philadelphia, Pennsylvania, USA},
series = {GECCO '12}
}

@inproceedings{10.1145/2380552.2380575,
author = {Lincke, Susan J.},
title = {Green IT: Serving Multiple Purposes},
year = {2012},
isbn = {9781450314640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380552.2380575},
doi = {10.1145/2380552.2380575},
abstract = {Data centers require 40 times the energy requirements of a regular office. Projections show that IT growth will continue to increase, with annual network growth at 45%. Increased energy demand in IT is growing rapidly as the world becomes more industrialized. Increasing energy demands results in an increase in both costs and global warming. To be competitive and a good world citizen means reducing IT energy costs.This poster discusses teaching materials to prepare the educator and the student in this relevant topic. Teaching this subject helps to achieve five ABET program goals, including ethics and local/global impact. It also enables students to experiment with electricity, graphs, and a lab report.},
booktitle = {Proceedings of the 13th Annual Conference on Information Technology Education},
pages = {81–82},
numpages = {2},
keywords = {green computing, education, energy efficient computing},
location = {Calgary, Alberta, Canada},
series = {SIGITE '12}
}

@inproceedings{10.5555/2662693.2662695,
author = {Dustdar, Schahram and Li, Fei and Truong, Hong-Linh and Sehic, Sanjin and Nastic, Stefan and Qanbari, Soheil and V\"{o}gler, Michael and Clae\ss{}ens, Markus},
title = {Green Software Services: From Requirements to Business Models},
year = {2013},
isbn = {9781467362672},
publisher = {IEEE Press},
abstract = {In recent years, green software research is gaining momentum because of the acute need for sustainable development. Most past research has been focused on the definitions, metrics and technical solutions for green software, but few has addressed green software from the business perspective. In this paper, we present the analysis on three key elements of Green Software Services (GSS)---stakeholders, their requirements, and business models. The stakeholders of GSS are detailed with the services each stakeholder can provide and consume, thus clarifying their interests to GSS. Based on this analysis, we present the domain-independent, high-level requirements to GSS that cover diverse needs of different stakeholders. Six business models are then proposed to promote collaborations of stakeholders on the delivery of GSS. In the end, the relationship between GSS and cloud is discussed and a GSS marketplace is envisioned.},
booktitle = {Proceedings of the 2nd International Workshop on Green and Sustainable Software},
pages = {1–7},
numpages = {7},
location = {San Francisco, California},
series = {GREENS '13}
}

@inproceedings{10.5555/2616606.3254867,
author = {Coskun, Ayse and Ruggiero, Martino},
title = {Session Details: Green Computing Systems},
year = {2014},
isbn = {9783981537024},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
booktitle = {Proceedings of the Conference on Design, Automation &amp; Test in Europe},
location = {Dresden, Germany},
series = {DATE '14}
}

@inproceedings{10.1145/1620545.1620583,
author = {Dillahunt, Tawanna and Mankoff, Jennifer and Paulos, Eric and Fussell, Susan},
title = {It's Not All about "Green": Energy Use in Low-Income Communities},
year = {2009},
isbn = {9781605584317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1620545.1620583},
doi = {10.1145/1620545.1620583},
abstract = {Personal energy consumption, specifically home energy consumption such as heating, cooling, and electricity, has been an important environmental and economic topic for decades. Despite the attention paid to this area, few researchers have specifically explored these issues within a community that makes up approximately 30% of U.S. households -- those below the federal poverty line. We present a study of 26 low-income households in two very different locations -- a small town in the Southern U.S. and a northerly metropolitan area. Through a photo-elicitation study and directed interviews, we explore the relationship between energy saving behaviors, external factors, and users' intrinsic values and beliefs. Most of our participants are committed to saving energy for non-financial reasons, even when not responsible for paying bills. Challenges to saving energy include safety and lack of control over the environment. We discuss how Ubicomp technologies for saving energy can address some of these challenges.},
booktitle = {Proceedings of the 11th International Conference on Ubiquitous Computing},
pages = {255–264},
numpages = {10},
keywords = {domestic computing, sustainability, low-income},
location = {Orlando, Florida, USA},
series = {UbiComp '09}
}

@inproceedings{10.1145/3275245.3275258,
author = {Mour\~{a}o, Brunna C. and Karita, Leila and do Carmo Machado, Ivan},
title = {Green and Sustainable Software Engineering - a Systematic Mapping Study},
year = {2018},
isbn = {9781450365659},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3275245.3275258},
doi = {10.1145/3275245.3275258},
abstract = {Understanding how the concepts of sustainability could be incorporated to the Software Engineering (SE) concepts has gained increased attention in the last years, particularly in terms of the Software Development Life Cycle (SDLC). Several studies have addressed the impact of sustainability in the SE practice, from a range of perspectives. This study presents a systematic mapping study that aggregates, summarizes and discusses the state-of-the-art approaches for sustainable SE practice. We analyzed 75 relevant primary studies addressing methods, processes, tools and metrics proposed to support the software development in a sustainable way. The included primary studies were selected using inclusion and exclusion criteria applied to studies published prior to 2017. They were analyzed based on a set of classification criteria, including contribution types, SDLC phases, evidence types, research types, application domains, publication venues, distribution between academia and industry and research methods. The results indicated a growing interest by the SE research community in the Green and Sustainable software domain. Besides, there is an observed need for more studies on techniques, tools and metrics covering construction, testing and maintenance. The results also point out a clear view of the SE community about the need for a better alignment between research and practice in this domain.},
booktitle = {Proceedings of the XVII Brazilian Symposium on Software Quality},
pages = {121–130},
numpages = {10},
keywords = {green software engineering, sustainable software, Systematic mapping study},
location = {Curitiba, Brazil},
series = {SBQS '18}
}

@inproceedings{10.1145/2576768.2598265,
author = {Liu, Xiao-Fang and Zhan, Zhi-Hui and Du, Ke-Jing and Chen, Wei-Neng},
title = {Energy Aware Virtual Machine Placement Scheduling in Cloud Computing Based on Ant Colony Optimization Approach},
year = {2014},
isbn = {9781450326629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2576768.2598265},
doi = {10.1145/2576768.2598265},
abstract = {Cloud computing provides resources as services in pay-as-you-go mode to customers by using virtualization technology. As virtual machine (VM) is hosted on physical server, great energy is consumed by maintaining the servers in data center. More physical servers means more energy consumption and more money cost. Therefore, the VM placement (VMP) problem is significant in cloud computing. This paper proposes an approach based on ant colony optimization (ACO) to solve the VMP problem, named as ACO-VMP, so as to effectively use the physical resources and to reduce the number of running physical servers. The number of physical servers is the same as the number of the VMs at the beginning. Then the ACO approach tries to reduce the physical server one by one. We evaluate the performance of the proposed ACO-VMP approach in solving VMP with the number of VMs being up to 600. Experimental results compared with the ones obtained by the first-fit decreasing (FFD) algorithm show that ACO-VMP can solve VMP more efficiently to reduce the number of physical servers significantly, especially when the number of VMs is large.},
booktitle = {Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation},
pages = {41–48},
numpages = {8},
keywords = {ant colony optimization, cloud computing, resource scheduling, virtual machine placement},
location = {Vancouver, BC, Canada},
series = {GECCO '14}
}

@inproceedings{10.1145/3194554.3194565,
author = {Eshratifar, Amir Erfan and Pedram, Massoud},
title = {Energy and Performance Efficient Computation Offloading for Deep Neural Networks in a Mobile Cloud Computing Environment},
year = {2018},
isbn = {9781450357241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194554.3194565},
doi = {10.1145/3194554.3194565},
abstract = {In today's computing technology scene, mobile devices are considered to be computationally weak, while large cloud servers are capable of handling expensive workloads, therefore, intensive computing tasks are typically offloaded to the cloud. Recent advances in learning techniques have enabled Deep Neural Networks (DNNs) to be deployed in a wide range of applications. Commercial speech based intelligent personal assistants (IPA) like Apple's Siri, which employs DNN as its recognition model, operate solely over the cloud. The cloud-only approach may require a large amount of data transfer between the cloud and the mobile device. The mobile-only approach may lack performance efficiency. In addition, the cloud server may be slow at times due to the congestion and limited subscription and mobile devices may have battery usage constraints. In this paper, we investigate the efficiency of offloading only some parts of the computations in DNNs to the cloud. We have formulated an optimal computation offloading framework for forward propagation in DNNs, which adapts to battery usage constraints on the mobile side and limited available resources on the cloud. Our simulation results show that our framework can achieve 1.42x on average and up to 3.07x speedup in the execution time on the mobile device. In addition, it results in 2.11x on average and up to 4.26x reduction in mobile energy consumption.},
booktitle = {Proceedings of the 2018 on Great Lakes Symposium on VLSI},
pages = {111–116},
numpages = {6},
keywords = {high performance computing, computation offloading, mobile cloud computing, deep neural networks, energy efficient computing},
location = {Chicago, IL, USA},
series = {GLSVLSI '18}
}

@inproceedings{10.1145/2464576.2482735,
author = {Chang, Xiaolin and Wang, Bin and Liu, Jiqiang and Wang, Wenbo and Muppala, Jogesh},
title = {Green Cloud Virtual Network Provisioning Based Ant Colony Optimization},
year = {2013},
isbn = {9781450319645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2464576.2482735},
doi = {10.1145/2464576.2482735},
abstract = {Network virtualization is being regarded as a promising technology to create an ecosystem for cloud computing applications. One critical issue in network virtualization technology is power-efficient virtual network embedding (PE-VNE), which deals with the physical resource allocation to virtual nodes and links of a virtual network while minimizing the energy consumption in the cloud data center. When the node and link constraints (including CPU, memory, network bandwidth, and network delay) are both taken into account, the VN embedding problem is NP-hard, even in the offline case. This paper aims to investigate the ability of the Ant-Colony-Optimization (ACO) technique in handling PE-VNE problem. We propose an ACO-based heuristic PE-VNE algorithm, called E-ACO. E-ACO minimizes the energy consumption by considering the embedding power consumption in the node mapping phase and by making an implicit coordination between the node and link mapping phases. Extensive simulations are conducted to evaluate the performance of the proposed algorithm and investigate different energy-aware link embedding algorithms on the ability of E-ACO.},
booktitle = {Proceedings of the 15th Annual Conference Companion on Genetic and Evolutionary Computation},
pages = {1553–1560},
numpages = {8},
keywords = {optimization, cloud data center, ant colony optimization, virtual network embedding, energy consumption, mixed integer programming},
location = {Amsterdam, The Netherlands},
series = {GECCO '13 Companion}
}

@inproceedings{10.5555/2662693.2662707,
author = {Dick, Markus and Drangmeister, Jakob and Kern, Eva and Naumann, Stefan},
title = {Green Software Engineering with Agile Methods},
year = {2013},
isbn = {9781467362672},
publisher = {IEEE Press},
abstract = {The energy consumption of information and communication technology (ICT) is still increasing. Since several concepts regarding hardware solutions for Green IT exist, the contribution of software to Green IT is still not well investigated. This comprises the production and the usage impact of software on energy consumption. In our paper, we discuss this contribution. Especially, we present a model that integrates Green IT aspects into software engineering processes with agile methods in order to produce "greener" software from scratch.},
booktitle = {Proceedings of the 2nd International Workshop on Green and Sustainable Software},
pages = {78–85},
numpages = {8},
keywords = {green software engineering, software engineering, agile methods, green IT},
location = {San Francisco, California},
series = {GREENS '13}
}

@inproceedings{10.1145/3457388.3458664,
author = {Titirsha, Twisha and Song, Shihao and Balaji, Adarsha and Das, Anup},
title = {On the Role of System Software in Energy Management of Neuromorphic Computing},
year = {2021},
isbn = {9781450384049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457388.3458664},
doi = {10.1145/3457388.3458664},
abstract = {Neuromorphic computing systems such as DYNAPs and Loihi have recently been introduced to the computing community to improve performance and energy efficiency of machine learning programs, especially those that are implemented using Spiking Neural Network (SNN). The role of a system software for neuromorphic systems is to cluster a large machine learning model (e.g., with many neurons and synapses) and map these clusters to the computing resources of the hardware. In this work, we formulate the energy consumption of a neuromorphic hardware, considering the power consumed by neurons and synapses, and the energy consumed in communicating spikes on the interconnect. Based on such formulation, we first evaluate the role of a system software in managing the energy consumption of neuromorphic systems. Next, we formulate a simple heuristic-based mapping approach to place the neurons and synapses onto the computing resources to reduce energy consumption. We evaluate our approach with 10 machine learning applications and demonstrate that the proposed mapping approach leads to a significant reduction of energy consumption of neuromorphic computing systems.},
booktitle = {Proceedings of the 18th ACM International Conference on Computing Frontiers},
pages = {124–132},
numpages = {9},
keywords = {dynamic power, static power, spiking neural network (SNN), energy consumption, non volatile memory (NVM), neuromorphic computing},
location = {Virtual Event, Italy},
series = {CF '21}
}

@article{10.1145/1347375.1347380,
author = {Fei, Yunsi and Zhong, Lin and Jha, Niraj K.},
title = {An Energy-Aware Framework for Dynamic Software Management in Mobile Computing Systems},
year = {2008},
issue_date = {April 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {1539-9087},
url = {https://doi.org/10.1145/1347375.1347380},
doi = {10.1145/1347375.1347380},
abstract = {Energy efficiency has become a very important and challenging issue for resource-constrained mobile computers. In this article, we propose a novel dynamic software management (DSOM) framework to improve battery utilization. We have designed and implemented a DSOM module in user space, independent of the operating system (OS), which explores quality-of-service (QoS) adaptation to reduce system energy and employs a priority-based preemption policy for multiple applications to avoid competition for limited energy resources. Software energy macromodels for mobile applications are employed to predict energy demand at each QoS level, so that the DSOM module is able to select the best possible trade-off between energy conservation and application QoS; it also honors the priority desired by the user. Our experimental results for some mobile applications (video player, speech recognizer, voice-over-IP) show that this approach can meet user-specified task-oriented goals and significantly improve battery utilization.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {may},
articleno = {27},
numpages = {31},
keywords = {energy macromodel, Software adaptation, runtime coordination}
}

@inproceedings{10.5555/3375069.3375126,
author = {McCune Jr., Earl},
title = {Power Proportional Computing for Green Servers},
year = {2016},
isbn = {9783901882852},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {Achieving energy-efficient Green operations within data centers used for applications such as Cloud Computing requires matching the power consumed to the data processed at each server in real-time. Beyond having a high efficiency in the server power supplies, it is vitally important to only draw power when the server is actually processing data. To operate at maximum energy efficiency, in the times when a server is idle it needs to draw no power for the server farm. By matching power draw to actual data processing activity at logic speeds, the average energy draw of the server farm drops by 50% or more with no reduction in throughput. Drawing on technology developed for efficient radio transmitters, an agile power supply, able to provide tight voltage regulation and still transition between power-off and power-on (or the other way) in nanoseconds without transition overshoot is described. With this nanosecond agility, this also solves the objective for elastic computing. Additionally, the supply pin pairing required by this energy management method provides benefits toward reducing electromagnetic interference (EMI). Proportional reduction in processor operating temperature improves reliability, along with reducing facility cooling loads.},
booktitle = {Proceedings of the 12th Conference on International Conference on Network and Service Management},
pages = {371–376},
numpages = {6},
keywords = {cloud computing},
location = {Montreal, Quebec, Canada},
series = {CNSM 2016}
}

@inproceedings{10.1145/1297846.1297917,
author = {Chan, Hoi and Kephart, Jeffrey O.},
title = {Green Applications: Software Applications That Optimize Energy Usage},
year = {2007},
isbn = {9781595938657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1297846.1297917},
doi = {10.1145/1297846.1297917},
abstract = {Energy consumption is a major cost of operating IT equipment in organizations and data centers. Hardware and software manufacturers are beginning to include power saving options in a range of products from processors to operating systems (OS). Previous work on power saving has focused mainly on OS control of the operating modes of laptop computers and mobile devices to maximize battery life. To take full advantage of these newly available energy saving features, we have developed a power management agent with a set of power control and monitoring interfaces which allows power saving features to be implemented on individual applications. We call these power saving capable applications Green Applications.In this demonstration, we will discuss and show a web based Green Application which implements these newly introduced power saving features. This application runs on an IBM HS20 Blade Server with Linux OS and equipped with a processor (Intel Xeon 3 GHz) capable of power management. When the application runs, it continuously adjusts the power level (range from standby to maximum) of the server processor in accordance with the state and performance requirements of the application (expressed as policies or static user-defined control parameters) via the power management agent. The power management agent can manage multiple Green Applications and can set the power level of the processor according to the aggregate power requirement of the applications. Using an advanced monitoring tool, the IBM Tivoli Monitoring (ITM) System [1], we will show graphically the dynamic interactions of the state and performance of the application, including processor temperature, CPU utilization, power cap, and power usage in a single integrated view, and present the amount of energy used in comparison with running the same application with no power saving features included.},
booktitle = {Companion to the 22nd ACM SIGPLAN Conference on Object-Oriented Programming Systems and Applications Companion},
pages = {842–843},
numpages = {2},
keywords = {power, management, agent, IBM Tivoli Monitoring, green applications, energy, power management},
location = {Montreal, Quebec, Canada},
series = {OOPSLA '07}
}

@inproceedings{10.5555/2486788.2486859,
author = {Bartenstein, Thomas W. and Liu, Yu David},
title = {Green Streams for Data-Intensive Software},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {This paper introduces GREEN STREAMS, a novel solution to address a critical but often overlooked property of data-intensive software: energy efficiency. GREEN STREAMS is built around two key insights into data-intensive software. First, energy consumption of data-intensive software is strongly correlated to data volume and data processing, both of which are naturally abstracted in the stream programming paradigm; Second, energy efficiency can be improved if the data processing components of a stream program coordinate in a “balanced” way, much like an assembly line that runs most efficiently when participating workers coordinate their pace. GREEN STREAMS adopts a standard stream programming model, and applies Dynamic Voltage and Frequency Scaling (DVFS) to coordinate the pace of data processing among components, ultimately achieving energy efficiency without degrading performance in a parallel processing environment. At the core of GREEN STREAMS is a novel constraint-based inference to abstract the intrinsic relationships of data flow rates inside a stream program, that uses linear programming to minimize the frequencies – hence the energy consumption – for processing components while still maintaining the maximum output data flow rate. The core algorithm of GREEN STREAMS is formalized, and its optimality is established. The effectiveness of GREEN STREAMS is evaluated on top of the StreamIt framework, and preliminary results show the approach can save CPU energy by an average of 28% with a 7% performance improvement.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {532–541},
numpages = {10},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/1899503.1899559,
author = {van Staden, Corn\`{e} Johandia},
title = {IT Moderation Going Green},
year = {2010},
isbn = {9781605589503},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1899503.1899559},
doi = {10.1145/1899503.1899559},
abstract = {It is axiomatic that a private Higher Education (HE) provider needs to focus on cost-effective and efficient ways to manage processes without compromising standards, quality and integrity. In order to ensure academic integrity, moderation of examinations is essential. Some of the challenges of the current system include a long turnaround period with regard to the moderation and return of scripts, high courier costs high printing volumes and the risks and costs involved in transporting original scripts.The private HE provider has therefore sought to find an alternative cost-effective and environmentally-friendly solution to this question. The Faculty of Information Technology -- with the support of the moderators concerned -- became involved in a pilot study with reference to a proposed electronic moderation process.In this paper both the processes that worked, as well as those which did not, will be discussed. The outcome of the pilot study indicated that the proposed process definitely had a positive impact on the environment, budgetary limitations and security issues regarding examination scripts; it also allowed for better turnaround time of moderators' feedback and afforded moderators the opportunity to moderate at a time more convenient to themselves.},
booktitle = {Proceedings of the 2010 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists},
pages = {426–428},
numpages = {3},
keywords = {online moderation, private higher education provider, validity, environmentally-friendly moderation, examination, higher education, moderator},
location = {Bela Bela, South Africa},
series = {SAICSIT '10}
}

@inproceedings{10.1145/3331542.3342570,
author = {Nagy, Gergely and M\'{e}sz\'{a}ros, \'{A}ron Attila and Boz\'{o}, Istv\'{a}n and T\'{o}th, Melinda},
title = {Tools Supporting Green Computing in Erlang},
year = {2019},
isbn = {9781450368100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331542.3342570},
doi = {10.1145/3331542.3342570},
abstract = {Energy efficiency is one of the key aspects of modern software. Therefore, we present a tool for measuring the energy consumption of Erlang programs. Using this tool, we measured the energy consumption of different basic language elements, such as data structures, higher-order functions and parallel language constructs. Based on the results of our measurements, we present refactorings that may help to decrease the energy consumption of Erlang software. The refactorings are part of the well-known RefactorErl static analyser and transformer framework for Erlang.},
booktitle = {Proceedings of the 18th ACM SIGPLAN International Workshop on Erlang},
pages = {30–35},
numpages = {6},
keywords = {energy consumption, refactoring, energy efficiency, green computing},
location = {Berlin, Germany},
series = {Erlang 2019}
}

@inproceedings{10.1145/3430665.3456386,
author = {Saraiva, Jo\~{a}o and Zong, Ziliang and Pereira, Rui},
title = {Bringing Green Software to Computer Science Curriculum: Perspectives from Researchers and Educators},
year = {2021},
isbn = {9781450382144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430665.3456386},
doi = {10.1145/3430665.3456386},
abstract = {Only recently has the software engineering community started conducting research on developing energy efficient software, or green software. This is shadowed when compared to the research already produced in the computer hardware community. While research in green software is rapidly increasing, several recent studies with software engineers show that they still miss techniques, knowledge, and tools to develop greener software. Indeed, all such studies suggest that green software should be part of a modern Computer Science Curriculum.In this paper, we present survey results from both researchers' and educators' perspective on green software education. These surveys confirm the lack of courses and educational material for teaching green software in current higher education. Additionally, we highlight three key pedagogical challenges in bringing green software to computer science curriculum and discussed existing solutions to address these key challenges. We firmly believe that 'green thinking" and the broad adoption of green software in computer science curriculum can greatly benefit our environment, society, and students in an era where software is everywhere and evolves in an unprecedented speed.},
booktitle = {Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {498–504},
numpages = {7},
keywords = {green computing, green education, green software},
location = {Virtual Event, Germany},
series = {ITiCSE '21}
}

@inproceedings{10.5555/2819009.2819220,
author = {Procaccianti, Giuseppe and Lago, Patricia and Vetr\`{o}, Antonio and Fern\'{a}ndez, Daniel M\'{e}ndez and Wieringa, Roel},
title = {The Green Lab: Experimentation in Software Energy Efficiency},
year = {2015},
publisher = {IEEE Press},
abstract = {Software energy efficiency is a research topic where experimentation is widely adopted. Nevertheless, current studies and research approaches struggle to find generalizable findings that can be used to build a consistent knowledge base for energy-efficient software. To this end, we will discuss how to combine the traditional hypothesis-driven (top-down) approach with a bottom-up discovery approach. In this technical briefing, participants will learn the challenges that characterize the research in software energy efficiency. They will experience the complexity in this field and its implications for experimentation.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {941–942},
numpages = {2},
location = {Florence, Italy},
series = {ICSE '15}
}

@article{10.1145/3264371,
author = {Hagimont, Daniel and De Palma, Noel},
title = {Session Details: Extended Papers from Green and Cloud Middleware Workshop},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0163-5980},
url = {https://doi.org/10.1145/3264371},
doi = {10.1145/3264371},
abstract = {Cloud computing has become a very hot topic over the past few years. One of the main requirements in cloud computing environments is a high degree of automation for provisioning and dynamic management of IT resources (compute, storage and network resources) and services. Also, in cloud computing environments composed of large virtualized datacenters, energy consumption and carbon footprint have become major concerns which significantly impact resource management. This special issue is based on extended versions of the Green and Cloud Management workshop (CGM 2012) which focused on management and control issues related to dependability, scalabilitity, performance and configuration at each level of cloud computing infrastructures, but also on green computing issues in such environments such as energy efficiency, carbon footprint reduction and cooling. This raises the issue of management automation for multi-criteria optimization (including green metrics) at each level of a cloud environment. Topics of interest addressed by this special issue include: Monitoring for Green and Cloud computingControl algorithms and policies for Green and Cloud computingAutonomic Computing applyied to Green and Cloud ComputingDesign of energy efficient cloud stacksGreen-oriented Autonomic computingQoS and Green computing models for CloudsEnergy efficiency benchmarking and profiling for CloudsEnergy-aware configuration and resource management for CloudsComponent model for cloud and green computingSoftware engineering methodologies and tools for cloud and green computingScalability and reliability of management software for Green and Cloud computingReporting and exposing carbon and energy impactGreen architectures for Grids, Clouds and clustersDesign of green computing middlewareGreen-aware configuration and resource managementScheduling and control in green computingControl and optimization techniques for green computing Real life experiments.This issue gathers papers which focus on : (i) processors and routers management ranging from thermal awareness to power control and DVFS techniques, (ii) coarce grain control in the case of cloud infrastructures using discrete controller synthesis or neural predictor, (iii) fine grain energy profiler which can be used to understand the energy consumption of a software stack. We would like to thank the program committee members for their help during the reviewing process. We are also thankful to the OSR editors for their help about this special issue.We hope you will enjoy this special issue so that the presented papers will help you opening perspectives for your future researches.},
journal = {SIGOPS Oper. Syst. Rev.},
month = {nov},
numpages = {1}
}

@article{10.1145/2413038.2413062,
author = {Lago, Patricia and Kazman, Rick and Meyer, Niklaus and Morisio, Maurizio and M\"{u}ller, Hausi A. and Paulisch, Frances},
title = {Exploring Initial Challenges for Green Software Engineering: Summary of the First GREENS Workshop, at ICSE 2012},
year = {2013},
issue_date = {January 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2413038.2413062},
doi = {10.1145/2413038.2413062},
abstract = {The GREENS workshop provides a forum for practitioners and academics to share knowledge, ideas, practices and current results related to green and sustainable software engineering. This first workshop was held at ICSE 2012 in Zurich, Switzerland. It featured a keynote talk, twelve research position statements and two breakout sessions that discussed topics that ranged from bringing sustainability and energy efficiency into all software lifecycle stages, to green measures and estimations, practices, notations, and tools to both greening the software engineering process, and greening the resulting Information and Communication Technology systems. This report presents the themes of the workshop, summarizes the results of the discussions held in the breakout sessions, as well as the identified research challenges.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {31–33},
numpages = {3},
keywords = {sustainability, green IT, energy efficiency, software engineering}
}

@proceedings{10.1145/2593743,
title = {GREENS 2014: Proceedings of the 3rd International Workshop on Green and Sustainable Software},
year = {2014},
isbn = {9781450328449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hyderabad, India}
}

@inproceedings{10.1145/2554850.2555182,
author = {Hassan, Mahamat Issa and Bahsoon, Rami},
title = {Green-as-a-Service (GaaS) for Cloud Service Provision Operation},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2555182},
doi = {10.1145/2554850.2555182},
abstract = {We introduce the concept of green-as-a-service that provides a cost-effective and specialized on-demand monitoring, analysis, and continuous feeds for energy use and savings which can be exploited by both providers and consumers to meet energy targets. We describe a decentralized architecture model for implementing GaaS and discuss its constituent components. The architecture leverages on SOA and publish-subscribe model to provide an effective solution for wider adoption of the vision and to render an inherently scalable solution. The service has the promise to provide transparency in the way energy and long-term sustainability are linked to the business objectives along with its cost and revenues.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1219–1220},
numpages = {2},
keywords = {energy efficiency, green computing, cloud computing},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/2451605.2451607,
author = {Moshnyaga, Vasily G.},
title = {Want to Green Application Software? Mind the Target Hardware},
year = {2013},
isbn = {9781450318662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451605.2451607},
doi = {10.1145/2451605.2451607},
abstract = {With the explosive use of Information Technology (IT) in modern life, "green" or sustainable solutions capable of minimizing IT impact on the environment become very important. Research on green IT has already produced a variety of approaches aiming at reducing energy usage for data centers and technical equipment, such as computers, projectors, etc. Also methods have been proposed to improve energy efficiency of compilers and software. While focusing on code transformation, the software optimization methods frequently ignore operational features of target hardware and therefore have a limited effect in practice. In this talk we urge for software "greening" techniques that increase efficiency of energy reduction schemes of target hardware. The talk starts with a brief review of factors of energy consumption and main hardware schemes used in the state-of-the-art portable battery-operated devices. Then it discusses software optimizations for lowering energy consumption of CPU, memory, HDD, display, and communication. We argue that algorithm and software optimizations capable of improving computational and data efficiency, exploit adaptive, context-aware and quality-aware processing can all contribute to "green" applications. Open problems of "green" software development are also outlined.},
booktitle = {Proceedings of the 2013 Workshop on Green in/by Software Engineering},
pages = {1–2},
numpages = {2},
keywords = {context-aware, low-power, energy consumption, algorithm, quality-aware, hardware, efficiency, software, optimization, adaptive},
location = {Fukuoka, Japan},
series = {GIBSE '13}
}

@article{10.1145/2367736.2367737,
author = {Pande, Partha Pratim and Ganguly, Amlan},
title = {Introduction to the Special Issue on Sustainable and Green Computing Systems},
year = {2012},
issue_date = {October 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/2367736.2367737},
doi = {10.1145/2367736.2367737},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {nov},
articleno = {26},
numpages = {3}
}

@proceedings{10.5555/2820158,
title = {GREENS '15: Proceedings of the Fourth International Workshop on Green and Sustainable Software},
year = {2015},
publisher = {IEEE Press},
abstract = {The GREENS workshop provides a forum for practitioners and academics to share knowledge, ideas, practices, and current results related to green and sustainable software engineering. The goal of green software engineering is to apply green principles to the design and operation of softwareintensive systems. Green and self-greening software systems have tremendous potential to decrease energy consumption. Moreover, enterprise software can and should be re-thought to address sustainability issues using innovative business models, processes, and incentives. Monitoring and measuring the greenness of software is critical towards the notion of sustainable and green software. Demonstrating improvement is paramount for users to achieve and affect change. Thus, the theme of GREENS 2015 is Towards a Green Software Body of Knowledge. GREENS 2015 is interested in contributions from industry, government, and academia on all topics related to greener software engineering. Topics range from bringing sustainability and energy efficiency into all software lifecycle stages, to green measures and estimations, practices, notations, and tools to both greening the software engineering process, and greening the resulting ICT systems.To ensure high quality papers and presentations, all submissions were reviewed by at least three program committee members whose identity was not revealed to any of the authors. The reviewers did not review papers for which they had a conflict of interest. The organizers were excluded by the reviewer selection process when in direct or indirect conflict of interest.},
location = {Florence, Italy}
}

@proceedings{10.1145/3194078,
title = {GREENS '18: Proceedings of the 6th International Workshop on Green and Sustainable Software},
year = {2018},
isbn = {9781450357326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to GREENS 2018, the 6th International Workshop on Green and Sustainable Software, May 27, 2018, in Gothenburg, Sweden. GREENS 2018 is co-located with the 40th International Conference on Software Engineering (ICSE 2018).The GREENS workshop provides a forum for practitioners and academics to share knowledge, ideas, practices, and current results related to green and sustainable software engineering. Engineering green software-intensive systems is critical in our drive towards a sustainable, smarter planet. The goal of green software engineering is to apply green principles to the design and operation of software-intensive systems. Green and self-greening software systems have tremendous potential to decrease energy consumption. Moreover, enterprise software can and should be re-thought to address sustainability issues using innovative business models, processes, and incentives. Monitoring and measuring the greenness of software is critical towards the notion of sustainable and green software. Demonstrating improvement is paramount for users to achieve and affect change. The GREENS 2018 theme is design patterns and reference architecture for green and sustainable software. Analysis of the sustainability of a specific software system requires software developers to weigh four major dimensions of sustainability - economic, social, environmental, and technical - which affects their trade-offs. The software engineering community must assume leadership in this important challenge.},
location = {Gothenburg, Sweden}
}

@proceedings{10.5555/2663779,
title = {GREENS '12: Proceedings of the First International Workshop on Green and Sustainable Software},
year = {2012},
isbn = {9781467318327},
publisher = {IEEE Press},
abstract = {The GREENS workshop provides a forum for practitioners and academics to share knowledge, ideas, practices and current results related to green and sustainable software engineering. The goal of GREENS 2012 is to discuss emerging research and the state of industrial practice, and to define a roadmap, both for academic research and for technology exchange with industry. Topics range from bringing sustainability and energy efficiency into all software lifecycle stages, to green measures and estimations, practices, notations, and tools to both greening the software engineering process, and greening the resulting ICT systems.},
location = {Zurich, Switzerland}
}

@proceedings{10.1145/2896967,
title = {GREENS '16: Proceedings of the 5th International Workshop on Green and Sustainable Software},
year = {2016},
isbn = {9781450341615},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to GREENS 2016, the 5th ACM/IEEE International Workshop on Green and Sustainable Software on May 16, 2016 in Austin, Texas, USA. GREENS 2016 is co-located with the 38th ACM/IEEE International Conference on Software Engineering (ICSE 2016).WOne of the grand challenges for the next decade is to develop software engineering and control mechanisms and techniques for the long-term operation of cyber physical systems (CPS) using green sources of energy. While research results exist in measuring and controlling the level of greenness of hardware components, research is needed to relate energy consumption to executing software and entire cyber physical ecosystems. In the age of context, we can sense and monitor continuously context changes, perform analytics in the cloud, and then actuate physical components according to the computed findings---all from the palm of our hand. While researchers continue to innovate in the realm of CPS, we need to make the feedback loops more sustainable by minimizing energy consumption in its supported processes and decreasing its environmental impact---sensors, monitors, analyzers, planners, actuators, networks, controllers, applications and services. With monitoring in place, we have the opportunity for adaptive control to facilitate greening dynamically. We need to investigate engineering methods to aid engineers with CPS sustainability capabilities. Demonstrating green improvement while still controlling physical components is a key challenge. Showing CPS use, habits, or lifestyles can effectively decrease the energy footprint is the ultimate goal.},
location = {Austin, Texas}
}

@proceedings{10.5555/2662693,
title = {GREENS '13: Proceedings of the 2nd International Workshop on Green and Sustainable Software},
year = {2013},
isbn = {9781467362672},
publisher = {IEEE Press},
abstract = {The GREENS workshop provides a forum for practitioners and academics to share knowledge, ideas, practices and current results related to green and sustainable software engineering. The goal of GREENS 2013 is to discuss emerging research and the state of industrial practice, and to define a roadmap, both for academic research and for technology exchange with industry. Topics range from bringing sustainability and energy efficiency into all software lifecycle stages, to green measures and estimations, practices, notations, and tools to both greening the software engineering process, and greening the resulting ICT systems.},
location = {San Francisco, California}
}

@inproceedings{10.1145/3253826,
author = {Pettis, Eddie},
title = {Session Details: Special Session 2: Green Computing},
year = {2009},
isbn = {9781605586847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253826},
doi = {10.1145/3253826},
booktitle = {Proceedings of the 2009 ACM/IEEE International Symposium on Low Power Electronics and Design},
location = {San Fancisco, CA, USA},
series = {ISLPED '09}
}

@inproceedings{10.1109/CCGrid.2014.37,
author = {Guazzone, Marco and Anglano, Cosimo and Sereno, Matteo},
title = {A Game-Theoretic Approach to Coalition Formation in Green Cloud Federations},
year = {2014},
isbn = {9781479927838},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2014.37},
doi = {10.1109/CCGrid.2014.37},
abstract = {Federations among sets of Cloud Providers (CPs), whereby a set of CPs agree to mutually use their own resources to run the VMs of other CPs, are considered a promising solution to the problem of reducing the energy cost. In this paper, we address the problem of federation formation for a set of CPs, whose solution is necessary to exploit the potential of cloud federations for the reduction of the energy bill. We devise an algorithm, based on cooperative game theory, that can be readily implemented in a distributed fashion, and that allows a set of CPs to cooperatively set up their federations in such a way that their individual profit is increased with respect to the case in which they work in isolation.We show that, by using our algorithm and the proposed CPs' utility function, they are able to self-organize into Nash-stable federations and, by means of iterated executions, to adapt themselves to environmental changes. Numerical results are presented to demonstrate the effectiveness of the proposed algorithm.},
booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {618–625},
numpages = {8},
keywords = {cloud federation, coalition formation, cooperative game theory},
location = {Chicago, Illinois},
series = {CCGRID '14}
}

@inproceedings{10.1145/3510457.3513077,
author = {Mehra, Rohit and Sharma, Vibhu Saujanya and Kaulgud, Vikrant and Podder, Sanjay and Burden, Adam P.},
title = {Towards a Green Quotient for Software Projects},
year = {2022},
isbn = {9781450392266},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510457.3513077},
doi = {10.1145/3510457.3513077},
abstract = {As sustainability takes center stage across businesses, green and energy-efficient choices are more crucial than ever. While it is becoming increasingly evident that software and the software industry are substantial and rapidly evolving contributors to carbon emissions, there is a dearth of approaches to create actionable awareness about this during the software development lifecycle (SDLC). Can software teams comprehend how green are their projects? Here we provide an industry perspective on why this is a challenging and worthy problem that needs to be addressed. We also outline an approach to quickly gauge the "greenness" of a software project based on the choices made across different SDLC dimensions and present the initial encouraging feedback this approach has received.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice},
pages = {295–296},
numpages = {2},
keywords = {carbon emissions, green software, energy-aware software, sustainable software engineering, software metrics},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-SEIP '22}
}

@article{10.1145/3229329.3229334,
author = {Pawlish, Michael J. and Varde, Aparna S.},
title = {The DevOps Paradigm with Cloud Data Analytics for Green Business Applications},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/3229329.3229334},
doi = {10.1145/3229329.3229334},
abstract = {This paper reviews the emergence of the DevOps (development and operations) paradigm in the industry and the influence it has along with cloud based data management and analytics in the greening of business applications. It considers the geoscience domain as an example discussing usefulness in a GIS (geographic information system). Similar claims can be applied to other domains. Investigating the emergence of DevOps technologies and examining the dramatic shift in IT towards cloud and hybrid models for data analytics, the paper paints a picture of systems that have the ability to green their impact on society. It also addresses concerns from a privacy and security perspective and concludes with open issues for further research.},
journal = {SIGKDD Explor. Newsl.},
month = {may},
pages = {51–59},
numpages = {9},
keywords = {Hybrid Models, Geoscience, Security, Privacy, Cloud Computing, Green Energy, DevOps}
}

@inproceedings{10.5555/3233397.3233505,
author = {Al-Dulaimy, Auday and Zantout, Rached and Zekri, Ahmed and Itani, Wassim},
title = {Job Classification in Cloud Computing: The Classification Effects on Energy Efficiency},
year = {2015},
isbn = {9780769556970},
publisher = {IEEE Press},
abstract = {One of the recent and major challenges in cloud computing is to enhance the energy efficiency in cloud data centers. Such enhancements can be done by improving the resource allocation and management algorithms. In this paper, a model that identifies common patterns for the jobs submitted to the cloud is proposed. This model is able to predict the type of the job submitted, and accordingly, the set of users' jobs is classified into four subsets. Each subset contains jobs that have similar requirements. In addition to the jobs' common pattern and requirements, the users' history is considered in the jobs' type prediction model. The goal of job classification is to find a way to propose useful strategy that helps improve energy efficiency. Following the process of jobs' classification, the best fit virtual machine is allocated to each job. Then, the virtual machines are placed to the physical machines according to a novel strategy called Mixed Type Placement strategy. The core idea of the proposed strategy is to place virtual machines of the jobs of different types in the same physical machine whenever possible, based on Knapsack Problem. This is because different types of jobs do not intensively use the same compute or storage resources in the physical machine. This strategy reduces the number of active physical machines which leads to major reduction in the total energy consumption in the data center. A simulation of the results shows that the presented strategy outperforms both Genetic Algorithm and Round Robin from an energy efficiency perspective.},
booktitle = {Proceedings of the 8th International Conference on Utility and Cloud Computing},
pages = {547–552},
numpages = {6},
keywords = {virtualization management, energy efficiency, data center, cloud computing},
location = {Limassol, Cyprus},
series = {UCC '15}
}

@inproceedings{10.1145/3503047.3503088,
author = {Saengkaenpetch, Kittipat and Aswakul, Chaodit},
title = {Cloud-Based Smart Energy Framework for Accelerated Data Analytics with Parallel Computing of Orchestrated Containers: Study Case of CU-BEMS},
year = {2022},
isbn = {9781450385862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503047.3503088},
doi = {10.1145/3503047.3503088},
abstract = {This paper proposes a practical smart energy framework for data analytic on energy management system at Chulalongkorn University, called CU-BEMS. This serves as an example of demand-sided smart energy application that copes with the challenges of big data analytic and real-time processing needs. The framework is based on the divide and conquer paradigm to accelerate data analytics with parallel computing. The workload is containerized and deployed on the Kubernetes cloud facility of our internationally collaborated IoTcloudServe@TEIN playground. With this playground, the workload scalability and portability can be achieved. Applying the proposed framework, this paper reports on a practical data log analysis to determine the wasted energy consumption. Based on the experimental result, the wasted energy consumption of the whole data set of CU-BEMS's communication research laboratory area from March 2014 to August 2017 can be computed within 81 seconds by using 32 cores running in parallel. The framework is expected to serve as a basis template for further research ongoing at CU-BEMS and smart energy applications that can be computationally enhanced by data analytic pipelining with containerized services as orchestrated by Kubernetes.},
booktitle = {Proceedings of the 3rd International Conference on Advanced Information Science and System},
articleno = {37},
numpages = {6},
keywords = {Kubernetes, Parallel Computing, Data Analytics, Smart Energy Framework},
location = {Sanya, China},
series = {AISS '21}
}

@inproceedings{10.5555/2147671.2147755,
author = {Salah, K. and Al-Shaikh, R. and Sindi, M.},
title = {Towards Green Computing Using Diskless High Performance Clusters},
year = {2011},
isbn = {9783901882449},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {In recent years, significant research has been conducted to boost the performance and increase the reliability of high performance computing (HPC) clusters. As the number of compute nodes in modern HPC clusters continues to grow, it is critical to design clusters with low power consumption and low failure rate. In particular, it is widely known that the internal disk drives of compute nodes (in the case of diskfull clusters) are a major source of failures. In addition, these diskfull HPC clusters tend to require more power and cooling requirements compared to diskless clusters. In this paper, we propose and implement a large-scale Infiniband-based diskless HPC cluster. The paper presents the cluster configuration and evaluates its performance using various High Performance LINPACK (HPL) benchmarks. The performance is measured in terms of the overall efficiency, speed in Giga-Floating Point Operations per Second (GFLOPS), and HPL execution time. We also measure temperature and power consumption. We compare the performance measurements of our diskless cluster to its diskfull counterpart. For our measurement and comparison, we consider three cluster sizes of 32, 64, and 126 compute nodes.},
booktitle = {Proceedings of the 7th International Conference on Network and Services Management},
pages = {456–459},
numpages = {4},
keywords = {performance evaluation, green computing, Linux, cluster computing and architecture},
location = {Paris, France},
series = {CNSM '11}
}

@inproceedings{10.1145/1753846.1753981,
author = {Amsel, Nadine and Tomlinson, Bill},
title = {Green Tracker: A Tool for Estimating the Energy Consumption of Software},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1753981},
doi = {10.1145/1753846.1753981},
abstract = {The energy consumption of computers has become an important environmental issue. This paper describes the development of Green Tracker, a tool that estimates the energy consumption of software in order to help concerned users make informed decisions about the software they use. We present preliminary results gathered from this system's initial usage. Ultimately the information gathered from this tool will be used to raise awareness and help make the energy consumption of software a more central concern among software developers.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {3337–3342},
numpages = {6},
keywords = {green computing, green it, software, sustainability},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}

@inproceedings{10.5555/3375069.3375133,
author = {Nonde, Leonard and Lawey, Ahmed and Elgorashi, Taisir and Elmirghani, Jaafar},
title = {Energy Efficient Cloud Networks},
year = {2016},
isbn = {9783901882852},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {Cloud computing is expected to be a major factor that will dominate the future Internet service model.This paper summarizes our work on energy efficiency for cloud networks. We develop a framework for studying the energy efficiency of four cloud services in IP over WDM networks: cloud content delivery, storage as a service (StaaS), and virtual machines (VMS) placement for processing applications and infrastructure as a service (IaaS).Our approach is based on the co-optimization of both external network related factors such as whether to geographically centralize or distribute the clouds, the influence of users demand distribution, content popularity, access frequency and renewable energyavailabilityand internal capability factors such as the number of servers, switches and routers as well as the amount of storage demanded in each cloud.Our investigation of the different energy efficient approaches is backed with Mixed Integer Linear Programming (MILP) models and real time heuristics.},
booktitle = {Proceedings of the 12th Conference on International Conference on Network and Service Management},
pages = {412–417},
numpages = {6},
keywords = {cloud},
location = {Montreal, Quebec, Canada},
series = {CNSM 2016}
}

@inproceedings{10.1109/SECM.2017.4,
author = {Torre, Damiano and Procaccianti, Giuseppe and Fucci, Davide and Lutovac, Sonja and Scanniello, Giuseppe},
title = {On the Presence of Green and Sustainable Software Engineering in Higher Education Curricula},
year = {2017},
isbn = {9781538627952},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SECM.2017.4},
doi = {10.1109/SECM.2017.4},
abstract = {Nowadays, software is pervasive in our everyday lives. Its sustainability and environmental impact have become major factors to be considered in the development of software systems. Millennials-the newer generation of university students-are particularly keen to learn about and contribute to a more sustainable and green society. The need for training on green and sustainable topics in software engineering has been reflected in a number of recent studies. The goal of this paper is to get a first understanding of what is the current state of teaching sustainability in the software engineering community, what are the motivations behind the current state of teaching, and what can be done to improve it. To this end, we report the findings from a targeted survey of 33 academics on the presence of green and sustainable software engineering in higher education. The major findings from the collected data suggest that sustainability is under-represented in the curricula, while the current focus of teaching is on energy efficiency delivered through a fact-based approach. The reasons vary from lack of awareness, teaching material and suitable technologies, to the high effort required to teach sustainability. Finally, we provide recommendations for educators willing to teach sustainability in software engineering that can help to suit millennial students needs.},
booktitle = {Proceedings of the 1st International Workshop on Software Engineering Curricula for Millennials},
pages = {54–60},
numpages = {7},
keywords = {curricula, academia, green and sustainable software engineering, millennials, teaching},
location = {Buenos Aires, Argentina},
series = {SECM '17}
}

@inproceedings{10.1145/3493700.3493772,
author = {Barua, Hrishav Bakul and Mondal, Kartick Chandra and Khatua, Sunirmal},
title = {Green Computing for Big Data and Machine Learning},
year = {2022},
isbn = {9781450385824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493700.3493772},
doi = {10.1145/3493700.3493772},
abstract = {The current decade has beheld a tremendous spike in data volume, velocity, variety and many other such aspects which we call as Big Data and which gave birth to a new kind of science commonly known as ”Data Science”. With the ”Data Apocalypse” in progress, it is evident that the conventional methods to handle these data would not suffice. We need distributed and parallel architectures like Cloud services (IaaS, PaaS, SaaS, STaaS, etc.). But is that enough to satisfy our needs? Here, we propose a tutorial in a very different direction when we are talking about Data Science, that is, bringing greenness in Big Data and Machine Learning (ML). We divide the tutorial into two parts primarily assuming that we are using cloud backbone for analytic and prediction tasks. The first part speaks about the techniques and tools to bring energy efficiency/greenness in the algorithmic and code level for Big Data and ML using Approximate Computing. The second part talks about the green techniques and power models at the infrastructural level for the cloud.},
booktitle = {5th Joint International Conference on Data Science &amp; Management of Data (9th ACM IKDD CODS and 27th COMAD)},
pages = {348–351},
numpages = {4},
keywords = {Green Computing, Heuristics, Cloud Computing, Data Science, Resource Scheduling, Approximate Computing, Machine Learning, Big Data, Power Modelling},
location = {Bangalore, India},
series = {CODS-COMAD 2022}
}

@inproceedings{10.1145/2445196.2445457,
author = {Fox, Susan Eileen},
title = {Green Computing in the Introductory Curriculum (Abstract Only)},
year = {2013},
isbn = {9781450318686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2445196.2445457},
doi = {10.1145/2445196.2445457},
abstract = {Green computing is a catchall phrase that includes efforts to improve sustainability both within the IT industry and outside of it. The green IT movement seeks to reduce energy use, waste, and toxic substances by the IT industry. In many other industries, mobile and computing devices connected to the network enable sustainability through automation, virtualization, and reduced travel. Green computing is a topic of increasing importance within the IT industry. There are few green computing courses for undergraduates, and most are for advanced students. I present a "CS1 Lite" course centered on the theme of green computing. The course integrates programming activities with readings, discussion and online research. The first course module examined how the Internet and mobile networks enable sustainable practices, such as: the virtualization of goods and services, telecommuting and virtual meetings, and cloud computing. The second module examined the "Green IT" movement, including sustainability across the computer life cycle, and increasing energy efficiency, from individual computers up to data centers. The third module focused on "Smart Technology," where network-connected computing devices drive improvements. Topics included the smart energy grid, smart buildings, and applications in health care and agriculture. Throughout the course, programming assignments were tailored to problems relevant to the green computing topics. Students implemented simulations of green computing systems. Students exhibited increased interest and motivation for these projects, and learned naturally about data abstraction and computer networks.},
booktitle = {Proceeding of the 44th ACM Technical Symposium on Computer Science Education},
pages = {743},
numpages = {1},
keywords = {theme-based introductory course, green computing, sustainable computing, computer science 1},
location = {Denver, Colorado, USA},
series = {SIGCSE '13}
}

@proceedings{10.1145/1925013,
title = {GCM '10: Proceedings of the 1st Workshop on Green Computing},
year = {2010},
isbn = {9781450304504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@inproceedings{10.1145/3106195.3106214,
author = {Couto, Marco and Borba, Paulo and Cunha, J\'{a}come and Fernandes, Jo\~{a}o Paulo and Pereira, Rui and Saraiva, Jo\~{a}o},
title = {Products Go Green: Worst-Case Energy Consumption in Software Product Lines},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106195.3106214},
doi = {10.1145/3106195.3106214},
abstract = {The optimization of software to be (more) energy efficient is becoming a major concern for the software industry. Although several techniques have been presented to measure energy consumption for software, none has addressed software product lines (SPLs). Thus, to measure energy consumption of a SPL, the products must be generated and measured individually, which is too costly.In this paper, we present a technique and a prototype tool to statically estimate the worst case energy consumption for SPL. The goal is to provide developers with techniques and tools to reason about the energy consumption of all products in a SPL, without having to produce, run and measure the energy in all of them.Our technique combines static program analysis techniques and worst case execution time prediction with energy consumption analysis. This technique analyzes all products in a feature-sensitive manner, that is, a feature used in several products is analyzed only once, while the energy consumption is estimated once per product.We implemented our technique in a tool called Serapis. We did a preliminary evaluation using a product line for image processing implemented in C. Our experiments considered 7 products from such line and our initial results show that the tool was able to estimate the worst-case energy consumption with a mean error percentage of 9.4% and standard deviation of 6.2% when compared with the energy measured when running the products.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {84–93},
numpages = {10},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.1145/3208903.3208906,
author = {Zhou, Yanglin and Ci, Song and Lin, Ni and Li, Hongjia and Yang, Yang},
title = {Distributed Energy Management of P2P Energy Sharing in Energy Internet Based on Cloud Energy Storage},
year = {2018},
isbn = {9781450357678},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3208903.3208906},
doi = {10.1145/3208903.3208906},
abstract = {Cloud energy storage (CES) has recently been proposed as one of the most economic saving techniques for peer-to-peer (P2P) energy sharing and coordination in energy internet. By transforming traditional consumers into self-sufficient customers and utility customers, CES enables transactions between customers and utility company, as well as among customers. In this paper, an architecture and operational technology which support P2P energy transactions are suggested based on the case of CES. With the aim of shared and virtually integrated CES among individual customers, a distributed algorithm is proposed to achieve higher renewable energy penetration and economic saving, in combination with alternating direction method of multipliers (ADMM). On the basis of a real-world dataset of renewable energy and real-time electricity price, numerical results show the effectiveness of the proposed framework in terms of economic saving for a long time application.},
booktitle = {Proceedings of the Ninth International Conference on Future Energy Systems},
pages = {173–177},
numpages = {5},
keywords = {ADMM, Distributed energy resource management, P2P energy sharing},
location = {Karlsruhe, Germany},
series = {e-Energy '18}
}

@inproceedings{10.5555/2675983.2676222,
author = {Cabrera, Guillem and P\'{e}rez-Roses, Hebert and Juan, Angel A. and Marqu\`{e}s, Joan M. and Faulin, Javier},
title = {Promoting Green Internet Computing throughout Simulation-Optimization Scheduling Algorithms},
year = {2013},
isbn = {9781479920778},
publisher = {IEEE Press},
abstract = {This work introduces an application of simulation-optimization techniques to the emerging field of green internet computing. The paper discusses the relevance of considering environmental factors in modern computing and then describes how simulation can be combined with scheduling metaheuristics in order to reduce the expected time needed to complete a set of tasks in a server under the realistic assumption of stochastic processing times. This, in turn, allows for a reduction in average energy consumption, which makes the computing facility more efficient from an environmental perspective. Some experiments have been carried out in order to illustrate these potential savings.},
booktitle = {Proceedings of the 2013 Winter Simulation Conference: Simulation: Making Decisions in a Complex World},
pages = {1917–1925},
numpages = {9},
location = {Washington, D.C.},
series = {WSC '13}
}

@inproceedings{10.1145/3278681.3278695,
author = {Dlamini, R. N. and Howard, G. R.},
title = {Investigating the Antecedents to Teaching Green Information Technology (Green IT): A Survey of Student Teachers in Swaziland},
year = {2018},
isbn = {9781450366472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278681.3278695},
doi = {10.1145/3278681.3278695},
abstract = {There is abundant scientific evidence that the natural environment, on which we are completely dependent for life, is degrading and depleting to the extent that our medium- to long-term well-being and existence is under threat. It is also clear that IT is contributing to this degradation and depletion, which requires that Green IT practices be an imperative. Since Green IT practices are often not common sense, it is vital that these Green IT practices are taught to others, and teachers typically have the skills and opportunities to teach many people. This demonstrates the relevance and significance of the study. The research problem is the lack of research addressing the theoretical antecedents to teaching Green IT, which are considered vital for understanding how to improve student teachers' intention to teach Green IT and their resultant teaching of Green IT. The study addressed this research problem by surveying student teachers using a quantitative questionnaire at three teacher training institutions in Swaziland, Africa. The resultant data was analysed using structural equation modeling (SEM) based on an a priori set of antecedents and their hypothesized relationships from the literature. The findings indicate that the most beneficial allocation of time and resources would be to enhance the student teachers' level of awareness, perceived behavioural control and person-related beliefs to positively influence their intention to teach Green IT, and consequently, their actual behaviour of teaching Green IT.},
booktitle = {Proceedings of the Annual Conference of the South African Institute of Computer Scientists and Information Technologists},
pages = {108–117},
numpages = {10},
keywords = {green information technology (Green It), environmental sustainability, student teachers, education and teaching, green computing, theory of planned behaviour (TPB), structural equation modeling (SEM), theory of reasoned action (TRA), green information systems (Green Is)},
location = {Port Elizabeth, South Africa},
series = {SAICSIT '18}
}

@article{10.1145/2377677.2377719,
author = {Gao, Peter Xiang and Curtis, Andrew R. and Wong, Bernard and Keshav, Srinivasan},
title = {It's Not Easy Being Green},
year = {2012},
issue_date = {October 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2377677.2377719},
doi = {10.1145/2377677.2377719},
abstract = {Large-scale Internet applications, such as content distribution networks, are deployed across multiple datacenters and consume massive amounts of electricity. To provide uniformly low access latencies, these datacenters are geographically distributed and the deployment size at each location reflects the regional demand for the application. Consequently, an application's environmental impact can vary significantly depending on the geographical distribution of end-users, as electricity cost and carbon footprint per watt is location specific. In this paper, we describe FORTE: Flow Optimization based framework for request-Routing and Traffic Engineering. FORTE dynamically controls the fraction of user traffic directed to each datacenter in response to changes in both request workload and carbon footprint. It allows an operator to navigate the three-way tradeoff between access latency, carbon footprint, and electricity costs and to determine an optimal datacenter upgrade plan in response to increases in traffic load. We use FORTE to show that carbon taxes or credits are impractical in incentivizing carbon output reduction by providers of large-scale Internet applications. However, they can reduce carbon emissions by 10% without increasing the mean latency nor the electricity bill.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {aug},
pages = {211–222},
numpages = {12},
keywords = {energy, green computing}
}

@inproceedings{10.1145/3129790.3129818,
author = {Munoz, Daniel-Jesus and Pinto, M\'{o}nica and Fuentes, Lidia},
title = {Green Software Development and Research with the HADAS Toolkit},
year = {2017},
isbn = {9781450352178},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3129790.3129818},
doi = {10.1145/3129790.3129818},
abstract = {Energy is a critical resource, and designing a sustainable software architecture is a non-trivial task. Developers require energy metrics that support sustainable software architectures reflecting quality attributes such as security, reliability, performance, etc., identifying what are the concerns that impact more in the energy consumption. A variability model of different designs and implementations of an energy model should exist for this task, as well as a service that stores and compares the experimentation results of energy and time consumption of each concern, finding out what is the most eco-efficient solution. The experimental measurements are performed by energy experts and researchers that share the energy model and metrics in a collaborative repository. HADAS confronts these tasks modelling and reasoning with the variability of energy consuming concerns for different energy contexts, connecting HADAS variability model with its energy efficiency collaborative repository, establishing a Software Product Line (SPL) service. Our main goal is to help developers to perform sustainability analyses finding out the eco-friendliest architecture configurations. A HADAS toolkit prototype is implemented based on a Clafer model and Choco solver, and it has been tested with several case studies.},
booktitle = {Proceedings of the 11th European Conference on Software Architecture: Companion Proceedings},
pages = {205–211},
numpages = {7},
keywords = {optimisation, repository, variability, software product line, energy efficiency, CVL, metrics, clafer},
location = {Canterbury, United Kingdom},
series = {ECSA '17}
}

@inproceedings{10.1145/2892664.2892690,
author = {G\'{a}mez, Nadia and Fuentes, Lidia},
title = {Green Software Using Aspect Orientation for Cyber-Physical-Systems},
year = {2016},
isbn = {9781450340335},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2892664.2892690},
doi = {10.1145/2892664.2892690},
abstract = {Green Computing emphasizes the need for reducing the environ-mental impact of systems by reducing their energy waste. Nowa-days IT systems as Cyber-Physical-Systems (CPS) are composed by many physical entities interconnected and working together. Therefore, saving energy in these systems implies to be aware of the energy in all the software modules that compose the system running in every device. Since all modules could collaborate in making a software system more energy efficient, these green-ness attributes may have a crosscutting nature. Aspect-Oriented tech-niques could be applied specifically for energy saving in this kind of systems with specific requirements. We discuss the characteris-tics that a framework to allow injecting green aspects to CPS both at design and at runtime would have to provide.},
booktitle = {Companion Proceedings of the 15th International Conference on Modularity},
pages = {176–177},
numpages = {2},
keywords = {Aspect Orientation, Green Software},
location = {M\'{a}laga, Spain},
series = {MODULARITY Companion 2016}
}

@inproceedings{10.1145/2889160.2889216,
author = {Jagroep, Erik A. and van der Werf, Jan Martijn and Brinkkemper, Sjaak and Procaccianti, Giuseppe and Lago, Patricia and Blom, Leen and van Vliet, Rob},
title = {Software Energy Profiling: Comparing Releases of a Software Product},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889216},
doi = {10.1145/2889160.2889216},
abstract = {In the quest for energy efficiency of Information and Communication Technology, so far research has mostly focused on the role of hardware. However, as hardware technology becomes more sophisticated, the role of software becomes crucial. Recently, the impact of software on energy consumption has been acknowledged as significant by researchers in software engineering. In spite of that, measuring the energy consumption of software has proven to be a challenge, due to the large number of variables that need to be controlled to obtain reliable measurements. Due to cost and time constraints, many software product organizations are unable to effectively measure the energy consumption of software. This prevents them to be in control over the energy efficiency of their products.In this paper, we propose a software energy profiling method to reliably compare the energy consumed by a software product across different releases, from the perspective of a software organization. Our method allows to attribute differences in energy consumption to changes in the software. We validate our profiling method through an empirical experiment on two consecutive releases of a commercial software product. We demonstrate how the method can be applied by organizations and provide an analysis of the software related changes in energy consumption. Our results show that, despite a lack of precise measurements, energy consumption differences between releases of a software product can be quantified down to the level of individual processes. Additionally, the results provide insights on how specific software changes might affect energy consumption.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {523–532},
numpages = {10},
keywords = {software product, energy efficiency, software architecture, profiling},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2593743.2593746,
author = {Sierszecki, Krzysztof and Steffens, Michaela and Fogdal, Thomas and Savolainen, Juha and Mikkonen, Tommi},
title = {Towards Green Power Electronics: Software Controllers and Domain Knowledge},
year = {2014},
isbn = {9781450328449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593743.2593746},
doi = {10.1145/2593743.2593746},
abstract = {One of the key challenges of green software is that various aspects have an impact to the overall energy consumption over the lifetime of a system operated by software. In particular, in the field of industrial applications, where embedded devices cooperate with many IT systems to make the industrial processes more efficient, to reduce waste or raw materials, and to save the environment, the concept of green software becomes unclear. In this paper, we address the green aspects of software in different phases – software construction, software execution, and software control in both inside an individual component and as a part of a complete industrial application. Furthermore, we demonstrate that the insight into system knowledge, not aspects related to software per se, is the key to create truly green software. Consequently, when considering truly software green, the focus is to be placed on the system level savings for embedded systems at the highest possible level where domain knowledge can be taken into account, not on software development or execution.},
booktitle = {Proceedings of the 3rd International Workshop on Green and Sustainable Software},
pages = {17–22},
numpages = {6},
keywords = {Green software, embedded control systems, green systems, software development, software product lines, variable speed drives},
location = {Hyderabad, India},
series = {GREENS 2014}
}

@inproceedings{10.1145/2342356.2342398,
author = {Gao, Peter Xiang and Curtis, Andrew R. and Wong, Bernard and Keshav, Srinivasan},
title = {It's Not Easy Being Green},
year = {2012},
isbn = {9781450314190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2342356.2342398},
doi = {10.1145/2342356.2342398},
abstract = {Large-scale Internet applications, such as content distribution networks, are deployed across multiple datacenters and consume massive amounts of electricity. To provide uniformly low access latencies, these datacenters are geographically distributed and the deployment size at each location reflects the regional demand for the application. Consequently, an application's environmental impact can vary significantly depending on the geographical distribution of end-users, as electricity cost and carbon footprint per watt is location specific. In this paper, we describe FORTE: Flow Optimization based framework for request-Routing and Traffic Engineering. FORTE dynamically controls the fraction of user traffic directed to each datacenter in response to changes in both request workload and carbon footprint. It allows an operator to navigate the three-way tradeoff between access latency, carbon footprint, and electricity costs and to determine an optimal datacenter upgrade plan in response to increases in traffic load. We use FORTE to show that carbon taxes or credits are impractical in incentivizing carbon output reduction by providers of large-scale Internet applications. However, they can reduce carbon emissions by 10% without increasing the mean latency nor the electricity bill.},
booktitle = {Proceedings of the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {211–222},
numpages = {12},
keywords = {green computing, energy},
location = {Helsinki, Finland},
series = {SIGCOMM '12}
}

@inproceedings{10.1145/1401032.1401044,
author = {Rijpkema, Hans and Steele, Gregory and Derksen, Matt},
title = {It's Not Easy Being Green},
year = {2008},
isbn = {9781605583433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1401032.1401044},
doi = {10.1145/1401032.1401044},
booktitle = {ACM SIGGRAPH 2008 Talks},
articleno = {9},
numpages = {1},
location = {Los Angeles, California},
series = {SIGGRAPH '08}
}

@inproceedings{10.1109/CCGRID.2009.89,
author = {Niyato, Dusit and Chaisiri, Sivadon and Sung, Lee Bu},
title = {Optimal Power Management for Server Farm to Support Green Computing},
year = {2009},
isbn = {9780769536224},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGRID.2009.89},
doi = {10.1109/CCGRID.2009.89},
abstract = {Green computing is a new paradigm of designing the computer system which considers not only the processing performance but also the energy efficiency. Power management is one of the approaches in green computing to reduce the power consumption in distributed computing system. In this paper, we first propose an optimal power management (OPM) used by a batch scheduler in a server farm. This OPM observes the state of a server farm and makes the decision to switch the operation mode (i.e., active or sleep) of the server to minimize the power consumption while the performance requirements are met. An optimization problem based on constrained Markov decision process (CMDP) is formulated and solved to obtain an optimal decision of OPM. Given that OPM is used in the server farm, then an assignment of users to the server farms by a job broker is considered. This assignment is to ensure that the cost due to power consumption and network transportation is minimized. The performance of the system is extensively evaluated. The result shows that with OPM the job waiting time can be maintained below the maximum threshold while the power consumption is much smaller than that without OPM.},
booktitle = {Proceedings of the 2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid},
pages = {84–91},
numpages = {8},
keywords = {Markov decision process, Green computing, optimal power management},
series = {CCGRID '09}
}

@inproceedings{10.1145/1864431.1864496,
author = {Schmidt, Albrecht and Friday, Adrian and Gellersen, Hans W. and Mattern, Friedemann},
title = {Ubiquitous Computing for Sustainable Energy (UCSE2010)},
year = {2010},
isbn = {9781450302838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1864431.1864496},
doi = {10.1145/1864431.1864496},
abstract = {Providing sustainable energy is one of the fundamental challenges for mankind. With energy usage being a part of everyday activities and with the increasingly diversity of energy creation this is an inherently multi-disciplinary problem. Transportation and travel, heating and cooling, manu-facturing and production are major areas in which energy is used and all these domains become more and more linked to ubiquitous computing. With an increase in decentralized energy provision, ranging from energy harvesting in devices to personal green power plants, a great potential for creating sustainable energy arises, however at the cost of a higher complexity of the distribution network and storage mechanisms. Overall we believe that research in ubiquitous computing can provide important contributions for a world with sustainable energy. In this workshop we hope to get people from different disciplines together to share their visions and insights on how to conserve, efficiently produce, use, and distribute energy.},
booktitle = {Proceedings of the 12th ACM International Conference Adjunct Papers on Ubiquitous Computing - Adjunct},
pages = {495–496},
numpages = {2},
keywords = {energy conservation, smart grid, green ict, smart energy, e-energy, energy efficiency, energy harvesting},
location = {Copenhagen, Denmark},
series = {UbiComp '10 Adjunct}
}

@inproceedings{10.1145/2884781.2884810,
author = {Manotas, Irene and Bird, Christian and Zhang, Rui and Shepherd, David and Jaspan, Ciera and Sadowski, Caitlin and Pollock, Lori and Clause, James},
title = {An Empirical Study of Practitioners' Perspectives on Green Software Engineering},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884810},
doi = {10.1145/2884781.2884810},
abstract = {The energy consumption of software is an increasing concern as the use of mobile applications, embedded systems, and data center-based services expands. While research in green software engineering is correspondingly increasing, little is known about the current practices and perspectives of software engineers in the field. This paper describes the first empirical study of how practitioners think about energy when they write requirements, design, construct, test, and maintain their software. We report findings from a quantitative, targeted survey of 464 practitioners from ABB, Google, IBM, and Microsoft, which was motivated by and supported with qualitative data from 18 in-depth interviews with Microsoft employees. The major findings and implications from the collected data contextualize existing green software engineering research and suggest directions for researchers aiming to develop strategies and tools to help practitioners improve the energy usage of their applications.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {237–248},
numpages = {12},
keywords = {empirical study, green software engineering, survey},
location = {Austin, Texas},
series = {ICSE '16}
}

@proceedings{10.1145/2088996,
title = {GCM '11: Green Computing Middleware on Proceedings of the 2nd International Workshop},
year = {2011},
isbn = {9781450310642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Green computing is nowadays a major challenge for most IT organizations that involve medium and large scale distributed infrastructures like Grids, Clouds and Clusters. Many organizations rely on data centers to obtain the required computing power. Two strategies are generally followed: either building and managing a data center within the organization itself, or externalizing its computing infrastructure which is therefore managed by a third-party hosting provider (or data center). Many studies show that old-generation data centers are not designed to be energy efficient and are not used at their full capacity which results in a huge source of waste. Thus, new generations of green data centers and middleware are designed to improve their efficiency in terms of Power Usage Efficiency (PUE), Carbon Usage Efficiency (CUE), Water Usage Efficiency (WUE), Data Center Infrastructure Efficiency (DCIE) and Virtualization Usage Effectiveness (VUE). The management of these infrastructures have to take into account these previous metrics, which implies that it has to be adapted according to its usage. Most of these adaptations cannot be performed manually and have to be automated in order to be reactive and accurate. In today's distributed computing environments, energy management may be implemented in different layers, be it at the hardware level, operating system level or middleware level. Therefore several energy managers may be implemented in these different levels, and they have to take globally consistent decisions. Moreover Green IT is not restricted to energy management. Previously enumerated metrics (PUE, CUE, WUE, DCIE, VUE...) show that many factors (materialized by sensors and actuators) may be taken into account in order to be green efficient. Again, it means that many energy managers will have to be implemented to control these factors, which raises a consistency problem.The GCM workshop focuses on next generation middlewares that will require solutions for all aspects of green computing such as energy efficiency, carbon footprint reduction and cooling management. These middleware must take into account the impact of green computing on the traditional distributed system issues like Dependability, Scalabilitity, Performance and Configuration management. The GCM workshop, building on the success of last year's event, sought to further develop a roadmap for research on the essential middleware abstractions and infrastructures for Green computing and to provide a forum to a wide audience from both the academia and the industry to discuss recent and innovative results in the field.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/1518701.1518860,
author = {Chetty, Marshini and Brush, A.J. Bernheim and Meyers, Brian R. and Johns, Paul},
title = {It's Not Easy Being Green: Understanding Home Computer Power Management},
year = {2009},
isbn = {9781605582467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1518701.1518860},
doi = {10.1145/1518701.1518860},
abstract = {Although domestic computer use is increasing, most efforts to reduce energy use through improved power management have focused on computers in the workplace. We studied 20 households to understand how people use power management strategies on their home computers. We saw computers in the home, particularly desktop computers, are left on much more than they are actively used suggesting opportunities for economic and energy savings. However, for most of our participants, the economic incentives were too minor to motivate them to turn off devices when not in use, especially given other frustrations such as long boot up times. We suggest research directions for home computer power management that could help users be more green without having to dramatically change their home computing habits.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1033–1042},
numpages = {10},
keywords = {home computer use, sustainability, power management},
location = {Boston, MA, USA},
series = {CHI '09}
}

@inproceedings{10.1145/3310273.3323427,
author = {Gillani, G. A. and Kokkeler, A. B. J.},
title = {Go Green Radio Astronomy: Approximate Computing Perspective: Opportunities and Challenges: POSTER},
year = {2019},
isbn = {9781450366854},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3310273.3323427},
doi = {10.1145/3310273.3323427},
abstract = {Modern radio telescopes require highly energy/power-efficient computing systems. Signal processing pipelines of such radio telescopes are dominated by accumulation based iterative processes. As the input signal received at a radio telescope is regarded as Gaussian noise, employing approximate computing looks promising. Therefore, we present opportunities and challenges offered by the approximate computing paradigm to achieve the required efficiency targets.},
booktitle = {Proceedings of the 16th ACM International Conference on Computing Frontiers},
pages = {300–301},
numpages = {2},
keywords = {approximate computing, radio astronomy, power efficiency, iterative workloads, energy efficiency},
location = {Alghero, Italy},
series = {CF '19}
}

@inproceedings{10.1145/3234664.3234672,
author = {Rahman, Abdul Fuad Abdul and Halim, Azni Ab and Alwi, Najwa Hayaati Mohd and Alwi, Kamaruzzaman Seman and Mohamad, Farhan Arif and Taufiq, Mohamad Nasrul and Mohamad, Madihah Zulfa and Abidin, Khairul Azri Zainal},
title = {Measuring Sensor to Cloud Energy Consumption},
year = {2018},
isbn = {9781450364850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234664.3234672},
doi = {10.1145/3234664.3234672},
abstract = {IoT devices must provide seamless connectivity while obeying stringent power and size constraints. Power consumption plays important factor to determine the status and connectivity of Sensor Node. This paper describes a series of simple experiments which measure the energy consumption of two IoT Sensor Nodes transmitting data to the cloud. The experiments will be used to compare the best solution between wire and wireless for IoT Sensor Nodes implementation. The experimental result shows that wireless connection consume more power compared to wire connection. Apart from comparison of two methods, the goal of this paper is also to develop a solid experimental basis, thus setting a better foundation for future research on IoT Sensor Nodes.},
booktitle = {Proceedings of the 2018 2nd High Performance Computing and Cluster Technologies Conference},
pages = {43–47},
numpages = {5},
keywords = {Internet of things (IoT), energy consumption, energy saving, sensor to cloud},
location = {Beijing, China},
series = {HPCCT '18}
}

@proceedings{10.1145/2451605,
title = {GIBSE '13: Proceedings of the 2013 Workshop on Green in/by Software Engineering},
year = {2013},
isbn = {9781450318662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The increasing amount of energy consumption in today's IT solutions significantly contributes to green house gas emissions. "Green Computing" or "Green IT" emphasizes the need for reducing the environmental impacts of IT solutions by reducing their energy consumption and, consequently, their green house gas emissions. Among others, green computing can be achieved in software and by software. While greening by software aims at saving energy (or other resources) by the help of software, greening in software aims at reducing the environmental impact caused by the software itself.The "Green In Software Engineering, Green By Software Engineering" (GIBSE) workshop aims to bring together academic and industrial researchers to share their experience in achieving the green-ness in and by software. You can find more information about the GIBSE workshop at the website located at: http://trese.ewi.utwente.nl/workshops/GIBSE.These proceedings contain a selection of papers that were submitted for the GIBSE 2013 workshop that will be held as part of the MODULARITY: aosd-13 conference in Fukuoka, Japan, March 24-29, 2013. We would like to thank the members of the program committee for their efforts in reviewing the papers and the authors for their paper contributions. We hope that you will find this program interesting and welcome you to participate in the GIBSE workshop.},
location = {Fukuoka, Japan}
}

@inproceedings{10.1145/3018896.3056803,
author = {Azni, A H and Rahman, Abdul Fuad Abdul and Alwi, Najwa Hayaati Mohd and Seman, Kamaruzzaman},
title = {Measuring Sensor to Cloud Energy Consumption},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3056803},
doi = {10.1145/3018896.3056803},
abstract = {IoT devices must provide seamless connectivity while obeying stringent power and size constraints. Power consumption plays important factor to determine the status and connectivity of Sensor Node. This paper describes a series of simple experiments which measure the energy consumption of two IoT Sensor Nodes transmitting data to the cloud. The experiments will be used to compare the best solution between wire and wireless for IoT Sensor Nodes implementation. The experimental result shows that wireless connection consume more power compared to wire connection. Apart from comparison of two methods, the goal of this paper is also to develop a solid experimental basis, thus setting a better foundation for future research on IoT Sensor Nodes.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {186},
numpages = {6},
keywords = {internet of things (IoT)), sensor to cloud, energy consumption, energy saving, wireless sensor network (WSN)},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/2333660.2333662,
author = {Bose, Pradip},
title = {Energy-Secure Computing},
year = {2012},
isbn = {9781450312493},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2333660.2333662},
doi = {10.1145/2333660.2333662},
abstract = {The "power wall" has forced chip and system architects to design with smaller margins between nominal and worst-case operating points. Localized hot spots and temperature gradients exacerbate lifetime reliability problems. Smaller voltage margins make processors more vulnerable to inductive noise on the voltage rails, as well as soft errors induced by high energy particle incidence. The problem of process variation presents another obstacle to sustained performance growth in the late CMOS design era. At the same time, the emerging phase change memory (a promising technology for future low power, dense storage in systems) is vulnerable to malicious attacks that can reduce the lifetime of an already wear-out prone technology. These issues have all led to R&amp;D in "better than worst-case" design principles. Dynamic power and thermal management control loops have already become an integral part of chip and system design. New research in wearout and general reliability management have recently been published. These new generation management protocols have, however, opened up other sources of concern: e.g. potential security holes exposed by the integrated control loops and system safety issues triggered by potential violations of power or thermal limits imposed by the original specification. We coin the term "Energy-Secure System Architectures" to cover the range of research being pursued within industry and academia in order to ensure robust and secure functionality, while meeting the energy-related constraints of the emerging "green computing" era. This keynote speech attempts to provide a summary overview of the problem and solution spaces around the theme of energy-secure computing -- with a special focus on servers and extreme-scale systems.},
booktitle = {Proceedings of the 2012 ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {1–2},
numpages = {2},
keywords = {system architecture, energy-secure computing, extreme-scale systems, power wall, servers},
location = {Redondo Beach, California, USA},
series = {ISLPED '12}
}

@article{10.1145/3286688,
author = {Boukerche, Azzedine and Guan, Shichao and Grande, Robson E. De},
title = {Sustainable Offloading in Mobile Cloud Computing: Algorithmic Design and Implementation},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3286688},
doi = {10.1145/3286688},
abstract = {Mobile Cloud Computing (MCC) has been extensively explored to be applied as a vital tool to enhance the capabilities of mobile devices, increasing computing power, expanding storage capacity, and prolonging battery life. Offloading works as the fundamental feature that enables MCC to relieve task load and extend data storage through an accessible cloud resource pool. Several initiatives have drawn attention to delivering MCC-supported energy-oriented offloading as a method to cope with a lately steep increase in the number of rich mobile applications and the enduring limitations of battery technologies. However, MCC offloading relieves only the burden of energy consumption of mobile devices; performance concerns about Cloud resources, in most cases, are not considered when dynamically allocating them for dealing with mobile tasks. The application context of MCC, encompassing urban computing, aggravates the situation with very large-scale scenarios, posing as a challenge for achieving greener solutions in the scope of Cloud resources. Thus, this article gathers and analyzes recent energy-aware offloading protocols and architectures, as well as scheduling and balancing algorithms employed toward Cloud green computing. This survey provides a comparison among system architectures by identifying their most notable advantages and disadvantages. The existing enabling frameworks are categorized and compared based on the stage of the task offloading process and resource management types, describing current open challenges and future research directions.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {11},
numpages = {37},
keywords = {Mobile Cloud Computing, resource, energy consumption, offloading}
}

@inproceedings{10.1145/2330784.2330788,
author = {Phan, Dung H. and Suzuki, Junichi and Carroll, Raymond and Balasubramaniam, Sasitharan and Donnelly, William and Botvich, Dmitri},
title = {Evolutionary Multiobjective Optimization for Green Clouds},
year = {2012},
isbn = {9781450311786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330784.2330788},
doi = {10.1145/2330784.2330788},
abstract = {As Internet data centers (IDCs) have been increasing in scale and complexity, they are currently a significant source of energy consumption and CO2 emission. This paper proposes and evaluates a new framework to operate a federation of IDCs in a "green" way. The proposed framework, called Green Monster, dynamically moves services (i.e., workload) across IDCs for increasing renewable energy consumption while maintaining their performance. It makes decisions of service migration and placement with an evolutionary multiobjective optimization algorithm (EMOA) that evolves a set of solution candidates through global and local search processes. The proposed EMOA seeks the Pareto-optimal solutions by balancing the trade-offs among conflicting optimization objectives such as renewable energy consumption, cooling energy consumption and response time performance.},
booktitle = {Proceedings of the 14th Annual Conference Companion on Genetic and Evolutionary Computation},
pages = {19–26},
numpages = {8},
keywords = {cloud computing, renewable energy, evolutionary multiobjective optimization, sustainability, internet data centers},
location = {Philadelphia, Pennsylvania, USA},
series = {GECCO '12}
}

@inproceedings{10.1145/3290420.3290456,
author = {Cheng, Yulun and Zhao, Peng and Wang, Lei},
title = {User-Oriented Green Computation in Small Cell Networks with Mobile Edge Computing},
year = {2018},
isbn = {9781450365345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290420.3290456},
doi = {10.1145/3290420.3290456},
abstract = {Mobile edge computing (MEC) is significant in reducing the energy consumption of user equipment (UE), since the computation task can be transferred to MEC server through offloading. However, conventional offloading only considered the scenario in which the MEC server is integrated with macro base station. In this paper, we investigate the energy consumption of the UE for small cell networks integrated with MEC. The problem is firstly formulated as a mixed integer nonlinear programming. Through variable and problem transformation, it is decomposed by the alternating direction method of multipliers. And then, a greedy scheme is proposed to solve the integer optimization. On the basis of that, a distributed green offloading algorithm is proposed. Simulation results show that the proposed scheme can converge to the suboptimal solution, with slight gap comparing with the optimal one.},
booktitle = {Proceedings of the 4th International Conference on Communication and Information Processing},
pages = {246–250},
numpages = {5},
keywords = {wireless virtualization, mobile edge computing, computation offloading},
location = {Qingdao, China},
series = {ICCIP '18}
}

@inproceedings{10.1145/2491266.2491271,
author = {Lu, You and Zhou, Biao and Tung, Lung-Chih and Gerla, Mario and Ramesh, Ashwin and Nagaraja, Lohith},
title = {Energy-Efficient Content Retrieval in Mobile Cloud},
year = {2013},
isbn = {9781450321808},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491266.2491271},
doi = {10.1145/2491266.2491271},
abstract = {Mobile cloud computing (MCC) has recently been drawing increased attention in academia as well as industry. Content retrieval is a critical service, for many mobile cloud applications and in turns relies on other resources and tools, e.g., internal storage, content searching and sharing, etc. Previous studies have shown that conventional ICN interest query schemes and content searching architectures, if not properly designed, can cause significant performance degradation and energy consumption, especially for large scale MANETs.In this paper, we specifically address the scalability and energy efficiency of the content retrieval scheme in mobile cloud computing. We propose a direction-selective forwarding scheme for the content query method that decreases traffic overhead and energy cost caused by duplicate copies of the query packets. We also advocate the parallel search method of multiple caches to increase the hit rate. Simulation experiments show that the proposed scheme yields significant improvements in efficiency and scalability for the content retrieval in large scale MANETs.},
booktitle = {Proceedings of the Second ACM SIGCOMM Workshop on Mobile Cloud Computing},
pages = {21–26},
numpages = {6},
keywords = {content retrieval, interest dissemination, mobile cloud},
location = {Hong Kong, China},
series = {MCC '13}
}

@inproceedings{10.1145/2426656.2426666,
author = {Liu, Jie and Priyantha, Bodhi and Hart, Ted and Ramos, Heitor S. and Loureiro, Antonio A. F. and Wang, Qiang},
title = {Energy Efficient GPS Sensing with Cloud Offloading},
year = {2012},
isbn = {9781450311694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2426656.2426666},
doi = {10.1145/2426656.2426666},
abstract = {Location is a fundamental service for mobile computing. Typical GPS receivers, although widely available, consume too much energy to be useful for many applications. Observing that in many sensing scenarios, the location information can be post-processed when the data is uploaded to a server, we design a Cloud-Offloaded GPS (CO-GPS) solution that allows a sensing device to aggressively duty-cycle its GPS receiver and log just enough raw GPS signal for post-processing. Leveraging publicly available information such as GNSS satellite ephemeris and an Earth elevation database, a cloud service can derive good quality GPS locations from a few milliseconds of raw data. Using our design of a portable sensing device platform called CLEO, we evaluate the accuracy and efficiency of the solution. Compared to more than 30 seconds of heavy signal processing on standalone GPS receivers, we can achieve three orders of magnitude lower energy consumption per location tagging.},
booktitle = {Proceedings of the 10th ACM Conference on Embedded Network Sensor Systems},
pages = {85–98},
numpages = {14},
keywords = {coarse-time navigation, cloud-offloading, location, assisted GPS},
location = {Toronto, Ontario, Canada},
series = {SenSys '12}
}

@inproceedings{10.1145/1980022.1980321,
author = {Siddavatam, I. and Johri, E. and Patole, D.},
title = {Optimization of Load Balancing Algorithm for Green IT},
year = {2011},
isbn = {9781450304498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1980022.1980321},
doi = {10.1145/1980022.1980321},
abstract = {This paper is focused on calculating the processor utilization of various machines having different types of processor configurations employed in data centers by providing solutions to reduce the energy cost component of companies total IT budget. In this paper different parameters like CPU Utilization and Power Utilization on different machines installed in data centers have been analyzed. Also calculation of power required by different machines of different configurations in different modes of operations like active mode, hibernation mode and standby mode is been performed. Here an algorithm has been developed that will calculate the processor utilization by different machines according to the Load Distribution in a network and propose a strategy to utilize minimum possible energy by optimal resource utilization.},
booktitle = {Proceedings of the International Conference &amp; Workshop on Emerging Trends in Technology},
pages = {1344–1346},
numpages = {3},
keywords = {processor utilization, green IT, energy consumption, processor sharing computer systems},
location = {Mumbai, Maharashtra, India},
series = {ICWET '11}
}

@inproceedings{10.1145/1878335.1878392,
author = {Kimmel-Smith, Stacey E. and Sakasitz, Stephen},
title = {It's Not Easy Being Green: Students and "the Problem with Printing"},
year = {2010},
isbn = {9781450300032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878335.1878392},
doi = {10.1145/1878335.1878392},
abstract = {As green initiatives become more prevalent on campus, university administrators are seeking ways to reduce consumption of resources. One area commonly targeted in technology services is use of printing hardware, paper, and toner. At Lehigh University, printing at public site labs has traditionally been free. Though popular, free printing creates a "false economy" that encourages waste and abuse of resources. The challenge to Library and Technology Services (LTS) is to raise student awareness of the problems with free printing and engage them in finding solutions..LTS staff worked with students taking a Politics of the Environment course to produce a video, "The Problem with Printing." During Earthweek 2010, LTS disseminated the five minute video presenting photos of paper waste, student interviews, statistics/facts, and solutions (specifically a print management system). The goal was to help students understand that the system of free printing is unsustainable and to increase student acceptance of printing limits. This paper will offer some background on "the problem with printing" on campuses nationwide and at Lehigh, the solutions available, and the marketing campaign that LTS undertook to raise awareness of printing waste. The video is available at: http://www.youtube.com/watch?v=4DqLqW4Zkw},
booktitle = {Proceedings of the 38th  Annual ACM SIGUCCS Fall Conference: Navigation and Discovery},
pages = {223–228},
numpages = {6},
keywords = {printing, paper, sustainability, printers, environmental, marketing, papercut, students, waste},
location = {Norfolk, Virginia, USA},
series = {SIGUCCS '10}
}

@inproceedings{10.5555/3566055.3566075,
author = {Dantas, Jaime and Khazaei, Hamzeh and Litoiu, Marin},
title = {Green LAC: Resource-Aware Dynamic Load Balancer for Serverless Edge Computing Platforms},
year = {2022},
publisher = {IBM Corp.},
address = {USA},
abstract = {Edge computing is a distributed computing paradigm that brings computation resources closer to the sources of data. This recently­introduced model enables low latency applications to access com­puting and storage services deployed on-premises. In this paper, we present GreenLAC, a load balancer and reverse proxy for supporting serverless deployments of edge-core IoT applications. GreenLAC enables applications running on resource-constrained edge nodes to leverage neighbours edge nodes and the core cloud for real-time processing of workloads. It monitors the host hardware and dis­tributes requests according to predefined configurations to prevent failures at the edge. We performed rigorous experiments on AWS cloud and with a real-world application deployment using IoT de­vices and edge nodes. Preliminary results show that GreenLAC can increase the processing capabilities of hardware-restricted edge ma­chines when using core resources in combination with serverless functions for IoT applications.},
booktitle = {Proceedings of the 32nd Annual International Conference on Computer Science and Software Engineering},
pages = {169–174},
numpages = {6},
keywords = {Serverless Computing, Function as a Service, Edge Computing, AWS Greengrass, IoT},
location = {Toronto, Canada},
series = {CASCON '22}
}

@inproceedings{10.1145/3471988.3472013,
author = {Xin, Bai and Wei Keng, Zhou and Zi Yao, Chen and Zi Han, Huang and Qing Long, Lai and Jing Qi, Wang},
title = {How Green Finance Sparks Sustainability: Using Big Data Analysis and Visualization Software to Unite Future Economic and Social Value Potential},
year = {2021},
isbn = {9781450390217},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3471988.3472013},
doi = {10.1145/3471988.3472013},
abstract = {The core concept of socialism with Chinese characteristics for the new era is to promote the optimization and upgrading of the economic system and the construction of sustainable ecological civilization. In the wake of the COVID-19, it has become a major issue for countries around the world to pursue green recovery. Green is a necessary condition for sustainable development, finance is the leading force of social economy, and the development of green finance is the core call of today's era. Guangdong, as the main force of the national economic lifeline, took the lead in green finance innovation and promoted the transformation and adjustment of leading industries. At present, the banking industry has repeatedly disclosed the environment, society and governance (ESG) in its social responsibility reports in order to achieve the strategic goal of carbon peak and carbon neutral, but there is a lack of systematic review on the measures and implementation. Aiming at objective problems, this paper mainly discusses how green finance stimulates sustainability and explores the value potential of the future economy and society. Based on this, this paper selected 300 literatures from the Web of Science (WOS) database, mapped the coword cluster, and analyzed their annual trend, topic scope, literature sources, etc. With the help of big data analysis technology and visualization software function, scientometrics is used to demonstrate the possibility and feasibility of the research contents in relevant fields, and to produce cutting-edge academic achievements with insight. In order to achieve the ultimate goal of green development with capital and financial design for diversified and deep thinking, to provide reference value theory for co-construction environment, data-driven investment scale and sustainable development, to accelerate the green finance reform in Guangdong Province and even the country to make a forward-looking small contribution.},
booktitle = {Proceedings of the 2021 2nd International Conference on Internet and E-Business},
pages = {145–149},
numpages = {5},
keywords = {Green Finance, Social Responsibility, Sustainable Development, Social Science Literature Review, Economic Transformation},
location = {Barcelona, Spain},
series = {ICIEB '21}
}

@article{10.1145/2367736.2367744,
author = {Kant, Krishna and Murugan, Muthukumar and Du, David H. C.},
title = {Enhancing Data Center Sustainability through Energy-Adaptive Computing},
year = {2012},
issue_date = {October 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/2367736.2367744},
doi = {10.1145/2367736.2367744},
abstract = {The sustainability concerns of Information Technology (IT) go well beyond energy-efficient computing and require techniques for minimizing environmental impact of IT infrastructure over its entire life-cycle. Traditionally, IT infrastructure is overdesigned at all levels from chips to entire data centers and ecosystem; the paradigm explored in this article is to replace overdesign with rightsizing coupled with smarter control, henceforth referred to as Energy-Adaptive Computing or EAC. The article lays out the challenges of EAC in various environments in terms of the adaptation of the workload and the infrastructure to cope with energy and cooling deficiencies. The article then focuses on implementing EAC in a data center environment, and addresses the problem of simultaneous energy demand and energy supply regulation at multiple levels, work, from servers to the entire data center. The proposed control scheme adapts the assignments of tasks to servers in a way that can cope with the varying energy limitations. The article also presents some experimental results to show how the scheme can continue to meet Quality of Service (QoS) requirements of tasks under energy limitations.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {nov},
articleno = {33},
numpages = {20},
keywords = {energy adaption, workload adaptation, Energy efficiency, energy- and thermal-adaptive computing}
}

@inproceedings{10.5555/2492708.2492755,
author = {Bartolini, Andrea and Sadri, MohammadSadegh and Furst, John-Nicholas and Coskun, Ayse Kivilcim and Benini, Luca},
title = {Quantifying the Impact of Frequency Scaling on the Energy Efficiency of the Single-Chip Cloud Computer},
year = {2012},
isbn = {9783981080186},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Dynamic frequency and voltage scaling (DVFS) techniques have been widely used for meeting energy constraints. Single-chip many-core systems bring new challenges owing to the large number of operating points and the shift to message passing interface (MPI) from shared memory communication. DVFS, however, has been mostly studied on single-chip systems with one or few cores, without considering the impact of the communication among cores. This paper evaluates the impact of frequency scaling on the performance and power of many-core systems with MPI. We conduct experiments on the Single-Chip Cloud Computer (SCC), an experimental many-core processor developed by Intel. The paper first introduces the run-time monitoring infrastructure and the application suite we have designed for an in-depth evaluation of the SCC. We provide an extensive analysis quantifying the effects of frequency perturbations on performance and energy efficiency. Experimental results show that run-time communication patterns lead to significant differences in power/performance tradeoffs in many-core systems with MPI.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {181–186},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '12}
}

@inproceedings{10.1145/3479162.3479171,
author = {Spina, Roberto and Tramontana, Emiliano},
title = {An Image-Processing Approach for Computing the Size of Green Areas in Cities},
year = {2021},
isbn = {9781450390071},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479162.3479171},
doi = {10.1145/3479162.3479171},
abstract = {The delimitation of green areas from urban ones is a fundamental operation for a correct estimate of green spaces within cities. Specific GIS applications assist users in the tracing of boundaries and the calculation of lengths and areas. However, when using such techniques, the main limitation concerns the analysis of irregularly shaped areas. For them, tracing outlines that overlap the original ones is performed manually, hence difficult, error prone and time consuming. This paper proposes a novel approach that is automatically performed by means of a Python-based application to recognize boundaries and compute the main geometric parameters of urban and green areas. Such operations are based on new algorithms that give an innovative character to the entire application. The application was tested in the territory of Kamakura, a Japanese city that embodies the “City Country Fingers” design pattern characterized by extensive intersections between the vegetation, coming from the peripheral areas, and the urban center. Their complexity and irregularity are a proper testbed to evaluate the behavior of the application in the presence of irregular areas. The obtained results confirmed the reliability of the proposed approach and the efficiency of the application.},
booktitle = {Proceedings of the 9th International Conference on Computer and Communications Management},
pages = {59–65},
numpages = {7},
keywords = {JSON query, Image-Processing, GIS, Additional Key Words and Phrases: Border detection},
location = {Singapore, Singapore},
series = {ICCCM '21}
}

@inproceedings{10.1145/3436829.3436846,
author = {Danial, Christina William and Saroit, Imane Aly and Mohamed, Shaimaa M.},
title = {Energy Efficient Ant Colony Cloud Offloading Algorithm (EACO)},
year = {2021},
isbn = {9781450377218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3436829.3436846},
doi = {10.1145/3436829.3436846},
abstract = {Mobile cloud computing is a computing paradigm that helps to reduce the application energy consumption, so increases the battery life. Mobile application is divided to fine grained tasks with sequential and parallel topology. Offloading application tasks to cloud provides more energy but increases the completion time. The scheduling of tasks between executing in mobile device and cloud is more important to limit the increasing in the completion time. In this paper, energy efficient ant colony cloud offloading algorithm (EACO) is developed to reduce the energy consumption with the hard condition of completion time. EACO decreases the energy by an average 24%-59% with increasing in completion time by 3.6%-28% compared with previous work. The algorithm is verified in different experiments with different tasks input data and computation workload.},
booktitle = {Proceedings of the 9th International Conference on Software and Information Engineering},
pages = {190–197},
numpages = {8},
keywords = {cloud computing, MCC, Ant colony algorithm},
location = {Cairo, Egypt},
series = {ICSIE '20}
}

@article{10.1145/1666420.1666438,
author = {Brown, David J. and Reams, Charles},
title = {Toward Energy-Efficient Computing},
year = {2010},
issue_date = {March 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/1666420.1666438},
doi = {10.1145/1666420.1666438},
abstract = {What will it take to make server-side computing more energy efficient?},
journal = {Commun. ACM},
month = {mar},
pages = {50–58},
numpages = {9}
}

@inproceedings{10.1145/1791314.1791316,
author = {Mattern, Friedemann and Staake, Thorsten and Weiss, Markus},
title = {ICT for Green: How Computers Can Help Us to Conserve Energy},
year = {2010},
isbn = {9781450300421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1791314.1791316},
doi = {10.1145/1791314.1791316},
abstract = {Information and communication technology (ICT) consumes energy, but is also an important means of conserving energy. Conventionally, it has done so by optimizing the performance of energy-using systems and processes in industry and commerce. In the near future, ICT will also play a critical role in supporting the necessary paradigm shifts within the energy sector towards more sustainable electricity generation. However, with the advent of "smart" technology from the field of ubiquitous computing, further ways of reducing growing levels of domestic energy consumption are now emerging. With this in mind, we discuss how getting consumers "into the loop" can achieve energy savings on top of the efficiency gains resulting from automated systems, and we describe a prototype application aimed at inducing behavioral change by providing direct feedback on household electricity consumption.},
booktitle = {Proceedings of the 1st International Conference on Energy-Efficient Computing and Networking},
pages = {1–10},
numpages = {10},
keywords = {smart meter, feedback systems, advanced metering, smart grid, behavioral change, energy conservation},
location = {Passau, Germany},
series = {e-Energy '10}
}

@inproceedings{10.1145/3041021.3054768,
author = {Gong, Xiaoxue and Guo, Lei and Ning, Zhaolong},
title = {Green Virtual Network Embedding for Collaborative Edge Computing in Environment-Friendly Optical-Wireless Networks},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3054768},
doi = {10.1145/3041021.3054768},
abstract = {To reduce the cost and delay caused by transferring data to the remote cloud, the trend is to design an intelligent Edge Device (ED) for preliminary data processing, i.e., edge computing. Some EDs usually form a group where they wirelessly communicate with each other. Different ED groups are interconnected by optical fiber cables. Through coordinating the use of ED groups, we can perform a collaborative edge computing in a hybrid network where a cost-efficient optical-wireless convergence is achieved by virtualization. In this paper, we use the virtual network to describe one computing-application's requirement for the substrate resource, and we investigate how embed multiple virtual networks onto the common network infrastructure. In our approach, a graph-cutting algorithm is firstly utilized to embed as many virtual networks as possible onto the specified EDs within the same group. However, a single ED group cannot handle all computing applications competing for limited wireless and computing resources. To solve this challenging problem, we transform the virtual networks-impossibly embedded onto the same ED group into new ones processed by ED groups. Simulations results demonstrate the green feature of our solution: 1) the total transmitting power assigned for EDs is effectively reduced using the graph cutting algorithm provided that all of computing applications can be solved by a single ED group; 2) our method accepts more virtual networks with the improvement ratio of 77%, through the coordination of ED groups. In addition, there is a good match between the algorithm result and the optimal number of consumed wavelengths per optical fiber cable.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1531–1536},
numpages = {6},
keywords = {green virtual network embedding, environment-friendly opticalwireless network, collaborative edge computing},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/2768510.2768541,
author = {Wang, Cheng and Nasiriani, Neda and Kesidis, George and Urgaonkar, Bhuvan and Wang, Qian and Chen, Lydia Y. and Gupta, Aayush and Birke, Robert},
title = {Recouping Energy Costs From Cloud Tenants: Tenant Demand Response Aware Pricing Design},
year = {2015},
isbn = {9781450336093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2768510.2768541},
doi = {10.1145/2768510.2768541},
abstract = {As energy costs become increasingly greater contributors to a cloud provider's overall costs, it is important for the cloud to recoup these energy costs from its tenants for profitability via appropriate pricing design. The poor predictability of real-world tenants' demand and demand responses (DRs) make such pricing design a challenging problem. We formulate a leader-follower game-based cloud pricing framework with the goal of maximizing cloud's profit. The key distinguishing aspect of our approach is our emphasis on modeling both the cloud and its tenants as working with low predictability in their inputs. Consequently, we model them as employing myopic control with short-term predictive models. Our empirical evaluation using tenant trace from IBM production data centers shows that (i) cloud's profit and VM prices are sensitive to the tradeoffs between its energy costs, tenant's demand and DR, and (ii) the cloud's estimation of tenants' demands/DR may significantly affect its profitability.},
booktitle = {Proceedings of the 2015 ACM Sixth International Conference on Future Energy Systems},
pages = {141–150},
numpages = {10},
keywords = {demand response, cloud tenant, pricing design, game},
location = {Bangalore, India},
series = {e-Energy '15}
}

@inproceedings{10.1145/1791314.1791329,
author = {Da Costa, Georges and de Assun\c{c}\~{a}o, Marcos Dias and Gelas, Jean-Patrick and Georgiou, Yiannis and Lef\`{e}vre, Laurent and Orgerie, Anne-C\'{e}cile and Pierson, Jean-Marc and Richard, Olivier and Sayah, Amal},
title = {Multi-Facet Approach to Reduce Energy Consumption in Clouds and Grids: The GREEN-NET Framework},
year = {2010},
isbn = {9781450300421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1791314.1791329},
doi = {10.1145/1791314.1791329},
abstract = {This paper presents an integrated framework for energy savings in large scale distributed systems such as grids and clouds. The framework comprises tools and mechanisms: to measure and log data about the energy consumed by resources; to present this information to users; to involve the users in decisions to reduce the energy consumed by their applications; and to enforce energy reduction decisions automatically while respecting the users' requirements and achieving the resource availability demanded by current services. Experiments demonstrate the energy savings achieved by the proposed mechanisms and explore trade-offs between energy efficiency and performance degradation.},
booktitle = {Proceedings of the 1st International Conference on Energy-Efficient Computing and Networking},
pages = {95–104},
numpages = {10},
location = {Passau, Germany},
series = {e-Energy '10}
}

@inproceedings{10.1145/2832987.2833028,
author = {Kayed, Ahmad and Akijian, Taleen},
title = {Resource Allocation Technique to Obtain Energy Efficient Cloud},
year = {2015},
isbn = {9781450334181},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2832987.2833028},
doi = {10.1145/2832987.2833028},
abstract = {Cloud computing has been featured in the information and communication technology by providing end users by on-demand computing resources. The enormous demand on cloud computing services resulted in setting up data centers around the world with thousands of computer stations. However, these data centers consume huge amount of power thus increasing operational costs in addition to the negative impact on the environment. This paper presents an enhanced resource allocation technique that uses an enhanced resource allocation technique that takes into consideration two factors; the CPU and the RAM.},
booktitle = {Proceedings of the The International Conference on Engineering &amp; MIS 2015},
articleno = {27},
numpages = {4},
keywords = {Data Centers, Cloud Computing, Green Cloud, Virtual Machine},
location = {Istanbul, Turkey},
series = {ICEMIS '15}
}

@article{10.1145/3263959,
author = {Hagimont, Daniel and De Palma, Noel},
title = {Session Details: Extended Papers from GCM 2011: Second International Workshop on Green Computing Middleware},
year = {2012},
issue_date = {July 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0163-5980},
url = {https://doi.org/10.1145/3263959},
doi = {10.1145/3263959},
journal = {SIGOPS Oper. Syst. Rev.},
month = {jul},
numpages = {1}
}

@inproceedings{10.5555/2648668.2648670,
author = {Zhao, Feng},
title = {Energy Efficient Computing: From Milliwatt to Megawatt},
year = {2013},
isbn = {9781479912353},
publisher = {IEEE Press},
abstract = {Energy is an important resource in today's computing systems, from mega data centers to tiny embedded devices. But the energy efficiency of these systems can be limited by our inability to accurately model and predict the energy usage. In this talk, I will describe our research in designing and deploying resource-constrained wireless sensor and mobile systems, and our work on monitoring and optimizing data centers with Internet-scale workloads. I will focus on the principles and tradeoffs learned from working on these systems. The design and optimization for energy efficiency requires a rethinking of the entire stack, from hardware to systems, networking, programming, and all the way to applications.},
booktitle = {Proceedings of the 2013 International Symposium on Low Power Electronics and Design},
pages = {1},
numpages = {1},
location = {Beijing, China},
series = {ISLPED '13}
}

@inproceedings{10.1145/2751957.2751964,
author = {Bandi, Rajendra K. and Bose, Anik Kumar and Saxena, Ashay},
title = {Exploring Green IT Awareness and Adoption among Indian Students},
year = {2015},
isbn = {9781450335577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2751957.2751964},
doi = {10.1145/2751957.2751964},
abstract = {The effect of global warming on our environment has shifted the focus to green technologies worldwide. Subsequently, multiple research studies have attempted to assess awareness around the concept of "Green IT" in different countries. This study explored Green IT awareness, adoption and practice of Green IT among the Indian students' at leading universities and colleges. This study also explored the willingness of Indian students to pay for Green IT. Descriptive statistics, independent-samples t-test and Factor analysis were used to analyze the data. Findings suggest that Indian students are adequately aware of the terms related to Green IT and the specific reasons for its adoption. Moreover, results suggest that Indian students follow Green IT practices; largely dominated by those practices which promote "reducing paper consumption". However, there exist a significant percentage of Indian students who are willing to adopt Green IT, but the relatively higher cost of adoption seems to be an inhibitor.},
booktitle = {Proceedings of the 2015 ACM SIGMIS Conference on Computers and People Research},
pages = {87–96},
numpages = {10},
keywords = {adoption, awareness, green it, practices, willingness to pay},
location = {Newport Beach, California, USA},
series = {SIGMIS-CPR '15}
}

@article{10.1145/3378935,
author = {Cong, Peijin and Zhou, Junlong and Li, Liying and Cao, Kun and Wei, Tongquan and Li, Keqin},
title = {A Survey of Hierarchical Energy Optimization for Mobile Edge Computing: A Perspective from End Devices to the Cloud},
year = {2020},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3378935},
doi = {10.1145/3378935},
abstract = {With the development of wireless technology, various emerging mobile applications are attracting significant attention and drastically changing our daily lives. Applications such as augmented reality and object recognition demand stringent delay and powerful processing capability, which exerts enormous pressure on mobile devices with limited resources and energy. In this article, a survey of techniques for mobile device energy optimization is presented in a hierarchy of device design and operation, computation offloading, wireless data transmission, and cloud execution of offloaded computation. Energy management strategies for mobile devices from hardware and software aspects are first discussed, followed by energy-efficient computation offloading frameworks for mobile applications that trade application response time for device energy consumption. Then, techniques for efficient wireless data communication to reduce transmission energy are summarized. Finally, the execution mechanisms of application components or tasks in various clouds are further described to provide energy-saving opportunities for mobile devices. We classify the research works based on key characteristics of devices and applications to emphasize their similarities and differences. We hope that this survey will give insights to researchers into energy management mechanisms on mobile devices, and emphasize the crucial importance of optimizing device energy consumption for more research efforts in this area.},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {38},
numpages = {44},
keywords = {mobile cloud computing (MCC), mobile edge computing (MEC), wireless communication, mobile devices, energy optimization, mobile computing (MC), Computation offloading}
}

@article{10.1145/3241038,
author = {Gill, Sukhpal Singh and Buyya, Rajkumar},
title = {A Taxonomy and Future Directions for Sustainable Cloud Computing: 360 Degree View},
year = {2018},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3241038},
doi = {10.1145/3241038},
abstract = {The cloud-computing paradigm offers on-demand services over the Internet and supports a wide variety of applications. With the recent growth of Internet of Things (IoT)--based applications, the use of cloud services is increasing exponentially. The next generation of cloud computing must be energy efficient and sustainable to fulfill end-user requirements, which are changing dynamically. Presently, cloud providers are facing challenges to ensure the energy efficiency and sustainability of their services. The use of a large number of cloud datacenters increases cost as well as carbon footprints, which further affects the sustainability of cloud services. In this article, we propose a comprehensive taxonomy of sustainable cloud computing. The taxonomy is used to investigate the existing techniques for sustainability that need careful attention and investigation as proposed by several academic and industry groups. The current research on sustainable cloud computing is organized into several categories: application design, sustainability metrics, capacity planning, energy management, virtualization, thermal-aware scheduling, cooling management, renewable energy, and waste heat utilization. The existing techniques have been compared and categorized based on common characteristics and properties. A conceptual model for sustainable cloud computing has been presented along with a discussion on future research directions.},
journal = {ACM Comput. Surv.},
month = {dec},
articleno = {104},
numpages = {33},
keywords = {sustainability, sustainable cloud computing, cooling management, holistic management, renewable energy, green computing, sustainable cloud datacenters, application design, virtualization, quality of service, thermal-aware scheduling, energy management, cloud datacenters, capacity planning, sustainable metrics, and waste heat utilization, Energy efficiency}
}

@inproceedings{10.1145/3053600.3053613,
author = {Marmaras, Charalampos and Javed, Amir and Rana, Omer and Cipcigan, Liana M.},
title = {A Cloud-Based Energy Management System for Building Managers},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053613},
doi = {10.1145/3053600.3053613},
abstract = {A Local Energy Management System (LEMS) is described to control Electric Vehicle charging and Energy Storage Units within built environments. To this end, the LEMS predicts the most probable half hours for a triad peak, and forecasts the electricity demand of a building facility at those times. Three operational algorithms were designed, enabling the LEMS to (i) flatten the demand profile of the building facility and reduce its peak, (ii) reduce the demand of the building facility during triad peaks in order to reduce the Transmission Network Use of System (TNUoS) charges, and (iii) enable the participation of the building manager in the grid balancing services market through demand side response. The LEMS was deployed on over a cloud-based system and demonstrated on a real building facility in Manchester, UK.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {61–66},
numpages = {6},
keywords = {cloud computing, energy storage, electric vehicles, triad peak estimation, energy management system},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/3034950.3035000,
author = {Gao, Yongqiang and Yu, Lei},
title = {Energy-Aware Load Balancing in Heterogeneous Cloud Data Centers},
year = {2017},
isbn = {9781450348348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3034950.3035000},
doi = {10.1145/3034950.3035000},
abstract = {With the increasing popularity of cloud computing, its large energy consumption cannot only contribute to greenhouse gas emissions, but also result in the rising of the cost of operating a cloud data centers. Therefore, energy-aware load balancing is increasingly becoming a core and challenging issue in cloud computing. In this paper, we propose an energy efficient load balancing algorithm which takes advantage of both dynamic voltage/frequency scaling and virtual machine consolidation to reduce energy consumed by cloud infrastructures. Our experimental results indicate that, compared to a round robin algorithm for load balancing in cloud computing, the proposed algorithm can achieve up to 35.3% energy saving in heterogeneous cloud data center.},
booktitle = {Proceedings of the 2017 International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {80–84},
numpages = {5},
keywords = {Load Balancing, Virtualization, Cloud Computing, Data Center},
location = {Wuhan, China},
series = {ICMSS '17}
}

@inproceedings{10.1109/CCGrid.2013.96,
author = {Diaz, Cesar O. and Castro, Harold and Villamizar, Mario and Pecero, Johnatan E. and Bouvry, Pascal},
title = {Energy-Aware VM Allocation on an Opportunistic Cloud Infrastructure},
year = {2013},
isbn = {9780768549965},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2013.96},
doi = {10.1109/CCGrid.2013.96},
abstract = {UnaCloud is an opportunistic based cloud infrastructure (IaaS) that allows to access on-demand computing capabilities using commodity desktops. Although UnaCloud maximizes the use of idle resources to deploy virtual machines, it does not use energy-efficient resource allocation algorithms. In this paper, we design and develop different energy-aware algorithms to operate in an energy-efficient way and at the same time to guarantee the performance of the UnaCloud users. Performance tests with different algorithms and scenarios using real trace workloads from UnaCloud, show how different policies can change the energy consumption patterns and reduce the energy consumption in the opportunistic cloud infrastructure. The results show that some algorithms can reduce the energy-consumption power up to 30% over the percentage earned by the opportunistic environment.},
booktitle = {Proceedings of the 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {663–670},
numpages = {8},
keywords = {desktop grid, UnaCloud, opportunistic cloud, cloud computing, green computing},
location = {Delft, Netherlands},
series = {CCGRID '13}
}

@inproceedings{10.1109/CCGRID.2010.46,
author = {Beloglazov, Anton and Buyya, Rajkumar},
title = {Energy Efficient Resource Management in Virtualized Cloud Data Centers},
year = {2010},
isbn = {9780769540399},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGRID.2010.46},
doi = {10.1109/CCGRID.2010.46},
abstract = {Rapid growth of the demand for computational power by scientific, business and web-applications has led to the creation of large-scale data centers consuming enormous amounts of electrical power. We propose an energy efficient resource management system for virtualized Cloud data centers that reduces operational costs and provides required Quality of Service (QoS). Energy savings are achieved by continuous consolidation of VMs according to current utilization of resources, virtual network topologies established between VMs and thermal state of computing nodes. We present first results of simulation-driven evaluation of heuristics for dynamic reallocation of VMs using live migration according to current requirements for CPU performance. The results show that the proposed technique brings substantial energy savings, while ensuring reliable QoS. This justifies further investigation and development of the proposed resource management system.},
booktitle = {Proceedings of the 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing},
pages = {826–831},
numpages = {6},
keywords = {Allocation of virtual machines, Cloud computing, Energy efficiency, Energy consumption, Green IT, Virtualization, Live migration of virtual machines, Resource management},
series = {CCGRID '10}
}

@inproceedings{10.5555/2755753.3253947,
author = {Querlioz, Damien and Ghosh, Swaroop},
title = {Session Details: Energy-Efficient Computing},
year = {2015},
isbn = {9783981537048},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
booktitle = {Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition},
location = {Grenoble, France},
series = {DATE '15}
}

@inproceedings{10.1145/3077839.3084026,
author = {Ho, N. T.T. and Gribaudo, M. and Pernici, B.},
title = {Improving Energy Efficiency for Transactional Workloads in Cloud Environments},
year = {2017},
isbn = {9781450350365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3077839.3084026},
doi = {10.1145/3077839.3084026},
abstract = {Research on energy efficiency in data centers has been focusing on reducing energy consumption, and state-of-the-art techniques have been emphasizing on optimizing power and energy consumption at hardware and infrastructure levels of data centers. Although these techniques have achieved significant improvement in reducing the energy consumption of data centers, the increasing heterogeneity of the current workloads call for more holistic approaches to enable optimization at higher levels. The goal of this work is to look for new opportunities to further improve energy efficiency at the level of applications with a focus on transactional workloads. In particular, we propose the model to characterize the energy per job of transactional-based applications. The model is experimentally validated on a real federated cloud infrastructure. Alternative policies to optimize the energy consumption of transactional applications are evaluated on the basis of the model.},
booktitle = {Proceedings of the Eighth International Conference on Future Energy Systems},
pages = {290–295},
numpages = {6},
keywords = {data center, energy efficiency, transactional workloads},
location = {Shatin, Hong Kong},
series = {e-Energy '17}
}

@inproceedings{10.1109/UCC.2014.166,
author = {Alboaneen, Dabiah Ahmed and Pranggono, Bernardi and Tianfield, Huaglory},
title = {Energy-Aware Virtual Machine Consolidation for Cloud Data Centers},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.166},
doi = {10.1109/UCC.2014.166},
abstract = {One of the issues in virtual machine consolidation (VMC) in cloud data centers is categorizing different workloads to classify the state of physical servers. In this paper, we propose a new scheme of host's load categorization in energy-performance VMC framework to reduce energy consumption while meeting the quality of service (QoS) requirement. Specifically the under loaded hosts are classified into three further states, i.e., Under loaded, normal and critical by applying the under load detection algorithm. We also design overload detection and virtual machine (VM) selection policies. The simulation results show that the proposed policies outperform the existing policies in Cloud Sim in terms of both energy and service level agreements violation (SLAV) reduction.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {1010–1015},
numpages = {6},
keywords = {energy-aware, energy-efficient, virtual machine consolidation (VMC), cloud data center},
series = {UCC '14}
}

@inproceedings{10.1145/263272.263286,
author = {Mehta, Huzefa and Owens, Robert Michael and Irwin, Mary Jane and Chen, Rita and Ghosh, Debashree},
title = {Techniques for Low Energy Software},
year = {1997},
isbn = {0897919033},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/263272.263286},
doi = {10.1145/263272.263286},
booktitle = {Proceedings of the 1997 International Symposium on Low Power Electronics and Design},
pages = {72–75},
numpages = {4},
location = {Monterey, California, USA},
series = {ISLPED '97}
}

@inproceedings{10.1145/3563357.3564082,
author = {Martin, Sonia and Mosier, Nicholas and Nnorom, Obi and Ou, Yancheng and Patel, Liana and Triebe, Oskar and Cezar, Gustavo and Levis, Philip and Rajagopal, Ram},
title = {Software Defined Grid Energy Storage},
year = {2022},
isbn = {9781450398909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563357.3564082},
doi = {10.1145/3563357.3564082},
abstract = {Today, consumer battery installations are isolated, physical devices. Virtual power plants (VPPs) allow consumer devices to aggregate for grid services, but they are are vertically integrated, vendor controlled systems (e.g., Tesla's VPP). Consumer batteries are therefore unable to participate in energy markets or other grid services outside what their vendor provides.We describe a software system that provides software control of multiple, networked battery energy storage systems in the electric grid. The system introduces two new ideas that enable flexible and dependable management of energy storage. The first is a virtual battery, which can either partition a battery or aggregate multiple batteries. The second is a reservation-based API which allows asynchronous control of batteries to meet contractual guarantees in a safe and dependable manner.Virtual batteries and a reservation-based API address the unique challenges of achieving high and efficient utilization of energy storage systems, including heterogeneity of battery systems such as varying C-rates, participation in energy markets, utility bill management systems, community resource sharing, and reliability. Using a testbed comprised of sonnen Inc. storage units installed in several homes and a lab, we demonstrate that virtualized batteries can seamlessly replace physical batteries, flexibly manage energy storage resources, isolate multiple clients using a shared battery, and create new energy storage applications.},
booktitle = {Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {218–227},
numpages = {10},
keywords = {battery energy storage systems, virtualization},
location = {Boston, Massachusetts},
series = {BuildSys '22}
}

@article{10.1145/505863.505875,
author = {Kokol, Peter and Podgorelec, Vili and Dion, Francis and de Loach, Rich},
title = {Intellectual Energy in Software Design},
year = {2000},
issue_date = {May 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/505863.505875},
doi = {10.1145/505863.505875},
abstract = {In the paper we use the sequential study approach to empirical software engineering to research a novel idea about assessing the intellectual energy built into the software products. The study showed that we can use product of Function Points and α metric to calculate both the intellectual energy reflected in the software and the intellectual energy spend during the software design.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {may},
pages = {44–45},
numpages = {2}
}

@article{10.1145/3466861,
author = {Switzer, Jennifer},
title = {Flexible Computing for Intermittent Energy},
year = {2021},
issue_date = {Summer 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {1528-4972},
url = {https://doi.org/10.1145/3466861},
doi = {10.1145/3466861},
abstract = {How flexible computing can help speed the adoption of inflexible renewables.},
journal = {XRDS},
month = {jun},
pages = {30–33},
numpages = {4}
}

@article{10.1145/2557833.2557859,
author = {Lago, Patricia and Meyer, Niklaus and Morisio, Maurizio and M\"{u}ller, Hausi A. and Scanniello, Giuseppe},
title = {Leveraging "Energy Efficiency to Software Users": Summary of the Second GREENS Workshop, at ICSE 2013},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2557833.2557859},
doi = {10.1145/2557833.2557859},
abstract = {The Focus of the GREENS workshop is the engineering of green and sustainable software. Our goal is to bring together academics and practitioners to discuss research initiatives, challenges, ideas, and results in this critically important area of the software industry. This second edition of the workshop was held at ICSE 2013 in San Francisco, CA, USA. The theme of GREENS 2013 is Leveraging "Energy Efficiency to Software Users." It featured a keynote talk, ten research papers and three breakout sessions that discussed topics that ranged from qualities vs. energy efficiency and environmental sustainability, to green models and views for (software) products/process and to stakeholders, relevant metrics and measurements. In this report, we present the themes of the workshop, and summarize the results of the discussions held in the breakout sessions, as well as the identified research challenges for future investigation.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {feb},
pages = {36–38},
numpages = {3},
keywords = {green IT, sustainability, software engineering, energy efficiency}
}

@inproceedings{10.1145/3447555.3465378,
author = {Yosuf, Barzan A. and Mohamed, Sanaa H. and Alenazi, Mohammed M. and El-Gorashi, Taisir E. H. and Elmirghani, Jaafar M. H.},
title = {Energy-Efficient AI over a Virtualized Cloud Fog Network},
year = {2021},
isbn = {9781450383332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447555.3465378},
doi = {10.1145/3447555.3465378},
abstract = {Deep Neural Networks (DNNs) have served as a catalyst in introducing a plethora of next-generation services in the era of Internet of Things (IoT), thanks to the availability of massive amounts of data collected by the objects on the edge. Currently, DNN models are used to deliver many Artificial Intelligence (AI) services that include image and natural language processing, speech recognition, and robotics. Accordingly, such services utilize various DNN models that make it computationally intensive for deployment on the edge devices alone. Thus, most AI models are offloaded to distant cloud data centers (CDCs), which tend to consolidate large amounts of computing and storage resources into one or more CDCs. Deploying services in the CDC will inevitably lead to excessive latencies and overall increase in power consumption. Instead, fog computing allows for cloud services to be extended to the edge of the network, which allows for data processing to be performed closer to the end-user device. However, different from cloud data centers, fog nodes have limited computational power and are highly distributed in the network. In this paper, using Mixed Integer Linear Programming (MILP), we formulate the placement of DNN inference models, which is abstracted as a network embedding problem in a Cloud Fog Network (CFN) architecture, where power savings are introduced through trade-offs between processing and networking. We study the performance of the CFN architecture by comparing the energy savings when compared to the baseline approach which is the CDC.},
booktitle = {Proceedings of the Twelfth ACM International Conference on Future Energy Systems},
pages = {328–334},
numpages = {7},
keywords = {Internet-of-Things) IoT, energy efficiency, resource allocation, cloud-fog networks, optimization, Deep Neural Network (DNN) placement, Mixed Integer Linear Programming (MILP)},
location = {Virtual Event, Italy},
series = {e-Energy '21}
}

@inproceedings{10.1109/CCGrid.2013.107,
author = {Dong, Jiankang and Jin, Xing and Wang, Hongbo and Li, Yangyang and Zhang, Peng and Cheng, Shiduan},
title = {Energy-Saving Virtual Machine Placement in Cloud Data Centers},
year = {2013},
isbn = {9780768549965},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2013.107},
doi = {10.1109/CCGrid.2013.107},
abstract = {In cloud data centers, different mapping relationships between virtual machines (VMs) and physical machines (PMs) cause different resource utilization, therefore, how to place VMs on PMs to improve resource utilization and reduce energy consumption is one of the major concerns for cloud providers. The existing VM placement schemes are to optimize physical server resources utilization or network resources utilization, but few of them focuses on optimizing multiple resources utilization simultaneously. To address the issue, this paper proposes a VM placement scheme meeting multiple resource constraints, such as the physical server size (CPU, memory, storage, bandwidth, etc.) and network link capacity to improve resource utilization and reduce both the number of active physical servers and network elements so as to finally reduce energy consumption. Since VM placement problem is abstracted as a combination of bin packing problem and quadratic assignment problem, which is also known as a classic combinatorial optimization and NP-hard problem, we design a novel greedy algorithm by combining minimum cut with the best-fit, and the simulations show that our solution achieves better results.},
booktitle = {Proceedings of the 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {618–624},
numpages = {7},
keywords = {energy optimization, cloud data center, multiple resource constraints, virtual machine placement},
location = {Delft, Netherlands},
series = {CCGRID '13}
}

@inproceedings{10.1109/CCGrid.2012.49,
author = {Huang, Qingjia and Su, Sen and Li, Jian and Xu, Peng and Shuang, Kai and Huang, Xiao},
title = {Enhanced Energy-Efficient Scheduling for Parallel Applications in Cloud},
year = {2012},
isbn = {9780769546919},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGrid.2012.49},
doi = {10.1109/CCGrid.2012.49},
abstract = {Energy consumption has become a major concern to the widespread deployment of cloud data centers. The growing importance for parallel applications in the cloud introduces significant challenges in reducing the power consumption drawn by the hosted servers. In this paper, we propose an enhanced energy-efficient scheduling (EES) algorithm to reduce energy consumption while meeting the performance-based service level agreement (SLA). Since slacking non-critical jobs can achieve significant power saving, we exploit the slack room and allocate them in a global manner in our schedule. Using random generated and real-life application workflows, our results demonstrate that EES is able to reduce considerable energy consumption while still meeting SLA.},
booktitle = {Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (Ccgrid 2012)},
pages = {781–786},
numpages = {6},
keywords = {Directed Acyclic Graph, Cloud Data Center, Parallel Applications, Energy-efficient Scheduling, Performance Guarantee, List Scheduling},
series = {CCGRID '12}
}

@article{10.1145/3434774,
author = {Lv, Zhihan and Lou, Ranran and Kumar Singh, Amit and Wang, Qingjun},
title = {Transfer Learning-Powered Resource Optimization for Green Computing in 5G-Aided Industrial Internet of Things},
year = {2021},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3434774},
doi = {10.1145/3434774},
abstract = {Objective: Green computing meets the needs of a low-carbon society and it is an important aspect of promoting social sustainable development and technological progress. In the investigation, green computing for resource management and allocation issues is only discussed. Therefore, in the context of the 5G communication network, the investigation of the data classification and resource optimization of the Internet of Things are conducted. Method: The virtualization architecture of the heterogeneous wireless network resource based on 5G technology is designed. The related investigation is conducted based on 5G network and Internet of Things technology. Under the traditional method, the transfer learning is introduced to improve the AdaBoost (Adaptive Boosting) algorithm to classify the data. The investigated complete resource reuse method is used to optimize resources. A method that a sub-channel can be reused by a cellular link and any number of D2D links at the same time is proposed to conduct resource optimization investigation. Results: The investigation indicates that the classification accuracy of the algorithm is excellent for the data classification of the Internet of Things and has different advantages in various aspects compared with other algorithms. The designed algorithm can find a larger set of resource reuse and have a significant increase in spectrum utilization efficiency. Conclusion: The investigation can contribute to the boom in the Internet of Things in terms of data classification and resource optimization based on 5G.},
journal = {ACM Trans. Internet Technol.},
month = {oct},
articleno = {38},
numpages = {16},
keywords = {transfer learning, Internet of Things, resource optimization, AdaBoost, 5G, data classification}
}

@article{10.1145/2764464,
author = {Moghaddam, Fahimeh Alizadeh and Lago, Patricia and Grosso, Paola},
title = {Energy-Efficient Networking Solutions in Cloud-Based Environments: A Systematic Literature Review},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2764464},
doi = {10.1145/2764464},
abstract = {The energy consumed by data centers hosting cloud services is increasing enormously. This brings the need to reduce energy consumption of different components in data centers. In this work, we focus on energy efficiency of the networking component. However, how different networking solutions impact energy consumption is still an open question. We investigate the state of the art in energy-efficient networking solutions in cloud-based environments. We follow a systematic literature review method to select primary studies. We create a metamodel based on the codes extracted from our primary studies using the Coding analytical method. Our findings show three abstraction levels of the proposed networking solutions to achieve energy efficiency in cloud-based environments: Strategy, Solution, and Technology. We study the historical trends in the investigated solutions and conclude that the emerging and most widely adopted one is the Decision framework.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {64},
numpages = {32},
keywords = {Energy efficiency, networking, cloud, systematic literature review}
}

@inproceedings{10.1145/2940679.2940688,
author = {Kuehn, Paul J.},
title = {Energy Effciency and Performance of Cloud Data Centers: Which Role Can Modeling Play?},
year = {2016},
isbn = {9781450344210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2940679.2940688},
doi = {10.1145/2940679.2940688},
abstract = {Resource Virtualization and Load Balancing are main objectives to reduce the power consumption and to improve the performance of large data centers (DC). The management of Cloud Data Centers (CDC) requires an accurate planning and an efficient use of system resources in order to save energy consumption ("greening"), to provide Quality of Service (QoS), and to meet negotiated Service Level Agreements (SLA). This contribution addresses the question of modeling and the development of generic queuing models for energy-efficient use of resources for dynamic load balancing in virtualized CDCs. Performance models are developed for energy efficiency through automatic Server Consolidation, Dynamic Voltage and Frequency Scaling (DVFS) under Static Load Balancing; Dynamic Load Balancing can be achieved through Virtual Machine (VM) migrations. The analysis of such models provides quantitative performance figures upon which the system operation can be optimized with respect to guaranteed real-time performance and energy efficiency under prescribed SLAs.},
booktitle = {Proceedings of the 5th International Workshop on Energy Efficient Data Centres},
articleno = {8},
numpages = {6},
keywords = {cloud data centers, performance modeling, process migration, queuing systems, server consolidation, service level agreements, VM migration, load balancing},
location = {Waterloo, Ontario, Canada},
series = {E2DC '16}
}

@inproceedings{10.1109/CCGrid.2013.89,
author = {Ghribi, Chaima and Hadji, Makhlouf and Zeghlache, Djamal},
title = {Energy Efficient VM Scheduling for Cloud Data Centers: Exact Allocation and Migration Algorithms},
year = {2013},
isbn = {9780768549965},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2013.89},
doi = {10.1109/CCGrid.2013.89},
abstract = {This paper presents two exact algorithms for energy efficient scheduling of virtual machines (VMs) in cloud data centers. Modeling of energy aware allocation and consolidation to minimize overall energy consumption leads us to the combination of an optimal allocation algorithm with a consolidation algorithm relying on migration of VMs at service departures. The optimal allocation algorithm is solved as a bin packing problem with a minimum power consumption objective. It is compared with an energy aware best fit algorithm. The exact migration algorithm results from a linear and integer formulation of VM migration to adapt placement when resources are released. The proposed migration is general and goes beyond the current state of the art by minimizing both the number of migrations needed for consolidation and energy consumption in a single algorithm with a set of valid inequalities and conditions. Experimental results show the benefits of combining the allocation and migration algorithms and demonstrate their ability to achieve significant energy savings while maintaining feasible convergence times when compared with the best fit heuristic.},
booktitle = {Proceedings of the 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {671–678},
numpages = {8},
keywords = {VM migration, VM placement, cloud data center, energy efficiency, linear integer programming},
location = {Delft, Netherlands},
series = {CCGRID '13}
}

@inproceedings{10.1145/3386723.3387889,
author = {Mehrez, Ahmed and Aladel, Lamia},
title = {Modelling Sustainability, Cloud Computing and Knowledge Transmission in Education in Developing Countries},
year = {2020},
isbn = {9781450376341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386723.3387889},
doi = {10.1145/3386723.3387889},
abstract = {This paper focuses on presenting a conceptual model in order to integrate sustainability in cloud computing resulting in facilitating transmission of knowledge in education with a focus on developing countries. From one perspective and while cloud computing has been considered as a recent area of research due to arguments round its value to organizational performance, sustainability has turned to be a typical common norm due to the discovery of uncertainty in various human aspects. From a different perspective, the role of Knowledge Management in enhancing organisational success has been detected in different researches. The main consensus after these researches is that the more effective management of knowledge is the more effective the organizational performance will be. Therefore, this paper presents a theoretical framework of potential links among cloud computing, knowledge management and sustainability.},
booktitle = {Proceedings of the 3rd International Conference on Networking, Information Systems &amp; Security},
articleno = {70},
numpages = {9},
keywords = {Sustainability, Explicit knowledge, Cloud computing, Tacit knowledge, Knowledge management, Knowledge transmission, Education},
location = {Marrakech, Morocco},
series = {NISS2020}
}

@inproceedings{10.1145/3142992.3142993,
author = {Senkans, Uvis and Balsamo, Domenico and Verykios, Theodoros D. and Merrett, Geoff V.},
title = {Applications of Energy-Driven Computing: A Transiently-Powered Wireless Cycle Computer},
year = {2017},
isbn = {9781450354776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3142992.3142993},
doi = {10.1145/3142992.3142993},
abstract = {There has been a dramatic increase in recent years in the number of battery-powered embedded electronic devices. However, the lifetime of these devices is limited by battery capacity. Energy harvesting is an efficient solution to overcome this limitation; however, large energy buffers have been traditionally employed to tackle the temporal variation of the source. These buffers typically require considerable time to charge while introducing a cost, size and weight overhead. Energy-driven systems are specifically designed to operate from an energy harvesting source, without overprovisioning energy storage to make the system appear "battery-like". Furthermore, a transiently-powered system is capable of sustaining computation despite an intermittent supply, without the need for additional energy storage. While this shows much promise, the wide applicability of these systems to real-life applications is yet to be demonstrated. This paper presents a transiently-powered wireless bicycle trip counter which measures distance, speed and active cycling time, and transmits data wirelessly. The system sustains operation by harvesting energy from the rotation of the wheel, operating from a minimum speed of 6kph, while adapting its operation in response to the harvested energy.},
booktitle = {Proceedings of the Fifth ACM International Workshop on Energy Harvesting and Energy-Neutral Sensing Systems},
pages = {1–7},
numpages = {7},
keywords = {Energy Harvesting, Embedded Systems, Transient Computing},
location = {Delft, Netherlands},
series = {ENSsys'17}
}

@article{10.1145/2331576.2331579,
author = {de Oliveira, Frederico Alvares and Ledoux, Thomas},
title = {Self-Management of Cloud Applications and Infrastructure for Energy Optimization},
year = {2012},
issue_date = {July 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0163-5980},
url = {https://doi.org/10.1145/2331576.2331579},
doi = {10.1145/2331576.2331579},
abstract = {As a direct consequence of the increasing popularity of Cloud Computing solutions, data centers are amazingly growing and hence have to urgently face with the energy consumption issue. Available solutions rely on Cloud Computing models and virtualization techniques to scale up/down application based on their performance metrics. Although those proposals can reduce the energy footprint of applications and by transitivity of cloud infrastructures, they do not consider the internal characteristics of applications to finely define a trade-off between applications Quality of Service and energy footprint. In this paper, we propose a self-adaptation approach that considers both application internals and system to reduce the energy footprint in cloud infrastructure. Each application and the infrastructure are equipped with their own control loop, which allows them to autonomously optimize their executions. Simulations show that the approach may lead to appreciable energy savings without interfering on application provider revenues.},
journal = {SIGOPS Oper. Syst. Rev.},
month = {jul},
pages = {10–18},
numpages = {9}
}

@inproceedings{10.1109/CCGRID.2010.45,
author = {Beloglazov, Anton and Buyya, Rajkumar},
title = {Energy Efficient Allocation of Virtual Machines in Cloud Data Centers},
year = {2010},
isbn = {9780769540399},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGRID.2010.45},
doi = {10.1109/CCGRID.2010.45},
abstract = {Rapid growth of the demand for computational power has led to the creation of large-scale data centers. They consume enormous amounts of electrical power resulting in high operational costs and carbon dioxide emissions. Moreover, modern Cloud computing environments have to provide high Quality of Service (QoS) for their customers resulting in the necessity to deal with power-performance trade-off. We propose an efficient resource management policy for virtualized Cloud data centers. The objective is to continuously consolidate VMs leveraging live migration and switch off idle nodes to minimize power consumption, while providing required Quality of Service. We present evaluation results showing that dynamic reallocation of VMs brings substantial energy savings, thus justifying further development of the proposed policy.},
booktitle = {Proceedings of the 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing},
pages = {577–578},
numpages = {2},
keywords = {Allocation of virtual machines, Energy consumption, Live migration of virtual machines, Cloud computing, Green IT, Virtualization, Energy efficiency, Resource management},
series = {CCGRID '10}
}

@inproceedings{10.1145/3299874.3319337,
author = {Thapliyal, Himanshu and Kahleifeh, Zachary},
title = {Solving Energy and Cybersecurity Constraints in IoT Devices Using Energy Recovery Computing},
year = {2019},
isbn = {9781450362528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299874.3319337},
doi = {10.1145/3299874.3319337},
abstract = {With the growth of Internet-of-Things (IoT), the potential threat vectors for malicious cyber and hardware attacks are rapidly expanding. As the IoT paradigm emerges, there are challenging requirements to design energy-efficient and secure systems. To address these challenges, we illustrate energy recovery computing as a potential solution to design low-energy hardware security primitives for IoT devices. Energy Recovery (ER) is a circuit design technique in which circuits recycle the charge stored in the load capacitor. This overview provides example applications of ER computing in (i) low-energy and Differential Power Analysis (DPA) resistant design, (ii) low-energy Physically Unclonable Function (PUF), and (iii) hardware trojan detection.},
booktitle = {Proceedings of the 2019 on Great Lakes Symposium on VLSI},
pages = {525–530},
numpages = {6},
keywords = {hardware security, dpa attack, low-power, physically unclonable functions, hardware trojan},
location = {Tysons Corner, VA, USA},
series = {GLSVLSI '19}
}

@inproceedings{10.1145/2797143.2797153,
author = {Oikonomou, Efthymios and Panagiotou, Dimitra and Rouskas, Angelos},
title = {Energy-Aware Management of Virtual Machines in Cloud Data Centers},
year = {2015},
isbn = {9781450335805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2797143.2797153},
doi = {10.1145/2797143.2797153},
abstract = {The demand for more resources in computational power, memory and disk storage by modern applications and enterprises, results in the consumption of huge amounts of electrical power at cloud data centers. Consequently, cloud service providers, should not only attempt to provide competitive services to their customers, but also keep at the same time their operational costs at acceptable levels by minimizing energy consumption. The reduction of the number of active servers, using live virtual machine (VM) migrations, while keeping the system performance within the levels specified by the SLAs with customers, are main objectives of cloud service providers towards the above goals. In this paper, an efficient VM provisioning mechanism for cloud data center environments is proposed. We first describe our proposed VM allocation policy and then perform a series of simulation experiments based on CloudSim [1] toolkit. Simulation results show that all variations of our proposed provisioning mechanism behave better, in terms of energy consumption and reduction of SLA violations, than the well-known and efficient LrMmt provisioning mechanism [2].},
booktitle = {Proceedings of the 16th International Conference on Engineering Applications of Neural Networks (INNS)},
articleno = {35},
numpages = {6},
keywords = {energy consumption, VM provisioning, VM migration, Service Level Agreement, CloudSim, Quality of Service, Data centers},
location = {Rhodes, Island, Greece},
series = {EANN '15}
}

@inproceedings{10.1145/2528282.2534160,
author = {Campbell, Bradford and DeBruin, Samuel and Clark, Meghan and Dutta, Prabal},
title = {Disaggregating End Loads with Energy-Harvesting Sensors and Cloud Analytics},
year = {2013},
isbn = {9781450324311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2528282.2534160},
doi = {10.1145/2528282.2534160},
abstract = {Obtaining a detailed breakdown of household energy consumption would allow occupants to better understand their energy usage patterns and identify opportunities for energy savings. Current solutions are too course-grained, too difficult to deploy, not networked, or offer poor coverage of hard to meter items, such as ceiling lights. To address these problems, we demonstrate a wirelessly networked, energy-harvesting power metering system that draws zero standby power and is power proportional to the load it is metering. The system is comprised of three different meters: one for plugged-in loads, one for panel-level circuits, and one for hard-to-sense loads, such as ceiling lights. Each meter harvests energy proportionally to the load it is measuring and powers a sensor node intermittently. Together, these sensors create multiple data streams which are aggregated by a receiver. When combined with a calibrated meter that measures total household power, our system can iteratively determine the contributions of each load to the total power usage, allowing users to gain a broad yet detailed view of their energy consumption and costs.},
booktitle = {Proceedings of the 5th ACM Workshop on Embedded Systems For Energy-Efficient Buildings},
pages = {1–2},
numpages = {2},
keywords = {Energy-harvesting, Data aggregation, Power metering},
location = {Roma, Italy},
series = {BuildSys'13}
}

@inproceedings{10.1145/2487166.2487174,
author = {Singh, Rayman Preet and Keshav, S. and Brecht, Tim},
title = {A Cloud-Based Consumer-Centric Architecture for Energy Data Analytics},
year = {2013},
isbn = {9781450320528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487166.2487174},
doi = {10.1145/2487166.2487174},
abstract = {With the advent of utility-owned smart meters and smart appliances, the amount of data generated and collected about consumer energy consumption has rapidly increased. Energy usage data is of immense practical use for consumers for audits, analytics, and automation. Currently, utility companies collect, use, share, and discard usage data at their discretion, with no input from consumers. In many cases, consumers do not even have access to their own data. Moreover, consumers do not have the ability to extract actionable intelligence from their usage data using analytic algorithms of their own choosing: at best they are limited to the analysis chosen for them by their utility. We address these issues by designing and implementing a cloud-based architecture that provides consumers with fast access and fine-grained control over their usage data, as well as the ability to analyse this data with algorithms of their choosing, including third party applications that analyse that data in a privacy preserving fashion. We explain why a cloud-based solution is required, describe our prototype implementation, and report on some example applications we have implemented that demonstrate personal data ownership, control, and analytics.},
booktitle = {Proceedings of the Fourth International Conference on Future Energy Systems},
pages = {63–74},
numpages = {12},
keywords = {smart meters, third party applications, personal data, system architecture, data control, privacy-preserving applications, data privacy, data analytics, application ecosystem, energy data, data ownership, data access, home energy consumption, energy consumption feedback, cloud computing},
location = {Berkeley, California, USA},
series = {e-Energy '13}
}

@inproceedings{10.5555/2485288.2485402,
author = {Lehner, Wolfgang},
title = {Energy-Efficient in-Memory Database Computing},
year = {2013},
isbn = {9781450321532},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {The efficient and flexible management of large datasets is one of the core requirements of modern business applications. Having access to consistent and up-to-date information is the foundation for operational, tactical, and strategic decision making. Within the last few years, the database community sparked a large number of extremely innovative research projects to push the envelope in the context of modern database system architectures. In this paper, we outline requirements and influencing factors to identify some of the hot research topics in database management systems. We argue that---even after 30 years of active database research---the time is right to rethink some of the core architectural principles and come up with novel approaches to meet the requirements of the next decades in data management. The sheer number of diverse and novel (e.g., scientific) application areas, the existence of modern hardware capabilities, and the need of large data centers to become more energy-efficient will be the drivers for database research in the years to come.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {470–474},
numpages = {5},
location = {Grenoble, France},
series = {DATE '13}
}

@inproceedings{10.1145/1840845.1840921,
author = {Nair, Ravi},
title = {Models for Energy-Efficient Approximate Computing},
year = {2010},
isbn = {9781450301466},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1840845.1840921},
doi = {10.1145/1840845.1840921},
abstract = {We are at the threshold of an explosion in new data, produced not only by large, powerful scientific and commercial computers, but also by billions of low-power devices. The traditional techniques of processing such information by first storing them in databases and then manipulating and serving them through large computers are becoming too expensive. These complex large systems have a high acquisition cost, but in addition, suffer also from high running costs, especially in power consumption. Both these costs can be contained by recognizing that there is a precision implied by traditional computing that is not needed in the processing of most new types of data. The relaxation of precision can help in the wider exploitation of known energy-efficient modes of computing like throughput computing. More important, such relaxation provides us an opportunity to deploy in the processing of this vast new data the same low-power, low-cost technology that was used to generate the data in the first place. Such energy-efficient circuits suffer from greater unreliability and variability in performance when used in the high-throughput mode, but these problems can be addressed by changing the way we design such systems, changing the nature of the algorithms for such systems, and by modifying the expectation of the quality of results produced by such systems. We have called this the approximate computing paradigm.There are two sources of imperfection in approximate computing. The first arises from imperfect execution of an algorithm. The second arises from imperfection in the data stream itself. All these imperfections could potentially be rectified through the use of expensive techniques such as redundancy, conservative design, or conservative device operating range. The goal of approximate computing, however, is to combat these sources of imperfection inexpensively and in an energy-efficient manner while producing results that may be different, yet acceptable. Computing models that achieve this goal have to address both the detection and the correction of such imperfections. The detection of such imperfections can be done either by the user observing and reacting to a wrong result, by the algorithm expecting a range of correct results, or by the run-time monitoring of the execution of the system. The correction of system behavior can be done either by attempting a different algorithm, by patching the code, or by repeating the execution. We will argue in this talk that future systems will need to combine all these techniques and integrate new ones into a single dynamically optimized system that employs feedback from the user to guide the high-level choice of energy-efficient algorithms, and that employs prediction based on past experience to guide the low-level energy-efficient execution of the system. This has a tantalizing similarity to some models of functioning of a remarkably efficient approximate computing appliance we all know -- the human brain.},
booktitle = {Proceedings of the 16th ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {359–360},
numpages = {2},
keywords = {energy-efficient computing, prediction systems, approximate computing},
location = {Austin, Texas, USA},
series = {ISLPED '10}
}

@inproceedings{10.5555/2664446.2664458,
author = {Hindle, Abram},
title = {Green Mining: A Methodology of Relating Software Change to Power Consumption},
year = {2012},
isbn = {9781467317610},
publisher = {IEEE Press},
abstract = {Power consumption is becoming more and more important with the increased popularity of smart-phones, tablets and laptops. The threat of reducing a customer's battery-life now hangs over the software developer who asks, "will this next change be the one that causes my software to drain a customer's battery?" One solution is to detect power consumption regressions by measuring the power usage of tests, but this is time-consuming and often noisy. An alternative is to rely on software metrics that allow us to estimate the impact that a change might have on power consumption thus relieving the developer from expensive testing. This paper presents a general methodology for investigating the impact of software change on power consumption, we relate power consumption to software changes, and then investigate the impact of static OO software metrics on power consumption. We demonstrated that software change can effect power consumption using the Firefox web-browser and the Azureus/Vuze BitTorrent client. We found evidence of a potential relationship between some software metrics and power consumption. In conclusion, we explored the effect of software change on power consumption on two projects; and we provide an initial investigation on the impact of software metrics on power consumption.},
booktitle = {Proceedings of the 9th IEEE Working Conference on Mining Software Repositories},
pages = {78–87},
numpages = {10},
keywords = {software metrics, mining software repositories, sustainable-software, power, dynamic analysis, power consumption},
location = {Zurich, Switzerland},
series = {MSR '12}
}

@article{10.1145/3046682,
author = {Sen, Rathijit and Wood, David A.},
title = {Pareto Governors for Energy-Optimal Computing},
year = {2017},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {1544-3566},
url = {https://doi.org/10.1145/3046682},
doi = {10.1145/3046682},
abstract = {The original definition of energy-proportional computing does not characterize the energy efficiency of recent reconfigurable computers, resulting in nonintuitive “super-proportional” behavior. This article introduces a new definition of ideal energy-proportional computing, new metrics to quantify computational energy waste, and new SLA-aware OS governors that seek Pareto optimality to achieve power-efficient performance.},
journal = {ACM Trans. Archit. Code Optim.},
month = {mar},
articleno = {6},
numpages = {25},
keywords = {RAPL, prefetching, DVFS, performance-per-watt, SLA}
}

@inproceedings{10.1145/2597073.2597097,
author = {Hindle, Abram and Wilson, Alex and Rasmussen, Kent and Barlow, E. Jed and Campbell, Joshua Charles and Romansky, Stephen},
title = {GreenMiner: A Hardware Based Mining Software Repositories Software Energy Consumption Framework},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597097},
doi = {10.1145/2597073.2597097},
abstract = {Green Mining is a field of MSR that studies software energy consumption and relies on software performance data. Unfortunately there is a severe lack of publicly available software power use performance data. This means that green mining researchers must generate this data themselves by writing tests, building multiple revisions of a product, and then running these tests multiple times (10+) for each software revision while measuring power use. Then, they must aggregate these measurements to estimate the energy consumed by the tests for each software revision. This is time consuming and is made more difficult by the constraints of mobile devices and their OSes. In this paper we propose, implement, and demonstrate Green Miner: the first dedicated hardware mining software repositories testbed. The Green Miner physically measures the energy consumption of mobile devices (Android phones) and automates the testing of applications, and the reporting of measurements back to developers and researchers. The Green Miner has already produced valuable results for commercial Android application developers, and has been shown to replicate other power studies' results.},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {12–21},
numpages = {10},
keywords = {Software Energy Consumption, Software Change, Android},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/2568088.2568093,
author = {Chen, Feifei and Grundy, John and Schneider, Jean-Guy and Yang, Yun and He, Qiang},
title = {Automated Analysis of Performance and Energy Consumption for Cloud Applications},
year = {2014},
isbn = {9781450327336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568088.2568093},
doi = {10.1145/2568088.2568093},
abstract = {In cloud environments, IT solutions are delivered to users via shared infrastructure. One consequence of this model is that large cloud data centres consume large amounts of energy and produce significant carbon footprints. A key objective of cloud providers is thus to develop resource provisioning and management solutions at minimum energy consumption while still guaranteeing Service Level Agreements (SLAs). However, a thorough understanding of both system performance and energy consumption patterns in complex cloud systems is imperative to achieve a balance of energy efficiency and acceptable performance. In this paper, we present StressCloud, a performance and energy consumption analysis tool for cloud systems. StressCloud can automatically generate load tests and profile system performance and energy consumption data. Using StressCloud, we have conducted extensive experiments to profile and analyse system performance and energy consumption with different types and mixes of runtime tasks. We collected fine-grained energy consumption and performance data with different resource allocation strategies, system configurations and workloads. The experimental results show the correlation coefficients of energy consumption, system resource allocation strategies and workload, as well as the performance of the cloud applications. Our results can be used to guide the design and deployment of cloud applications to balance energy and performance requirements.},
booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
pages = {39–50},
numpages = {12},
keywords = {energy consumption, green cloud, performance analysis, automation, cloud computing},
location = {Dublin, Ireland},
series = {ICPE '14}
}

@article{10.1145/2553070.2553072,
author = {Chihi, Hanen and Chainbi, Walid and Ghedira, Khaled},
title = {An Energy-Efficient Self-Provisioning Approach for Cloud Resources Management},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0163-5980},
url = {https://doi.org/10.1145/2553070.2553072},
doi = {10.1145/2553070.2553072},
abstract = {In recent years, energy conservation has become a major issue in information technology. Cloud computing is an emerging model for distributed utility computing and is being considered as an attractive opportunity for saving energy through central management of computational resources. Obviously, a substantial reduction in energy consumption can be made by powering down servers when they are not in use. This work presents a resources provisioning approach based on an unsupervised predictor model in the form of an unsupervised, recurrent neural network based on a self-organizing map. Another unique feature of our work is a resources administration strategy for energy saving in the cloud. Such a strategy is implemented as a selfadministration module. We show that the proposed approach gives promising results.},
journal = {SIGOPS Oper. Syst. Rev.},
month = {nov},
pages = {2–9},
numpages = {8},
keywords = {prediction, recurrent self-organizing map, cloud computing, autonomic computing}
}

@inproceedings{10.1109/CCGrid.2012.47,
author = {Kantarci, Burak and Mouftah, Hussein T.},
title = {Optimal Reconfiguration of the Cloud Network for Maximum Energy Savings},
year = {2012},
isbn = {9780769546919},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGrid.2012.47},
doi = {10.1109/CCGrid.2012.47},
abstract = {With the advent of cloud computing, storage and computing functions are migrating to remote resources such as virtual servers and storage systems which are mostly hosted in the data centers. This migration can ensure significant energy savings as utilization of local resources contribute to 40% of the Greenhouse Gas emissions of the Information and Communication Technologies (ICTs). On the other hand, provisioning of the cloud services needs to be handled carefully since energy consumption of the transport network, as well as the energy consumed by the data centers, is expected to increase. We revisit our previously proposed Mixed Integer Linear Programming (MILP) models that are used to reconfigure the cloud network design with look-ahead demand profile. Due to long runtimes of the MILP models in large-scale scenarios, in this paper, we propose two heuristics to reconfigure the cloud network for provisioning the cloud and Internet computing demands. The first heuristic aims to minimize the propagation delay while the second one targets minimizing the power consumption of the data centers and the transport network. We verify the heuristics through simulations where MILP models are used as the benchmarks. Numerical results show that power minimized provisioning can guarantee significant energy savings in the cloud network with less resource consumption. We also present the energy versus delay trade-off and point out possible solutions.},
booktitle = {Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (Ccgrid 2012)},
pages = {835–840},
numpages = {6},
keywords = {virtual topology, energy-efficiency, demand provisioning, data centers, Cloud computing},
series = {CCGRID '12}
}

@inproceedings{10.1145/2068897.2068904,
author = {Xu, Yi and Helal, Sumi and Thai, My and Scmalz, Mark},
title = {Optimizing Push/Pull Envelopes for Energy-Efficient Cloud-Sensor Systems},
year = {2011},
isbn = {9781450308984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2068897.2068904},
doi = {10.1145/2068897.2068904},
abstract = {Unlike traditional distributed systems, where the resources/needs of computation and communication dominate the performance equation, sensor-based systems (SBS) raise new metrics and requirements for sensors as well as for computing and communication. This includes sensing latency and energy consumption. In this paper, we present a performance model for SBS based on a three-tier architecture that uses edge devices to connect massive-scale networks of sensors to the cloud. In this architecture, which we call Cloud, Edge, and Beneath (CEB), initial processing of sensor data occurs in- and near-network, in order to achieve system sentience and energy efficiency. To optimize CEB performance, we propose the concept of optimal push/pull envelope (PPE). PPE dynamically and minimally adjusts the base push and pull rates for each sensor, according to the relative characteristics of sensor requests (demand side from the Cloud) and sensor data change (supply side from Beneath). We demonstrate the CEB architecture and its push/pull envelope optimization algorithm in an experimental evaluation that measures energy savings and sentience efficiency over a wide range of practical constraints. In addition, from the experiments we demonstrate that by combining PPE optimization algorithm with lazy sampling algorithm, we can achieve further energy saving.},
booktitle = {Proceedings of the 14th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {17–26},
numpages = {10},
keywords = {performance, cloud computing, sentience efficiency, push pull envelope, energy efficiency, optimization, pervasive computing},
location = {Miami, Florida, USA},
series = {MSWiM '11}
}

@inproceedings{10.1145/2872362.2872409,
author = {Colin, Alexei and Harvey, Graham and Lucia, Brandon and Sample, Alanson P.},
title = {An Energy-Interference-Free Hardware-Software Debugger for Intermittent Energy-Harvesting Systems},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872409},
doi = {10.1145/2872362.2872409},
abstract = {Energy-autonomous computing devices have the potential to extend the reach of computing to a scale beyond either wired or battery-powered systems. However, these devices pose a unique set of challenges to application developers who lack both hardware and software support tools. Energy harvesting devices experience power intermittence which causes the system to reset and power-cycle unpredictably, tens to hundreds of times per second. This can result in code execution errors that are not possible in continuously-powered systems and cannot be diagnosed with conventional debugging tools such as JTAG and/or oscilloscopes. We propose the Energy-interference-free Debugger, a hardware and software platform for monitoring and debugging intermittent systems without adversely effecting their energy state. The Energy-interference-free Debugger re-creates a familiar debugging environment for intermittent software and augments it with debugging primitives for effective diagnosis of intermittence bugs. Our evaluation of the Energy-interference-free Debugger quantifies its energy-interference-freedom and shows its value in a set of debugging tasks in complex test programs and several real applications, including RFID code and a machine-learning-based activity recognition system.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {577–589},
numpages = {13},
keywords = {energy-harvesting},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3253297,
author = {Macii, Enrico},
title = {Session Details: Energy Efficient Mobile Computing},
year = {2002},
isbn = {1581134614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253297},
doi = {10.1145/3253297},
booktitle = {Proceedings of the 39th Annual Design Automation Conference},
location = {New Orleans, Louisiana, USA},
series = {DAC '02}
}

@inproceedings{10.1145/3431379.3466719,
author = {Girone, Maria},
title = {Computing Challenges for High Energy Physics},
year = {2021},
isbn = {9781450382175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3431379.3466719},
doi = {10.1145/3431379.3466719},
abstract = {High-energy physics faces unprecedented computing challenges in preparation for the 'high-luminosity' phase of the Large Hadron Collider, which will be known as the HL-LHC. The complexity of particle-collision events will increase, together with the data collection rate, substantially outstripping the gains expected from technology evolution. The LHC experiments, through the Worldwide LHC Computing Grid (WLCG), operate a distributed computing infrastructure at about 170 sites over more than 40 countries. This infrastructure has successfully exploited the exabyte of data collected and processed during the first 10 years of the program. During the HL-LHC regime, each experiment will collect an exabyte of data annually and additional computing resources will be needed.The efficient use of HPC facilities may be an important opportunity to address the anticipated resource gap. In this talk, I will discuss the future computing needs in high-energy physics and how these can be met combining our dedicated distributed computing infrastructure with large-scale HPC sites. As a community, we have identified common challenges for integrating these large facilities into our computing ecosystem. I will also discuss the current progress in addressing those challenges, focusing on software development for heterogeneous architectures, data management at scale, supporting services and opportunities for collaboration.},
booktitle = {Proceedings of the 30th International Symposium on High-Performance Parallel and Distributed Computing},
pages = {3},
numpages = {1},
keywords = {big-data, high-energy physics, data analytics},
location = {Virtual Event, Sweden},
series = {HPDC '21}
}

@article{10.1145/1710115.1710117,
author = {Kant, Krishna},
title = {Challenges in Distributed Energy Adaptive Computing},
year = {2010},
issue_date = {December 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {3},
issn = {0163-5999},
url = {https://doi.org/10.1145/1710115.1710117},
doi = {10.1145/1710115.1710117},
abstract = {Fueled by burgeoning online services, energy consumption in information technology (IT) equipment is becoming a major concern from a variety of perspectives including the continuation of Moore's Law for hardware design, enabling sophisticated mobile client functionality, mounting utility costs in data centers, and increasing CO2 emissions associated with IT manufacturing, distribution, usage and disposal. This article discusses an approach where energy consumption and related issues of heat dissipation and sustainability are considered as the primary concerns that drive the way computation and communication is organized at both clients and servers. This article describes the challenges in supporting such a distributed energy adaptive computing paradigm.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jan},
pages = {3–7},
numpages = {5}
}

@inproceedings{10.1145/2597073.2597110,
author = {Pinto, Gustavo and Castor, Fernando and Liu, Yu David},
title = {Mining Questions about Software Energy Consumption},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597110},
doi = {10.1145/2597073.2597110},
abstract = {A growing number of software solutions have been proposed to address application-level energy consumption problems in the last few years. However, little is known about how much software developers are concerned about energy consumption, what aspects of energy consumption they consider important, and what solutions they have in mind for improving energy efficiency. In this paper we present the first empirical study on understanding the views of application programmers on software energy consumption problems. Using StackOverflow as our primary data source, we analyze a carefully curated sample of more than 300 questions and 550 answers from more than 800 users. With this data, we observed a number of interesting findings. Our study shows that practitioners are aware of the energy consumption problems: the questions they ask are not only diverse -- we found 5 main themes of questions -- but also often more interesting and challenging when compared to the control question set. Even though energy consumption-related questions are popular when considering a number of different popularity measures, the same cannot be said about the quality of their answers. In addition, we observed that some of these answers are often flawed or vague. We contrast the advice provided by these answers with the state-of-the-art research on energy consumption. Our summary of software energy consumption problems may help researchers focus on what matters the most to software developers and end users.},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {22–31},
numpages = {10},
keywords = {Practitioners, Software Energy Consumption, Q&amp;A},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1145/2351676.2351699,
author = {Noureddine, Adel and Bourdon, Aurelien and Rouvoy, Romain and Seinturier, Lionel},
title = {Runtime Monitoring of Software Energy Hotspots},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351699},
doi = {10.1145/2351676.2351699},
abstract = {GreenIT has emerged as a discipline concerned with the optimization of software solutions with regards to their energy consumption. In this domain, most of the state-of-the-art solutions concentrate on coarse-grained approaches to monitor the energy consumption of a device or a process. However, none of the existing solutions addresses in-process energy monitoring to provide in-depth analysis of a process energy consumption. In this paper, we therefore report on a fine-grained runtime energy monitoring framework we developed to help developers to diagnose energy hotspots with a better accuracy than the state-of-the-art. Concretely, our approach adopts a 2-layer architecture including OS-level and process-level energy monitoring. OS-level energy monitoring estimates the energy consumption of processes according to different hardware devices (CPU, network card). Process-level energy monitoring focuses on Java-based applications and builds on OS-level energy monitoring to provide an estimation of energy consumption at the granularity of classes and methods. We argue that this per-method analysis of energy consumption provides better insights to the application in order to identify potential energy hotspots. In particular, our preliminary validation demonstrates that we can monitor energy hotspots of Jetty web servers and monitor their variations under stress scenarios.},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {160–169},
numpages = {10},
keywords = {Power Monitoring, Bytecode Instrumentation, Power Model, Profiling},
location = {Essen, Germany},
series = {ASE '12}
}

@inproceedings{10.1145/1322263.1322319,
author = {Dunkels, Adam and \"{O}sterlind, Fredrik and Tsiftes, Nicolas and He, Zhitao},
title = {Software-Based Sensor Node Energy Estimation},
year = {2007},
isbn = {9781595937636},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1322263.1322319},
doi = {10.1145/1322263.1322319},
abstract = {Being able to estimate the energy consumption of sensor nodes is essential both for evaluating existing sensor network mechanisms and for constructing new energy-aware mechanisms. We present a software-based mechanism for estimating the energy consumption of sensor node at run-time. Unlike previous energy estimation mechanisms, our mechanism does not require any additional hardware components or add-ons.Our demonstration shows the energy estimation in practice on a small network of Tmote Sky motes running the Contiki operating system. A PC connected to one of the motes shows the real-time energy estimation of the network nodes and where the energy is spent: CPU active, CPU sleeping, radio transmitting, radio listening, and LEDs.},
booktitle = {Proceedings of the 5th International Conference on Embedded Networked Sensor Systems},
pages = {409–410},
numpages = {2},
keywords = {energy estimation, Contiki, wireless sensor networks},
location = {Sydney, Australia},
series = {SenSys '07}
}

@inproceedings{10.1145/378239.379033,
author = {Tan, T. K. and Raghunathan, A. K. and Lakishminarayana, G. and Jha, N. K.},
title = {High-Level Software Energy Macro-Modeling},
year = {2001},
isbn = {1581132972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/378239.379033},
doi = {10.1145/378239.379033},
abstract = {This paper presents an efficient and accurate high-level software energy estimation methodology using the concept of characterization-based macro-modeling. In characterization-based macro-modeling, a function or sub-routine is characterized using an accurate lower-level energy model of the target processor, to construct a macro-model that relates the energy consumed in the function under consideration to various parameters that can be easily observed or calculated from a high-level programming language description. The constructed macro-models eliminate the need for significantly slower instruction-level interpretation or hardware simulation that is required in conventional approaches to software energy estimation.We present two different approaches to macro-modeling for embedded software that offer distinct efficiency-accuracy characteristics: (i) complexity-based macro-modeling, where the variables that determine the algorithmic complexity of the function under consideration are used as macro-modeling parameters, and (ii) profiling-based macro-modeling, where internal profiling statistics for the functions are used as parameters in the energy macro-models. We have experimentally validated our software energy macro-modeling techniques on a wide range of embedded software routines and two different target processor architectures. Our experiments demonstrate that high-level macro-models constructed using the proposed techniques are able to estimate the energy consumption to within 95% accuracy on the average, while commanding speedups of one to five orders-of-magnitude over current instruction-level and architectural energy estimation techniques.},
booktitle = {Proceedings of the 38th Annual Design Automation Conference},
pages = {605–610},
numpages = {6},
location = {Las Vegas, Nevada, USA},
series = {DAC '01}
}

@inproceedings{10.1145/2791405.2791446,
author = {Shrimali, Bela and Patel, Hiren},
title = {Performance Based Energy Efficient Techniques For VM Allocation In Cloud Environment},
year = {2015},
isbn = {9781450333610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791405.2791446},
doi = {10.1145/2791405.2791446},
abstract = {Cloud computing is emerging as a new paradigm for providing different services like platform, infrastructure and software as a large scale distributed computing applications via Internet. Computing resources are available in Cloud through virtualization. It divides a physical machine into many half or full isolated machines (known as Virtual Machines-VMs) using various allocation techniques. To identify a technique that can satisfy a quality of service in consideration of energy consumption in Cloud environment is one of the challenging issues for Virtual Machine allocation in Cloud as there are tradeoffs between energy consumption and performance. In the present research, we aim to survey various techniques that combine energy efficiency and performance. Hence, different real world virtual machine allocation policies are explored and the performance based energy efficient techniques for VM allocation are discussed. This survey may assist the researchers who wish to step in to the domain of performance based energy efficient VM techniques.},
booktitle = {Proceedings of the Third International Symposium on Women in Computing and Informatics},
pages = {477–486},
numpages = {10},
keywords = {Cloud computing, Performance, Virtual machine, Energy efficient},
location = {Kochi, India},
series = {WCI '15}
}

@inproceedings{10.1145/2901739.2903494,
author = {Chowdhury, Shaiful Alam and Hindle, Abram},
title = {Characterizing Energy-Aware Software Projects: Are They Different?},
year = {2016},
isbn = {9781450341868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901739.2903494},
doi = {10.1145/2901739.2903494},
abstract = {The improvement in battery technology for battery-driven devices is insignificant compared to their computing ability. In spite of the overwhelming advances in processing ability, adoption of sophisticated applications is hindered by the fear of shorter battery life. This is one of the several reasons software developers are becoming conscious of writing energy efficient code.Research has been conducted to model software energy consumption, to reduce energy drains, and to understand developers expertise on energy efficiency. In this paper, however, we investigate the nature of energy-aware software projects. We observed that projects concerned with energy issues are larger and more popular than the projects that do not address energy consumption. Energy related code changes are larger than others (e.g., bug fixes). In addition, our initial results suggest that energy efficiency is mostly addressed on certain platforms and applications.},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
pages = {508–511},
numpages = {4},
location = {Austin, Texas},
series = {MSR '16}
}

@inproceedings{10.1145/3417113.3422997,
author = {Swanborn, Stan and Malavolta, Ivano},
title = {Energy Efficiency in Robotics Software: A Systematic Literature Review},
year = {2021},
isbn = {9781450381284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417113.3422997},
doi = {10.1145/3417113.3422997},
abstract = {Nowadays, robots are widely used in many areas of our lifes, such as autonomous storage, self-driving vehicles, drones, industrial automation, etc. Energy is a critical factor for robotic systems, especially for mobile robots where energy is a finite resource (e.g., surveillance autonomous rovers). Since software is becoming the central focus of modern robotic systems, it is important to understand how it influences the energy consumption of the entire system. However, there is no systematic study of the state of the art in energy efficiency of robotics software that could guide research or practitioners in finding solutions and tools to develop robotic systems with energy efficiency in mind.The goal of this paper is to present a review of existing research on energy efficiency in robotics software. Specifically, we investigate on (i) the used metrics for energy efficiency, (ii) the application domains within the robotics area covered by research on energy efficiency, (iii) the identified major energy consumers within a robotic system, (iv) how existing approaches are evaluated, (v) the used energy models, (vi) the techniques supporting the development of energy-efficient robotics software, and (vii) which quality attributes tend to be traded off when dealing with energy efficiency in robotics. We also provide a replication package to assess, extend, and/or replicate the study.The results of this work can guide researchers and practitioners in robotics and software engineering in better reasoning and contributing to energy-efficient robotics software.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {144–151},
numpages = {8},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.5555/2755535.2755542,
author = {Huang, Chun-Ying and Chen, Po-Han and Huang, Yu-Ling and Chen, Kuan-Ta and Hsu, Cheng-Hsin},
title = {Measuring the Client Performance and Energy Consumption in Mobile Cloud Gaming},
year = {2014},
publisher = {IEEE Press},
abstract = {Mobile cloud gaming allows gamers to play games on resource-constrained mobile devices, and a measurement study to quality the client performance and energy consumption is crucial to attract and retain the gamers. In this paper, we adopt an open source cloud gaming platform to conduct extensive experiments on real mobile clients. Our experiment results show two major findings that are of interests to researchers, developers, and gamers. First, compared to mobile native games, mobile cloud games save energy by up to 30%. Second, the frame rate, bit rate, and resolution all affect the decoders' resource consumption, while frame rate imposes the highest impact. These findings shed some light on the further enhancements of the emerging mobile cloud gaming platforms.},
booktitle = {Proceedings of the 13th Annual Workshop on Network and Systems Support for Games},
articleno = {5},
numpages = {3},
location = {Nagoya, Japan},
series = {NetGames '14}
}

@inproceedings{10.1109/MOBILESoft.2017.4,
author = {Lee1, Wooseok and Sunwoo, Dam and Gerstlauer, Andreas and John, Lizy K.},
title = {Cloud-Guided QoS and Energy Management for Mobile Interactive Web Applications},
year = {2017},
isbn = {9781538626696},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MOBILESoft.2017.4},
doi = {10.1109/MOBILESoft.2017.4},
abstract = {In mobile interactive web applications, energy-efficient quali-ty-of-service (QoS) scheduling involves setting a deadline for the best user experience and providing just enough performance to minimize energy. Such performance-slacking approaches require precise performance adjustment using execution time prediction. However, prior prediction approaches suffer from prohibitive training due to extensive input data and manual source code instrumentation. In this paper, we propose a cloud-guided QoS and energy management approach that eliminates the prediction overhead by offloading it to cloud resources. Our approach pre-computes per-input execution time models by profiling web applications on dedicated mobile devices in the cloud. When mobile web applications request data to servers, both the data and its execution time models are delivered to users' mobile devices. Based on the delivered models, a performance control agent on the mobile device selects an operating point to meet the response time requirement. Experimental results show that, by offloading modeling and prediction overheads, our performance-slacking approach can provide average energy savings of 22% and 39% (and up to 89%) for two different timing budgets compared to an industry-quality approach.},
booktitle = {Proceedings of the 4th International Conference on Mobile Software Engineering and Systems},
pages = {25–29},
numpages = {5},
location = {Buenos Aires, Argentina},
series = {MOBILESoft '17}
}

@inproceedings{10.1145/3436829.3436867,
author = {Behiya, Noora Nahidh and Ahmed, Rabah Abood},
title = {Efficient VCPU Utilization for Reducing Energy Consumption in Cloud Data Centers},
year = {2021},
isbn = {9781450377218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3436829.3436867},
doi = {10.1145/3436829.3436867},
abstract = {As the demand for cloud computing services continues to grow, the requirement for expanding cloud data centers also increases. One main issue facing this growth is the huge amount of energy consumed by the cloud data centers. The massive energy consumption expenses considered the main problem for cloud service providers. Recent reports revealed that the electricity expenses of Information and communications technology or (ICT) devices occupy 42% per month of the total budgets. Nevertheless, the continuous increase in energy consumption has become the main challenging subject. Due to this reason, researches have proposed many techniques and approaches (such as virtual machine VM consolidation, Voltage and Frequency Scaling, VM migration policies, etc.) for addressing this issue. This paper presents a study to evaluate the influence of controlling virtual machine central process unit (vCPU) on energy consumption of Cloud data center. CloudSim simulator is used to apply the dynamic voltage and frequency scaling (DVFS) technique with the proposed approach while processing different types of general purpose cloud computing applications (video streaming, file compression process, and video games). Results indicate that about 13% of data center energy was saved compared with the base DVFS system. This saving percentage result was a better percentage comparing with other results obtained from previous work.},
booktitle = {Proceedings of the 9th International Conference on Software and Information Engineering},
pages = {84–87},
numpages = {4},
keywords = {Cloud Computing, Data center, Power Consumption, vCPU},
location = {Cairo, Egypt},
series = {ICSIE '20}
}

@inproceedings{10.1145/3144789.3144792,
author = {Tan, Mingzhe and Chi, Ce and Zhang, Jiahao and Zhao, Shichang and Li, Guangli and L\"{u}, Shuai},
title = {An Energy-Aware Virtual Machine Placement Algorithm in Cloud Data Center},
year = {2017},
isbn = {9781450352871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3144789.3144792},
doi = {10.1145/3144789.3144792},
abstract = {In order to reduce the energy waste in the data center, while taking into account the violation rate of user service level and the resource utilization rate, this paper studies how to adopt effective strategy to get the reasonable suboptimal solution by combining above three indexes. This paper designs a nonlinear energy consumption model based on polynomials and exponents to measure the energy consumption of different deployment schemes. It is the basis of the deployment strategy. At the heart of this paper, the probability transfer function and the fitness function are designed to optimize the ant colony algorithm. Finally a multi-objective optimization ant colony algorithm based on threshold-dependent pheromone updating was proposed. The algorithm is a kind of distributed optimization method, which is beneficial to parallel computation and has a positive feedback mechanism. The optimal solution can be efficiently obtained by continuous updating of pheromone. The experimental results show that the ant colony algorithm of multi-objective virtual machine placement can achieve the optimal trade-off between multiple conflicting targets, so that the system's energy consumption is less, the violation rate of user service level and the resource utilization rate is also small.},
booktitle = {Proceedings of the 2nd International Conference on Intelligent Information Processing},
articleno = {1},
numpages = {9},
keywords = {Data center, Cloud computing, Virtual machine, Energy saving},
location = {Bangkok, Thailand},
series = {ICIIP '17}
}

@inproceedings{10.1145/3018896.3018957,
author = {Kumari, Raj and Kaushal, Sakshi},
title = {Energy Efficient Approach for Application Execution in Mobile Cloud IoT Environment},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3018957},
doi = {10.1145/3018896.3018957},
abstract = {Smart mobile devices (SMD) are able to provide different services to the users with minimum delay. Generally, the users are not aware of the complexity of the applications over which they are expecting fast response. SMD are constrained by their processing speed, storage capacity and many other resources, therefore, to make them to perform well with different types of applications, the concept of mobile cloud is used. Internet of Things (IoT) provides dynamic control and monitoring of energy resources enabling stakeholders to save energy usage at granular levels. With the advancement of IoT technologies and mobile cloud, a new concept is developed called as mobile cloud IoT (MCIoT) which is the convergence of both. The main objective of MCIoT is to provide the sufficient resources to the application so that the application can be executed without any deficiencies. When an application is partitioned complex part is on the cloud and rest is on the SMD, the battery life of the SMD highly improves. In this paper, we have presented an analytical model in MCIoT environment to represent the appropriate partition rate which effects execution time and energy consumption on SMD and cloud. The experiments are conducted on the bases of varying partition rate, bandwidth and data size of an application. Further, the impact of these parameters are analysed over the residual energy of SMD.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {61},
numpages = {8},
keywords = {mobile cloud computing, offloading, internet of things, smart mobile devices},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/3299874.3319489,
author = {Aly, Mohamed M. Sabry},
title = {N3XT Monolithic 3D Energy-Efficient Computing Systems},
year = {2019},
isbn = {9781450362528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299874.3319489},
doi = {10.1145/3299874.3319489},
abstract = {The world's appetite for analyzing massive amounts of structured and unstructured data has grown dramatically. The computational demands of these abundant-data applications far exceed the capabilities of today's computing systems. The N3XT (Nano-Engineered Computing Systems Technology) approach overcomes this challenge through: (i) new logic devices such as carbon nanotube field-effect transistors, (ii) high-density non-volatile memory, and (iii) ultra-dense monolithic 3D integration of thin layers of logic and memory devices that are fabricated at low temperature. N3XT hardware prototypes demonstrate the practicality of this approach. We evaluate the benefits of N3XT using a simulation framework calibrated using experimental measurements, which also enables the analysis of a several device and integration technologies. N3XT improves the system-level energy-delay product of common implementations of abundant-data workloads by three orders of magnitude compared to conventional architectures.},
booktitle = {Proceedings of the 2019 on Great Lakes Symposium on VLSI},
pages = {463},
numpages = {1},
keywords = {resistive ram, monolithic 3d, carbon nanotubes},
location = {Tysons Corner, VA, USA},
series = {GLSVLSI '19}
}

@inproceedings{10.5555/2693848.2694246,
author = {Agdas, Duzgun and Srinivasan, Ravi S.},
title = {Building Energy Simulation and Parallel Computing: Opportunities and Challenges},
year = {2014},
publisher = {IEEE Press},
abstract = {Increased focus on energy cost savings and carbon footprint reduction efforts improved the visibility of building energy simulation, which became a mandatory requirement of several building rating systems. Despite developments in building energy simulation algorithms and user interfaces, there are some major challenges associated with building energy simulation; an important one is the computational demands and processing time. In this paper, we analyze the opportunities and challenges associated with this topic while executing a set of 275 parametric energy models simultaneously in EnergyPlus using a High Performance Computing (HPC) cluster. Successful parallel computing implementation of building energy simulations will not only improve the time necessary to get the results and enable scenario development for different design considerations, but also might enable Dynamic-Building Information Modeling (BIM) integration and near real-time decision-making. This paper concludes with the discussions on future directions and opportunities associated with building energy modeling simulations.},
booktitle = {Proceedings of the 2014 Winter Simulation Conference},
pages = {3167–3175},
numpages = {9},
location = {Savannah, Georgia},
series = {WSC '14}
}

@inproceedings{10.1145/3526071.3527517,
author = {Mendez, Reynaldo Cobos and Hobert, Eddo and Dresscher, Douwe and Broenink, Jan},
title = {On Structuring Energy-Aware Sequence-Control Software},
year = {2023},
isbn = {9781450393171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526071.3527517},
doi = {10.1145/3526071.3527517},
abstract = {This paper presents a framework to structure sequence-control software that accounts for the communication of energy information by design when interfacing planners with loop controllers. Communicating velocity or force values as setpoints to a loop controller can be characterised as energy that is downstreamed to the rest of the control structure and exchanged with the environment. Awareness of this energy information is useful for addressing dependability aspects in robotics where energy plays a role. This framework comprises metamodels and models for composing and structuring energy-aware sequence-control software that provides information of the energy supplied, for instance, by a trajectory planner. In addition, this paper gives an overview of the computation and communication requirements of this energy information. We present a use case where this structure facilitates using energy as a physical-interaction constraint and dependability metric for robot control.},
booktitle = {Proceedings of the 4th International Workshop on Robotics Software Engineering},
pages = {1–8},
numpages = {8},
keywords = {metamodel, planning, energy computation, software architecture, energy awareness, robot control, control structure},
location = {Pittsburgh, Pennsylvania},
series = {RoSE '22}
}

@inproceedings{10.5555/2461196.2461209,
author = {Suzuki, Akira and Uchizawa, Kei and Zhou, Xiao},
title = {Energy-Efficient Threshold Circuits Computing Mod Functions},
year = {2011},
isbn = {9781920682989},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {We prove that the modulus function MODm of n variables can be computed by a threshold circuit C of energy e and size s = O(e(n/m)1/(e−1)) for any integer e ≥ 2, where the energy e is defined to be the maximum number of gates outputting "1" over all inputs to C, and the size s to be the number of gates in C. Our upper bound on the size s almost matches the known lower bound s = Ω(e(n/m)1/e).},
booktitle = {Proceedings of the Seventeenth Computing: The Australasian Theory Symposium - Volume 119},
pages = {105–110},
numpages = {6},
location = {Perth, Australia},
series = {CATS '11}
}

@inproceedings{10.1145/1854153.1854155,
author = {Oklobdzija, Vojin},
title = {Computing at the Ultimate Low-Energy Limits},
year = {2010},
isbn = {9781450301527},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1854153.1854155},
doi = {10.1145/1854153.1854155},
abstract = {Given the fixed performance target, various parameters such as transistor sizing, supply voltage, transistor threshold and bias are the parameters determining the amount of energy required. While these parameters can be independently tuned, there is a physical limit determining the minimal amount of energy needed in order to achieve target performance. This lecture will examine various optimization parameters and inter-relationship between various transistor and circuit design parameters leading to computation with minimal energy.},
booktitle = {Proceedings of the 23rd Symposium on Integrated Circuits and System Design},
pages = {1},
numpages = {1},
keywords = {low power design},
location = {S\~{a}o Paulo, Brazil},
series = {SBCCI '10}
}

@inproceedings{10.1145/3239264.3239275,
author = {Al-shehri, Hanan Ali and Hamdi, Khaoula},
title = {Energy-Aware Multi-Objective Placement of Virtual Machines in Cloud Data Centers},
year = {2018},
isbn = {9781450364096},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239264.3239275},
doi = {10.1145/3239264.3239275},
abstract = {Cloud computing is a model for enabling convenient, on-demand access to a shared pool of configurable computing resources. The main advantage of cloud computing is minimizing the cost, but on the other hand energy consumption in cloud data centers is exponentially increasing. Thus, there is a need to improve the energy efficiency of cloud data centers. In this paper, the optimization of the virtual machines placement is considered with the objective of improving the energy efficiency. An Ant Colony Algorithm is proposed with multiple objectives. In addition to minimizing the energy consumption by reducing the number of active physical machines, the generated network traffic is minimized and the utilization of the resources is maximized. CloudSim tool is then used to simulate the results of the proposed algorithm.},
booktitle = {Proceedings of the 2018 7th International Conference on Bioinformatics and Biomedical Science},
pages = {41–45},
numpages = {5},
keywords = {Network-aware, Energy-aware, VMs placement, Virtual Machines, Green cloud, Ant Colony Optimization},
location = {Shenzhen, China},
series = {ICBBS '18}
}

@article{10.1145/2425248.2425254,
author = {Ghumre, Pooja and Li, Junwei and Kesavan, Mukil and Gavrilovska, Ada and Schwan, Karsten},
title = {Evaluating the Need for Complexity in Energy-Aware Management for Cloud Platforms},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {3},
issn = {0163-5999},
url = {https://doi.org/10.1145/2425248.2425254},
doi = {10.1145/2425248.2425254},
abstract = {In order to curtail the continuous increase in power consumption of modern datacenters, researchers are responding with sophisticated energy-aware workload management methods. This increases the complexity and cost of the management operation, and may lead to increases in failure rates. The goal of this paper is to illustrate that there exists considerable diversity in the effectiveness of different, potentially 'smarter' workload management methods depending on the target metric or the characteristics of the workload being managed. We conduct experiments on a datacenter prototype platform, virtualized with the VMware vSphere software, and using representative cloud applications -- a distributed key-value store and a map-reduce computation. We observe that, on our testbed, different workload placement decisions may be quite effective for some metrics, but may lead to only marginal impact on others. In particular, we are considering the impact on energy-related metrics, such as power or temperature, as corresponding energy-aware management methods typically come with greater complexity due to fact that they must consider the complex energy consumption trends of various components in the cloud infrastructure. We show that for certain applications, such costs can be avoided, as different management policies and placement decisions have marginal impact on the target metric. The objective is to understand whether for certain classes of applications, and/or application configurations, it is necessary to incur, or if it is benefitial to avoid, the use of complex management methods.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jan},
pages = {23–27},
numpages = {5}
}

@article{10.1145/3097264,
author = {Sarwar, Syed Shakib and Venkataramani, Swagath and Ankit, Aayush and Raghunathan, Anand and Roy, Kaushik},
title = {Energy-Efficient Neural Computing with Approximate Multipliers},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {1550-4832},
url = {https://doi.org/10.1145/3097264},
doi = {10.1145/3097264},
abstract = {Neural networks, with their remarkable ability to derive meaning from a large volume of complicated or imprecise data, can be used to extract patterns and detect trends that are too complex for the von Neumann computing paradigm. Their considerable computational requirements stretch the capabilities of even modern computing platforms. We propose an approximate multiplier that exploits the inherent application resilience to error and utilizes the notion of computation sharing to achieve improved energy consumption for neural networks. We also propose a Multiplier-less Artificial Neuron (MAN), which is even more compact and energy efficient. We also propose a network retraining methodology to recover some of the accuracy loss due to the use of these approximate multipliers. We evaluated the proposed algorithm/design on several recognition applications. The results show that we achieve ∼33%, ∼32%, and ∼25% reduction in power consumption and ∼33%, ∼34%, and ∼27% reduction in area, respectively, for 12-, 8-, and 4-bit MAN, with a maximum ∼2.4% loss in accuracy compared to a conventional neuron implementation of equivalent bit precision. These comparisons were performed under iso-speed conditions.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {jul},
articleno = {16},
numpages = {23},
keywords = {artificial neural network (ANN), computation sharing multiplication (CSHM), Alphabet set multiplier (ASM), bit precision scaling, multiplier-less artificial neuron (MAN)}
}

@inproceedings{10.1145/1791314.1791347,
author = {Vasudevan, Vijay and Andersen, David and Kaminsky, Michael and Tan, Lawrence and Franklin, Jason and Moraru, Iulian},
title = {Energy-Efficient Cluster Computing with FAWN: Workloads and Implications},
year = {2010},
isbn = {9781450300421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1791314.1791347},
doi = {10.1145/1791314.1791347},
abstract = {This paper presents the architecture and motivation for a cluster-based, many-core computing architecture for energy-efficient, data-intensive computing. FAWN, a Fast Array of Wimpy Nodes, consists of a large number of slower but efficient nodes coupled with low-power storage. We present the computing trends that motivate a FAWN-like approach, for CPU, memory, and storage. We follow with a set of microbenchmarks to explore under what workloads these "wimpy nodes" perform well (or perform poorly). We conclude with an outline of the longer-term implications of FAWN that lead us to select a tightly integrated stacked chip-and-memory architecture for future FAWN development.},
booktitle = {Proceedings of the 1st International Conference on Energy-Efficient Computing and Networking},
pages = {195–204},
numpages = {10},
keywords = {energy efficiency, performance, flash, cluster computing, measurement, design},
location = {Passau, Germany},
series = {e-Energy '10}
}

@inproceedings{10.1145/1998561.1998566,
author = {Bodenstein, Christian and Hedwig, Markus and Neumann, Dirk},
title = {Low-Energy Automated Scheduling of Computing Resources},
year = {2011},
isbn = {9781450307345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1998561.1998566},
doi = {10.1145/1998561.1998566},
abstract = {The cost of electricity for datacenters is a substantial operational cost that can and should be managed, not only for saving energy, but also due to the ecologic commitment inherent to power consumption. This work proposes, formalizes and numerically evaluates LEAS, a low-energy scheduling model, for clearing scheduling markets, based on the maximization of welfare, subject to utility-level dependant energy costs. We promote energy-efficient policies in management of datacenters, to enhance the efficiency of modernized datacenters. We focus specifically on linear power models, and the implications of the inherent fixed costs related to energy consumption of modern datacenters. We rigorously test the model by running multiple simulation scenarios derived from real workload traces, and evaluate the results using common statistical methods. We conclude with positive results and implications for long-term sustainable management of modern datacenters.},
booktitle = {Proceedings of the 1st ACM/IEEE Workshop on Autonomic Computing in Economics},
pages = {11–18},
numpages = {8},
keywords = {decision support system, datacenters, scheduling, green it},
location = {Karlsruhe, Germany},
series = {ACE '11}
}

@inproceedings{10.5555/2483191.2483204,
author = {Suzuki, Akira and Uchizawa, Kei and Zhou, Xiao},
title = {Energy-Efficient Threshold Circuits Computing Mod Functions},
year = {2011},
isbn = {9781920682989},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {We prove that the modulus function MODm of n variables can be computed by a threshold circuit C of energy e and size s = O(e(n/m)1/(e−1)) for any integer e ≥ 2, where the energy e is defined to be the maximum number of gates outputting "1" over all inputs to C, and the size s to be the number of gates in C. Our upper bound on the size s almost matches the known lower bound s = Ω(e(n/m)1/e).},
booktitle = {Proceedings of the Seventeenth Computing on The Australasian Theory Symposium - Volume 119},
pages = {105–110},
numpages = {6},
location = {Perth, Australia},
series = {CATS 2011}
}

@inproceedings{10.1145/3195970.3196060,
author = {Imani, Mohsen and Huang, Chenyu and Kong, Deqian and Rosing, Tajana},
title = {Hierarchical Hyperdimensional Computing for Energy Efficient Classification},
year = {2018},
isbn = {9781450357005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195970.3196060},
doi = {10.1145/3195970.3196060},
abstract = {Brain-inspired Hyperdimensional (HD) computing emulates cognition tasks by computing with hypervectors rather than traditional numerical values. In HD, an encoder maps inputs to high dimensional vectors (hypervectors) and combines them to generate a model for each existing class. During inference, HD performs the task of reasoning by looking for similarities of the input hypervector and each pre-stored class hypervector However, there is not a unique encoding in HD which can perfectly map inputs to hypervectors. This results in low HD classification accuracy over complex tasks such as speech recognition. In this paper we propose MHD, a multi-encoder hierarchical classifier, which enables HD to take full advantages of multiple encoders without increasing the cost of classification. MHD consists of two HD stages: a main stage and a decider stage. The main stage makes use of multiple classifiers with different encoders to classify a wide range of input data. Each classifier in the main stage can trade between efficiency and accuracy by dynamically varying the hypervectors' dimensions. The decider stage, located before the main stage, learns the difficulty of the input data and selects an encoder within the main stage that will provide the maximum accuracy, while also maximizing the efficiency of the classification task. We test the accuracy/efficiency of the proposed MHD on speech recognition application. Our evaluation shows that MHD can provide a 6.6\texttimes{} improvement in energy efficiency and a 6.3\texttimes{} speedup, as compared to baseline single level HD.},
booktitle = {Proceedings of the 55th Annual Design Automation Conference},
articleno = {108},
numpages = {6},
keywords = {energy efficiency, brain-inspired computing, machine learning, hyperdimensional computing},
location = {San Francisco, California},
series = {DAC '18}
}

@inproceedings{10.1145/1065579.1065590,
author = {Muttreja, Anish and Raghunathan, Anand and Ravi, Srivaths and Jha, Niraj K.},
title = {Hybrid Simulation for Embedded Software Energy Estimation},
year = {2005},
isbn = {1595930582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1065579.1065590},
doi = {10.1145/1065579.1065590},
abstract = {Software energy estimation is a critical step in the design of energy-efficient embedded systems. Instruction-level simulation techniques, despite several advances, remain too slow for iterative use in system-level exploration. In this paper, we propose a methodology called hybrid simulation, which combines instruction set simulation with selective native execution (execution of some parts of the program directly on the simulation host computer), thereby overcoming the disadvantages of instruction-level simulation (low speed) and pure native execution (estimation accuracy, inapplicability to target-dependent code), while exploiting their advantages. Previously developed techniques for software energy macromodeling are utilized to estimate energy consumption for natively executed sub-programs. We identify and address the main challenges involved in hybrid simulation, and present an automatic tool flow for it, which analyzes a given program and selects functions for native execution in order to achieve maximum estimation efficiency while limiting estimation error. We have applied the proposed hybrid simulation methodology to a variety of embedded software programs, resulting in an average speed-up of 70% and estimation error of at most 6%, compared to one of the fastest publicly-available instruction set simulators.},
booktitle = {Proceedings of the 42nd Annual Design Automation Conference},
pages = {23–26},
numpages = {4},
keywords = {pointers analysis, hybrid simulation, energy estimation, embedded software, energy macromodels},
location = {Anaheim, California, USA},
series = {DAC '05}
}

@inproceedings{10.1145/800208.806439,
author = {Butler, Margaret K.},
title = {Portability and the National Energy Software Center},
year = {1978},
isbn = {9781450377966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800208.806439},
doi = {10.1145/800208.806439},
abstract = {The software portability problem is examined from the viewpoint of experience gained in the operation of a software exchange and information center. First, the factors contributing to the program interchange to date are identified, then major problem areas remaining are noted. The import of the development of programming language and documentation standards is noted, and the program packaging procedures and dissemination practices employed by the Center to facilitate successful software transport are described. Organization, or installation, dependencies of the computing environment, often hidden from the program author, and data interchange complexities are seen as today's primary issues with dedicated processors and network communications offering an alternative solution.},
booktitle = {Proceedings of the SIGNUM Conference on the Programming Environment for Development of Numerical Software},
pages = {87–89},
numpages = {3}
}

@inproceedings{10.1145/3555776.3577767,
author = {Mhatre, Jui and Lee, Ahyoung},
title = {MP-DDPG: Optimal Latency-Energy Dynamic Offloading Scheme in Collaborative Cloud Networks},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577767},
doi = {10.1145/3555776.3577767},
abstract = {Growing technologies like virtualization and artificial intelligence have become more popular on mobile devices. But lack of resources faced for processing these applications is still major hurdle. Collaborative edge and cloud computing are one of the solutions to this problem. We have proposed a multi-period deep deterministic policy gradient (MP-DDPG) algorithm to find an optimal offloading policy by partitioning the task and offloading it to the collaborative cloud and edge network to reduce energy consumption. Our results show that MP-DDPG achieves the minimum latency and energy consumption in the collaborative cloud network.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {658–660},
numpages = {3},
keywords = {multi-period deep deterministic policy gradient, energy efficiency, latency, collaborative cloud computing, computation offloading, deep reinforcement learning},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/1943628.1943664,
author = {Akhtar, Imran and Borggaard, Jeff and Burns, John A.},
title = {High Performance Computing for Energy Efficient Buildings},
year = {2010},
isbn = {9781450303422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1943628.1943664},
doi = {10.1145/1943628.1943664},
abstract = {Commercial buildings are the largest single consumer of energy in the United States. Energy efficient buildings will have a significant impact on overall energy consumption and greenhouse gas emissions. Buildings being multi-scale, multi-physics, highly uncertain dynamic systems, its energy efficiency is directly linked with the design and control of various systems in buildings. Achieving substantial levels of energy savings over the life-time of a building require not only the state-of-the-art hardware technology but also a thorough computational framework which includes mathematical algorithms, computational science methodologies and computer tools targeted for rapid analysis, optimization and control. Direct application of high fidelity simulation models to problems of optimal design and control is not feasible. Thus, reduced-order models are often developed for an efficient design and control. In this study, we present the application of high performance computing tools to perform high fidelity flow simulations in a typical room which serves as a basic unit in a building. Using a large data set of the flow and temperature field distributed among various processors, we compute optimal basis functions in parallel. These basis functions are used in developing reduced-order models of complex systems for control and optimization purposes.},
booktitle = {Proceedings of the 8th International Conference on Frontiers of Information Technology},
articleno = {36},
numpages = {6},
keywords = {proper orthogonal decomposition, high performance computing, reduced-order modeling},
location = {Islamabad, Pakistan},
series = {FIT '10}
}

@inproceedings{10.1145/3328833.3328868,
author = {Moussa, Rania Rushdy and Dewidar, Khaled Mohamed},
title = {Evaluating the Efficiency of Energy-Scape Software},
year = {2019},
isbn = {9781450361057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328833.3328868},
doi = {10.1145/3328833.3328868},
abstract = {Recently, researchers were focusing on integrating renewable energy (RE) within urban environment instead of integrating renewables with buildings due to the large occupies of urban areas. Urban areas have a great potential in generating sufficient amount of energy that could satisfy the needs of urban neighborhoods. Energy-scape elements are sustainable elements that integrates RE devices with landscape elements. This research focuses on analyzing the importance and efficiency of Energy-scape software through a qualitative method. The efficiency of Energy-scape web-based application will be tested using qualitative method and a site survey. The research concludes that Energy-scape software application is an effective tool for landscape designers in using Energy-scape elements, it identifies the optimum type and location of Energy-scape elements within their projects, and it calculates the impact of using Energy-scape elements in term of energy-savings and carbon emission (CO2) reduction.},
booktitle = {Proceedings of the 8th International Conference on Software and Information Engineering},
pages = {60–65},
numpages = {6},
keywords = {Renewable energy, Energy-scape database, Energy-scape software, Energy-scape Elements, Landscape elements},
location = {Cairo, Egypt},
series = {ICSIE '19}
}

@inproceedings{10.1145/2541940.2541980,
author = {Schulte, Eric and Dorn, Jonathan and Harding, Stephen and Forrest, Stephanie and Weimer, Westley},
title = {Post-Compiler Software Optimization for Reducing Energy},
year = {2014},
isbn = {9781450323055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541940.2541980},
doi = {10.1145/2541940.2541980},
abstract = {Modern compilers typically optimize for executable size and speed, rarely exploring non-functional properties such as power efficiency. These properties are often hardware-specific, time-intensive to optimize, and may not be amenable to standard dataflow optimizations. We present a general post-compilation approach called Genetic Optimization Algorithm (GOA), which targets measurable non-functional aspects of software execution in programs that compile to x86 assembly. GOA combines insights from profile-guided optimization, superoptimization, evolutionary computation and mutational robustness. GOA searches for program variants that retain required functional behavior while improving non-functional behavior, using characteristic workloads and predictive modeling to guide the search. The resulting optimizations are validated using physical performance measurements and a larger held-out test suite. Our experimental results on PARSEC benchmark programs show average energy reductions of 20%, both for a large AMD system and a small Intel system, while maintaining program functionality on target workloads.},
booktitle = {Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {639–652},
numpages = {14},
keywords = {compilation, mutational robustness, power modeling, superoptimization, profile-guided optimization, assembly code, evolutionary computation},
location = {Salt Lake City, Utah, USA},
series = {ASPLOS '14}
}

@inproceedings{10.1145/1062261.1062335,
author = {Vit\'{a}nyi, Paul},
title = {Time, Space, and Energy in Reversible Computing},
year = {2005},
isbn = {1595930191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1062261.1062335},
doi = {10.1145/1062261.1062335},
abstract = {We survey some results of a quarter century of work on general reversible computation about energy-, time- and space requirements.},
booktitle = {Proceedings of the 2nd Conference on Computing Frontiers},
pages = {435–444},
numpages = {10},
keywords = {space complexity, low-energy computing, reversible computing, adiabatic computing, time complexity, tradeoffs, energy dissipation complexity, computational complexity, reversible simulation},
location = {Ischia, Italy},
series = {CF '05}
}

@inproceedings{10.1145/566408.566449,
author = {Rakhmatov, Daler and Vrudhula, Sarma and Wallach, Deborah A.},
title = {Battery Lifetime Prediction for Energy-Aware Computing},
year = {2002},
isbn = {1581134754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/566408.566449},
doi = {10.1145/566408.566449},
abstract = {Predicting the time of full discharge of a finite-capacity energy source, such as a battery, is important for the design of portable electronic systems and applications. In this paper we present a novel analytical model of a battery that not only can be used to predict battery lifetime, but also can serve as a cost function for optimization of the energy usage in battery-powered systems. The model is physically justified, and involves only two parameters, which are easily estimated. The paper includes the results of extensive experimental evaluation of the model with respect to numerical simulations of the electrochemical cell, as well as measurements taken on a real battery. The model was tested using constant, interrupted, periodic and non-periodic discharge profiles, which were derived from standard applications run on a pocket computer.},
booktitle = {Proceedings of the 2002 International Symposium on Low Power Electronics and Design},
pages = {154–159},
numpages = {6},
keywords = {battery, modeling, low-power design},
location = {Monterey, California, USA},
series = {ISLPED '02}
}

@inproceedings{10.1145/3412841.3442070,
author = {Kishor, Avadh and Niyogi, Rajdeep},
title = {A Bargaining Game Based Energy-Aware Load Balancing in Cloud Data Centers},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442070},
doi = {10.1145/3412841.3442070},
abstract = {This paper addresses the energy-aware load balancing problem in the cloud computing environment. The problem considers two performance criteria- response time and energy. First, it is modeled as a cooperative game, and then an efficient algorithm is proposed to compute the Nash bargaining solution (NBS). The proposed algorithm is compared with an existing approach called NCG. The experimental results show that the proposed algorithm provides less response time while consuming less energy.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {86–88},
numpages = {3},
keywords = {load balancing, cloud computing, energy minimization, cooperative game, nash bargaining solution},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@inproceedings{10.1145/3599733.3600253,
author = {Br\"{a}nnvall, Rickard and Stark, Tina and Gustafsson, Jonas and Eriksson, Mats and Summers, Jon},
title = {Cost Optimization for the Edge-Cloud Continuum by Energy-Aware Workload Placement},
year = {2023},
isbn = {9798400702273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3599733.3600253},
doi = {10.1145/3599733.3600253},
abstract = {This article investigates the problem of where to place the computation workload in an edge-cloud network topology considering the trade-off between the location-specific cost of computation and data communication. For this purpose, a Monte Carlo simulation model is defined that accounts for different workload types, their distribution across time and location, as well as correlation structure. Results confirm and quantify the intuition that optimization can be achieved by distributing a part of cloud computation to make efficient use of resources in an edge data center network, with operational energy savings of 4–6% and up to 50% reduction in its claim for cloud capacity.},
booktitle = {Companion Proceedings of the 14th ACM International Conference on Future Energy Systems},
pages = {79–84},
numpages = {6},
keywords = {energy efficiency, sustainability, cost optimization, edge, data center},
location = {Orlando, FL, USA},
series = {e-Energy '23 Companion}
}

@inproceedings{10.1145/2905055.2905135,
author = {Patel, Khyati and Patel, Nimisha and Patel, Hiren},
title = {Efficient Resource Allocation Strategy to Improve Energy Consumption in Cloud Data Centers},
year = {2016},
isbn = {9781450339629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2905055.2905135},
doi = {10.1145/2905055.2905135},
abstract = {The Cloud provider offers computing resources such as processing capabilities, storage, network bandwidth etc. to the consumers on pay-as-go model. Due to its wide adaptability and ease of use, Cloud has emerged drastically over the last few years. However, increase in Cloud usage has lead to increase in number of computing resources and hence, increase in energy consumption. Recently, the issue of effective energy consumption has been addressed by a good number of researchers. In our work, we intend to study various energy efficient techniques for Cloud which uses resource allocation and consolidation to achieve the same. Further, we try to modify the existing technique by adding an extra parameter viz. time which assists in maximizing resource utilization and minimizing number of running servers.},
booktitle = {Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {76},
numpages = {6},
keywords = {Resource Management, Live migration, Virtualization, Cloud computing, Energy efficiency, Resource allocation, VM consolidation},
location = {Udaipur, India},
series = {ICTCS '16}
}

@article{10.1145/2825236.2825251,
author = {Wu, Huaming and Sun, Yi and Wolter, Katinka},
title = {Analysis of the Energy-Response Time Tradeoff for Delayed Mobile Cloud Offloading},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {0163-5999},
url = {https://doi.org/10.1145/2825236.2825251},
doi = {10.1145/2825236.2825251},
abstract = {We develop a delayed offloading model to leverage the complementary strength of WiFi and cellular networks when choosing heterogeneous wireless interfaces for offloading. Optimality analysis of the energy-delay tradeoff is carried out by using a queueing model with impatient jobs and service interruptions, which captures both energy and performance metrics and also intermittently available access links.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {sep},
pages = {33–35},
numpages = {3}
}

@inproceedings{10.1145/996566.996599,
author = {Muttreja, Anish and Raghunathan, Anand and Ravi, Srivaths and Jha, Niraj K.},
title = {Automated Energy/Performance Macromodeling of Embedded Software},
year = {2004},
isbn = {1581138288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/996566.996599},
doi = {10.1145/996566.996599},
abstract = {Efficient energy and performance estimation of embedded software is a critical part of any system-level design flow. Macromodeling based estimation is an attempt to speed up estimation by exploiting reuse that is inherent in the design process. Macromodeling involves pre-characterizing reusable software components to construct high-level models, which express the execution time or energy consumption of a sub-program as a function of suitable parameters. During simulation, macromodels can be used instead of detailed hardware models, resulting in orders of magnitude simulation speedup. However, in order to realize this potential, significant challenges need to be overcome in both the generation and use of macromodels--- including how to identify the parameters to be used in the macromodel, how to define the template function to which the macromodel is fitted, em etc. This paper presents an automatic methodology to perform characterization-based high-level software macromodeling, which addresses the aforementioned issues. Given a sub-program to be macromodeled for execution time and/or energy consumption, the proposed methodology automates the steps of parameter identification, data collection through detailed simulation, macromodel template selection, and fitting. We propose a novel technique to identify potential macromodel parameters and perform data collection, which draws from the concept of bf data structure serialization used in distributed programming. We utilize bf symbolic regression techniques to concurrently filter out irrelevant macromodel parameters, construct a macromodel function, and derive the optimal coefficient values to minimize fitting error. Experiments with several realistic benchmarks suggest that the proposed methodology improves estimation accuracy and enables wide applicability of macromodeling to complex embedded software, while realizing its potential for estimation speedup. We describe a case study of how macromodeling can be used to rapidly explore algorithm-level energy tradeoffs, for the tt zlib data compression library.},
booktitle = {Proceedings of the 41st Annual Design Automation Conference},
pages = {99–102},
numpages = {4},
keywords = {genetic programming, embedded software, macromodeling, regression, symbolic, data serialization},
location = {San Diego, CA, USA},
series = {DAC '04}
}

@article{10.1145/3337773,
author = {Georgiou, Stefanos and Rizou, Stamatia and Spinellis, Diomidis},
title = {Software Development Lifecycle for Energy Efficiency: Techniques and Tools},
year = {2019},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3337773},
doi = {10.1145/3337773},
abstract = {Motivation: In modern it systems, the increasing demand for computational power is tightly coupled with ever higher energy consumption. Traditionally, energy efficiency research has focused on reducing energy consumption at the hardware level. Nevertheless, the software itself provides numerous opportunities for improving energy efficiency.Goal: Given that energy efficiency for it systems is a rising concern, we investigate existing work in the area of energy-aware software development and identify open research challenges. Our goal is to reveal limitations, features, and tradeoffs regarding energy-performance for software development and provide insights on existing approaches, tools, and techniques for energy-efficient programming.Method: We analyze and categorize research work mostly extracted from top-tier conferences and journals concerning energy efficiency across the software development lifecycle phases.Results: Our analysis shows that related work in this area has focused mainly on the implementation and verification phases of the software development lifecycle. Existing work shows that the use of parallel and approximate programming, source code analyzers, efficient data structures, coding practices, and specific programming languages can significantly increase energy efficiency. Moreover, the utilization of energy monitoring tools and benchmarks can provide insights for the software practitioners and raise energy-awareness during the development phase.},
journal = {ACM Comput. Surv.},
month = {aug},
articleno = {81},
numpages = {33},
keywords = {software development lifecycle, code refactoring, parallel programming, approximate programming, design patterns, coding practices, source code analysis, energy efficiency, GreenIT, energy profiling, energy optimization}
}

@inproceedings{10.5555/3539845.3539900,
author = {Wang, Bo and Zhu, Rong and Shang, Jiaxing and Liu, Dajiang},
title = {Towards Energy-Efficient CGRAs via Stochastic Computing},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Stochastic computing (SC) is a promising computing paradigm for low-power and low-cost applications with the added benefit of high error tolerance. Meanwhile, Coarse-Grained Re-configurable Architecture (CGRA) is also a promising platform for domain-specific applications for its combination of energy efficiency and flexibility. Intuitively, introducing SC to CGRA would synergistically reinforce the strengths of both paradigms. Accordingly, this paper proposes an SC-based CGRA by replacing the exact multiplication in traditional CGRA with an SC-based multiplication, where the problem of accuracy and latency are both improved using parallel stochastic sequence generators and leading zero shifters. In addition, with the flexible connections among PEs, the high-accuracy operation can be easily achieved by combing neighbor PEs without switching costs like power-gating. Compared to the state-of-the-art approximate computing design of CGRA, our proposed CGRA has 16% more energy reduction and 34% energy efficiency improvement while keeping high configuration flexibility.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {202–207},
numpages = {6},
keywords = {energy efficiency, CGRA, stochastic computing, approximate computing, configuration flexibility},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3253825,
author = {Choi, Ken and Pangrle, Brarry},
title = {Session Details: Energy-Aware Client-Server Computing},
year = {2009},
isbn = {9781605586847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3253825},
doi = {10.1145/3253825},
booktitle = {Proceedings of the 2009 ACM/IEEE International Symposium on Low Power Electronics and Design},
location = {San Fancisco, CA, USA},
series = {ISLPED '09}
}

@inproceedings{10.1145/3171592.3171616,
author = {Guo, Wenxia and Ren, Xiaoqin and Tian, Wenhong and Venugopal, Srikumar},
title = {Self-Adaptive Consolidation of Virtual Machines For Energy-Efficiency in the Cloud},
year = {2017},
isbn = {9781450353663},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3171592.3171616},
doi = {10.1145/3171592.3171616},
abstract = {In virtualized data centers, consolidation of Virtual Machines (VMs) on minimizing the number of total physical machines (PMs) has been recognized as a very efficient approach. This paper considers the energy-efficient consolidation of VMs in a Cloud Data center. Concentrating on CPU-intensive applications, the objective is to schedule all requests non-preemptively, subjecting to constraints of PM capacities and running time interval spans, such that the total energy consumption of all PMs is minimized (called MinTE for abbreviation). The MinTE problem is NP-complete in general. We propose a self-adaptive approached called SAVE. The approach makes decisions of the assignment and migration of VMs by probabilistic processes and is based exclusively on local information, therefore it is very simple to implement. Both simulation and real environment test show that our proposed method SAVE can reduce energy consumption about 30% against VMWare DRS and 10-20% against EcoCloud on average.},
booktitle = {Proceedings of the 2017 VI International Conference on Network, Communication and Computing},
pages = {120–124},
numpages = {5},
keywords = {self-adaptive, energy-efficiency, Cloud computing, consolidation of virtual machines},
location = {Kunming, China},
series = {ICNCC '17}
}

@inproceedings{10.5555/3451271.3451277,
author = {Sp\"{o}rk, Michael and Schu\ss{}, Markus and Boano, Carlo Alberto and R\"{o}mer, Kay},
title = {Ensuring End-to-End Dependability Requirements in Cloud-Based Bluetooth Low Energy Applications},
year = {2021},
publisher = {Junction Publishing},
address = {USA},
abstract = {Bluetooth Low Energy (BLE) is increasingly used for time-critical IoT applications, where BLE-based smart objects need to exchange data with a remote server within stringent end-to-end latency and reliability bounds. While existing research has investigated how to timely send packets between pairs of BLE devices, it is still unclear how a BLE device can sustain time-critical end-to-end communication with a remote server, for example, hosted in the cloud. In this paper, we tackle this problem and show how BLE devices can autonomously measure and cope with end-toend network delays and loss along the path to the remote server. To this end, we first devise an analytical model of the communication between a BLE end-node and the cloud. We then leverage this model to dynamically adapt the communication parameters of the BLE device and sustain the desired end-to-end dependability requirements while minimizing the energy expenditure. Specifically, we design and implement two adaptation strategies on the popular nRF52 platform, and experimentally show that they both allow to sustain a given end-to-end reliability and a given end-to-end latency for data transmissions from/to the BLE node, while limiting the node's power consumption.},
booktitle = {Proceedings of the 2021 International Conference on Embedded Wireless Systems and Networks},
pages = {55–66},
numpages = {12},
location = {Delft, The Netherlands},
series = {EWSN '21}
}

@inproceedings{10.1145/3242102.3242133,
author = {Mazouzi, Houssemeddine and Achir, Nadjib and Boussetta, Khaled},
title = {Maximizing Mobiles Energy Saving Through Tasks Optimal Offloading Placement in Two-Tier Cloud},
year = {2018},
isbn = {9781450359603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3242102.3242133},
doi = {10.1145/3242102.3242133},
abstract = {In this paper, we focus on tasks offloading over two tiered mobile cloud computing environment. We consider several users with energy constrained tasks that can be offloaded over cloudlets or on a remote cloud with differentiated system and network resources capacities. We investigate offloading policy that decides which tasks should be offloaded and determine the offloading location on the cloudlets or on the cloud. The objective is to minimize the total energy consumed by the users. We formulate this problem as a Non-Linear Binary Integer Programming. Since the centralized optimal solution is NP-hard, we propose a distributed linear relaxation heuristic based on Lagrangian decomposition approach. To solve the subproblems, we also propose a greedy heuristic that computes the best cloudlet selection and bandwidth allocation following tasks' energy consumption. We compared our proposal against existing approaches under different system parameters (e.g. CPU resources), variable number of users and for six applications, each having specific traffic pattern, resource demands and time constraints. Numerical results show that our proposal outperforms existing approaches. We also analyze the performance of our proposal for each application.},
booktitle = {Proceedings of the 21st ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {137–145},
numpages = {9},
keywords = {computation offloading, mobile cloud computing, cloudlet, lagrangian decomposition, mobile edge computing},
location = {Montreal, QC, Canada},
series = {MSWIM '18}
}

@inproceedings{10.1109/CCGrid.2014.119,
author = {Subramaniam, Balaji},
title = {Metrics, Models and Methodologies for Energy-Proportional Computing},
year = {2014},
isbn = {9781479927838},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2014.119},
doi = {10.1109/CCGrid.2014.119},
abstract = {The proliferation of web application has led to the rapid growth in large-scale data centers. The commensurate increase in the cost of building infrastructure capable of powering such massive data centers and the recurring energy costs to keep such data centers operational has exposed power as a first-order design constraint. Such data centers are typically overprovisioned to avoid unexpected outages associated with the potential overloading of electrical circuitry [8], [9]. However, these data centers are under-utilized due to the inherent nature of the workloads [5], [8] and the need to provide isolation to mitigate serious violation of performance agreements (i.e., throughput and response time constraints) [9]. Unfortunately, power efficiency is traditionally measured only when a server is maximally exercised, and effective techniques to improve non-peak power efficiency is an active research area as improving it has been shown to help in the design of better power-provisioning strategies for data centers.},
booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {575–578},
numpages = {4},
location = {Chicago, Illinois},
series = {CCGRID '14}
}

@inproceedings{10.1145/3578245.3585329,
author = {Iosup, Alexandru and Prodan, Radu and Varbanescu, Ana-Lucia and Talluri, Sacheendra and Magalhaes, Gilles and Hokstam, Kailhan and Zwaan, Hugo and van Beek, Vincent and Farahani, Reza and Kimovski, Dragi},
title = {Graph Greenifier: Towards Sustainable and Energy-Aware Massive Graph Processing in the Computing Continuum},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585329},
doi = {10.1145/3578245.3585329},
abstract = {Our society is increasingly digital, and its processes are increasingly digitalized. As an emerging technology for the digital society, graphs provide a universal abstraction to represent concepts and objects, and the relationships between them. However, processing graphs at a massive scale raises numerous sustainability challenges; becoming energy-aware could help graph-processing infrastructure alleviate its climate impact. Graph Greenifier aims to address this challenge in the conceptual framework offered by the Graph Massivizer architecture. We present an early vision of how Graph Greenifier could provide sustainability analysis and decision-making capabilities for extreme graph-processing workloads. Graph Greenifier leverages an advanced digital twin for data center operations, based on the OpenDC open-source simulator, a novel toolchain for workload-driven simulation of graph processing at scale, and a sustainability predictor. The input to the digital twin combines monitoring of the information and communication technology infrastructure used for graph processing with data collected from the power grid. Graph Greenifier thus informs providers and consumers on operational sustainability aspects, requiring mutual information sharing, reducing energy consumption for graph analytics, and increasing the use of electricity from renewable sources.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {209–214},
numpages = {6},
keywords = {scalability, computing continuum, graph massivizer, sustainability, energy-awareness, graph processing, graph greenifier, digital twin},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1109/CCGRID.2018.00022,
author = {Ghosh, Rajrup and Komma, Siva Prakash Reddy and Simmhan, Yogesh},
title = {Adaptive Energy-Aware Scheduling of Dynamic Event Analytics across Edge and Cloud Resources},
year = {2018},
isbn = {9781538658154},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2018.00022},
doi = {10.1109/CCGRID.2018.00022},
abstract = {The growing deployment of sensors as part of Internet of Things (IoT) is generating thousands of event streams. Complex Event Processing (CEP) queries offer a useful paradigm for rapid decision-making over such data sources. While often centralized in the Cloud, the deployment of capable edge devices on the field motivates the need for cooperative event analytics that span Edge and Cloud computing. Here, we identify a novel problem of query placement on edge and Cloud resources for dynamically arriving and departing analytic dataflows. We define this as an optimization problem to minimize the total makespan for all event analytics, while meeting energy and compute constraints of the resources. We propose 4 adaptive heuristics and 3 rebalancing strategies for such dynamic dataflows, and validate them using detailed simulations for 100 -- 1000 edge devices and VMs. The results show that our heuristics offer O(seconds) planning time, give a valid and high quality solution in all cases, and reduce the number of query migrations. Furthermore, rebalance strategies when applied in these heuristics have significantly reduced the makespan by around 20 -- 25%.},
booktitle = {Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {72–82},
numpages = {11},
location = {Washington, District of Columbia},
series = {CCGrid '18}
}

@article{10.1145/2638550,
author = {Wu, Lisa and Polychroniou, Orestis and Barker, Raymond J. and Kim, Martha A. and Ross, Kenneth A.},
title = {Energy Analysis of Hardware and Software Range Partitioning},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {0734-2071},
url = {https://doi.org/10.1145/2638550},
doi = {10.1145/2638550},
abstract = {Data partitioning is a critical operation for manipulating large datasets because it subdivides tasks into pieces that are more amenable to efficient processing. It is often the limiting factor in database performance and represents a significant fraction of the overall runtime of large data queries. This article measures the performance and energy of state-of-the-art software partitioners, and describes and evaluates a hardware range partitioner that further improves efficiency.The software implementation is broken into two phases, allowing separate analysis of the partition function computation and data shuffling costs. Although range partitioning is commonly thought to be more expensive than simpler strategies such as hash partitioning, our measurements indicate that careful data movement and optimization of the partition function can allow it to approach the throughput and energy consumption of hash or radix partitioning.For further acceleration, we describe a hardware range partitioner, or HARP, a streaming framework that offers a seamless execution environment for this and other streaming accelerators, and a detailed analysis of a 32nm physical design that matches the throughput of four to eight software threads while consuming just 6.9% of the area and 4.3% of the power of a Xeon core in the same technology generation.},
journal = {ACM Trans. Comput. Syst.},
month = {aug},
articleno = {8},
numpages = {24},
keywords = {data partitioning, microarchitecture, Accelerator, streaming data, specialized functional unit}
}

@inproceedings{10.5555/3539845.3540224,
author = {Qiu, Qinru and Anagnostopoulos, Iraklis},
title = {Session Details: Energy Efficiency with Emerging Technologies for the Edge and the Cloud},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/1229428.1229480,
author = {Gontmakher, Alex and Mendelson, Avi and Schuster, Assaf},
title = {Using Fine Grain Multithreading for Energy Efficient Computing},
year = {2007},
isbn = {9781595936028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1229428.1229480},
doi = {10.1145/1229428.1229480},
abstract = {We investigate extremely fine-grain multithreading as a means for improving energy efficiency of single-task program execution.Our work is based on low-overhead threads executing an explicitly parallel program in a register-sharing context. The thread-based parallelism takes the place of instruction-level parallelism, allowing us to use simple and more energy-efficient in-order pipelines while retaining performance that is characteristic of classical out-of-order processors. Our evaluation shows that in energy terms, the parallelized code running over in-order pipelines can outperform both plain in-order and out-of-order processors.},
booktitle = {Proceedings of the 12th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {259–269},
numpages = {11},
keywords = {register sharing, energy efficiency, fine grain parallelization},
location = {San Jose, California, USA},
series = {PPoPP '07}
}

@inproceedings{10.1145/2905055.2905071,
author = {Reddy, K. Hemant Kumar and Mudali, Geetika and Roy, Diptendu Sinha},
title = {Energy Aware Heuristic Scheduling of Variable Class Constraint Resources in Cloud Data Centres},
year = {2016},
isbn = {9781450339629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2905055.2905071},
doi = {10.1145/2905055.2905071},
abstract = {Energy consumption management in cloud data centres is a very challenging research issue at present and the growth in cloud data centres have only compounded this challenge. In this paper, we focus on minimizing energy consumption of datacentres assuming the placement of VMs in physical servers as a bin packing problem having variable class constraints. We propose two algorithms, namely an energy-aware heuristic VM placement algorithm and an energy aware live Migration algorithm with variable resource class constraints intact for current resources' status. This paper presents some simulations carried out to investigate the efficacy of the proposed algorithms and the results obtained demonstrate the superiority of the proposed scheme.},
booktitle = {Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {13},
numpages = {6},
keywords = {Energy aware live migration, cloud data centre, Heuristic VM Placement, Variable class constraints},
location = {Udaipur, India},
series = {ICTCS '16}
}

@inproceedings{10.1109/CCGRID.2009.88,
author = {Huang, S. and Feng, W.},
title = {Energy-Efficient Cluster Computing via Accurate Workload Characterization},
year = {2009},
isbn = {9780769536224},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGRID.2009.88},
doi = {10.1109/CCGRID.2009.88},
abstract = {This paper presents an eco-friendly daemon that reduces power and energy consumption while better maintaining high performance via an accurate workload characterization that infers “processor stall cycles due to off-chip activities.” The eco-friendly daemon is an interval-based, run-time algorithm that uses the workload characterization to dynamically adjust a processor’s frequency and voltage to reduce power and energy consumption with little impact on application performance. Using the NAS Parallel Benchmarks as our workload, we then evaluate our eco-friendly daemon on a cluster computer. The results indicate that our workload characterization allows the power-aware daemon to more tightly control performance (5% loss instead of 11%) while delivering substantial energy savings (11% instead of 8%).},
booktitle = {Proceedings of the 2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid},
pages = {68–75},
numpages = {8},
series = {CCGRID '09}
}

@inproceedings{10.1145/2208828.2208832,
author = {Dupont, Corentin and Schulze, Thomas and Giuliani, Giovanni and Somov, Andrey and Hermenier, Fabien},
title = {An Energy Aware Framework for Virtual Machine Placement in Cloud Federated Data Centres},
year = {2012},
isbn = {9781450310550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2208828.2208832},
doi = {10.1145/2208828.2208832},
abstract = {Data centres are powerful ICT facilities which constantly evolve in size, complexity, and power consumption. At the same time users' and operators' requirements become more and more complex. However, existing data centre frameworks do not typically take energy consumption into account as a key parameter of the data centre's configuration. To lower the power consumption while fulfilling performance requirements we propose a flexible and energy-aware framework for the (re)allocation of virtual machines in a data centre. The framework, being independent from the data centre management system, computes and enacts the best possible placement of virtual machines based on constraints expressed through service level agreements. The framework's flexibility is achieved by decoupling the expressed constraints from the algorithms using the Constraint Programming (CP) paradigm and programming language, basing ourselves on a cluster management library called Entropy. Finally, the experimental and simulation results demonstrate the effectiveness of this approach in achieving the pursued energy optimization goals.},
booktitle = {Proceedings of the 3rd International Conference on Future Energy Systems: Where Energy, Computing and Communication Meet},
articleno = {4},
numpages = {10},
keywords = {service level agreement, data centre, energy efficiency, constraint programming, virtualization, resource management, cloud computing},
location = {Madrid, Spain},
series = {e-Energy '12}
}

@inproceedings{10.1145/3593908.3593947,
author = {De Cock, Jan},
title = {Energy Efficiency Improvements in Software-Based Video Encoding},
year = {2023},
isbn = {9798400701962},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593908.3593947},
doi = {10.1145/3593908.3593947},
abstract = {In this paper, we discuss the evolution in energy efficiency for software-based encoding on general-purpose processors, along with recent trends that enable increasingly power-efficient video encoding. We provide an overview of different contributing factors that have led to a massive increase in software-based performance, along with innovations that are leading to further efficiency improvements.},
booktitle = {Proceedings of the First International Workshop on Green Multimedia Systems},
pages = {19–21},
numpages = {3},
location = {Vancouver, BC, Canada},
series = {GMSys '23}
}

@inproceedings{10.1145/339647.339659,
author = {Vijaykrishnan, N. and Kandemir, M. and Irwin, M. J. and Kim, H. S. and Ye, W.},
title = {Energy-Driven Integrated Hardware-Software Optimizations Using SimplePower},
year = {2000},
isbn = {1581132328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/339647.339659},
doi = {10.1145/339647.339659},
abstract = {With the emergence of a plethora of embedded and portable applications, energy dissipation has joined throughput, area, and accuracy/precision as a major design constraint. Thus, designers must be concerned with both optimizing and estimating the energy consumption of circuits, architectures, and software. Most of the research in energy optimization and/or estimation has focused on single components of the system and has not looked across the interacting spectrum of the hardware and software. The novelty of our new energy estimation framework, SimplePower, is that it evaluates the energy considering the system as a whole rather than just as a sum of parts, and that it concurrently supports both compiler and architectural experimentation.We present the design and use of the SimplePower framework that includes a transition-sensitive, cycle-accurate datapath energy model that interfaces with analytical and transition sensitive energy models for the memory and bus subsystems, respectively. We analyzed the energy consumption of ten codes from the multidimensional array domain, a domain that is important for embedded video and signal processing systems, after applying different compiler and architectural optimizations. Our experiments demonstrate that early estimates from the SimplePower energy estimation framework can help identify the system energy hotspots and enable architects and compiler designers to focus their efforts on these areas.},
booktitle = {Proceedings of the 27th Annual International Symposium on Computer Architecture},
pages = {95–106},
numpages = {12},
keywords = {compiler optimizations, hardware-software interaction, system energy, energy optimization and estimation, energy simulator, low-power architectures},
location = {Vancouver, British Columbia, Canada},
series = {ISCA '00}
}

@inproceedings{10.1145/3079368.3079396,
author = {van Gastel, Bernard},
title = {Analysing Energy Consumption of Systems Controlled by Software},
year = {2017},
isbn = {9781450348362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3079368.3079396},
doi = {10.1145/3079368.3079396},
abstract = {Energy consumption analysis of IT-controlled systems can play a major role in minimising the overall energy consumption of such IT systems, during the development phase, or for optimisation in the field. As software is increasingly embedded in our daily life, with IT using more and more energy, the software industry should become aware of their energy footprint, and methods must be developed to assist in reducing this footprint.Recently, we developed a precise energy analysis, to analyse software in conjunction with hardware. It has the property of being parametric with regard to the hardware. In principle, this creates the opportunity to investigate which is the best software implementation for given hardware, or the other way around: choose the best hardware for a given algorithm.},
booktitle = {Companion Proceedings of the 1st International Conference on the Art, Science, and Engineering of Programming},
articleno = {19},
numpages = {2},
location = {Brussels, Belgium},
series = {Programming '17}
}

@inproceedings{10.1145/3020078.3021730,
author = {Weller, Dennis and Oboril, Fabian and Lukarski, Dimitar and Becker, Juergen and Tahoori, Mehdi},
title = {Energy Efficient Scientific Computing on FPGAs Using OpenCL},
year = {2017},
isbn = {9781450343541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3020078.3021730},
doi = {10.1145/3020078.3021730},
abstract = {An indispensable part of our modern life is scientific computing which is used in large-scale high-performance systems as well as in low-power smart cyber-physical systems. Hence, accelerators for scientific computing need to be fast and energy efficient. Therefore, partial differential equations (PDEs), as an integral component of many scientific computing tasks, require efficient implementation. In this regard, FPGAs are well suited for data-parallel computations as they occur in PDE solvers. However, including FPGAs in the programming flow is not trivial, as hardware description languages (HDLs) have to be exploited, which requires detailed knowledge of the underlying hardware. This issue is tackled by OpenCL, which allows to write standardized code in a C-like fashion, rendering experience with HDLs unnecessary. Yet, hiding the underlying hardware from the developer makes it challenging to implement solvers that exploit the full FPGA potential. Therefore, we propose in this work a comprehensive set of generic and specific optimization techniques for PDE solvers using OpenCL that improve the FPGA performance and energy efficiency by orders of magnitude. Based on these optimizations, our study shows that, despite the high abstraction level of OpenCL, very energy efficient PDE accelerators on the FPGA fabric can be designed, making the FPGA an ideal solution for power-constrained applications.},
booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {247–256},
numpages = {10},
keywords = {vector, partial differential equation, FPGA, altera, conjugated gradient, xilinx, matrix, sparse, OpenCL, performance, energy efficiency, bandwidth},
location = {Monterey, California, USA},
series = {FPGA '17}
}

@inproceedings{10.1109/MICRO.2014.11,
author = {Chen, Xuhao and Chang, Li-Wen and Rodrigues, Christopher I. and Lv, Jie and Wang, Zhiying and Hwu, Wen-Mei},
title = {Adaptive Cache Management for Energy-Efficient GPU Computing},
year = {2014},
isbn = {9781479969982},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MICRO.2014.11},
doi = {10.1109/MICRO.2014.11},
abstract = {With the SIMT execution model, GPUs can hidememory latency through massive multithreading for many applications that have regular memory access patterns. To support applications with irregular memory access patterns, cache hierarchies have been introduced to GPU architectures to capture temporal and spatial locality and mitigate the effect of irregular accesses. However, GPU caches exhibit poor efficiency due to the mismatch of the throughput-oriented execution model and its cache hierarchy design, which limits system performance and energy-efficiency.The massive amount of memory requests generated by GPU scause cache contention and resource congestion. Existing CPUcache management policies that are designed for multicore systems, can be suboptimal when directly applied to GPUcaches. We propose a specialized cache management policy for GPGPUs. The cache hierarchy is protected from contention by the bypass policy based on reuse distance. Contention and resource congestion are detected at runtime. To avoid oversaturatingon-chip resources, the bypass policy is coordinated with warp throttling to dynamically control the active number of warps. We also propose a simple predictor to dynamically estimate the optimal number of active warps that can take full advantage of the cache space and on-chip resources. Experimental results show that cache efficiency is significantly improved and on-chip resources are better utilized for cache sensitive benchmarks. This results in a harmonic mean IPCimprovement of 74% and 17% (maximum 661% and 44% IPCimprovement), compared to the baseline GPU architecture and optimal static warp throttling, respectively.},
booktitle = {Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {343–355},
numpages = {13},
keywords = {bypass, cache management, GPGPU, warp throttling},
location = {Cambridge, United Kingdom},
series = {MICRO-47}
}

@inproceedings{10.1109/ICSE-SEIS.2017.10,
author = {Jagroep, Erik and Broekman, Jordy and van der Werf, Jan Martijn E. M. and Brinkkemper, Sjaak and Lago, Patricia and Blom, Leen and van Vliet, Rob},
title = {Awakening Awareness on Energy Consumption in Software Engineering},
year = {2017},
isbn = {9781538626733},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIS.2017.10},
doi = {10.1109/ICSE-SEIS.2017.10},
abstract = {Software producing organizations have the ability to address the energy impact of their ICT solutions during the development process. However, while industry is convinced of the energy impact of hardware, the role of software has mostly been acknowledged by researchers in software engineering. Strengthened by the limited practical knowledge to reduce the energy consumption, organizations have less control over the energy impact of their products and lose the contribution of software towards energy related strategies. Consequently, industry risks not being able to meet customer requirements or even fulfill corporate sustainability goals.In this paper we perform an exploratory case study on how to create and maintain awareness on an energy consumption perspective for software among stakeholders involved with the development of software products. During the study, we followed the development process of two commercial software products and provided direct feedback to the stakeholders on the effects of their development efforts, specifically concerning energy consumption and performance, using an energy dashboard. Multiple awareness measurements allowed us to keep track of changes over time on specific aspects affecting software development. Our results show that, despite a mixed sentiment towards the dashboard, changed awareness has triggered discussion on the energy consumption of software.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Society Track},
pages = {76–85},
numpages = {10},
keywords = {software energy consumption, energy consumption perspective, software engineering, awareness},
location = {Buenos Aires, Argentina},
series = {ICSE-SEIS '17}
}

@inproceedings{10.1145/3141842.3141846,
author = {Rieger, Felix and Bockisch, Christoph},
title = {Survey of Approaches for Assessing Software Energy Consumption},
year = {2017},
isbn = {9781450355216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3141842.3141846},
doi = {10.1145/3141842.3141846},
abstract = {Though the energy consumption of software-controlled ICT systems ranging from mobile devices to data centers is increasingly gaining attention, energy optimization is still far from an established task in the software development process. Therefore, we have surveyed the available research on assessing the energy consumption of software systems, which showed a lack of development tools, but several approaches exist for measuring the energy consumption. We group these approaches according to how measurement data is made available and compare several characteristics of the collected data. The survey shows that not only development tools for software energy optimization are still missing, but there is also a lack of fine-grained measurement approaches as well as approaches for general-purpose platforms.},
booktitle = {Proceedings of the 2nd ACM SIGPLAN International Workshop on Comprehension of Complex Systems},
pages = {19–24},
numpages = {6},
keywords = {Energy Measurement, Energy Analysis, Survey, Software Energy Behavior},
location = {Vancouver, BC, Canada},
series = {CoCoS 2017}
}

@inproceedings{10.1145/2554850.2554932,
author = {Noureddine, Adel and Rouvoy, Romain and Seinturier, Lionel},
title = {Unit Testing of Energy Consumption of Software Libraries},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554932},
doi = {10.1145/2554850.2554932},
abstract = {The development of energy-efficient software has become a key requirement for a large number of devices, from smartphones to data centers. However, measuring accurately this consumption is a major challenge that state-of-the-art approaches have tried to tackle with a limited success. While monitoring applications' consumption offers a clear insight on where the energy is being spent, it does not help in understanding how the energy is consumed. In this paper, we therefore introduce JalenUnit, a software framework that infers the energy consumption model of software libraries from execution traces. This model can then be used to diagnose application code for detecting energy bugs, understanding energy distribution, establishing energy profiles and classifications, and comparing software libraries against their energy consumption.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1200–1205},
numpages = {6},
keywords = {software metrics, empirical benchmarking, modeling, power modeling, energy, energy measurement, benchmarks},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/2480362.2480584,
author = {te Brinke, Steven and Malakuti, Somayeh and Bockisch, Christoph and Bergmans, Lodewijk and Ak\c{s}it, Mehmet},
title = {A Design Method for Modular Energy-Aware Software},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480584},
doi = {10.1145/2480362.2480584},
abstract = {Nowadays reducing the overall energy consumption of software is important. A well-known solution is extending the functionality of software with energy optimizers, which monitor the energy consumption of software and adapt it accordingly. To make such extensions manageable and to cope with the complexity of the software, modular design of energy-aware software is necessary. Therefore, this paper proposes a dedicated design method for energy-aware software.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {1180–1182},
numpages = {3},
keywords = {modularity, design method, energy-aware software},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@inproceedings{10.1145/3406365,
author = {Liu, Jason},
title = {Session Details: Large-Scale and Energy-Efficient Computing},
year = {2020},
isbn = {9781450375924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3406365},
doi = {10.1145/3406365},
booktitle = {Proceedings of the 2020 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
location = {Miami, FL, Spain},
series = {SIGSIM-PADS '20}
}

@inproceedings{10.5555/3201607.3258548,
author = {Yamashita, Shigeru and Wen, Wujie},
title = {Session Details: Emerging Technologies for Energy Efficient Computing},
year = {2018},
publisher = {IEEE Press},
booktitle = {Proceedings of the 23rd Asia and South Pacific Design Automation Conference},
location = {Jeju, Republic of Korea},
series = {ASPDAC '18}
}

@inproceedings{10.1145/1188455.1188516,
author = {Batchelor, Donald B.},
title = {High Performance Computing in Magnetic Fusion Energy Research},
year = {2006},
isbn = {0769527000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1188455.1188516},
doi = {10.1145/1188455.1188516},
abstract = {Obtaining energy from nuclear fusion requires heating the fuel to about 100 times the temperature of the sun to produce a plasma, and holding the hot plasma long enough for fusion reactions to produce a net energy gain. In a magnetic fusion device, this plasma is maintained in a largely self-organized state that far from equilibrium the mathematical description of which is characterized by high dimensionality, nonlinearity, extreme range of time and space scales, and sensitivity to geometric details. High-performance computing plays an essential role in fusion research not just to understand the theory and make quantitative comparison to experiments, but also to provide direct support to the experiments by interpreting measurements and designing experiments. The fusion community has begun a major new phase of research with ITER, an international prototype fusion energy reactor. This talk will review recent advances in the computational modeling of fusion plasmas and describe the challenges of simulating a reactor scale experiment such as ITER.},
booktitle = {Proceedings of the 2006 ACM/IEEE Conference on Supercomputing},
pages = {58–es},
location = {Tampa, Florida},
series = {SC '06}
}

@inproceedings{10.1145/2897937.2905011,
author = {Merrett, Geoff V.},
title = {Invited - Energy Harvesting and Transient Computing: A Paradigm Shift for Embedded Systems?},
year = {2016},
isbn = {9781450342360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897937.2905011},
doi = {10.1145/2897937.2905011},
abstract = {Embedded systems powered from time-varying energy harvesting sources traditionally operate using the principles of energy-neutral computing: over a certain period of time, the energy that they consume equals the energy that they harvest. This has the significant advantage of making the system 'look like' a battery-powered system, yet typically results in large, complex and expensive power conversion circuitry and introduces numerous challenges including fast and reliable cold-start. In recent years, the concept of transient computing has emerged to challenge this traditional approach, whereby low-power embedded systems are enabled to operate as usual while energy is available but, after loss of supply, can quickly regain state and continue where they left off. This paper provides a summary of these different approaches.},
booktitle = {Proceedings of the 53rd Annual Design Automation Conference},
articleno = {33},
numpages = {2},
keywords = {embedded systems, transient computing, energy harvesting},
location = {Austin, Texas},
series = {DAC '16}
}

@inproceedings{10.5555/2485288.3250246,
author = {Acquavivia, Andrea and Coppola, Marcello},
title = {Session Details: Hot Topic: Internet of Energy - Connecting Smart Mobility in the Cloud},
year = {2013},
isbn = {9781450321532},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
location = {Grenoble, France},
series = {DATE '13}
}

@inproceedings{10.5555/2663779.2663781,
author = {G\"{o}tz, Sebastian and Wilke, Claas and Richly, Sebastian and A\ss{}mann, Uwe},
title = {Approximating Quality Contracts for Energy Auto-Tuning Software},
year = {2012},
isbn = {9781467318327},
publisher = {IEEE Press},
abstract = {An emerging trend for future software systems is self-optimization, especially w.r.t. energy efficiency. Models of soft- and hardware components at runtime, expressing current and alternative system configurations, are exploited to improve service utility as well as to decrease energy consumption. In recent work we showed how quality contracts---expressing dependencies between software and hardware components---can be used for energy auto-tuning. Notably, the declared provisions and requirements of individual components depend on software containers (i.e., the servers, components are deployed on) and thus, cannot be declared completely at design time. In this paper we present a semi-automated contract creation process that combines manual created contract templates with benchmarking and mathematical approximations for non-functional properties depending on the components' runtime behavior as well as their service's input parameters. We identify individual process activities and show how the process can be applied to approximate the non-functional behavior of software components providing simple sorting functionality.},
booktitle = {Proceedings of the First International Workshop on Green and Sustainable Software},
pages = {8–14},
numpages = {7},
keywords = {energy self-optimization, benchmarking, quality contracts},
location = {Zurich, Switzerland},
series = {GREENS '12}
}

@inproceedings{10.5555/2016802.3249200,
author = {Gauthier, Lovic and Tiwari, Vivek},
title = {Session Details: Software Based Techniques for Energy Optimization},
year = {2011},
isbn = {9781612846606},
publisher = {IEEE Press},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Low-Power Electronics and Design},
location = {Fukuoka, Japan},
series = {ISLPED '11}
}

@inproceedings{10.1145/1601896.1601938,
author = {Klein, F. and Baldassin, A. and Araujo, G. and Centoducatte, P. and Azevedo, R.},
title = {On the Energy-Efficiency of Software Transactional Memory},
year = {2009},
isbn = {9781605587059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1601896.1601938},
doi = {10.1145/1601896.1601938},
abstract = {Traditional software transactional memory designs are targeted towards performance and therefore little is known about their impact on energy consumption. We provide, in this paper, a comprehensive energy analysis of a standard STM design and propose novel scratchpad-based energy-aware STM design strategies. Experimental results collected through a state-of-the-art MPSoC simulation infrastructure show that our approach can achieve an energy improvement of up to ~36% with regard to the base STM for applications characterized by short-lived transactions and relatively high abort rate.},
booktitle = {Proceedings of the 22nd Annual Symposium on Integrated Circuits and System Design: Chip on the Dunes},
articleno = {33},
numpages = {6},
keywords = {multi-core, transactional memory, low power design, MPSoC},
location = {Natal, Brazil},
series = {SBCCI '09}
}

@article{10.1145/2996866,
author = {Hoe, James C.},
title = {Technical Perspective: FPGA Compute Acceleration is First about Energy Efficiency},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {59},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/2996866},
doi = {10.1145/2996866},
journal = {Commun. ACM},
month = {oct},
pages = {113},
numpages = {1}
}

@inproceedings{10.1145/3538393.3544935,
author = {Caiazza, Chiara and Luconi, Valerio and Vecchio, Alessio},
title = {Saving Energy on Smartphones through Edge Computing: An Experimental Evaluation},
year = {2022},
isbn = {9781450393928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3538393.3544935},
doi = {10.1145/3538393.3544935},
abstract = {Edge computing is a network architecture in which computing and storage capabilities are moved at the fringes of the Internet, close to the end-users. The main goal of edge computing is to enable responsive services, thanks to much shorter paths compared to the ones encountered when communicating with remotely positioned cloud servers. In this paper, we report experimental results concerning an overlooked benefit of edge computing: energy is saved on client devices. We carried out an experimental evaluation using both software-based and hardware-based energy estimation methods. Results show that, for HTTP-based communication, the lifetime of a device can be extended significantly when using the edge instead of a remote cloud.},
booktitle = {Proceedings of the ACM SIGCOMM Workshop on Networked Sensing Systems for a Sustainable Society},
pages = {20–25},
numpages = {6},
keywords = {LTE, edge computing, energy consumption},
location = {Amsterdam, Netherlands},
series = {NET4us '22}
}

@inproceedings{10.1145/3320326.3320340,
author = {Lamharras, Farah and Elkamoun, Najib and Labouidya, Ouidad},
title = {Energy Saved Approaches in Software Defined Networks: State of the Art},
year = {2019},
isbn = {9781450366458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320326.3320340},
doi = {10.1145/3320326.3320340},
abstract = {The new paradigm of software defined network SDN has attracted much attention of researchers mainly for flexibility of handling and processing, since the separation of the control plane to the data plane. On the other hand, the energy consumption of information and communications technology, ICTs, has become a field of research given the high energy dissipation due to the manufacture of high-tech equipment and the direct use of electricity. Our study is part of the energy economy in the SDN networks by assembling and classifying several approaches of them.},
booktitle = {Proceedings of the 2nd International Conference on Networking, Information Systems &amp; Security},
articleno = {14},
numpages = {5},
keywords = {energy efficient, traffic engineering, Sdn, tcam},
location = {Rabat, Morocco},
series = {NISS19}
}

@inproceedings{10.1145/605397.605408,
author = {Juang, Philo and Oki, Hidekazu and Wang, Yong and Martonosi, Margaret and Peh, Li Shiuan and Rubenstein, Daniel},
title = {Energy-Efficient Computing for Wildlife Tracking: Design Tradeoffs and Early Experiences with ZebraNet},
year = {2002},
isbn = {1581135742},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/605397.605408},
doi = {10.1145/605397.605408},
abstract = {Over the past decade, mobile computing and wireless communication have become increasingly important drivers of many new computing applications. The field of wireless sensor networks particularly focuses on applications involving autonomous use of compute, sensing, and wireless communication devices for both scientific and commercial purposes. This paper examines the research decisions and design tradeoffs that arise when applying wireless peer-to-peer networking techniques in a mobile sensor network designed to support wildlife tracking for biology research.The ZebraNet system includes custom tracking collars (nodes) carried by animals under study across a large, wild area; the collars operate as a peer-to-peer network to deliver logged data back to researchers. The collars include global positioning system (GPS), Flash memory, wireless transceivers, and a small CPU; essentially each node is a small, wireless computing device. Since there is no cellular service or broadcast communication covering the region where animals are studied, ad hoc, peer-to-peer routing is needed. Although numerous ad hoc protocols exist, additional challenges arise because the researchers themselves are mobile and thus there is no fixed base station towards which to aim data. Overall, our goal is to use the least energy, storage, and other resources necessary to maintain a reliable system with a very high `data homing' success rate. We plan to deploy a 30-node ZebraNet system at the Mpala Research Centre in central Kenya. More broadly, we believe that the domain-centric protocols and energy tradeoffs presented here for ZebraNet will have general applicability in other wireless and sensor applications.},
booktitle = {Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {96–107},
numpages = {12},
location = {San Jose, California},
series = {ASPLOS X}
}

@inproceedings{10.1145/2907950.2907956,
author = {Chakraborty, Prasenjit and Doshi, Gautam and Shekhar, Shashank and Kumar, Vikrant},
title = {Opportunity for Compute Partitioning in Pursuit of Energy-Efficient Systems},
year = {2016},
isbn = {9781450343169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2907950.2907956},
doi = {10.1145/2907950.2907956},
abstract = {Performance of computing systems, from handhelds to supercomputers, is increasingly constrained by the energy consumed. A significant and increasing fraction of the energy is consumed in the movement of data. In a compute node, caches have been very effective in reducing data movement by exploiting the available data locality in programs. Program regions with poor data locality, then effect most of the data movement, and consequently consume an ever larger fraction of energy. In this paper we explore the energy efficiency opportunity of minimizing the data movement in precisely such program regions, by first imagining the possibility of compute near memory, and then partitioning the program’s execution between a compute core and the compute near memory (CnM). Due to the emergence of 3D stacked memory, a CnM implementation appears more realistic. Our focus is on evaluating the partitioning opportunity in applications and to do a limit study of systems enabled with CnM capabilities to understand and guide their architectural embodiment. We describe an automated method of analyzing the data access pattern of optimized workload binaries, via a binary-instrumentation tool called SnapCnM, to identify the beneficial program regions (loops) for CnM execution.We also perform a limit study to evaluate the impact of such partitioning over a range of parameters affecting CnM design choices. Our results show that compute partitioning a small (&lt;10%) fraction of a workload can improve its energy efficiency from 3% (for compute-bound applications) to 27% (for memory-bound applications). From the study in this work we discuss the important aspects that help to shape the future CnM design space.},
booktitle = {Proceedings of the 17th ACM SIGPLAN/SIGBED Conference on Languages, Compilers, Tools, and Theory for Embedded Systems},
pages = {92–101},
numpages = {10},
keywords = {Processing-in-memory, reuse distance, workload characteristics},
location = {Santa Barbara, CA, USA},
series = {LCTES 2016}
}

@inproceedings{10.1145/2962564.2962568,
author = {Soultanopoulos, Theodoros and Sotiriadis, Stelios and Petrakis, Euripides and Amza, Cristiana},
title = {Internet of Things Data Management in the Cloud for Bluetooth Low Energy (BLE) Devices},
year = {2016},
isbn = {9781450342278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2962564.2962568},
doi = {10.1145/2962564.2962568},
abstract = {The use of wearable sensors and their connectivity to Internet offers significant benefits for storing sensing data that could be utilized intelligently for multiple purpose applications such as for monitoring purposes in healthcare domain. This work presents an Internet of Things (IoT) gateway service taking advantage of modern mobile devices and their capabilities to communicate with wearable Bluetooth low energy (BLE) sensors so data could be forwarded to the cloud on the fly and on real time. The service transforms a mobile platform (such as a smartphone) to a gateway allowing continuous and fast communication of data that is forwarded from the device to the cloud on demand or automatically for an automated decision making. Its features include (a) use of an internal processing mechanism for the BLE sensor signals and defines the way in which data is send to the cloud, (b) dynamic service as it has the ability to recognize new BLE sensors properties by easily adapting the data model according to a dynamic schema and (c) universal BLE devices capability that are registered automatically and are monitored on the fly while it keeps historical data that could be integrated into meaningful business intelligence. Building upon principles of service oriented design, the service takes full advantage of cloud services for processing potential big data streams produced by an ever increasing number of users and sensors. The contribution of this work is on the IoT data transmission rate that is averagely calculated to 128 milliseconds and in the experimental section we discuss that this is significantly low for real time data.},
booktitle = {Proceedings of the Third International Workshop on Adaptive Resource Management and Scheduling for Cloud Computing},
pages = {35–39},
numpages = {5},
keywords = {Bluetooth Low Energy (BLE), REST services, Cloud Computing, Sensor data collection service, Internet of Things},
location = {Chicago, IL, USA},
series = {ARMS-CC'16}
}

@inproceedings{10.1145/500141.500231,
author = {Moncrieff, Simon and Dorai, Chitra and Venkatesh, Svetha},
title = {Affect Computing in Film through Sound Energy Dynamics},
year = {2001},
isbn = {1581133944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/500141.500231},
doi = {10.1145/500141.500231},
abstract = {We develop an algorithm for the detection and classification of affective sound events underscored by specific patterns of sound energy dynamics. We relate the portrayal of these events to proposed high level affect or emotional coloring of the events. In this paper, four possible characteristic sound energy events are identified that convey well established meanings through their dynamics to portray and deliver certain affect, sentiment related to the horror film genre. Our algorithm is developed with the ultimate aim of automatically structuring sections of films that contain distinct shades of emotion related to horror themes for nonlinear media access and navigation. An average of 82% of the energy events, obtained from the analysis of the audio tracks of sections of four sample films corresponded correctly to the proposed affect. While the discrimination between certain sound energy event types was low, the algotithm correctly detected 71% of the occurrences of the sound energy events within audio tracks of the films analyzed, and thus forms a useful basis for determining affective scenes characteristic of horror in movies.},
booktitle = {Proceedings of the Ninth ACM International Conference on Multimedia},
pages = {525–527},
numpages = {3},
location = {Ottawa, Canada},
series = {MULTIMEDIA '01}
}

@inproceedings{10.5555/2663779.2663788,
author = {Johann, Timo and Dick, Markus and Naumann, Stefan and Kern, Eva},
title = {How to Measure Energy-Efficiency of Software: Metrics and Measurement Results},
year = {2012},
isbn = {9781467318327},
publisher = {IEEE Press},
abstract = {In the field of information and computer technology (ICT), saving energy has its focus set on energy efficient hardware and its operation. Recently, efforts have also been made in the area of computer software. However, the development of energy efficient software requires metrics, which measure the software's energy consumption as well as models to monitor and minimize it. In software and software development processes they hardly exist. In this work we present a generic metric to measure software and a method to apply it in a software engineering process.},
booktitle = {Proceedings of the First International Workshop on Green and Sustainable Software},
pages = {51–54},
numpages = {4},
keywords = {metrics, green software, energy efficiency},
location = {Zurich, Switzerland},
series = {GREENS '12}
}

@proceedings{10.1145/2208828,
title = {e-Energy '12: Proceedings of the 3rd International Conference on Future Energy Systems: Where Energy, Computing and Communication Meet},
year = {2012},
isbn = {9781450310550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are very pleased to present in this volume the proceedings of the Third International Conference on Future Energy Systems (e-Energy 2012). e-Energy is an international meeting that brings together researchers, developers and practitioners working at the intersection of the areas of energy, computation and communication, to discuss recent and innovative results, as well as identify future directions and challenges. That is why the conference has the motto Where Energy, Computing and Communication Meet.This third e-Energy conference, e-Energy 2012, is held from May 9th to 11th, 2012, hosted by Institute IMDEA Networks and the University Carlos III of Madrid, Spain. The first e-Energy Conference was held in April 2010, in Passau (Germany), and the second took place in May/June 2011 at Columbia University, in New York City (USA).In response to the call for papers, almost one hundred submissions were received, with authors from 30 different countries. After a careful review process that involved a Technical Program Committee of 44 members, 29 papers were selected (22 full papers and 7 discussion papers, with a 34% acceptance rate). We would like to thank all authors for allowing us to consider their work, and all reviewers for their fundamental contribution in selecting the best submissions.The papers and associated presentations are grouped in 8 sessions. These proceedings also include the abstract of the keynote speech, which is given by Professor Jon Crowcroft, from University of Cambridge.The conference also includes two invited presentations by officers of the European Commission on funding opportunities in the research area at the intersection of ICT and energy, and an Industry Session, co-organized with the TREND Network of Excellence of the European 7-th Framework Programme, where industrial lead researchers discuss the challenges of this research field.This edition has also two colocated events: the 1st International Work- shop on Energy-Efficient Data Centres, and the plenary meeting of the COST Action IC0804 on Energy Efficiency in Large Scale Distributed Systems (www.cost804.org). In addition, participants are offered a tutorial on Energy Efficiency versus Quality of Experience in wireless networks: From measurements to trade-off analysis.},
location = {Madrid, Spain}
}

@inproceedings{10.1145/2168697.2168698,
author = {Gelenbe, Erol},
title = {Energy Packet Networks: Adaptive Energy Management for the Cloud},
year = {2012},
isbn = {9781450311618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2168697.2168698},
doi = {10.1145/2168697.2168698},
abstract = {In the presence of limitations in the availability of energy for data centres, especially in dense urban areas, a novel system that we call an Energy Packet Network is discussed as a means to provide energy on demand to Cloud Computing servers. This approach can be useful in the presence of renewable energy sources, and if scarce sources of energy must be shared by multiple computational units whose peak to average power consumption ratio is high. Such a system will use energy storage units to best match and smooth the intermittent supply and the intermittent demand. The analysis of such systems based on queueing networks is suggested and applied to a special case for illustration.},
booktitle = {Proceedings of the 2nd International Workshop on Cloud Computing Platforms},
articleno = {1},
numpages = {5},
keywords = {energy provisioning on demand, smart grid, energy packet networks, cloud computing},
location = {Bern, Switzerland},
series = {CloudCP '12}
}

@inproceedings{10.1145/1940761.1940869,
author = {Hussain, Faheem},
title = {"Green" Digital Bangladesh: Is It Ready to Face the Challenges of Climate Change?},
year = {2011},
isbn = {9781450301213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1940761.1940869},
doi = {10.1145/1940761.1940869},
abstract = {This poster focuses on the national level efforts taken in Bangladesh (one of the most climate-vulnerable countries) to face the immediate as well as long term challenges of climate change through green ICT based applications and infrastructure. "Digital Bangladesh" is a vision supported by the Government of Bangladesh (GoB) to integrate the ICT based interventions at every level of life [1]. It envisions the micro-level social inclusion of the base of the pyramid population (BoP) in the mainstream economic activities through ensuring access to information, cost-effective connectivity and efficient e-governance. As climate change is severely negating many achievement made by this developing country, efforts are in place to implement strategies towards developing "Green" ICT based nationwide infrastructure and services all over Bangladesh. This poster looks into the challenges towards fulfilling such objective. It also focuses on the strategic priorities and identifies future opportunities for making a nation's collective effort for a "green" future sustainable. The original research is a part of the ongoing process to monitor and evaluate this national level initiative.},
booktitle = {Proceedings of the 2011 IConference},
pages = {684–685},
numpages = {2},
keywords = {green ICT, ICT, climate change},
location = {Seattle, Washington, USA},
series = {iConference '11}
}

@inproceedings{10.1145/3155016.3155021,
author = {He, Jiacong and Callenes-Sloan, Joseph},
title = {A Software-Defined Hybrid Cache with Reduced Energy: Poster},
year = {2017},
isbn = {9781450352017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3155016.3155021},
doi = {10.1145/3155016.3155021},
abstract = {Energy becomes an inevitable challenge when using a large die-stacking DRAM cache as part of memory. Emerging volatile STT-RAM can be integrated with DRAM as a software-managed hybrid cache to effectively reduce the static and dynamic energy of large cache, but there is extra refresh energy overhead. We observe that reducing the refresh rate of volatile STT-RAM will provide significant energy savings while introducing a small number of bit errors that can be easily tolerated by most error-resilient applications. Thus, we propose a quality-aware approximate die-stacking hybrid cache and develop a novel data allocation scheme. We also propose the online quality monitor and the light-weight check scheme for error recovery. The results show an average 91% reduction in volatile STT-RAM refresh energy with minimal loss in output quality.},
booktitle = {Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference: Posters and Demos},
pages = {1–2},
numpages = {2},
keywords = {STT-RAM, cache, approximate computing},
location = {Las Vegas, Nevada},
series = {Middleware '17}
}

@inproceedings{10.1145/3528575.3551438,
author = {Rochat, Julie and Ragot, Martin},
title = {Adoption of Green IT Behaviours: A Perceived Knowledge Effect on Responsible Digital Practices?},
year = {2022},
isbn = {9781450393416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528575.3551438},
doi = {10.1145/3528575.3551438},
abstract = {The Green IT approach aims to reduce the environmental, social and economic impact of digital technology. A possible lever for change can be to study factors that encourage individuals to adopt pro-Green IT behaviours. However, few studies have explored these factors, especially the influence of perceived knowledge. To fill this gap, this study examines the relationship between perceived knowledge of Green IT, attitude and intention towards adopting specific Green IT behaviours. The study includes 143 participants, who completed an online survey and answered various questions on Green IT (e.g., on perceived knowledge, attitude, intention to adopt behaviours). The results of the study reveal that the more perceived knowledge of Green IT the participants had, the more positive their attitude towards Green IT and the greater their intention to adopt Green IT behaviours. This study paves the way for public policies promoting knowledge on Green IT and digital responsible technologies.},
booktitle = {Adjunct Publication of the 24th International Conference on Human-Computer Interaction with Mobile Devices and Services},
articleno = {23},
numpages = {6},
keywords = {perceived knowledge, intention to adopt, attitude, Green IT, responsible digital technology},
location = {Vancouver, BC, Canada},
series = {MobileHCI '22}
}

@inproceedings{10.1145/3382494.3410678,
author = {Ournani, Zakaria and Rouvoy, Romain and Rust, Pierre and Penhoat, Joel},
title = {On Reducing the Energy Consumption of Software: From Hurdles to Requirements},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410678},
doi = {10.1145/3382494.3410678},
abstract = {Background. As software took control over hardware in many domains, the question of the energy footprint induced by the software is becoming critical for our society, as the resources powering the underlying infrastructure are finite. Yet, beyond this growing interest, energy consumption remains a difficult concept to master for a developer.Aims. The purpose of this study is to better understand the root causes that prevent the issue of software energy consumption to be more widely considered by developers and companies.Method. To investigate this issue, this paper reports on a qualitative study we conducted in an industrial context. We applied an in-depth analysis of the interviews of 10 experienced developers and summarized a set of implications.Results. We argue that our study delivers i) insightful feedback on how green software design is considered among the interviewed developers and ii) a set of findings to build helpful tools, motivate further research, and establish better development strategies to promote green software design.Conclusion. This paper covers an industrial case study of developers' awareness of green software design and how to promote it within the company. While it might not be generalizable for any company, we believe our results deliver a common body of knowledge with implications to be considered for similar cases and further researches.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {14},
numpages = {12},
location = {Bari, Italy},
series = {ESEM '20}
}

@article{10.1145/3409772,
author = {Kaur, Kuljeet and Garg, Sahil and Kaddoum, Georges and Kumar, Neeraj},
title = {Energy and SLA-Driven MapReduce Job Scheduling Framework for Cloud-Based Cyber-Physical Systems},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3409772},
doi = {10.1145/3409772},
abstract = {Energy consumption minimization of cloud data centers (DCs) has attracted much attention from the research community in the recent years; particularly due to the increasing dependence of emerging Cyber-Physical Systems on them. An effective way to improve the energy efficiency of DCs is by using efficient job scheduling strategies. However, the most challenging issue in selection of efficient job scheduling strategy is to ensure service-level agreement (SLA) bindings of the scheduled tasks. Hence, an energy-aware and SLA-driven job scheduling framework based on MapReduce is presented in this article. The primary aim of the proposed framework is to explore task-to-slot/container mapping problem as a special case of energy-aware scheduling in deadline-constrained scenario. Thus, this problem can be viewed as a complex multi-objective problem comprised of different constraints. To address this problem efficiently, it is segregated into three major subproblems (SPs), namely, deadline segregation, map and reduce phase energy-aware scheduling. These SPs are individually formulated using Integer Linear Programming. To solve these SPs effectively, heuristics based on Greedy strategy along with classical Hungarian algorithm for serial and serial-parallel systems are used. Moreover, the proposed scheme also explores the potential of splitting Map/Reduce phase(s) into multiple stages to achieve higher energy reductions. This is achieved by leveraging the concepts of classical Greedy approach and priority queues. The proposed scheme has been validated using real-time data traces acquired from OpenCloud. Moreover, the performance of the proposed scheme is compared with the existing schemes using different evaluation metrics, namely, number of stages, total energy consumption, total makespan, and SLA violated. The results obtained prove the efficacy of the proposed scheme in comparison to the other schemes under different workload scenarios.},
journal = {ACM Trans. Internet Technol.},
month = {may},
articleno = {31},
numpages = {24},
keywords = {job scheduling, energy optimization, Hungarian algorithm, and MapReduce, greedy approach, Cyber-physical systems}
}

@inproceedings{10.1145/3267809.3275459,
author = {Makrani, Hosein Mohammadi and Sayadi, Hossein and Motwani, Devang and Wang, Han and Rafatirad, Setareh and Homayoun, Houman},
title = {Energy-Aware and Machine Learning-Based Resource Provisioning of In-Memory Analytics on Cloud},
year = {2018},
isbn = {9781450360111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267809.3275459},
doi = {10.1145/3267809.3275459},
abstract = {In this work, we propose a proactive online resource provisioning methodology that addresses the challenge of resource provisioning for IMC workloads in heterogeneous cloud platforms consist of diverse types of servers. As cloud platforms provide a wide range of server configuration choices [4], and the applications' performance and power consumption changes at run-time [3] and depends on the chosen configuration, resource provisioning in cloud platforms is a challenging optimization problem with a large search space to navigate. Our methodology proactively assigns a suitable hardware configuration to IMC program for energy-efficiency (EDP) optimization at run-time before any significant change occurs in application's behavior. This helps to save energy without sacrificing performance [2, 7]. We address these challenges by first characterizing diverse types of IMC workloads across different types of server architectures. The characterization aids to accurately capture applications' behavior [1] and train machine learning models [5, 6]. We use time series neural network to predict the next phase of an application. Our approach then uses artificial neural networks to estimate the performance and power consumption of predicted phase of application on various server configurations. Further, we use the genetic algorithm to distinguish close-to-optimal configuration to minimize EDP. Compared to Oracle scheduler, our methodology achieves 93% accuracy to allocate the right resource for each phase of the program. Our methodology improves the performance by 21% and the EDP by 40% on average, compared to the default scheduler.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {517},
numpages = {1},
keywords = {energy-aware, cloud, machine learning, Resource provisioning},
location = {Carlsbad, CA, USA},
series = {SoCC '18}
}

@inproceedings{10.5555/2555692.2555723,
author = {Gao, Yue and Wang, Yanzhi and Gupta, Sandeep K. and Pedram, Massoud},
title = {An Energy and Deadline Aware Resource Provisioning, Scheduling and Optimization Framework for Cloud Systems},
year = {2013},
isbn = {9781479914173},
publisher = {IEEE Press},
abstract = {Cloud computing has attracted significant attention due to the increasing demand for low-cost, high performance, and energy-efficient computing. Profit maximization for the cloud service provider (CSP) is a key objective in the large-scale, heterogeneous, and multi-user environment of a cloud system. This paper addresses the problem of minimizing the operation cost of a cloud system by maximizing its energy efficiency while ensuring that user deadlines as defined in Service Level Agreements are met. The workload in the cloud system can be modeled as independent batch requests or as task graphs with dependencies. This paper adopts the latter modeling approach, which provides more opportunities for energy and performance optimizations, thus enabling the CSP to meet user deadlines at lower operation costs. However, these optimizations require additional supporting efforts e.g., resource provisioning, virtual machine placement, and task scheduling, which are addressed in a holistic manner in the proposed framework. In the envisioned cloud environment, users can construct their own services and applications based on the available set of virtual machines, but are relieved from the burden of resource provisioning and task scheduling. The CSP will then exploit data parallelism in user workloads to create an energy and deadline-aware cloud platform.},
booktitle = {Proceedings of the Ninth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},
articleno = {31},
numpages = {10},
location = {Montreal, Quebec, Canada},
series = {CODES+ISSS '13}
}

@inproceedings{10.1145/3131672.3137000,
author = {Senkans, Uvis and Balsamo, Domenico and Verykios, Theodoros D. and Merrett, Geoff V.},
title = {Applications of Energy-Driven and Transient Computing: A Wireless Bicycle Trip Counter},
year = {2017},
isbn = {9781450354592},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131672.3137000},
doi = {10.1145/3131672.3137000},
abstract = {Energy harvesting is an efficient solution to power embedded systems instead of using batteries. However, it has been traditionally coupled with large energy buffers to tackle the temporal variation of the source. These buffers require time to charge and introduce a cost, size and weight overhead. Energy-driven and transiently-powered systems can operate from an energy harvesting source, while containing little or no additional energy storage. However, few real-life applications have been considered for such systems to demonstrate that they can actually be realised. This poster presents a transiently-powered wireless bicycle trip counter which measures distance, speed and active cycling time, and transmits data wirelessly. The system sustains operation by harvesting energy from the rotation of the wheel, operating from 6kph.},
booktitle = {Proceedings of the 15th ACM Conference on Embedded Network Sensor Systems},
articleno = {76},
numpages = {2},
keywords = {Energy Harvesting, Embedded Systems, Transient Computing},
location = {Delft, Netherlands},
series = {SenSys '17}
}

@inproceedings{10.1145/2908080.2908082,
author = {Zhu, Yuhao and Reddi, Vijay Janapa},
title = {GreenWeb: Language Extensions for Energy-Efficient Mobile Web Computing},
year = {2016},
isbn = {9781450342612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2908080.2908082},
doi = {10.1145/2908080.2908082},
abstract = {Web computing is gradually shifting toward mobile devices, in which the energy budget is severely constrained. As a result, Web developers must be conscious of energy efficiency. However, current Web languages provide developers little control over energy consumption. In this paper, we take a first step toward language-level research to enable energy-efficient Web computing. Our key motivation is that mobile systems can wisely budget energy usage if informed with user quality-of-service (QoS) constraints. To do this, programmers need new abstractions. We propose two language abstractions, QoS type and QoS target, to capture two fundamental aspects of user QoS experience. We then present GreenWeb, a set of language extensions that empower developers to easily express the QoS abstractions as program annotations. As a proof of concept, we develop a GreenWeb runtime, which intelligently determines how to deliver specified user QoS expectation while minimizing energy consumption. Overall, GreenWeb shows significant energy savings (29.2% ∼ 66.0%) over Android’s default Interactive governor with few QoS violations. Our work demonstrates a promising first step toward language innovations for energy-efficient Web computing.},
booktitle = {Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {145–160},
numpages = {16},
keywords = {Mobile computing, Energy-efficiency, Web},
location = {Santa Barbara, CA, USA},
series = {PLDI '16}
}

@inproceedings{10.1145/2820645.2820652,
author = {Rodriguez Arreola, Alberto and Balsamo, Domenico and Das, Anup K. and Weddell, Alex S. and Brunelli, Davide and Al-Hashimi, Bashir M. and Merrett, Geoff V.},
title = {Approaches to Transient Computing for Energy Harvesting Systems: A Quantitative Evaluation},
year = {2015},
isbn = {9781450338370},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2820645.2820652},
doi = {10.1145/2820645.2820652},
abstract = {Systems operating from harvested sources typically integrate batteries or supercapacitors to smooth out rapid changes in harvester output. However, such energy storage devices require time for charging and increase the size, mass and cost of the system. A recent approach to address this is to power systems directly from the harvester output, termed transient computing. To solve the problem of having to restart computation from the start due to power-cycles, a number of techniques have been proposed to deal with transient power sources. In this paper, we quantitatively evaluate three state-of-the-art approaches on a Texas Instruments MSP430 microcontroller characterizing the application scenarios where each performs best. Finally, recommendations are provided to system designers for selecting the most suitable approach.},
booktitle = {Proceedings of the 3rd International Workshop on Energy Harvesting &amp; Energy Neutral Sensing Systems},
pages = {3–8},
numpages = {6},
keywords = {wind turbines, checkpoint, quickrecall, energy harvesting, hibernus, mementos, transient computing, photo voltaic cells, IoT},
location = {Seoul, South Korea},
series = {ENSsys '15}
}

@inproceedings{10.1145/2742854.2742886,
author = {Hassan, Ahmad and Vandierendonck, Hans and Nikolopoulos, Dimitrios S.},
title = {Software-Managed Energy-Efficient Hybrid DRAM/NVM Main Memory},
year = {2015},
isbn = {9781450333580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742854.2742886},
doi = {10.1145/2742854.2742886},
abstract = {This paper evaluates the viability of user-level software management of a hybrid DRAM/NVM main memory system. We propose an operating system (OS) and programming interface to place data from within the user application. We present a profiling tool to help programmers decide on the placement of application data in hybrid memory systems. Cycle-accurate simulation of modified applications confirms that our approach is more energy-efficient than state-of-the-art hardware or OS approaches at equivalent performance. Moreover, our results are validated on several candidate NVM technologies and a wide set of 14 benchmarks.The key observation behind this work is that, for the workloads we evaluated, application objects are too short-lived to motivate migration. Utilizing this property significantly reduces the hardware complexity of hybrid memory systems.},
booktitle = {Proceedings of the 12th ACM International Conference on Computing Frontiers},
articleno = {23},
numpages = {8},
location = {Ischia, Italy},
series = {CF '15}
}

@inproceedings{10.1145/2428955.2428986,
author = {Siebra, Clauirton and Costa, Paulo and Miranda, Regina and Silva, Fabio Q. B. and Santos, Andre},
title = {The Software Perspective for Energy-Efficient Mobile Applications Development},
year = {2012},
isbn = {9781450313070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2428955.2428986},
doi = {10.1145/2428955.2428986},
abstract = {Nowadays, there is a growing concern about the energy consumption of the ICT industry. This fact has given rise to a lot of energy saving research activities, which mainly focus on the hardware side of computational systems. However, it is tempting to suppose that only hardware dissipates power, not software. This paper discusses several software methods, which could be explored to develop energy-efficient mobile techniques. We argue that the development of applications that consider the energy saving, as one of their requirements, can result in a significant final energy saving because solutions will be part of the own software and they do not depend of external resources to obtain a lower consumption.},
booktitle = {Proceedings of the 10th International Conference on Advances in Mobile Computing &amp; Multimedia},
pages = {143–150},
numpages = {8},
keywords = {mobile applications, green technology, software design},
location = {Bali, Indonesia},
series = {MoMM '12}
}

@inproceedings{10.1145/1987816.1987827,
author = {Li, Zhichao and Grosu, Radu and Sehgal, Priya and Smolka, Scott A. and Stoller, Scott D. and Zadok, Erez},
title = {On the Energy Consumption and Performance of Systems Software},
year = {2011},
isbn = {9781450307734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1987816.1987827},
doi = {10.1145/1987816.1987827},
abstract = {Models of energy consumption and performance are necessary to understand and identify system behavior, prior to designing advanced controls that can balance out performance and energy use. This paper considers the energy consumption and performance of servers running a relatively simple file-compression workload. We found that standard techniques for system identification do not produce acceptable models of energy consumption and performance, due to the intricate interplay between the discrete nature of software and the continuous nature of energy and performance. This motivated us to perform a detailed empirical study of the energy consumption and performance of this system with varying compression algorithms and compression levels, file types, persistent storage media, CPU DVFS levels, and disk I/O schedulers. Our results identify and illustrate factors that complicate the system's energy consumption and performance, including nonlinearity, instability, and multi-dimensionality. Our results provide a basis for future work on modeling energy consumption and performance to support principled design of controllable energy-aware systems.},
booktitle = {Proceedings of the 4th Annual International Conference on Systems and Storage},
articleno = {8},
numpages = {12},
keywords = {data compression, system identification, energy efficiency},
location = {Haifa, Israel},
series = {SYSTOR '11}
}

@inproceedings{10.1145/1057661.1057727,
author = {Ozturk, O. and Kandemir, M.},
title = {Energy Management in Software-Controlled Multi-Level Memory Hierarchies},
year = {2005},
isbn = {1595930574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1057661.1057727},
doi = {10.1145/1057661.1057727},
abstract = {Performance and energy consumption behavior of embedded applications are increasingly being dependent on their memory usage/access patterns. Focusing on a software-managed, application-specific multi-level memory hierarchy, this paper studies three different memory hierarchy management schemes from both energy and performance angles. The first scheme is pure performance-oriented and tuned for extracting the maximum performance possible from the software-managed multi-level memory hierarchy. The second scheme is built upon the first one but it also reduces leakage by turning-on and off memory modules (i.e., different memory levels) at appropriate program points during execution based on the data access pattern information extracted by the compiler. The last scheme evaluated is oriented towards further reducing leakage energy, as well as dynamic energy, by modifying the data transfer policy (data access pattern) of the performance-oriented scheme. Our empirical analysis indicates that it is possible to reduce leakage consumption of the application-specific multi-level memory hierarchy without seriously impacting its performance, and that one can achieve further savings by modifying data transfer pattern across the different levels of the memory hierarchy.},
booktitle = {Proceedings of the 15th ACM Great Lakes Symposium on VLSI},
pages = {270–275},
numpages = {6},
keywords = {embedded systems, software-managed memory},
location = {Chicago, Illinois, USA},
series = {GLSVLSI '05}
}

@article{10.1145/1059876.1059879,
author = {Kadayif, I. and Sivasubramaniam, A. and Kandemir, M. and Kandiraju, G. and Chen, G.},
title = {Optimizing Instruction TLB Energy Using Software and Hardware Techniques},
year = {2005},
issue_date = {April 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/1059876.1059879},
doi = {10.1145/1059876.1059879},
abstract = {Power consumption and power density for the Translation Look-aside Buffer (TLB) are important considerations not only in its design, but can have a consequence on cache design as well. After pointing out the importance of instruction TLB (iTLB) power optimization, this article embarks on a new philosophy for reducing the number of accesses to this structure. The overall idea is to keep a translation currently being used in a register and avoid going to the iTLB as far as possible---until there is a page change. We propose four different approaches for achieving this, and experimentally demonstrate that one of these schemes that uses a combination of compiler and hardware enhancements can reduce iTLB dynamic power by over 85% in most cases.The proposed approaches can work with different instruction-cache (iL1) lookup mechanisms and achieve significant iTLB power savings without compromising on performance. Their importance grows with higher iL1 miss rates and larger page sizes. They can work very well with large iTLB structures that can possibly consume more power and take longer to lookup, without the iTLB getting into the common case. Further, we also experimentally demonstrate that they can provide performance savings for virtually indexed, virtually tagged iL1 caches, and can even make physically indexed, physically tagged iL1 caches a possible choice for implementation.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {apr},
pages = {229–257},
numpages = {29},
keywords = {instruction locality, translation look-aside buffer, cache design, compiler optimization, Power consumption}
}

@inproceedings{10.5555/2755753.2755927,
author = {D\"{u}ben, Peter and Schlachter, Jeremy and Parishkrati and Yenugula, Sreelatha and Augustine, John and Enz, Christian and Palem, K. and Palmer, T. N.},
title = {Opportunities for Energy Efficient Computing: A Study of Inexact General Purpose Processors for High-Performance and Big-Data Applications},
year = {2015},
isbn = {9783981537048},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {In this paper, we demonstrate that disproportionate gains are possible through a simple devise for injecting inexactness or approximation into the hardware architecture of a computing system with a general purpose template including a complete memory hierarchy. The focus of the study is on energy savings possible through this approach in the context of large and challenging applications. We choose two such from different ends of the computing spectrum---the IGCM model for weather and climate modeling which embodies significant features of a high-performance computing workload, and the ubiquitous PageRank algorithm used in Internet search. In both cases, we are able to show in the affirmative that an inexact system outperforms its exact counterpart in terms of its efficiency quantified through the relative metric of operations per virtual Joule (OPVJ)---a relative metric that is not tied to particular hardware technology. As one example, the IGCM application can be used to achieve savings through inexactness of (almost) a factor of 3 in energy without compromising the quality of the forecast, quantified through the forecast error metric, in a noticeable manner. As another example finding, we show that in the case of PageRank, an inexact system is able to outperform its exact counterpart by close to a factor of 1.5 using the OPVJ metric.},
booktitle = {Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition},
pages = {764–769},
numpages = {6},
location = {Grenoble, France},
series = {DATE '15}
}

@inproceedings{10.1145/3314221.3314583,
author = {Ruppel, Emily and Lucia, Brandon},
title = {Transactional Concurrency Control for Intermittent, Energy-Harvesting Computing Systems},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314583},
doi = {10.1145/3314221.3314583},
abstract = {Batteryless energy-harvesting devices are computing platforms that operate in environments where batteries are not viable for energy storage. Energy-harvesting devices operate intermittently, only as energy is available. Prior work developed software execution models robust to intermittent power failures but no existing intermittent execution model allows interrupts to update global persistent state without allowing incorrect behavior or requiring complex programming. We present Coati, a system that supports event-driven concurrency via interrupts in an intermittent software execution model. Coati exposes a task-based interface for synchronous computations and an event interface for asynchronous interrupts. Coati supports synchronizing tasks and events using transactions, which allow for multi-task atomic regions that extend across multiple power failures. This work explores two different models for serializing events and tasks that both safely provide intuitive semantics for event-driven intermittent programs. We implement a prototype of Coati as C language extensions and a runtime library. Using energy-harvesting hardware, we evaluate Coati on benchmarks adapted from prior work. We show that Coati prevents failures when interrupts are introduced, while the baseline fails in just seconds. Moreover, Coati operates with a reasonable run time overhead that is often comparable to an idealized baseline.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {1085–1100},
numpages = {16},
keywords = {intermittent computing, event-driven concurrency, transactions},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}

@inproceedings{10.1145/3120895.3120900,
author = {Shelor, Charles and Kavi, Krishna},
title = {Dataflow Based Near Data Computing Achieves Excellent Energy Efficiency},
year = {2017},
isbn = {9781450353168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3120895.3120900},
doi = {10.1145/3120895.3120900},
abstract = {The emergence of 3D-DRAM has rekindled interest in near data computing (NDC) research. This article introduces dataflow processing in memory (DFPIM) which melds near data computing, dataflow architecture, coarse-grained reconfigurable logic (CGRL), and 3D-DRAM technologies to provide high performance and very high energy efficiency for stream oriented and big data application kernels. The application of dataflow architecture with a CGRL implementation provides a flexible, energy efficient computing platform. The initial evaluation presented in this paper shows an average speedup of 5.5 is achieved with an energy efficiency factor of 460.},
booktitle = {Proceedings of the 8th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {6},
numpages = {6},
keywords = {big-data, Computer Architecture, Near Data Computing, 3D stacked DRAM, Dataflow, Processing-in-Memory, Coarse Grain Reconfigurable Logic, energy efficient computing},
location = {Bochum, Germany},
series = {HEART '17}
}

@inproceedings{10.1145/2069131.2069145,
author = {Asplund, Mikael and Thomasson, Anton and Vergara, Ekhiotz Jon and Nadjm-Tehrani, Simin},
title = {Software-Related Energy Footprint of a Wireless Broadband Module},
year = {2011},
isbn = {9781450309011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2069131.2069145},
doi = {10.1145/2069131.2069145},
abstract = {Energy economy in mobile devices is becoming an increasingly important factor as the devices become more advanced and rich in features. A large part of the energy footprint of a mobile device comes from the wireless communication module, and even more so as the amount of traffic increases. In this paper we study the energy footprint of a mobile broadband hardware module, and how it is affected by software, by performing systematic power consumption measurements. We show that there are several cases where the software does not properly take into account the effect that data communication has on the power consumption. This opens up for potential energy savings by creating better applications that are aware of the energy characteristics of the communication layer.},
booktitle = {Proceedings of the 9th ACM International Symposium on Mobility Management and Wireless Access},
pages = {75–82},
numpages = {8},
keywords = {energy footprint, power consumption, 3g, wireless broadband},
location = {Miami, Florida, USA},
series = {MobiWac '11}
}

@inproceedings{10.1145/3551659.3559062,
author = {Li, Yuchen and Liang, Weifa and Li, Jing and Cheng, Xiuzhen and Yu, Dongxiao and Zomaya, Albert Y. and Guo, Song},
title = {Energy-Constrained D2D Assisted Federated Learning in Edge Computing},
year = {2022},
isbn = {9781450394826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551659.3559062},
doi = {10.1145/3551659.3559062},
abstract = {The surging of deep learning brings new vigor and vitality to shape the prospect of intelligent Internet of Things (IoT), and edge intelligence arises to provision real-time deep neural network (DNN) inference services for mobile users. To perform efficient and effective DNN model training in edge environments while preserving training data security and privacy of IoT devices, federated learning has been envisioned as an ideal learning paradigm for this purpose. In this paper we study energy-aware DNN model training in an edge environment. We first formulate a novel energy-aware, device-to-device (D2D) assisted federated learning problem with the aim to minimize the global loss of a training DNN model, subject to bandwidth capacity on an edge server and the energy capacity on each IoT device. We then devise an efficient heuristic algorithm for the problem. The crux of the proposed algorithm is to explore the energy usage of neighboring devices of each device for its local model uploading, by reducing the problem to a series of maximum weight matching problems in corresponding auxiliary graphs. We finally evaluate the performance of the proposed algorithm through experimental simulations. Experimental results show that the proposed algorithm is promising.},
booktitle = {Proceedings of the 25th International ACM Conference on Modeling Analysis and Simulation of Wireless and Mobile Systems},
pages = {33–37},
numpages = {5},
keywords = {D2D-assisted edge learning, energy-aware federated learning},
location = {Montreal, Quebec, Canada},
series = {MSWiM '22}
}

@inproceedings{10.5555/3408352.3408384,
author = {Tang, Xifan and Giacomin, Edouard and Cadareanu, Patsy and Gore, Ganesh and Gaillardon, Pierre-Emmanuel},
title = {A RRAM-Based FPGA for Energy-Efficient Edge Computing},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {The shift from centralized cloud to edge computing demands hardware systems with data processing capability at ultra-low power. Reconfigurable solutions such as Field-Programmable Gate Arrays (FPGAs) offer a high flexibility in terms of hardware implementation and are thus popular for use in many edge computing systems. However, breaking through the energy wall of FPGAs is a challenge, as low-power operation often requires compromising performances. In this paper, we study a low-power high-performance FPGA architecture exploiting Resistive Random Access Memory (RRAM) technology. To perform a comprehensive analysis, we introduce a novel design flow which can rapidly prototype FPGA fabrics from which accurate area, delay, and power results can be obtained. Based on full-chip layouts and SPICE simulations, we show that RRAM-based FPGAs can improve up to 8%/22%/16% in area/delay/power compared to SRAM-based counterparts at nominal voltage. Even when operated at a near-Vt supply, the proposed RRAM-based FPGA can improve the Energy-Delay Product by about 2 X without any delay overhead, when compared to an SRAM-based FPGA. In addition, Monte Carlo simulations showed that the proposed RRAM-based FPGA architecture stays robust under different CMOS process corners as well as under a 30% RRAM resistance standard deviation.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {144a–144f},
keywords = {field-programmable gate arrays, low-power design, resistive memories},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.5555/3199700.3199759,
author = {Gao, Mingze and Qu, Gang},
title = {Energy Efficient Runtime Approximate Computing on Data Flow Graphs},
year = {2017},
publisher = {IEEE Press},
abstract = {Approximate computing is an emerging computation paradigm that utilizes many applications' intrinsic error resilience to improve power and energy efficiency. Several approaches have been proposed to identify the non-critical computations by analyzing the output sensitivity to the accuracy of the results, and then perform approximate computing on these computations. However, these static approaches only use the prior knowledge (e.g. input ranges) for analysis and fail to consider the runtime information, which limits the energy saving and incurs large computation error. In this paper, we propose a runtime approximate computing framework to solve this problem. The basic idea is to use a low cost method to estimate the impact of each immediate input value to the accuracy of computation at every node in the data flow graph, and then decide whether we should simply use the estimated value or perform an accurate computation. Our novel runtime estimation method is based on converting data to the logarithmic representation. We propose two algorithms to make the decision at certain nodes whether an accurate computation will be needed to balance energy saving and computation error. Experimental results show that this tradeoff ranges from 40% energy saving with 4.85% error on average to 8% energy saving with 0.18% error. Compared to the static DFG node cutting approach, our approach's estimation accuracy is 32x better to achieve the same amount of energy saving.},
booktitle = {Proceedings of the 36th International Conference on Computer-Aided Design},
pages = {444–449},
numpages = {6},
keywords = {energy efficient, approximate computing, logarithmic estimation, data flow graph, runtime},
location = {Irvine, California},
series = {ICCAD '17}
}

@inproceedings{10.1145/2735960.2735986,
author = {Vatanparvar, Korosh and Al Faruque, Mohammad Abdullah},
title = {Energy Management as a Service over Fog Computing Platform},
year = {2015},
isbn = {9781450334556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2735960.2735986},
doi = {10.1145/2735960.2735986},
abstract = {Cyber-Physical Energy System (CPES) has been seen as the new paradigm of tight integration of power systems, embedded systems, control, and communication. CPES is capable of improving power grid reliability, efficiency, and performance by managing the supply and demand functionalities of the power systems effectively and intelligently. In this demo, we present an energy management system prototype for home and microgrid levels (both from residential domain), implemented over a fog computing platform. The prototype is capable of supporting interoperability, scalability, ease of deployment, cost effectiveness, open architecture, plug-n-play, and local and remote monitoring in a single package to fulfill the mandates by US Department of Energy (DOE) [1].},
booktitle = {Proceedings of the ACM/IEEE Sixth International Conference on Cyber-Physical Systems},
pages = {248–249},
numpages = {2},
location = {Seattle, Washington},
series = {ICCPS '15}
}

@inproceedings{10.1145/2479871.2479878,
author = {Subramaniam, Balaji and Feng, Wu-chun},
title = {Towards Energy-Proportional Computing for Enterprise-Class Server Workloads},
year = {2013},
isbn = {9781450316361},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479871.2479878},
doi = {10.1145/2479871.2479878},
abstract = {Massive data centers housing thousands of computing nodes have become commonplace in enterprise computing, and the power consumption of such data centers is growing at an unprecedented rate. Adding to the problem is the inability of the servers to exhibit energy proportionality, i.e., provide energy-efficient execution under all levels of utilization, which diminishes the overall energy efficiency of the data center. It is imperative that we realize effective strategies to control the power consumption of the server and improve the energy efficiency of data centers. With the advent of Intel Sandy Bridge processors, we have the ability to specify a limit on power consumption during runtime, which creates opportunities to design new power-management techniques for enterprise workloads and make the systems that they run on more energy proportional.In this paper, we investigate whether it is possible to achieve energy proportionality for an enterprise-class server workload, namely SPECpower_ssj2008 benchmark, by using Intel's Running Average Power Limit (RAPL) interfaces. First, we analyze the power consumption and characterize the instantaneous power profile of the SPECpower benchmark within different subsystems using the on-chip energy meters exposed via the RAPL interfaces. We then analyze the impact of RAPL power limiting on the performance, per-transaction response time, power consumption, and energy efficiency of the benchmark under different load levels. Our observations and results shed light on the efficacy of the RAPL interfaces and provide guidance for designing power-management techniques for enterprise-class workloads.},
booktitle = {Proceedings of the 4th ACM/SPEC International Conference on Performance Engineering},
pages = {15–26},
numpages = {12},
keywords = {greenness, power limiting, energy proportionality},
location = {Prague, Czech Republic},
series = {ICPE '13}
}

@inproceedings{10.1145/1133572.1133604,
author = {Schiele, Gregor and Becker, Christian and Rothermel, Kurt},
title = {Energy-Efficient Cluster-Based Service Discovery for Ubiquitous Computing},
year = {2004},
isbn = {9781450378079},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1133572.1133604},
doi = {10.1145/1133572.1133604},
abstract = {Service discovery in Ubiquitous Computing is a task that has to be done frequently due to dynamically changing environments. The limited battery power of mobile devices requires us to optimize frequent and energy costly tasks, especially the ones incurring in communication activities. In this paper we present a novel service discovery algorithm based on node clustering. Nodes within a cluster may sleep to save energy when idle. A cluster head node is always active and answers discovery requests on behalf of other nodes to achieve low discovery latencies. Simulation experiments show energy savings of up to 66% compared to an approach where all nodes are permanently active while the discovery latencies were not increased.},
booktitle = {Proceedings of the 11th Workshop on ACM SIGOPS European Workshop},
pages = {14–es},
location = {Leuven, Belgium},
series = {EW 11}
}

@inproceedings{10.1109/ICSE-C.2017.133,
author = {Fernandes, Benito and Pinto, Gustavo and Castor, Fernando},
title = {Assisting Non-Specialist Developers to Build Energy-Efficient Software},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.133},
doi = {10.1109/ICSE-C.2017.133},
abstract = {In this paper we introduce CECOtool, a tool that analyzes the energy behavior of alternative collection implementations and provides potentially useful recommendations about good implementation options. We applied it to two real-world software systems from the DaCapo suite [1], Xalan and Tomcat. With no prior knowledge of the application domains, we were able to reduce the energy consumption up to 4.37%.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {158–160},
numpages = {3},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1145/2568225.2568297,
author = {Manotas, Irene and Pollock, Lori and Clause, James},
title = {SEEDS: A Software Engineer's Energy-Optimization Decision Support Framework},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568297},
doi = {10.1145/2568225.2568297},
abstract = {Reducing the energy usage of software is becoming more important in many environments, in particular, battery-powered mobile devices, embedded systems and data centers. Recent empirical studies indicate that software engineers can support the goal of reducing energy usage by making design and implementation decisions in ways that take into consideration how such decisions impact the energy usage of an application. However, the large number of possible choices and the lack of feedback and information available to software engineers necessitates some form of automated decision-making support. This paper describes the first known automated support for systematically optimizing the energy usage of applications by making code-level changes. It is effective at reducing energy usage while freeing developers from needing to deal with the low-level, tedious tasks of applying changes and monitoring the resulting impacts to the energy usage of their application. We present a general framework, SEEDS, as well as an instantiation of the framework that automatically optimizes Java applications by selecting the most energy-efficient library implementations for Java's Collections API. Our empirical evaluation of the framework and instantiation show that it is possible to improve the energy usage of an application in a fully automated manner for a reasonable cost.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {503–514},
numpages = {12},
keywords = {Energy usage, software optimization, analysis framework},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.1145/1391469.1391518,
author = {Goraczko, Michel and Liu, Jie and Lymberopoulos, Dimitrios and Matic, Slobodan and Priyantha, Bodhi and Zhao, Feng},
title = {Energy-Optimal Software Partitioning in Heterogeneous Multiprocessor Embedded Systems},
year = {2008},
isbn = {9781605581156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1391469.1391518},
doi = {10.1145/1391469.1391518},
abstract = {Embedded systems with heterogeneous processors extend the energy/timing trade-off flexibility and provide the opportunity to fine tune resource utilization for particular applications. In this paper, we present a resource model that considers the time and energy costs of run-time mode switching, which considerably improves the accuracy of existing models. Given an application, the software partitioning problem then becomes an optimization over energy cost given deadline constraints, which can be formulate as an integer linear programming (ILP) problem. We apply the resource modeling and software partitioning techniques to a multimodule embedded sensing device, the mPlatform, and present a case study of configuring the platform for a real-time sound source localization application on a stack of MSP430 and ARM7 processor based sensing and processing boards.},
booktitle = {Proceedings of the 45th Annual Design Automation Conference},
pages = {191–196},
numpages = {6},
keywords = {energy-aware, real-time systems, multi-processor scheduling},
location = {Anaheim, California},
series = {DAC '08}
}

@inproceedings{10.1145/1278972.1278979,
author = {Dunkels, Adam and Osterlind, Fredrik and Tsiftes, Nicolas and He, Zhitao},
title = {Software-Based on-Line Energy Estimation for Sensor Nodes},
year = {2007},
isbn = {9781595936943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1278972.1278979},
doi = {10.1145/1278972.1278979},
abstract = {Energy is of primary importance in wireless sensor networks. By being able to estimate the energy consumption of the sensor nodes, applications and routing protocols are able to make informed decisions that increase the lifetime of the sensor network. However, it is in general not possible to measure the energy consumption on popular sensor node platforms. In this paper, we present and evaluate a software-based on-line energy estimation mechanism that estimates the energy consumption of a sensor node. We evaluate the mechanism by comparing the estimated energy consumption with the lifetime of capacitor-powered sensor nodes. By implementing and evaluating the X-MAC protocol, we show how software-based on-line energy estimation can be used to empirically evaluate the energy efficiency of sensor network protocols.},
booktitle = {Proceedings of the 4th Workshop on Embedded Networked Sensors},
pages = {28–32},
numpages = {5},
location = {Cork, Ireland},
series = {EmNets '07}
}

@inproceedings{10.5555/1322109.1322126,
author = {Lee, D. and Ishihara, T. and Muroyama, M. and Yasuura, H. and Fallah, F.},
title = {An Energy Characterization Framework for Software-Based Embedded Systems},
year = {2006},
isbn = {0780397835},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper proposes an energy characterization framework which helps designers in developing a fast and accurate energy model for a target processor-based system. We use a linear model for energy estimation and we find the coefficients of the model using linear programming (LP). We use our approach for estimating the energy consumption of two commercial microprocessors with their on-chip caches and an off-chip SDRAM. Experimental results demonstrate that the error of our technique is on an average 3% and worst case 16% compared to the gate-level estimation results. Once the model has been developed, the energy consumption of an application program can be estimated with the speed of 300,000 instructions per second},
booktitle = {Proceedings of the 2006 IEEE/ACM/IFIP Workshop on Embedded Systems for Real Time Multimedia},
pages = {59–64},
numpages = {6},
keywords = {linear programming, linear model, software-based embedded system, off-chip SDRAM, commercial microprocessor, target processor-based system, energy estimation, on-chip cache, energy consumption},
series = {ESTMED '06}
}

@inproceedings{10.1145/2063384.2063482,
author = {Krueger, Jens and Donofrio, David and Shalf, John and Mohiyuddin, Marghoob and Williams, Samuel and Oliker, Leonid and Pfreund, Franz-Josef},
title = {Hardware/Software Co-Design for Energy-Efficient Seismic Modeling},
year = {2011},
isbn = {9781450307710},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2063384.2063482},
doi = {10.1145/2063384.2063482},
abstract = {Reverse Time Migration (RTM) has become the standard for high-quality imaging in the seismic industry. RTM relies on PDE solutions using stencils that are 8th order or larger, which require large-scale HPC clusters to meet the computational demands. However, the rising power consumption of conventional cluster technology has prompted investigation of architectural alternatives that offer higher computational efficiency. In this work, we compare the performance and energy efficiency of three architectural alternatives -- the Intel Nehalem X5530 multicore processor, the NVIDIA Tesla C2050 GPU, and a general-purpose manycore chip design optimized for high-order wave equations called "Green Wave." We have developed an FPGA-accelerated architectural simulation platform to accurately model the power and performance of the Green Wave design. Results show that across highly-tuned high-order RTM stencils, the Green Wave implementation can offer up to 8x and 3.5x energy efficiency improvement per node respectively, compared with the Nehalem and GPU platforms. These results point to the enormous potential energy advantages of our hardware/software co-design methodology.},
booktitle = {Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {73},
numpages = {12},
keywords = {seismic, RTM, GPU, stencil, co-design, manycore},
location = {Seattle, Washington},
series = {SC '11}
}

@inproceedings{10.1145/2931037.2948706,
author = {Noureddine, Adel and Islam, Syed and Bashroush, Rabih},
title = {Jolinar: Analysing the Energy Footprint of Software Applications (Demo)},
year = {2016},
isbn = {9781450343909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931037.2948706},
doi = {10.1145/2931037.2948706},
abstract = {Monitoring energy consumption of applications is crucial for energy optimisation and improvements in software systems. With the recent emphasis on energy efficiency, it is vital that software engineers have an understanding of the energy consumed by the code they write. In this paper, we present Jolinar, a tool that bridges the gap between energy measurements and accessibility to software engineers and even end-users. The tool builds on top of recent energy models to provide an accurate, light and easy-to-use interface for energy measurements. The target audience of Jolinar is both software engineers and non-technical end-users who want to monitor their applications' energy footprint. We show that end-users can use Jolinar's GUI to determine the energy consumed by the software they are using, and software engineers can use the tool to analyse energy consumption of systems to make energy-conscious decisions.},
booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
pages = {445–448},
numpages = {4},
keywords = {Program Analysis, Energy Footprint},
location = {Saarbr\"{u}cken, Germany},
series = {ISSTA 2016}
}

@inproceedings{10.5555/1322109.2927669,
author = {Ishihara, T. and Yasuura, H. and Fallah, F. and Muroyama, M. and Lee, D.},
title = {An Energy Characterization Framework for Software-Based Embedded Systems},
year = {2006},
isbn = {0780397835},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper proposes an energy characterization framework which helps designers in developing a fast and accurate energy model for a target processor-based system. We use a linear model for energy estimation and we find the coefficients of the model using linear programming (LP). We use our approach for estimating the energy consumption of two commercial microprocessors with their on-chip caches and an off-chip SDRAM. Experimental results demonstrate that the error of our technique is on an average 3% and worst case 16% compared to the gate-level estimation results. Once the model has been developed, the energy consumption of an application program can be estimated with the speed of 300,000 instructions per second},
booktitle = {Proceedings of the 2006 IEEE/ACM/IFIP Workshop on Embedded Systems for Real Time Multimedia},
series = {ESTMED '06}
}

@inproceedings{10.5555/1322109.2927651,
author = {Ishihara, T. and Yasuura, H. and Fallah, F. and Muroyama, M. and Lee, D.},
title = {An Energy Characterization Framework for Software-Based Embedded Systems},
year = {2006},
isbn = {0780397835},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper proposes an energy characterization framework which helps designers in developing a fast and accurate energy model for a target processor-based system. We use a linear model for energy estimation and we find the coefficients of the model using linear programming (LP). We use our approach for estimating the energy consumption of two commercial microprocessors with their on-chip caches and an off-chip SDRAM. Experimental results demonstrate that the error of our technique is on an average 3% and worst case 16% compared to the gate-level estimation results. Once the model has been developed, the energy consumption of an application program can be estimated with the speed of 300,000 instructions per second},
booktitle = {Proceedings of the 2006 IEEE/ACM/IFIP Workshop on Embedded Systems for Real Time Multimedia},
series = {ESTMED '06}
}

@article{10.1145/3609106,
author = {Mishra, Vishesh and Mittal, Sparsh and Hassan, Neelofar and Singhal, Rekha and Chatterjee, Urbi},
title = {VADF: Versatile Approximate Data Formats for Energy-Efficient Computing},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3609106},
doi = {10.1145/3609106},
abstract = {Approximate computing (AC) techniques provide overall performance gains in terms of power and energy savings at the cost of minor loss in application accuracy. For this reason, AC has emerged as a viable method for efficiently supporting several compute-intensive applications, e.g., machine learning, deep learning, and image processing, that can tolerate bounded errors in computations. However, most prior techniques do not consider the possibility of soft errors or malicious bit-flips in AC systems. These errors may interact with approximation-introduced errors in unforeseen ways, leading to disastrous consequences, such as the failure of computing systems. A recent research effort, FTApprox (DATE’21) proposes an error-resilient approximate data format. FTApprox stores two blocks, starting from the one containing the most significant valid (MSV) bit. It also stores location of the MSV block and protects them using error-correcting bits (ECBs). However, FTApprox has crucial limitations such as lack of flexibility, redundantly storing zeros in the MSV, etc.In this paper, we propose a novel storage format named Versatile Approximate Data Format (VADF) for storing approximate integer numbers while providing resilience to soft errors. VADF prescribes rules for storing, for example, a 32-bit number in either 8-bit, 12-bit or 16-bit numbers. VADF identifies the MSV bit and stores a certain number of bits following the MSV bit. It also stores the location of the MSV bit and protects it by ECBs. VADF does not explicitly store the MSB bit itself and this prevents VADF from accruing significant errors. VADF incurs lower error than both truncation methodologies and FTApprox. We further evaluate five image-processing and machine-learning applications and confirm that VADF provides higher application quality than FTApprox in the presence and absence of soft errors. Finally, VADF allows the use of narrow arithmetic units. For example, instead of using a 32-bit multiplier/adder, one can first use VADF (or FTApprox) to compress the data and then use a 8-bit multiplier/adder. Through this approach, VADF facilitates 95.97% and 79.3% energy savings in multiplication and addition, respectively. However, the subsequent re-conversion of the 8-bit output data to 32-bit data using Inv-VADF(16,3,32) diminishes the energy savings by 9.6% for addition and 0.56% for multiplication operation, respectively. The code is available at .},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
articleno = {111},
numpages = {21},
keywords = {approximate data formats, soft-error resilience, Approximate computing}
}

@inproceedings{10.1145/3301418.3313940,
author = {Bahreini, Tayebeh and Brocanelli, Marco and Grosu, Daniel},
title = {Energy-Aware Speculative Execution in Vehicular Edge Computing Systems},
year = {2019},
isbn = {9781450362757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3301418.3313940},
doi = {10.1145/3301418.3313940},
abstract = {We address the problem of energy-aware optimization of speculative execution in vehicular edge computing systems, where multiple copies of a workload are executed on a number of different nodes to ensure high reliability and performance. The objective is to minimize the energy consumption over multiple time periods while minimizing the latency for each of the periods. We prove that the problem is NP-hard and propose a greedy algorithm to solve it in polynomial time. We evaluate the performance of the proposed algorithm by conducting an extensive experimental analysis. The experimental results indicate that the proposed algorithm obtains near optimal solutions within a reasonable amount of time.},
booktitle = {Proceedings of the 2nd International Workshop on Edge Systems, Analytics and Networking},
pages = {18–23},
numpages = {6},
keywords = {Vehicular edge computing, energy consumption, speculative execution},
location = {Dresden, Germany},
series = {EdgeSys '19}
}

@inproceedings{10.1145/3422392.3422422,
author = {da Silva Alves, Danilo and Ferreira, Oseias Ayres and Duarte, Lucio Mauro and Maia, Paulo Henrique},
title = {Probabilistic Model-Based Analysis to Improve Software Energy Efficiency},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422422},
doi = {10.1145/3422392.3422422},
abstract = {Software energy consumption has recently become a concern in software development. However, developers still lack knowledge about how to produce, evaluate and evolve their software considering energy consumption, which might limit their execution in some platforms and prevent users from adopting them. Towards providing more support for energy consumption analysis, we provide a set of properties to analyse software consumption considering not only energy costs but also probabilistic information. We demonstrate how to use, combine and interpret the results of analyses of these properties. We discuss experiments involving the analysis of the proposed properties in different scenarios and how, based on the results of these analyses, recommendations of possible actions to adjust energy consumption can be proposed.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {132–136},
numpages = {5},
keywords = {Model-based Analysis, Software Energy Consumption},
location = {Natal, Brazil},
series = {SBES '20}
}

@inproceedings{10.1145/997163.997175,
author = {Pokam, Gilles and Rochecouste, Olivier and Seznec, Andr\'{e} and Bodin, Fran\c{c}ois},
title = {Speculative Software Management of Datapath-Width for Energy Optimization},
year = {2004},
isbn = {1581138067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/997163.997175},
doi = {10.1145/997163.997175},
abstract = {This paper evaluates managing the processor's datapath-width at the compiler level by means of exploiting dynamic narrow-width operands. We capitalize on the large occurrence of these operands in multimedia programs to build static narrow-width regions that may be directly exposed to the compiler. We propose to augment the ISA with instructions directly exposing the datapath and the register widths to the compiler. Simple exception management allows this exposition to be only speculative. In this way, we permit the software to speculatively accommodate the execution of a program on a narrower datapath-width in order to save energy. For this purpose, we introduce a novel register file organization, the byte-slice register file, which allows the width of the register file to be dynamically reconfigured, providing both static and dynamic energy savings. We show that by combining the advantages of the byte-slice register file with the advantages provided by clock-gating the datapath on a per-region basis, up to 17% of the datapath dynamic energy can be saved, while a 22% reduction of the register file static energy is achieved.},
booktitle = {Proceedings of the 2004 ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems},
pages = {78–87},
numpages = {10},
keywords = {speculative execution, narrow-width regions, reconfigurable computing, compiler, energy management, clock-gating},
location = {Washington, DC, USA},
series = {LCTES '04}
}

@article{10.1145/3391903,
author = {Ahmed, Saad and Bhatti, Naveed Anwar and Alizai, Muhammad Hamad and Siddiqui, Junaid Haroon and Mottola, Luca},
title = {Fast and Energy-Efficient State Checkpointing for Intermittent Computing},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {6},
issn = {1539-9087},
url = {https://doi.org/10.1145/3391903},
doi = {10.1145/3391903},
abstract = {Intermittently powered embedded devices ensure forward progress of programs through state checkpointing in non-volatile memory. Checkpointing is, however, expensive in energy and adds to the execution times. To minimize this overhead, we present DICE, a system that renders differential checkpointing profitable on these devices. DICE is unique because it is a software-only technique and efficient because it only operates in volatile main memory to evaluate the differential. DICE may be integrated with reactive (Hibernus) or proactive (MementOS, HarvOS) checkpointing systems, and arbitrary code can be enabled with DICE using automatic code-instrumentation requiring no additional programmer effort. By reducing the cost of checkpoints, DICE cuts the peak energy demand of these devices, allowing operation with energy buffers that are one-eighth of the size originally required, thus leading to benefits such as smaller device footprints and faster recharging to operational voltage level. The impact on final performance is striking: with DICE, Hibernus requires one order of magnitude fewer checkpoints and one order of magnitude shorter time to complete a workload in real-world settings.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
articleno = {45},
numpages = {27},
keywords = {differential checkpointing, Transiently powered computers, intermittent computing}
}

@inproceedings{10.1145/3338840.3355671,
author = {Wu, Chia-Hsueh and Hung, Chen-Tui and Chen, Ya-Shu},
title = {Energy-Aware Offloading for Mobile Computing with Heterogeneous Network},
year = {2019},
isbn = {9781450368438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338840.3355671},
doi = {10.1145/3338840.3355671},
abstract = {Computation offloading is widely applied to mobile embedded devices to deal with the challenge of the limited resource of energy and computation. However, the computation offloading introduces extra communication energy and communication delay to the mobile devices and applications. To meet the latency constraint of the applications and maximize the lifetime of the mobile device, an energy-efficient offloading for mobile devices with heterogeneous network interfaces is proposed in this paper. A queuing based estimation dispatcher is presented to minimize the communication energy considering the varied transmission speed of the heterogeneous network. The energy efficiency of the proposed methodology was evaluated and impressive results were obtained.},
booktitle = {Proceedings of the Conference on Research in Adaptive and Convergent Systems},
pages = {39–44},
numpages = {6},
keywords = {offloading, heterogeneous network, embedded device, energy efficiency, mobile cloud computing},
location = {Chongqing, China},
series = {RACS '19}
}

@inproceedings{10.5555/2616606.2616999,
author = {Paul, Somnath and Karam, Robert and Bhunia, Swarup and Puri, Ruchir},
title = {Energy-Efficient Hardware Acceleration through Computing in the Memory},
year = {2014},
isbn = {9783981537024},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Energy-efficiency has emerged as a major barrier to performance scalability for modern processors. We note that significant part of processor's energy requirement is contributed by processor-memory communication. To address the energy issue in processors, we propose a novel hardware accelerator framework that transforms high-density memory array into a configurable computing resource to accelerate variety of tasks - both compute- and data-intensive. It exploits the block-based architecture of nanoscale memory to create a spatially connected array of lightweight processors, each of which uses a memory block as its local memory. The proposed framework provides some unique advantages for hardware acceleration compared to conventional accelerators: 1) memory array provides large set of parallel resources with high bandwidth, which can be configured to perform computing in spatio/temporal manner leading to dramatic reduction in processor-memory traffic; 2) it brings the computing engine close to the data, thus drastically minimizing the von Neumann bottleneck; 3) finally, it exploits the advances in memory technologies and integration approaches e.g. 3D integration to achieve better technology scalability compared to alternative reconfigurable accelerator platforms. Simulation results for several data-intensive applications show that the proposed computing approach provides significant improvement in energy-efficiency compared to software while achieving significantly lower hardware overhead.},
booktitle = {Proceedings of the Conference on Design, Automation &amp; Test in Europe},
articleno = {266},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '14}
}

@inproceedings{10.1145/3461001.3471142,
author = {Gu\'{e}gain, \'{E}douard and Quinton, Cl\'{e}ment and Rouvoy, Romain},
title = {On Reducing the Energy Consumption of Software Product Lines},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3471142},
doi = {10.1145/3461001.3471142},
abstract = {Along the last decade, several studies considered green software design as a key development concern to improve the energy efficiency of software. Yet, few techniques address this concern for Software Product Lines (SPL). In this paper, we therefore introduce two approaches to measure and reduce the energy consumption of a SPL by analyzing a limited set of products sampled from this SPL. While the first approach relies on the analysis of individual feature consumptions, the second one takes feature interactions into account to better mitigate energy consumption of resulting products.Our experimental results on a real-world SPL indicate that both approaches succeed to produce significant energy improvements on a large number of products, while consumption data was modeled from a small set of sampled products. Furthermore, we show that taking feature interactions into account leads to more products improved with higher energy savings per product.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {89–99},
numpages = {11},
keywords = {software product lines, consumption, energy, measurement, mitigation},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@inproceedings{10.1145/3109729.3109744,
author = {Munoz, Daniel-Jesus},
title = {Achieving Energy Efficiency Using a Software Product Line Approach},
year = {2017},
isbn = {9781450351195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109729.3109744},
doi = {10.1145/3109729.3109744},
abstract = {Green computing and energy-aware software engineering are trend approaches that try to address the development of applications respectful with the environment. To reduce the energy consumption of an application the developer needs: (i) to identify what are the concerns that will impact more in the energy consumption; (ii) to model the variability of alternative designs and implementations of each concern; (iii) to store and compare the experimentation results related with the energy and time consumption of concerns; (iv) to find out what is the most eco-efficient solution for each concern. HADAS addresses these issues by modelling the variability of energy consuming concerns for different energy contexts. It connects the variability model with a repository that stores energy measurements, providing a Software Product Line (SPL) service, helping developers to reason and find out what are the most eco-friendly configurations. We have an initial implementation of the HADAS toolkit using Clafer. We have tested our implementation with several case studies.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume B},
pages = {131–138},
numpages = {8},
keywords = {Repository, Metrics, Variability, Clafer, Energy Efficiency, Software Product Line, Optimisation},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@inproceedings{10.5555/3539845.3539860,
author = {Zhang, Sizhe and Wang, Ruixuan and Ma, Dongning and Zhang, Jeff (Jun) and Yin, Xunzhao and Jiao, Xun},
title = {Energy-Efficient Brain-Inspired Hyperdimensional Computing Using Voltage Scaling},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Recently, brain-inspired hyperdimensional computing (HDC) has demonstrated promising capability in a wide range of applications such as medical diagnosis, human activity recognition, and voice classification, etc. Despite the growing popularity of HDC, its memory-centric computing characteristics make the associative memory implementation under significant energy consumption due to the massive data storage and processing. In this paper, we present a systematic case study to leverage the application-level error resilience of HDC to reduce the energy consumption of HDC associative memory by using voltage scaling. Evaluation results on various applications show that our proposed approach can achieve 47.6% energy saving on associative memory with a ≤1% accuracy loss. We further explore two low-cost error masking methods: word masking and bit masking, to mitigate the impact of voltage scaling-induced errors. Experimental results show that the proposed word masking (bit masking) method can further enhance energy saving up to 62.3% (72.5%) with accuracy loss ≤1%.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {52–55},
numpages = {4},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/2989081.2989083,
author = {Zivanovic, Darko and Radulovic, Milan and Llort, Germ\'{a}n and Zaragoza, David and Strassburg, Janko and Carpenter, Paul M. and Radojkovi\'{c}, Petar and Ayguad\'{e}, Eduard},
title = {Large-Memory Nodes for Energy Efficient High-Performance Computing},
year = {2016},
isbn = {9781450343053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2989081.2989083},
doi = {10.1145/2989081.2989083},
abstract = {Energy consumption is by far the most important contributor to HPC cluster operational costs, and it accounts for a significant share of the total cost of ownership. Advanced energy-saving techniques in HPC components have received significant research and development effort, but a simple measure that can dramatically reduce energy consumption is often overlooked. We show that, in capacity computing, where many small to medium-sized jobs have to be solved at the lowest cost, a practical energy-saving approach is to scale-in the application on large-memory nodes. We evaluate scaling-in; i.e. decreasing the number of application processes and compute nodes (servers) to solve a fixed-sized problem, using a set of HPC applications running in a production system. Using standard-memory nodes, we obtain average energy savings of 36%, already a huge figure. We show that the main source of these energy savings is a decrease in the node-hours (node_hours = #nodes x exe_time), which is a consequence of the more efficient use of hardware resources.Scaling-in is limited by the per-node memory capacity. We therefore consider using large-memory nodes to enable a greater degree of scaling-in. We show that the additional energy savings, of up to 52%, mean that in many cases the investment in upgrading the hardware would be recovered in a typical system lifetime of less than five years.},
booktitle = {Proceedings of the Second International Symposium on Memory Systems},
pages = {3–9},
numpages = {7},
keywords = {Energy efficiency, Large-memory nodes, Capacity computing, High-performance computing, Scaling-in},
location = {Alexandria, VA, USA},
series = {MEMSYS '16}
}

@inproceedings{10.5555/2485288.2485437,
author = {Ayad, Gasser and Acquaviva, Andrea and Macii, Enrico and Sahbi, Brahim and Lemaire, Romain},
title = {HW-SW Integration for Energy-Efficient/Variability-Aware Computing},
year = {2013},
isbn = {9781450321532},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Recent trends in embedded system architectures brought a rapid shift towards multicore, heterogeneous and reconfigurable platforms. This imposes a large effort for programmers to develop their applications to efficiently exploit the underlying architecture. In addition, process variability issues lead to performance and power uncertainties, impacting expected quality of service and energy efficiency of the running software. In particular, variability may lead to sub-optimal runtime task allocation.In this paper we present a holistic approach to tackle these issues exploiting high level HW/SW modeling to customize the runtime library. The customization introduces variability awareness in task allocation decisions, with the final purpose of optimizing a given objective: Execution time, power consumption, or overall energy consumption.We present a complete walkthrough, from top-level modeling down to variability-aware execution using a parallelized computational kernel running on a next generation, NoC based, heterogeneous multicore simulation platform.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {607–611},
numpages = {5},
location = {Grenoble, France},
series = {DATE '13}
}

@inproceedings{10.1145/1787275.1787294,
author = {Nallamuthu, Ananth and Smith, Melissa C. and Hampton, Scott and Agarwal, Pratul K. and Alam, Sadaf R.},
title = {Energy Efficient Biomolecular Simulations with FPGA-Based Reconfigurable Computing},
year = {2010},
isbn = {9781450300445},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1787275.1787294},
doi = {10.1145/1787275.1787294},
abstract = {Reconfigurable computing (RC) is being investigated as a hardware solution for improving time-to-solution for biomolecular simulations. A number of popular molecular dynamics (MD) codes are used to study various aspects of biomolecules. These codes are now capable of simulating nanosecond time-scale trajectories per day on conventional microprocessor-based hardware, but biomolecular processes often occur at the microsecond time-scale or longer. A wide gap exists between the desired and achievable simulation capability; therefore, there is considerable interest in alternative algorithms and hardware for improving the time-to-solution of MD codes. The fine-grain parallelism provided by Field Programmable Gate Arrays (FPGA) combined with their low power consumption make them an attractive solution for improving the performance of MD simulations. In this work, we use an FPGA-based coprocessor to accelerate the compute-intensive calculations of LAMMPS, a popular MD code, achieving up to 5.5 fold speed-up on the non-bonded force computations of the particle mesh Ewald method and up to 2.2 fold speed-up in overall time-to-solution, and potentially an increase by a factor of 9 in power-performance efficiencies for the pair-wise computations. The results presented here provide an example of the multi-faceted benefits to an application in a heterogeneous computing environment.},
booktitle = {Proceedings of the 7th ACM International Conference on Computing Frontiers},
pages = {83–84},
numpages = {2},
keywords = {fpga, molecular dynamics, reconfigurable computing, biomolecular simulations, lammps},
location = {Bertinoro, Italy},
series = {CF '10}
}

@inproceedings{10.1145/781027.781065,
author = {Wang, Bokyung and Singh, Suresh},
title = {Analysis of TCP's Computational Energy Cost for Mobile Computing},
year = {2003},
isbn = {1581136641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/781027.781065},
doi = {10.1145/781027.781065},
abstract = {In this paper we present results from a measurement study of TCP (Transmission Control Protocol) running over a wireless link. Our primary goal was on obtaining a breakdown of the computational energy cost of TCP at the sender and receiver (excluding radio energy costs) as a first step in developing techniques to reduce this cost in actual systems. We analyzed the energy consumption of TCP in FreeBSD 5 running on a wireless laptop. Our initial results showed that 60 - 70% of the energy cost (for transmission or reception) is accounted for by the Kernel -- NIC (Network Interface Card) copy operation. Of the remainder, 15% is accounted for in the copy operation from user space to kernel space with the remaining 15% being accounted for by TCP processing costs. We then further analyzed the TCP processing cost and determined the cost of computing checksums accounts for 20 -- 30% of TCP processing cost.},
booktitle = {Proceedings of the 2003 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {296–297},
numpages = {2},
keywords = {TCP, mobile, energy, wireless},
location = {San Diego, CA, USA},
series = {SIGMETRICS '03}
}

@inproceedings{10.1145/3241815.3241865,
author = {He, Jing (Selena) and Han, Meng and Bobbie, Patrick O.},
title = {An Energy-Efficient Secure Adaptive Cloud-of-Things (CoT) Framework to Facilitate Undergraduate STEM Education},
year = {2018},
isbn = {9781450359542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241815.3241865},
doi = {10.1145/3241815.3241865},
abstract = {This paper presents an adaptive framework (web application) that supports secure, end-to-end Internet of Things (IoT) sensing architecture, which includes loosely coupled set of components with well-defined interfaces that can be adapted to a wide range of uses. Moreover, the framework was adopted in a Computer Science (CS) Fog computing course to get formal evaluation by undergraduate students. IoT has emerged as a new network paradigm, involving connecting physical world through sensors (temperature, humidity, intensity, etc.) to the Internet, to provide opportunities for building intelligent systems and applications. There are a few notable characteristics of today's IoT systems that serve as impediments for greater adoption. First, the common, well-documented platform that spans end-to-end, and which can cover a multitude of practical uses, is still missing. The second impediment is the lack of standard energy-efficient platform. Third, with the growing deployment of IoT devices, the attack vector for possible exploitation increases, which dictates an increase in the ongoing cost to ensure Confidentiality-Integrity-Availability triad. In this project, we propose the solution to address these impediments. The proposed framework makes it economical and easy to adapt to (e.g. to learn and to support). The next benefit comes with the use of environment harvesting equipment (solar cell, in-line hydro-generators, thermoelectric cells, etc.) and use of energy efficient coding methods, including security and communication provisions. Overall, the project successfully integrates Amazon Cloud technologies, Raspberry-Pi and Arduino embedded systems using energy-harvesting technologies, secure communication using government standards, and highly available network of nodes using wireless technology into a Cloud-of-Things (CoF).The methodology allows a myriad IoT devices connected to the Internet to be easily monitored and manipulated through the implemented web application. On the other hand, since few dedicated IoT courses are currently offered, most Science, technology, Engineering, and Mathematics (STEM) students will have limited or no exposure to IoT development until after graduation, and inadequately prepared in IoT development to enter into the workforce. Therefore, the implemented framework was introduced in a CS special topic course to get comments and formal evaluations from undergraduate STEM students. An outline of a well-developed courseware is presented in the paper. The courseware is evaluated through survey questions. The majority of the students provided positive feedback and enjoyed the IoT framework.},
booktitle = {Proceedings of the 19th Annual SIG Conference on Information Technology Education},
pages = {123–128},
numpages = {6},
keywords = {secure cloud-of-things (cot) framework, arduino, advanced encryption standard (aes), energy efficient, automatic control, raspberry pi, undergraduate stem education},
location = {Fort Lauderdale, Florida, USA},
series = {SIGITE '18}
}

@inproceedings{10.1145/2996890.3007895,
author = {Govindaraju, Yatheendraprakash and Duran-Limon, Hector},
title = {A QoS and Energy Aware Load Balancing and Resource Allocation Framework for IaaS Cloud Providers},
year = {2016},
isbn = {9781450346160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996890.3007895},
doi = {10.1145/2996890.3007895},
abstract = {The exponential growth of cloud based applications and the increased number of cloud users have given rise to new challenges for cloud service providers, especially for Infrastructure as a Service (IaaS) providers. This exponential growth of datacenters increases the energy consumption, along with its carbon footprints. Hence, better energy aware techniques not only reduce energy costs, but they are also helpful for reducing pollution in the environment. Some of the main challenges for cloud providers include increasing the resource utilization and minimizing energy consumption while maintaining the quality of service (QoS) offered to the users. There are many load balancing and resource allocation techniques proposed to handle these challenges. Out of these techniques, only a few consider QoS goals for IaaS service providers. However, none of these techniques includes service level agreement (SLA) parameters related to the Virtual Machine (VM) life cycle such as VM startup times. In this paper, we propose a novel approach to address this problem.},
booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
pages = {410–415},
numpages = {6},
keywords = {iaaS cloud, service level agreement, energy efficiency, resource allocation, load balancing},
location = {Shanghai, China},
series = {UCC '16}
}

@inproceedings{10.5555/2825041.2825058,
author = {Kwon, Young-Woo and Tilevich, Eli},
title = {Facilitating the Implementation of Adaptive Cloud Offloading to Improve the Energy Efficiency of Mobile Applications},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Cloud offloading---leveraging remote cloud-based computing resources to execute energy-intensive functionality---has become a common optimization technique for mobile applications. However, implementing cloud offloading techniques remains a delicate and complex task, reserved for expert programmers. If cloud computing is to realize its promise as a generally applicable, powerful optimization technique for mobile applications, its implementation barrier must be lowered. As we have discovered, reusable system building blocks exposed via a convenient programming model can facilitate the implementation of complex cloud offloading optimizations. This paper describes a system architecture for implementing adaptive cloud offloading optimizations. In particular, the architecture features parameterizable building blocks for monitoring and estimating energy consumption and performance efficiency as well as state synchronization across address spaces, which the mobile programmer can use \`{a} la carte. These blocks streamline the implementation procedure for a wide array of adaptive offloading optimizations. Applying this system architecture to third-party mobile applications has optimized their energy efficiency, depending on the execution environment in place.},
booktitle = {Proceedings of the Second ACM International Conference on Mobile Software Engineering and Systems},
pages = {94–104},
numpages = {11},
keywords = {mobile applications, cloud offloading, programming model, energy optimization, adaptation},
location = {Florence, Italy},
series = {MOBILESoft '15}
}

@article{10.1145/3433541,
author = {Junaid, Muhammad and Sohail, Adnan and Turjman, Fadi Al and Ali, Rashid},
title = {Agile Support Vector Machine for Energy-Efficient Resource Allocation in IoT-Oriented Cloud Using PSO},
year = {2021},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
issn = {1533-5399},
url = {https://doi.org/10.1145/3433541},
doi = {10.1145/3433541},
abstract = {Over the years cloud computing has seen significant evolution in terms of improvement in infrastructure and resource provisioning. However the continuous emergence of new applications such as the Internet of Things (IoTs) with thousands of users put a significant load on cloud infrastructure. Load balancing of resource allocation in cloud-oriented IoT is a critical factor that has a significant impact on the smooth operation of cloud services and customer satisfaction. Several load balancing strategies for cloud environment have been proposed in the past. However the existing approaches mostly consider only a few parameters and ignore many critical factors having a pivotal role in load balancing leading to less optimized resource allocation. Load balancing is a challenging problem and therefore the research community has recently focused towards employing machine learning-based metaheuristic approaches for load balancing in the cloud. In this paper we propose a metaheuristics-based scheme Data Format Classification using Support Vector Machine (DFC-SVM), to deal with the load balancing problem. The proposed scheme aims to reduce the online load balancing complexity by offline-based pre-classification of raw-data from diverse sources (such as IoT) into different formats e.g. text images media etc. SVM is utilized to classify “n” types of data formats featuring audio video text digital images and maps etc. A one-to-many classification approach has been developed so that data formats from the cloud are initially classified into their respective classes and assigned to virtual machines through the proposed modified version of Particle Swarm Optimization (PSO) which schedules the data of a particular class efficiently. The experimental results compared with the baselines have shown a significant improvement in the performance of the proposed approach. Overall an average of 94% classification accuracy is achieved along with 11.82% less energy 16% less response time and 16.08% fewer SLA violations are observed.},
journal = {ACM Trans. Internet Technol.},
month = {nov},
articleno = {6},
numpages = {35},
keywords = {internet of things (IoT), particle swarm optimization (PSO), data format classification (DFC), machine learning, resource scheduling, support vector machine (SVM), Cloud, virtual machine (VM)}
}

@inproceedings{10.1145/1890799.1890803,
author = {Beloglazov, Anton and Buyya, Rajkumar},
title = {Adaptive Threshold-Based Approach for Energy-Efficient Consolidation of Virtual Machines in Cloud Data Centers},
year = {2010},
isbn = {9781450304535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1890799.1890803},
doi = {10.1145/1890799.1890803},
abstract = {The rapid growth in demand for computational power driven by modern service applications combined with the shift to the Cloud computing model have led to the establishment of large-scale virtualized data centers. Such data centers consume enormous amounts of electrical energy resulting in high operating costs and carbon dioxide emissions. Dynamic consolidation of virtual machines (VMs) and switching idle nodes off allow Cloud providers to optimize resource usage and reduce energy consumption. However, the obligation of providing high quality of service to customers leads to the necessity in dealing with the energy-performance trade-off. We propose a novel technique for dynamic consolidation of VMs based on adaptive utilization thresholds, which ensures a high level of meeting the Service Level Agreements (SLA). We validate the high efficiency of the proposed technique across different kinds of workloads using workload traces from more than a thousand PlanetLab servers.},
booktitle = {Proceedings of the 8th International Workshop on Middleware for Grids, Clouds and e-Science},
articleno = {4},
numpages = {6},
keywords = {VM placement, cloud computing, green IT},
location = {Bangalore, India},
series = {MGC '10}
}

@inproceedings{10.1145/3578451,
author = {Khatri, Sunil and Krishnakumar, Anish},
title = {Session Details: Energy Efficient Hardware Acceleration and Stochastic Computing},
year = {2022},
isbn = {9781450392174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578451},
doi = {10.1145/3578451},
booktitle = {Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design},
location = {San Diego, California},
series = {ICCAD '22}
}

@inproceedings{10.1145/3407197.3407217,
author = {Ganguly, Samiran and Ghosh, Avik W.},
title = {Building Reservoir Computing Hardware Using Low Energy-Barrier Magnetics},
year = {2020},
isbn = {9781450388511},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3407197.3407217},
doi = {10.1145/3407197.3407217},
abstract = {Biologically inspired recurrent neural networks, such as reservoir computers are of interest in designing spatio-temporal data processors from a hardware point of view due to the simple learning scheme and deep connections to Kalman filters. In this work we discuss using in-depth simulation studies a way to construct hardware reservoir computers using an analog stochastic neuron cell built from a low energy-barrier magnet based magnetic tunnel junction and a few transistors. This allows us to implement a physical embodiment of the mathematical model of reservoir computers. Compact implementation of reservoir computers using such devices may enable building compact, energy-efficient signal processors for standalone or in-situ machine cognition in edge devices.},
booktitle = {International Conference on Neuromorphic Systems 2020},
articleno = {17},
numpages = {8},
keywords = {Neuromorphics, Kalman filters, Stochastic Magnetics, Spintronics, Reservoir Computing},
location = {Oak Ridge, TN, USA},
series = {ICONS 2020}
}

@inproceedings{10.5555/3199700.3199824,
author = {Gao, Mingze and Qu, Gang},
title = {Energy Efficient Runtime Approximate Computing on Data Flow Graphs},
year = {2017},
publisher = {IEEE Press},
abstract = {Approximate computing is an emerging computation paradigm that utilizes many applications' intrinsic error resilience to improve power and energy efficiency. Several approaches have been proposed to identify the non-critical computations by analyzing the output sensitivity to the accuracy of the results, and then perform approximate computing on these computations. However, these static approaches only use the prior knowledge (e.g. input ranges) for analysis and fail to consider the runtime information, which limits the energy saving and incurs large computation error. In this paper, we propose a runtime approximate computing framework to solve this problem. The basic idea is to use a low cost method to estimate the impact of each immediate input value to the accuracy of computation at every node in the data flow graph, and then decide whether we should simply use the estimated value or perform an accurate computation. Our novel runtime estimation method is based on converting data to the logarithmic representation. We propose two algorithms to make the decision at certain nodes whether an accurate computation will be needed to balance energy saving and computation error. Experimental results show that this tradeoff ranges from 40% energy saving with 4.85% error on average to 8% energy saving with 0.18% error. Compared to the static DFG node cutting approach, our approach's estimation accuracy is 32x better to achieve the same amount of energy saving.},
booktitle = {Proceedings of the 36th International Conference on Computer-Aided Design},
pages = {902–907},
numpages = {6},
keywords = {energy efficient, logarithmic estimation, approximate computing, runtime, data flow graph},
location = {Irvine, California},
series = {ICCAD '17}
}

@article{10.1145/3140589,
author = {Lewis, Ted G.},
title = {Art Scott and Michael Frank on Energy-Efficient Computing},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2017},
number = {September},
url = {https://doi.org/10.1145/3140589},
doi = {10.1145/3140589},
abstract = {Clock speeds of computing chips have leveled off dramatically since 2005, and putting more cores in systems on a chip (SoC) has produced more heat, adding a new ceiling to further advances. Leading-edge researchers, like Mike Frank, and dedicated technologists with a wealth of experience, like Art Scott, represent a new vanguard of the leap-forward beyond Dennard scaling and Landauer's limit. Art looks for ways to reduce energy consumption and Mike looks for ways to "architect" future chips according to principles of reversibility. Is the future in reversible, adiabatic computing and simpler architectures using posit arithmetic? My guests think so.},
journal = {Ubiquity},
month = {sep},
articleno = {1},
numpages = {17}
}

@inproceedings{10.1109/CCGrid.2015.130,
author = {Mair, Jason and Huang, Zhiyi and Eyers, David and Chen, Yawen},
title = {Quantifying the Energy Efficiency Challenges of Achieving Exascale Computing},
year = {2015},
isbn = {9781479980062},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2015.130},
doi = {10.1109/CCGrid.2015.130},
abstract = {Power and performance are two potentially opposing objectives in the design of a supercomputer, where increases in performance often come at the cost of increased power consumption and vice versa. The task of simultaneously maximising both objectives is becoming an increasingly prominent challenge in the development of future exascale supercomputers. To gain some perspective on the scale of the challenge, we analyse the power and performance trends for the Top500 and Green500 supercomputer lists. We then present the Pa PW metric, which we use to evaluate the scalability of power efficiency, projecting the development of an exascale system. From this analysis, we found that when both power and performance are considered, the projected date of achieving an exascale system falls far beyond the current target of 2020.},
booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {943–950},
numpages = {8},
location = {Shenzhen, China},
series = {CCGRID '15}
}

@inproceedings{10.5555/3375069.3375100,
author = {Dias de Assun\c{c}\~{a}o, Marcos and Lef\`{e}vre, Laurent and Rossigneux, Fran\c{c}ois},
title = {On the Impact of Advance Reservations for Energy-Aware Provisioning of Bare-Metal Cloud Resources},
year = {2016},
isbn = {9783901882852},
publisher = {International Federation for Information Processing},
address = {Laxenburg, AUT},
abstract = {This work investigates factors that can impact the elasticity of bare-metal resources. We analyse data from a real bare-metal deployment system to build a deployment time model, which is used to evaluate how provisioning time impacts the reservation of bare-metal resources. Climate/Blazar, a reservation framework designed for OpenStack, is discussed. Simulation results show that reservations can help reduce the time to deliver a provisioned cluster to its customer while achieving energy savings similar to those of strategies that switch-off idle resources.},
booktitle = {Proceedings of the 12th Conference on International Conference on Network and Service Management},
pages = {238–242},
numpages = {5},
keywords = {resource management, bare-metal deployment, resource reservation, task scheduling},
location = {Montreal, Quebec, Canada},
series = {CNSM 2016}
}

@inproceedings{10.1109/UCC.2014.74,
author = {Celaya, Javier and Sakellariou, Rizos},
title = {An Adaptive Policy to Minimize Energy and SLA Violations of Parallel Jobs on the Cloud},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.74},
doi = {10.1109/UCC.2014.74},
abstract = {Energy consumption for Cloud providers and data centers is a major problem. Dynamic Power Management is a common solution to this problem, switching off and on idle servers as needed. However, failing to predict the impact of switching costs may adversely affect energy and/or SLA violations. This paper contributes a policy that adaptively decides when to switch servers on and off under a workload of parallel jobs. Its objective is to minimize both the energy consumption and the number of SLA violations. Experimental results using Cloud Sim show that our proactive policy strikes a good balance between consumed energy and the number of SLA violations and compares favorably with other policies from the literature.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {507–508},
numpages = {2},
keywords = {energy, parallel jobs, SLAs},
series = {UCC '14}
}

@article{10.1145/351440.351446,
author = {Machover, Carl},
title = {Green and Hopgood Share UK Computer Graphics History},
year = {2000},
issue_date = {May 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {0097-8930},
url = {https://doi.org/10.1145/351440.351446},
doi = {10.1145/351440.351446},
journal = {SIGGRAPH Comput. Graph.},
month = {may},
pages = {28–30},
numpages = {3}
}

@inproceedings{10.1145/2652524.2652578,
author = {Gupta, Ashish and Zimmermann, Thomas and Bird, Christian and Nagappan, Nachiappan and Bhat, Thirumalesh and Emran, Syed},
title = {Mining Energy Traces to Aid in Software Development: An Empirical Case Study},
year = {2014},
isbn = {9781450327749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2652524.2652578},
doi = {10.1145/2652524.2652578},
abstract = {Context: With the advent of increased computing on mobile devices such as phones and tablets, it has become crucial to pay attention to the energy consumption of mobile applications.Goal: The software engineering field is now faced with a whole new spectrum of energy-related challenges, ranging from power budgeting to testing and debugging the energy consumption, for which exists only limited tool support. The goal of this work is to provide techniques to engineers to analyze power consumption and detect anomalies.Method: In this paper, we present our work on analyzing energy patterns for the Windows Phone platform. We first describe the data that is collected for testing (power traces and execution logs). We then present several approaches for describing power consumption and detecting anomalous energy patterns and potential energy defects. Finally we show prediction models based on usage of individual modules that can estimate the overall energy consumption with high accuracy.Results: The techniques in this paper were successful in modeling and estimating power consumption and in detecting anomalies.Conclusions: The techniques presented in the paper allow assessing the individual impact of modules on the overall energy consumption and support overall energy planning.},
booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {40},
numpages = {8},
keywords = {energy consumption, power budget, energy modelling, power traces, energy patterns, debugging, prediction, defects, windows phone},
location = {Torino, Italy},
series = {ESEM '14}
}

@inproceedings{10.1145/3511430.3511434,
author = {Singh, Lavneet},
title = {RMVRVM – A Paradigm for Creating Energy Efficient User Applications Connected to Cloud through REST API},
year = {2022},
isbn = {9781450396189},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511430.3511434},
doi = {10.1145/3511430.3511434},
abstract = {The applications that run on resource-constrained devices, especially for batteries, pose a challenge. The activities such applications do while running on such devices consume energy and drain the device's battery. Many of these applications use REST API to communicate with their backend services running outside of the devices, primarily on the cloud. The paradigms like Model View View-Model (MVVM) used on the application side require data transformations that cause applications to consume more battery. There is a need for an improved approach and a paradigm that can be used to develop green software with reduced battery consumption. This paper proposes a novel Remote-Model View Remote-View-Model (RMVRVM) paradigm. The use of RMVRVM paradigm lowers the battery consumption on devices where the application is running and hence contributes to writing green software. In addition, RMVRVM makes an application more responsive and thus a delight to use. This paradigm has been implemented in industrial case studies, and significant gains in terms of the reduced amount of data transfer, reduced battery consumption, and faster response time were observed. Experiments were also done to further validate the paradigm with encouraging results. The practitioners can apply the RMVRVM to design applications for battery-constrained devices with smaller energy footprints and better response times.},
booktitle = {15th Innovations in Software Engineering Conference},
articleno = {6},
numpages = {11},
keywords = {Non-functional Requirements, Battery Saving, Energy Efficient Mobile Applications, Model View View-Model (MVVM), Green Software, Sustainable Software Engineering},
location = {Gandhinagar, India},
series = {ISEC 2022}
}

@inproceedings{10.1109/CCGrid.2014.34,
author = {Skeehan, Dillon and Brenner, Paul and Tovar, Ben and Thain, Douglas and Valls, N. and Woodard, A. and Wolf, M. and Pearson, T. and Lynch, S. and Lannon, K.},
title = {Opportunistic High Energy Physics Computing in User Space with Parrot},
year = {2014},
isbn = {9781479927838},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2014.34},
doi = {10.1109/CCGrid.2014.34},
abstract = {The computing needs of high energy physics experiments like the Compact Muon Solenoid experiment at the Large Hadron Collider currently exceed the available dedicated computational resources, hence motivating a push to leverage opportunistic resources. However, access to opportunistic resources faces many obstacles, not the least of which is making available the complex software stack typically associated with such computations. This paper describes a framework constructed using existing software packages to distribute the needed software to opportunistic resources without the need for the job to have root-level privileges. Preliminary tests with this framework have demonstrated the feasibility of the approach and identified bottlenecks as well as reliability issues which must be resolved in order to make this approach viable for broad use.},
booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {170–175},
numpages = {6},
keywords = {HTCondor, grid, job eviction, remote I/O, opportunistic computing, user space, high energy physics, XROOTD, Parrot, CVMFS},
location = {Chicago, Illinois},
series = {CCGRID '14}
}

@inproceedings{10.1145/2159344.2159346,
author = {Matsuoka, Satoshi},
title = {Power and Energy Aware Computing with Tsubame 2.0 and Beyond},
year = {2011},
isbn = {9781450311588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2159344.2159346},
doi = {10.1145/2159344.2159346},
booktitle = {Proceedings of the 2011 Workshop on Energy Efficiency: HPC System and Datacenters},
pages = {1–76},
numpages = {76},
keywords = {efficiency},
location = {Seattle, Washington, USA},
series = {EE-HPC-WG '11}
}

@inproceedings{10.1145/1996130.1996175,
author = {Zhang, Yuanrui and Liu, Jun and Wilson, Ellis and Kandemir, Mahmut},
title = {Software-Directed Data Access Scheduling for Reducing Disk Energy Consumption},
year = {2011},
isbn = {9781450305525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1996130.1996175},
doi = {10.1145/1996130.1996175},
booktitle = {Proceedings of the 20th International Symposium on High Performance Distributed Computing},
pages = {281–282},
numpages = {2},
keywords = {mpi-io, compiler-directed, multi-speed disk, power optimization, data access scheduling, spin-down disk, i/o storage},
location = {San Jose, California, USA},
series = {HPDC '11}
}

@article{10.1145/3609435,
author = {Yang, Zhao and Sun, Qingshuang},
title = {Energy-Efficient Personalized Federated Search with Graph for Edge Computing},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3609435},
doi = {10.1145/3609435},
abstract = {Federated Learning (FL) is a popular method for privacy-preserving machine learning on edge devices. However, the heterogeneity of edge devices, including differences in system architecture, data, and co-running applications, can significantly impact the energy efficiency of FL. To address these issues, we propose an energy-efficient personalized federated search framework. This framework has three key components. Firstly, we search for partial models with high inference efficiency to reduce training energy consumption and the occurrence of stragglers in each round. Secondly, we build lightweight search controllers that control the model sampling and respond to runtime variances, mitigating new straggler issues caused by co-running applications. Finally, we design an adaptive search update strategy based on graph aggregation to improve personalized training convergence. Our framework reduces the energy consumption of the training process by lowering the training overhead of each round and speeding up the training convergence rate. Experimental results show that our approach achieves up to 5.02% accuracy and 3.45\texttimes{} energy efficiency improvements.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
articleno = {99},
numpages = {24},
keywords = {Personalized FL, graph-based aggregation, energy-efficient, federated search}
}

@inproceedings{10.5555/3408352.3408812,
author = {Vinco, Sara and Rossi, Davide},
title = {Session Details: Architectural and Circuit Techniques toward Energy-Efficient Computing},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.1145/3256018,
author = {Cong, Jason},
title = {Session Details: Heterogeneous Computing in Data Centers for Energy Efficiency},
year = {2016},
isbn = {9781450341851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3256018},
doi = {10.1145/3256018},
booktitle = {Proceedings of the 2016 International Symposium on Low Power Electronics and Design},
location = {San Francisco Airport, CA, USA},
series = {ISLPED '16}
}

@inproceedings{10.1145/997163.997178,
author = {Li, Lian and Xue, Jingling},
title = {A Trace-Based Binary Compilation Framework for Energy-Aware Computing},
year = {2004},
isbn = {1581138067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/997163.997178},
doi = {10.1145/997163.997178},
abstract = {Energy-aware compilers are becoming increasingly important for embedded systems due to the need to meet conflicting constraints on time, code size and power consumption. We introduce a trace-based, offline compiler framework on binaries and demonstrate its benefits in supporting energy optimisations. The key innovation lies in identifying frequently executed paths in a binary program and duplicating them as single-entry traces. Separating frequently from infrequently executed paths enables the compiler to focus both performance and energy optimisations on the hot traces.Traces constructed at the level of binaries are inherently inter-procedural, spanning both application and library code. Such a framework allows an embedded application developer to exploit optimisation opportunities made possible due to the information that is available only at link time.We describe the implementation of our trace-based framework in alto, a link-time optimiser for the Alpha architecture. We present a new algorithm for constructing the hot traces from binaries. This algorithm is both effective (since the execution cycles are mostly spent on traces) and practical (due to small code size increases caused). We have developed and implemented a new optimisation to reduce the functional unit leakage energy. We show how the traces facilitate the development of such an optimisation, which results in significant leakage energy savings for benchmark programs at the cost of small performance penalties.},
booktitle = {Proceedings of the 2004 ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems},
pages = {95–106},
numpages = {12},
keywords = {link-time optimisation, profile-guided optimisation, trace, binary translation, energy optimisation},
location = {Washington, DC, USA},
series = {LCTES '04}
}

@inproceedings{10.1145/3529299.3533392,
author = {Xu, Zhisong and Zhang, Nanchuan and Zhong, Changjiao and Luo, Guiping and Gongze, Weiyi and Li, Chuan and Zhang, Yi and Yang, Qi and Feng, Lei and Chang, Yanping and Lu, Shisu and Li, Jie},
title = {Flexible Humidity Sensor Based on Edge Computing and Energy Harvesting},
year = {2022},
isbn = {9781450396127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3529299.3533392},
doi = {10.1145/3529299.3533392},
abstract = {The cable trench is in an underground environment and the surrounding humidity is high. The cable intermediate joint is in this environment for a long time. If the airtightness of the cable intermediate joint is damaged, moisture enters the cable intermediate joint. Once the humidity of the intermediate joint exceeds the normal value, it may cause a power accident. By placing a humidity sensor at the cable intermediate joint, the humidity around the intermediate joint can be effectively monitored, and an alarm will be issued once the humidity is abnormal which can reduce losses. In this paper, an energy harvesting flexible humidity sensor with edge computing is proposed for the power cable scenario. The sensor end uses the median mean filtering algorithm to process the measured data, and then judges whether the humidity is abnormal, and transmits the measured data and judgment results to the monitoring system. The sensor does not need batteries, and the sensor power is collected by collecting the electric field energy and thermal energy around the intermediate joint which make sensors more sustainable. The flexible design allows the sensor to be placed arbitrarily in the narrow environment of the intermediate joint and can expand the measurement area which makes the humidity measurement more accurate.},
booktitle = {Proceedings of the Asia Conference on Electrical, Power and Computer Engineering},
articleno = {62},
numpages = {5},
keywords = {edge computing, intermediate joint, flexible humidity sensor, energy harvesting},
location = {Shanghai, China},
series = {EPCE '22}
}

@inproceedings{10.1145/3130265.3138855,
author = {Tiku, Saideep and Pasricha, Sudeep},
title = {Energy-Efficient and Robust Middleware Prototyping for Smart Mobile Computing},
year = {2017},
isbn = {9781450354189},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3130265.3138855},
doi = {10.1145/3130265.3138855},
abstract = {A large amount of data is produced by mobile devices today. The rising computational abilities and sophisticated operating systems (OS) on these devices have allowed us to create applications that are able to leverage this data to deliver better services. But today's mobile technology is heavily limited by low battery capacity and limited cooling capabilities, which has motivated a search for new ways to optimize for energy-efficiency. A challenge in conducting such optimizations for today's mobile devices is to be able to make changes in complex OS and application software architectures. Middleware has been becoming an increasingly popular solution for inserting energy-efficient solutions and optimizations in a robust manner, without altering the OS or application code. This is because of the flexibility and standardization that can be achieved through middleware. In this paper, we discuss some powerful and promising developments in prototyping middleware for energy-efficient and robust execution of a variety of applications on commodity mobile computing devices.},
booktitle = {Proceedings of the 28th International Symposium on Rapid System Prototyping: Shortening the Path from Specification to Prototype},
pages = {2–8},
numpages = {7},
keywords = {robustness, middleware, energy-efficiency, mobile computing},
location = {Seoul, South Korea},
series = {RSP '17}
}

@inproceedings{10.1145/3466752.3480081,
author = {Zhang, Jie-Fang and Zhang, Zhengya},
title = {Point-X: A Spatial-Locality-Aware Architecture for Energy-Efficient Graph-Based Point-Cloud Deep Learning},
year = {2021},
isbn = {9781450385572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466752.3480081},
doi = {10.1145/3466752.3480081},
abstract = {Deep learning on point clouds has attracted increasing attention in the fields of 3D computer vision and robotics. In particular, graph-based point-cloud deep neural networks (DNNs) have demonstrated promising performance in 3D object classification and scene segmentation tasks. However, the scattered and irregular graph-structured data in a graph-based point-cloud DNN cannot be computed efficiently by existing SIMD architectures and accelerators. We present Point-X, an energy-efficient accelerator architecture that extracts and exploits the spatial locality in point cloud data for efficient processing. Point-X uses a clustering method to extract fine-grained and coarse-grained spatial locality from the input point cloud. The clustering maps the point cloud into distributed compute tiles to maximize intra-tile computational parallelism and minimize inter-tile data movement. Point-X employs a chain network-on-chip (NoC) to further reduce the NoC traffic and achieve up to 3.2 \texttimes{} speedup over a traditional mesh NoC. Point-X’s multi-mode dataflow can support all common operations in a graph-based point-cloud DNN, i.e., edge convolution, shared multi-layer perceptron, and fully-connected layers. Point-X is synthesized in a 28nm technology and it demonstrates a throughput of 1307.1 inference/s and an energy efficiency of 604.5 inference/J on the DGCNN workload. Compared to the Nvidia GTX-1080Ti GPU, Point-X shows 4.5 \texttimes{} and 342.9 \texttimes{} improvement in throughput and efficiency, respectively.},
booktitle = {MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {1078–1090},
numpages = {13},
keywords = {graph traversal, edge convolution, spatial locality, neural network, Point cloud, graph convolution},
location = {Virtual Event, Greece},
series = {MICRO '21}
}

@article{10.1145/2700104,
author = {Kerrison, Steve and Eder, Kerstin},
title = {Energy Modeling of Software for a Hardware Multithreaded Embedded Microprocessor},
year = {2015},
issue_date = {May 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1539-9087},
url = {https://doi.org/10.1145/2700104},
doi = {10.1145/2700104},
abstract = {This article examines a hardware multithreaded microprocessor and discusses the impact such an architecture has on existing software energy modeling techniques. A framework is constructed for analyzing the energy behavior of the XMOS XS1-L multithreaded processor and a variation on existing software energy models is proposed, based on analysis of collected energy data. It is shown that by combining execution statistics with sufficient data on the processor’s thread activity and instruction execution costs, a multithreaded software energy model used with Instruction Set Simulation can yield an average error margin of less than 7%.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {apr},
articleno = {56},
numpages = {25},
keywords = {ISA-level energy modeling, Software energy modeling, computer architecture, multithreading, XMOS XS1 xCORE, embedded systems}
}

@article{10.1145/3358174,
author = {Gon\c{c}alves, Larissa Rozales and Moura, Rafael F\~{a}o De and Carro, Luigi},
title = {Aggressive Energy Reduction for Video Inference with Software-Only Strategies},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3358174},
doi = {10.1145/3358174},
abstract = {In the past years, several works have proposed custom hardware and software-based techniques for the acceleration of Convolutional Neural Networks (CNNs). Most of these works focus on saving computations by changing the used precision or modifying frame processing. To reach a more aggressive energy reduction, in this paper we propose software-only modifications to the CNNs inference process.Our approach exploits the inherent locality in videos by replacing entire frame computations with a movement prediction algorithm. Furthermore, when a frame must be processed, we avoid energy-demanding floating-point operations, and at the same time reduce memory accesses by employing look-up tables in place of the original convolutions.Using the proposed approach, one can reach significant energy gains of more than 25\texttimes{} for security cameras, and 12\texttimes{} for moving vehicles applications, with only small software modifications.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {oct},
articleno = {46},
numpages = {20},
keywords = {frame predicton, computation reuse, Convolutional Neural Networks}
}

@article{10.1145/2693714.2693730,
author = {Nunez-Yanez, Jose},
title = {Energy Efficient Reconfigurable Computing with Adaptive Voltage and Logic Scaling},
year = {2014},
issue_date = {Setember 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0163-5964},
url = {https://doi.org/10.1145/2693714.2693730},
doi = {10.1145/2693714.2693730},
abstract = {This paper investigates a novel energy-proportional concept that combines closed-loop voltage scalability and run-time hardware reconfiguration. Voltage scaling is based on in-situ detectors that allow the device to detect valid working voltage and frequency pairs at run-time. The combined approach named AVLS (Adaptive Voltage and Logic Scaling) enables the adaptation of capacitance, voltage and frequency to obtain power and energy savings based on workload, process and operating conditions in a closed-loop configuration. The technique is applied to a reconfigurable motion estimation processor that can be configured with a variable number of execution units and it is used as a test vehicle. The results demonstrate that the proposed voltage scaling can obtain up to 85% reduction in energy compared with nominal voltage operation at the same frequency. This efficient energy point is obtained at a voltage of 0.62 V and frequency of 56 MHz compared with running the core at the same frequency and nominal 1 V. The addition of logic scalability means that if enough device resources are available a parallel configuration with six execution units operating at 0.62 V reduces energy by up to 95% compared with a single execution unit operating at 1 V and the same frequency.},
journal = {SIGARCH Comput. Archit. News},
month = {dec},
pages = {87–92},
numpages = {6},
keywords = {AVS, energy efficiency, DVFS, FPGA}
}

@inproceedings{10.1109/CCGrid.2014.43,
author = {Tarplee, Kyle M. and Maciejewski, Anthony A. and Siegel, Howard Jay},
title = {Energy-Aware Profit Maximizing Scheduling Algorithm for Heterogeneous Computing Systems},
year = {2014},
isbn = {9781479927838},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2014.43},
doi = {10.1109/CCGrid.2014.43},
abstract = {With the advent of energy-aware scheduling algorithms, it is now possible to find solutions that trade-off performance for decreased energy usage. There are now efficient algorithms to find high quality Pareto fronts that can be used to select the desired balance between makespan and energy consumption. One drawback of this approach is that it still requires a system administrator to select the desired operating point. In this paper, a market-oriented technique for scheduling is presented where the high performance computing system administrator is trying to maximize the return on investment. A model is developed where the users pay a given price to have a bag-of-tasks processed. The cost to the system administrator for processing this bag-of-tasks is strongly related to the energy consumption for executing these tasks. A novel algorithm is designed that efficiently finds the maximum profit resource allocation and tightly bounds the optimal solution. In addition, this algorithm has very desirable runtime and solution quality properties as the number of tasks and machines become large.},
booktitle = {Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {595–603},
numpages = {9},
keywords = {scheduling, profit, high performance computing, resource allocation, heterogeneous computing, bag-of-tasks},
location = {Chicago, Illinois},
series = {CCGRID '14}
}

@inproceedings{10.1145/2577080.2577095,
author = {Dubslaff, Clemens and Kl\"{u}ppelholz, Sascha and Baier, Christel},
title = {Probabilistic Model Checking for Energy Analysis in Software Product Lines},
year = {2014},
isbn = {9781450327725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2577080.2577095},
doi = {10.1145/2577080.2577095},
abstract = {In a software product line (SPL), a collection of software products is defined by their commonalities in terms of features rather than explicitly specifying all products one-by-one. Several verification techniques were adapted to establish temporal properties of SPLs. Symbolic and family-based model checking have been proven to be successful for tackling the combinatorial blow-up arising when reasoning about several feature combinations. However, most formal verification approaches for SPLs presented in the literature focus on the static SPLs, where the features of a product are fixed and cannot be changed during runtime. This is in contrast to dynamic SPLs, allowing to adapt feature combinations of a product dynamically after deployment.The main contribution of the paper is a compositional modeling framework for dynamic SPLs, which supports probabilistic and nondeterministic choices and allows for quantitative analysis. We specify the feature changes during runtime within an automata-based coordination component, enabling to reason over strategies how to trigger dynamic feature changes for optimizing various quantitative objectives, e.g., energy or monetary costs and reliability. For our framework there is a natural and conceptually simple translation into the input language of the prominent probabilistic model checker PRISM. This facilitates the application of PRISM's powerful symbolic engine to the operational behavior of dynamic SPLs and their family-based analysis against various quantitative queries. We demonstrate feasibility of our approach by a case study issuing an energy-aware bonding network device.},
booktitle = {Proceedings of the 13th International Conference on Modularity},
pages = {169–180},
numpages = {12},
keywords = {software product lines, probabilistic model checking, dynamic features, energy analysis},
location = {Lugano, Switzerland},
series = {MODULARITY '14}
}

@inproceedings{10.5555/2755753.2755906,
author = {Raha, Arnab and Venkataramani, Swagath and Raghunathan, Vijay and Raghunathan, Anand},
title = {Quality Configurable Reduce-and-Rank for Energy Efficient Approximate Computing},
year = {2015},
isbn = {9783981537048},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Approximate computing is an emerging design paradigm that exploits the intrinsic ability of applications to produce acceptable outputs even when their computations are executed approximately. In this work, we explore approximate computing for a key computation pattern, Reduce-and-Rank (RnR), which is prevalent in a wide range of workloads including video processing, recognition, search and data mining. An RnR kernel performs a reduction operation (e.g., distance computation, dot product, L1-norm) between an input vector and each of a set of reference vectors, and ranks the reduction outputs to select the top reference vectors for the current input. We propose two complementary approximation strategies for the RnR computation pattern. The first is interleaved reduction-and-ranking, wherein the vector reductions are decomposed into multiple partial reductions and interleaved with the rank computation. Leveraging this transformation, we propose the use of intermediate reduction results and ranks to identify future computations that are likely to have low impact on the output, and can hence be approximated. The second strategy, input similarity based approximation, exploits the spatial or temporal correlation of inputs (e.g., pixels of an image or frames of a video) to identify computations that are amenable to approximation. These strategies address a key challenge in approximate computing -- identification of which computations to approximate -- and may be used to drive any approximation mechanism such as computation skipping and precision scaling to realize performance or energy improvements.A second key challenge in approximate computing is that the extent to which computations can be approximated varies significantly from application to application, and across inputs for even a single application. Hence, quality configurability, or the ability to automatically modulate the degree of approximation at runtime is essential. To enable quality configurability in RnR kernels, we propose a kernel-level quality metric that correlates well to application-level quality, and identify key parameters that can be used to tune the proposed approximation strategies dynamically. We develop a runtime framework that modulates the identified parameters during execution of RnR kernels to minimize their energy while meeting a given target quality. To evaluate the proposed concepts, we designed quality-configurable hardware implementations of 6 RnR-based applications from the recognition, mining, search and video processing application domains in 45nm technology. Our experiments demonstrate 1.06X-2.18X reduction in energy consumption with virtually no loss in output quality (&lt;0.5%) at the application-level. The energy benefits further improve up to 2.38X and 2.5X when the quality constraints are relaxed to 2.5% and 5% respectively.},
booktitle = {Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition},
pages = {665–670},
numpages = {6},
location = {Grenoble, France},
series = {DATE '15}
}

@inproceedings{10.1145/2513683.2513689,
author = {Nunez-Yanez, Jose},
title = {Energy Proportional Computing in Commercial FPGAs with Adaptive Voltage Scaling},
year = {2013},
isbn = {9781450324960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2513683.2513689},
doi = {10.1145/2513683.2513689},
abstract = {Voltage and frequency adaptation can be used to create energy proportional systems in which energy usage adapts to the amount of work to be done in the available time. Closed-loop voltage and frequency scaling can also take into account process and temperature variations in addition to system load and this removes a significant proportion of the margins used by device manufacturers. This paper explores the capabilities of commercial FPGAs to use closed-loop adaptive voltage scaling to improve their energy and performance profiles beyond nominal. An adaptive power architecture based on a modified design flow is created with in-situ detectors and dynamic reconfiguration of clock management resources. The results of deploying AVS in FPGAs shows power and energy savings exceeding 85% compared with nominal voltage operation at the same frequency or 100% better performance at nominal energy. The in-situ detector approach compares favorably with critical path replication based on delay lines since it avoids the need of cumbersome and error-prone delay line calibration.},
booktitle = {Proceedings of the 10th FPGAworld Conference},
articleno = {6},
numpages = {5},
keywords = {energy efficiency, DVFS, FPGA, AVS},
location = {Stockholm, Sweden},
series = {FPGAworld '13}
}

@article{10.1145/3041024,
author = {Zhu, Yuhao and Reddi, Vijay Janapa},
title = {Optimizing General-Purpose CPUs for Energy-Efficient Mobile Web Computing},
year = {2017},
issue_date = {February 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0734-2071},
url = {https://doi.org/10.1145/3041024},
doi = {10.1145/3041024},
abstract = {Mobile applications are increasingly being built using web technologies as a common substrate to achieve portability and to improve developer productivity. Unfortunately, web applications often incur large performance overhead, directly affecting the user quality-of-service (QoS) experience. Traditional techniques in improving mobile processor performance have mostly been adopting desktop-like design techniques such as increasing single-core microarchitecture complexity and aggressively integrating more cores. However, such a desktop-oriented strategy is likely coming to an end due to the stringent energy and thermal constraints that mobile devices impose. Therefore, we must pivot away from traditional mobile processor design techniques in order to provide sustainable performance improvement while maintaining energy efficiency.In this article, we propose to combine hardware customization and specialization techniques to improve the performance and energy efficiency of mobile web applications. We first perform design-space exploration (DSE) and identify opportunities in customizing existing general-purpose mobile processors, that is, tuning microarchitecture parameters. The thorough DSE also lets us discover sources of energy inefficiency in customized general-purpose architectures. To mitigate these inefficiencies, we propose, synthesize, and evaluate two new domain-specific specializations, called the Style Resolution Unit and the Browser Engine Cache. Our optimizations boost performance and energy efficiency at the same time while maintaining general-purpose programmability. As emerging mobile workloads increasingly rely more on web technologies, the type of optimizations we propose will become important in the future and are likely to have a long-lasting and widespread impact.},
journal = {ACM Trans. Comput. Syst.},
month = {mar},
articleno = {1},
numpages = {31},
keywords = {specialization, accelerator, Web browsing, customization, software-managed cache}
}

@inproceedings{10.1145/2742854.2742857,
author = {Vassiliadis, Vassilis and Chalios, Charalampos and Parasyris, Konstantinos and Antonopoulos, Christos D. and Lalis, Spyros and Bellas, Nikolaos and Vandierendonck, Hans and Nikolopoulos, Dimitrios S.},
title = {A Significance-Driven Programming Framework for Energy-Constrained Approximate Computing},
year = {2015},
isbn = {9781450333580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742854.2742857},
doi = {10.1145/2742854.2742857},
abstract = {Approximate execution is a viable technique for energy-constrained environments, provided that applications have the mechanisms to produce outputs of the highest possible quality within the given energy budget.We introduce a framework for energy-constrained execution with controlled and graceful quality loss. A simple programming model allows users to express the relative importance of computations for the quality of the end result, as well as minimum quality requirements. The significance-aware runtime system uses an application-specific analytical energy model to identify the degree of concurrency and approximation that maximizes quality while meeting user-specified energy constraints.Evaluation on a dual-socket 8-core server shows that the proposed framework predicts the optimal configuration with high accuracy, enabling energy-constrained executions that result in significantly higher quality compared to loop perforation, a compiler approximation technique.},
booktitle = {Proceedings of the 12th ACM International Conference on Computing Frontiers},
articleno = {9},
numpages = {8},
keywords = {modeling, significance, energy efficiency, approximate computing},
location = {Ischia, Italy},
series = {CF '15}
}

@inproceedings{10.1145/951710.951712,
author = {Palem, Krishna V.},
title = {Energy Aware Algorithm Design via Probabilistic Computing: From Algorithms and Models to Moore's Law and Novel (Semiconductor) Devices},
year = {2003},
isbn = {1581136765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/951710.951712},
doi = {10.1145/951710.951712},
booktitle = {Proceedings of the 2003 International Conference on Compilers, Architecture and Synthesis for Embedded Systems},
pages = {113–116},
numpages = {4},
location = {San Jose, California, USA},
series = {CASES '03}
}

@inproceedings{10.5555/3539845.3540001,
author = {Ometov, Aleksandr and Nurmi, Jari},
title = {Towards Approximate Computing for Achieving Energy vs. Accuracy Trade-Offs},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Despite the recent advances in semiconductor technology and energy-aware system design, the overall energy consumption of computing and communication systems is rapidly growing. On the one hand, the pervasiveness of these technologies everywhere in the form of mobile devices, cyber-physical embedded systems, sensor networks, wearables, social media and context-awareness, intelligent machines, broadband cellular networks, Cloud computing, and Internet of Things (IoT) has drastically increased the demand for computing and communications. On the other hand, the user expectations on features and battery life of online devices are increasing all the time, and it creates another incentive for finding good trade-offs between performance and energy consumption. One of the opportunities to address this growing demand is to utilize an Approximate Computing approach through software and hardware design. The APROPOS project aims at finding the balance between accuracy and energy consumption, and this short paper provides an initial overview of the corresponding roadmap, as the project is still in the initial stage.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {632–635},
numpages = {4},
keywords = {communications, approximation, hardware design, computing, EU projects},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/2712386.2712396,
author = {Langer, Akhil and Totoni, Ehsan and Palekar, Udatta S. and Kal\'{e}, Laxmikant V.},
title = {Energy-Efficient Computing for HPC Workloads on Heterogeneous Manycore Chips},
year = {2015},
isbn = {9781450334044},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2712386.2712396},
doi = {10.1145/2712386.2712396},
abstract = {Power and energy efficiency is one of the major challenges to achieve exascale computing in the next several years. While chips operating at low voltages have been studied to be highly energy-efficient, low voltage operations lead to heterogeneity across cores within the microprocessor chip. In this work, we study chips with low voltage operation and discuss programming systems, and performance modeling in the presence of heterogeneity. We propose an integer linear programming based approach for selecting optimal configuration of a chip that minimizes its energy consumption. We obtain an average of 26% and 10.7% savings in energy consumption of the chip for two HPC mini-applications - miniMD and Jacobi, respectively. We also evaluate the energy savings with execution time constraints, using the proposed approach. These energy savings are significantly more than the savings by sub-optimal configurations obtained from heuristics.},
booktitle = {Proceedings of the Sixth International Workshop on Programming Models and Applications for Multicores and Manycores},
pages = {11–19},
numpages = {9},
keywords = {near threshold voltage computing, power, energy, integer programming, quadratic integer programming, optimization, multicore chips, heterogeneity, process variation, low voltage computing},
location = {San Francisco, California},
series = {PMAM '15}
}

@inproceedings{10.1145/3483529.3483711,
author = {Costalonga, Leandro and Hora, Daniel and Pimenta, Marcelo and Wanderley, Marcelo},
title = {The Ragpicking DMI Design: The Case for Green Computer Music},
year = {2022},
isbn = {9781450384209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483529.3483711},
doi = {10.1145/3483529.3483711},
abstract = {This article introduces the idea of sustainable development of DMIs, discussing how fundamental concepts like e-Waste, Ragpicking and Green Computing can be (re)used to minimize or eliminate where possible the environmental impact of DMIs. The arguments and fundamentals for this initiative are presented, as also some examples to illustrate our ideas. Our intention is to contribute to the reflection by the Computer Music community on the subject.},
booktitle = {10th International Conference on Digital and Interactive Arts},
articleno = {64},
numpages = {10},
keywords = {Computer Music, e-Waste, Ragpicking, Green Computing, Digital Musical Instrument},
location = {Aveiro, Portugal, Portugal},
series = {ARTECH 2021}
}

@inproceedings{10.1145/3411295.3411315,
author = {Lemic, Filip and Abadal, Sergi and Famaey, Jeroen},
title = {Toward Localization in Terahertz-Operating Energy Harvesting Software-Defined Metamaterials: Context Analysis},
year = {2020},
isbn = {9781450380836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411295.3411315},
doi = {10.1145/3411295.3411315},
abstract = {Software-defined metamaterials (SDMs) represent a novel paradigm for real-time control of metamaterials. SDMs are envisioned to enable a variety of exciting applications in the domains such as smart textiles and sensing in challenging conditions. Many of these applications envisage deformations of the SDM structure (e.g., rolling, bending, stretching). This affects the relative position of the metamaterial elements and requires their localization relative to each other. The question of how to perform such localization is, however, yet to spark in the community. We consider that the metamaterial elements are controlled wirelessly through a Terahertz (THz)-operating nanonetwork. Moreover, we consider the elements to be energy constrained, with their sole powering option being to harvest environmental energy. For such a setup, we demonstrate sub-millimeter accuracy of the two-way Time of Flight (ToF)-based localization, as well as high availability of the service (i.e., consistently more than 80% of the time), which is a result of the low energy consumed in localization. Finally, we provide the localization context for a number of relevant system parameters such as operational frequency, bandwidth, and harvesting rate.},
booktitle = {Proceedings of the 7th ACM International Conference on Nanoscale Computing and Communication},
articleno = {19},
numpages = {6},
keywords = {localization, two-way time of flight, software-defined metamaterials, energy harvesting, nanocommunication, trilateration, terahertz},
location = {Virtual Event, USA},
series = {NanoCom '20}
}

@inproceedings{10.1109/ESEM.2017.39,
author = {Verdecchia, Roberto and Procaccianti, Giuseppe and Malavolta, Ivano and Lago, Patricia and Koedijk, Joost},
title = {Estimating Energy Impact of Software Releases and Deployment Strategies: The KPMG Case Study},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ESEM.2017.39},
doi = {10.1109/ESEM.2017.39},
abstract = {Background. Often motivated by optimization objectives, software products are characterized by different subsequent releases and deployed through different strategies. The impact of these two aspects of software on energy consumption has still to be completely understood and can be improved by carrying out ad-hoc analyses for specific software products.Aims. In this research we report on an industrial collaboration aiming at assessing the different impact that releases and deployment strategies of a software product can have on the energy consumption of its underlying hardware infrastructure.Method. We designed and performed an empirical experiment in a controlled environment. Deployment strategies, releases and use case scenarios of an industrial third-party software product were adopted as experimental factors. The use case scenarios were used as a blocking factor and adopted to dynamically load-test the software product. Power consumption and execution time were selected as response variables to measure the energy consumption.Results. We observed that both deployment strategies and software releases significantly influence the energy consumption of the hardware infrastructure. A strong interaction between the two factors was identified. The impact of such interaction highly varied depending on which use case scenario was considered, making the identification of the most frequently adopted use case scenario critical for energy optimisation. The collaboration between industry and academia has been productive for both parties, even if some practitioners manifested low interest/awareness on software energy efficiency.Conclusions. For the software product considered there is no absolute preferable release or deployment strategy with respect to energy efficiency, as the interaction of these factors has to be considered. The number of machines involved in a software deployment strategy does not simply constitute an additive effect of the energy consumption of the underlying hardware infrastructure.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {257–266},
numpages = {10},
keywords = {software releases, energy, deployment},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}

@inproceedings{10.5555/3539845.3539998,
author = {Saxena, Utkarsh and Chakraborty, Indranil and Roy, Kaushik},
title = {Towards ADC-Less Compute-in-Memory Accelerators for Energy Efficient Deep Learning},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Compute-in-Memory (CiM) hardware has shown great potential in accelerating Deep Neural Networks (DNNs). However, most CiM accelerators for matrix vector multiplication rely on costly analog to digital converters (ADCs) which becomes a bottleneck in achieving high energy efficiency. In this work, we propose a hardware-software co-design approach to reduce the aforementioned ADC costs through partial-sum quantization. Specifically, we replace ADCs with 1-bit sense amplifiers and develop a quantization aware training methodology to compensate for the loss in representation ability. We show that the proposed ADC-less DNN model achieves 1.1x-9.6x reduction in energy consumption while maintaining accuracy within 1% of the DNN model without partial-sum quantization.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {624–627},
numpages = {4},
keywords = {quantization, hardware-software co-design, compute-in-memory, analog computing, DNN acceleration},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3582935.3583043,
author = {Wu, Jinbo and Liu, Yonggang and Song, Xingrong and Xiong, Shangfeng and Hu, Sijia and Li, Zhenwen},
title = {Research and Application of AGC Control Method for Energy Storage Power Stations Using Data of Regulation Cloud},
year = {2023},
isbn = {9781450396806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582935.3583043},
doi = {10.1145/3582935.3583043},
abstract = {With the development of new power systems, a large number of grid-connected new energy and energy storage power stations with voltage levels of 110kV and below cannot match the traditional AGC control strategy with the grid structure. This brings new challenges to the existing grid AGC control. In view of this situation, this paper proposes the principle of local balance of active power control. Based on this principle, an optimal control method for AGC is proposed. The grid-connected power supplies with voltage levels of 220kV and above and 110kV and below are controlled according to different goals. For the grid-connected new energy and energy storage power stations with voltage levels of 110kV and below, this paper proposes an ACE allocation method that uses cloud data to regulate. The contradiction between regulating cloud data transmission speed and AGC control period is resolved. The proposed method has been deployed and applied in a provincial power grid in southern China for more than 1 year. By running the data, the effectiveness of the proposed method is verified.},
booktitle = {Proceedings of the 5th International Conference on Information Technologies and Electrical Engineering},
pages = {646–650},
numpages = {5},
keywords = {New energy power station, Nearly balanced, Energy storage power station, AGC (Automatic Generation Control), Regulation Cloud},
location = {Changsha, China},
series = {ICITEE '22}
}

@inproceedings{10.1145/3396851.3402922,
author = {Zhang, Weigang and Zhou, Biyu and Dang, Weixia and Hu, Songlin},
title = {A Lightweight Energy-Efficient Computational Offloading Scheme in Mobile Edge Computing},
year = {2020},
isbn = {9781450380096},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3396851.3402922},
doi = {10.1145/3396851.3402922},
abstract = {Mobile edge computing (MEC) has been an alternative to mobile cloud computing (MCC) for computationally intensive mobile tasks by offloading computations to nearby servers. However, it is not easy to generate an optimal offloading scheme considering both energy consumption and time delay with low time complexity. In this paper, we propose a lightweight energy-efficient computational offloading scheme (LEEOS) for a task to make the offloading decision of each component. First, LEEOS calculates the cost values of local execution and remote execution for all components. Based on these cost values, it uses a greedy heuristic to determine which components to offload to mobile edge servers for execution. Experiment results show that our proposed approach is promising in terms of energy consumption of user equipment as well as computation time.},
booktitle = {Proceedings of the Eleventh ACM International Conference on Future Energy Systems},
pages = {560–565},
numpages = {6},
keywords = {partial offloading, Energy-efficient, Lightweight, MEC},
location = {Virtual Event, Australia},
series = {e-Energy '20}
}

@inproceedings{10.1145/2934583.2934624,
author = {Rahimi, Abbas and Kanerva, Pentti and Rabaey, Jan M.},
title = {A Robust and Energy-Efficient Classifier Using Brain-Inspired Hyperdimensional Computing},
year = {2016},
isbn = {9781450341851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934583.2934624},
doi = {10.1145/2934583.2934624},
abstract = {The mathematical properties of high-dimensional (HD) spaces show remarkable agreement with behaviors controlled by the brain. Computing with HD vectors, referred to as "hypervectors," is a brain-inspired alternative to computing with numbers. Hypervectors are high-dimensional, holographic, and (pseudo)random with independent and identically distributed (i.i.d.) components. They provide for energy-efficient computing while tolerating hardware variation typical of nanoscale fabrics. We describe a hardware architecture for a hypervector-based classifier and demonstrate it with language identification from letter trigrams. The HD classifier is 96.7% accurate, 1.2% lower than a conventional machine learning method, operating with half the energy. Moreover, the HD classifier is able to tolerate 8.8-fold probability of failure of memory cells while maintaining 94% accuracy. This robust behavior with erroneous memory cells can significantly improve energy efficiency.},
booktitle = {Proceedings of the 2016 International Symposium on Low Power Electronics and Design},
pages = {64–69},
numpages = {6},
location = {San Francisco Airport, CA, USA},
series = {ISLPED '16}
}

@inproceedings{10.1145/2811587.2811627,
author = {Altamimi, Majid L. and Naik, Kshirasagar},
title = {A Computing Profiling Procedure for Mobile Developers to Estimate Energy Cost},
year = {2015},
isbn = {9781450337625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811587.2811627},
doi = {10.1145/2811587.2811627},
abstract = {Mobile devices are constrained by the limited capacities of their small batteries. However, profiling the energy consumed in the task execution is crucial to help the developers to build energy efficient applications. Therefore, the major challenge in the profiling approach is to accurately estimating the energy consumed for an application by the hardware components, such as CPU, memory, storage unit, and network interfaces. In this work, we develop and validate hardware and software profiling models and procedures. We profile smartphone CPU, where we consider multi-core CPUs and the impact of Dynamic Voltage and Frequency Scaling mechanism on the power consumption. In addition, we profile smartphone storage unit by taking into account the writing and reading rate to the unit. Moreover, we experimentally validated these profiles on two diverse smartphones with different versions of operating systems. The experimental results reveal that our profiles are able to estimate the application energy accurately.},
booktitle = {Proceedings of the 18th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {301–305},
numpages = {5},
keywords = {mobile devices, dynamic voltage and frequency scaling, power and energy consumption, multi-core cpu, application energy, cpu},
location = {Cancun, Mexico},
series = {MSWiM '15}
}

@inproceedings{10.5555/2338816.2338822,
author = {Laros, James H. and Pedretti, Kevin T. and Kelly, Suzanne M. and Shu, Wei and Vaughan, Courtenay T.},
title = {Energy Based Performance Tuning for Large Scale High Performance Computing Systems},
year = {2012},
isbn = {9781618397881},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Recognition of the importance of power in the field of High Performance Computing, whether it be as an obstacle, expense or design consideration, has never been greater and more pervasive. In response to this challenge, we exploit the unique power measurement capabilities of the Cray XT architecture to gain an understanding of the power requirements of important DOE/NNSA production scientific computing applications executing at large scale (thousands of nodes). The effect of both CPU frequency and network bandwidth scaling on power usage is characterized in a series of empirical experiments and demonstrates energy savings opportunities of up to 39% with little to no impact on run-time performance. Our results provide strong evidence that next generation large-scale platforms should not only approach CPU frequency scaling differently, but could also benefit from the ability to tune other platform components, such as the network, to achieve energy efficient performance.},
booktitle = {Proceedings of the 2012 Symposium on High Performance Computing},
articleno = {6},
numpages = {10},
keywords = {frequency scaling, power, high performance computing (HPC), energy efficiency},
location = {Orlando, Florida},
series = {HPC '12}
}

@inproceedings{10.5555/2016802.2016877,
author = {Brandolese, Carlo and Corbetta, Simone and Fornaciari, William},
title = {Software Energy Estimation Based on Statistical Characterization of Intermediate Compilation Code},
year = {2011},
isbn = {9781612846606},
publisher = {IEEE Press},
abstract = {Early estimation of embedded software power consumption is a critical issue that can determine the quality and, sometimes, the feasibility of a system. Architecture-specific, cycle-accurate simulators are valuable tools for fine-tuning performance of critical sections of the application but are often too slow for the simulation of entire systems. This paper proposes a fast and statistically accurate methodology to evaluate the energy performance of embedded software and describes the associated toolchain. The methodology is based on a static characterization of the target instruction set to allow estimation on an equivalent, target-independent intermediate code representation.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Low-Power Electronics and Design},
pages = {333–338},
numpages = {6},
keywords = {instruction-level characterization, software energy estimation},
location = {Fukuoka, Japan},
series = {ISLPED '11}
}

@inproceedings{10.1145/2508244.2508260,
author = {Collin, Charly and Chen, Ke and Hakke-Patil, Ajit and Pattanaik, Sumanta and Bouatouch, Kadi},
title = {Green's Function Solution to Subsurface Light Transport for BRDF Computation},
year = {2013},
isbn = {9781450324809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508244.2508260},
doi = {10.1145/2508244.2508260},
abstract = {This paper presents an accurate method to compute the bidirectional reflectance distribution function (BRDF) due to subsurface scattering inside the material of the objects. This computation requires iterating over the different lighting directions, and solving the integro-differential equation of light transport (scattering and absorption). Solving the light transport equation is expensive, and solving it independently for different directions adds even further to the expense. However most of the computations are very similar between directions. We make use of Green's function of the transport problem to have a better separation between computations that are independent of incident directions from those that are dependent. This allows us to avoid as much repetition in the computations as possible, thus gives us a faster BRDF computation method without any loss of accuracy. We validate our method against a standard light transport solver and use it to compute BRDF for a variety of materials.},
booktitle = {Proceedings of the 29th Spring Conference on Computer Graphics},
pages = {123–130},
numpages = {8},
keywords = {BRDF, light transport, subsurface scattering, discrete-ordinates method, layered materials},
location = {Smolenice, Slovakia},
series = {SCCG '13}
}

@inproceedings{10.1145/1508865.1508995,
author = {Talebi, Mujtaba and Way, Thomas},
title = {Methods, Metrics and Motivation for a Green Computer Science Program},
year = {2009},
isbn = {9781605581835},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1508865.1508995},
doi = {10.1145/1508865.1508995},
abstract = {Computer science educators are uniquely positioned to promote greater awareness of Green Computing, using the academic setting to encourage environmentally conscious use of technology. This paper reports on practical techniques that can engage faculty and students, enabling Green Computing to be integrated into the classroom and research laboratory. Analysis and empirical evaluation of each reported technique is given, comparing the efficacy of each in terms of energy, environmental and financial cost savings. These results are provided as technological and economic evidence for the benefits of "Going Green," and to promote education in Green Computing in the classroom, department and research lab.},
booktitle = {Proceedings of the 40th ACM Technical Symposium on Computer Science Education},
pages = {362–366},
numpages = {5},
keywords = {green computing, environmental awareness, classroom economics},
location = {Chattanooga, TN, USA},
series = {SIGCSE '09}
}

@article{10.1145/2442116.2442131,
author = {Baek, Seungjae and Choi, Jongmoo and Lee, Donghee and Noh, Sam H.},
title = {Energy-Efficient and High-Performance Software Architecture for Storage Class Memory},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1539-9087},
url = {https://doi.org/10.1145/2442116.2442131},
doi = {10.1145/2442116.2442131},
abstract = {Recently, interest in incorporating Storage Class Memory (SCM), which blurs the distinction between memory and storage, into mainstream computing has been increasing rapidly. In this paper, we address the emerging questions regarding the use of SCM. Based on an embedded platform that employs FeRAM, a type of SCM, we present our findings. In summary, by introducing SCM, power efficiency improves while performance is degraded. We also show that such performance degradations may be removed with operating system level schemes that fully exploit the characteristics of SCM. Finally, we present permanent computing that supports lightweight system on/off capabilities by using SCM.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {apr},
articleno = {81},
numpages = {22},
keywords = {single object management, permanent computing, low-power consumption, Storage class memory, SCM manager}
}

@inproceedings{10.1109/DS-RT.2015.31,
author = {McGough, A. Stephen and Forshaw, Matthew},
title = {Energy-Aware Simulation of Workflow Execution in High Throughput Computing Systems},
year = {2015},
isbn = {9781467378222},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DS-RT.2015.31},
doi = {10.1109/DS-RT.2015.31},
abstract = {Workflows offer a great potential for enacting corelated jobs in an automated manner. This is especially desirable when workflows are large or there is a desire to run a workflow multiple times. Much research has been conducted in reducing the makespan of running workflows and maximising the utilisation of the resources they run on, with some existing research investigates how to reduce the energy consumption of workflows on dedicated resources. We extend the HTC-Sim simulation framework to support workflows allowing us to evaluate different scheduling strategies on the overheads and energy consumption of workflows run on non-dedicated systems. We evaluate a number of scheduling strategies from the literature in an environment where (workflow) jobs can be evicted by higher priority users.},
booktitle = {Proceedings of the 19th International Symposium on Distributed Simulation and Real Time Applications},
pages = {25–32},
numpages = {8},
location = {Chengdu, Sichuan, China},
series = {DS-RT 2015}
}

@inproceedings{10.5555/3539845.3540230,
author = {Balsamo, Domenico and Vermeulen, Bart},
title = {Session Details: Energy Efficient Platforms: From Autonomous Vehicles to Intermittent Computing},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3384441.3395991,
author = {Ahmed, Kishwar and Tasnim, Samia and Yoshii, Kazutomo},
title = {Simulation of Auction Mechanism Model for Energy-Efficient High Performance Computing},
year = {2020},
isbn = {9781450375924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384441.3395991},
doi = {10.1145/3384441.3395991},
abstract = {High performance computing (HPC) systems are large-scale computing systems with thousands of compute nodes. Massive energy consumption is a critical issue for HPC systems. In this paper, we develop an auction mechanism model for energy consumption reduction in an HPC system. Our proposed model includes an optimized resource allocation scheme for HPC jobs based on processor frequency and a Vickery-Clarke-Groove (VCG)-based forward auction model to enable energy reduction participation from HPC users. The model ensures truthful participation from HPC users, where users benefit from revealing their true valuation of energy reduction. We implement a job scheduler simulator and our mechanism model on a parallel discrete-event simulation engine. Through trace-based simulation, we demonstrate the effectiveness of our auction mechanism model. Simulation shows that our model can achieve overall energy reduction for an HPC system, while ensuring truthful participation from the users.},
booktitle = {Proceedings of the 2020 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
pages = {99–104},
numpages = {6},
keywords = {discrete simulation, high performance computing, auction mechanism, energy efficiency},
location = {Miami, FL, Spain},
series = {SIGSIM-PADS '20}
}

@inproceedings{10.1145/3194554.3194611,
author = {Chakma, Gangotree and Skuda, Nicholas D. and Schuman, Catherine D. and Plank, James S. and Dean, Mark E. and Rose, Garrett S.},
title = {Energy and Area Efficiency in Neuromorphic Computing for Resource Constrained Devices},
year = {2018},
isbn = {9781450357241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194554.3194611},
doi = {10.1145/3194554.3194611},
abstract = {Resource constrained devices are the building blocks of the internet of things (IoT) era. Since the idea behind IoT is to develop an interconnected environment where the devices are tiny enough to operate with limited resources, several control systems have been built to maintain low energy and area consumption while operating as IoT edge devices. Several researchers have begun work on implementing control systems built from resource constrained devices using machine learning. However, there are many ways such devices can achieve lower power consumption and area utilization while maximizing application efficiency. Spiky neuromorphic computing (SNC) is an emerging paradigm that can be leveraged in resource constrained devices for several emerging applications. While delivering the benefits of machine learning, SNC also helps minimize power consumption. For example, low energy memory devices (memristors) are often used to achieve low power operation and also help in reducing system area. In total, we anticipate SNC will provide computational efficiency approaching that of deep learning while using low power, resource constrained devices.},
booktitle = {Proceedings of the 2018 on Great Lakes Symposium on VLSI},
pages = {379–383},
numpages = {5},
keywords = {neuromorphic, internet of things, machine learning, memristor},
location = {Chicago, IL, USA},
series = {GLSVLSI '18}
}

@inproceedings{10.1145/2543651.2543673,
author = {Shin, Youngsam and Lee, Won-Jong and Lee, Jaedon and Lee, Shi-Hwa and Ryu, Soojung and Kim, Jeongwook},
title = {Energy Efficient Data Transmission for Ray Tracing on Mobile Computing Platform},
year = {2013},
isbn = {9781450326339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2543651.2543673},
doi = {10.1145/2543651.2543673},
abstract = {In this paper, we focus the impact of a memory bandwidth limitation by analyzing the bandwidth consumption for ray tracing system and present an energy efficient data transmission method between processor and ray tracing hardware engine. For evaluation of our approach, we have implemented a prototype of ray tracing architecture using our approach on FPGA platform. According to our experiment result, our approach shows a 48% reduction of system memory bandwidth on average.},
booktitle = {SIGGRAPH Asia 2013 Symposium on Mobile Graphics and Interactive Applications},
articleno = {64},
numpages = {5},
keywords = {ray tracing, GPU, mobile, memory bandwidth},
location = {Hong Kong, Hong Kong},
series = {SA '13}
}

@inproceedings{10.1145/3285957.3285981,
author = {Saroha, Vinod Kr. and Rana, Sanjeev},
title = {Implementing a Multi-Layer Job Scheduling Approach with Effective Load Balancing and Energy Saving over a Cloud},
year = {2018},
isbn = {9781450364898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3285957.3285981},
doi = {10.1145/3285957.3285981},
abstract = {Initially the client server database is created on the cloud. The servers are hereby categorized according to their processing time, speed and RAMs. On the basis of these configurational parameters they are classified as higher, intermediate and lower priority servers. The clients are categorized on basis of job requests and are differentiated into three priority types; viz. high priority, middle priority and low priority depending upon the processing need (time) of the job requests. The client job requests of longer time duration will take more processing time and hence shall be sent to the highest priority (configuration) server. In this paper we present the multilayered job scheduling approach on basis of preferences for both the client and the server. A high priority job request is executed by higher configuration server while the lower tasks are accomplished by the lower configuration servers; that helps in energy saving. If the higher server has finished up with its assigned jobs; then job requests from lower server are migrated to the higher server; which leads to load balancing with effective resource allocation. The overall process has been best illustrated with help of example wherein all the servers will execute the jobs requests in stipulated time. This fast execution helps the servers to free themselves early and results in better energy efficiency.},
booktitle = {Proceedings of the 2018 10th International Conference on Information Management and Engineering},
pages = {55–58},
numpages = {4},
keywords = {Job requests, Processing time, Load balancing, Energy efficient, Client, Scheduling, Priority, Cloud network, Server},
location = {Salford, United Kingdom},
series = {ICIME 2018}
}

@inproceedings{10.1145/3350768.3353813,
author = {Duarte, Lucio Mauro and da Silva Alves, Danilo and Toresan, Bruno Ramos and Maia, Paulo Henrique and Silva, Davi},
title = {A Model-Based Framework for the Analysis of Software Energy Consumption},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3353813},
doi = {10.1145/3350768.3353813},
abstract = {Software is present in all types of devices, some of them with restrictions as to the amount of energy they can spend to execute software applications. For this reason, energy costs are becoming an important factor during software development and evolution. However, there is still little support for creating energy-efficient software. In this work, we introduce a possible framework for software energy costs evaluation based on model analysis. We model software as Labelled Transitions Systems (LTS) and annotate these models with energy costs, which can be obtained using existing tools. We can then apply graph-based algorithms to traverse the models to obtain information about energy consumption related to software behaviour, such as its most/least costly execution, the cost of a specific execution, and the average cost of executing the software. No existing tool currently provides all the necessary analyses, even though they are essential for energy-consumption evaluation. We have conducted a small experiment with our framework where we employed jRAPL to measure energy costs. We annotated the models with the collected energy costs using an extended version of the LoTuS tool, where we have also implemented some of the desired analyses. Based on this support and on our initial results, we believe developers could create software more energy-efficient and consider possible trade-offs related to time, space, and energy costs when producing new versions of their systems.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {67–72},
numpages = {6},
keywords = {Labelled Transition System, Embedded Software, Energy Consumption Evaluation, Model-based Analysis},
location = {Salvador, Brazil},
series = {SBES '19}
}

@article{10.1145/1324969.1324971,
author = {Fei, Yunsi and Ravi, Srivaths and Raghunathan, Anand and Jha, Niraj K.},
title = {Energy-Optimizing Source Code Transformations for Operating System-Driven Embedded Software},
year = {2007},
issue_date = {December 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
issn = {1539-9087},
url = {https://doi.org/10.1145/1324969.1324971},
doi = {10.1145/1324969.1324971},
abstract = {This paper proposes four types of source code transformations for operating system (OS)-driven embedded software programs to reduce their energy consumption. Their key features include spanning of process boundaries and minimization of the energy consumed in the execution of OS services—opportunities which are beyond the reach of conventional compiler optimizations and source code transformations. We have applied the proposed transformations to several multiprocess benchmark programs in the context of an embedded Linux OS running on an Intel StrongARM processor. They achieve up to 37.9% (23.8%, on average) energy reduction compared to highly compiler-optimized implementations.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {dec},
articleno = {2},
numpages = {26},
keywords = {source code transformations, Linux, energy consumption}
}

@inproceedings{10.1145/3191697.3213805,
author = {Gastel, Pascal van and Gastel, Bernard van and Eekelen, Marko van},
title = {Detecting Energy Bugs and Hotspots in Control Software Using Model Checking},
year = {2018},
isbn = {9781450355131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3191697.3213805},
doi = {10.1145/3191697.3213805},
abstract = {We explore a way to find energy deficiencies in code by model checking, both properties related to utilisation (energy hotspots) and not related to utilisation (energy bugs). Temporal logic properties (expressed using LTL) finds these deficiencies during the development of a system, employing a novel energy-inefficiency metric. The formal model is deduced from hardware specifications, a definition of utilisation and a control software application written in C. Model checking results in a set of traces (formally a counter-example) that can be related to the matching execution path in the source code by the software developer. The traces include energy footprints and enable developers to improve the energy efficiency of the application. A smart light system serves as a case study to evaluate the proposed approach.},
booktitle = {Companion Proceedings of the 2nd International Conference on the Art, Science, and Engineering of Programming},
pages = {93–98},
numpages = {6},
keywords = {energy consumption analysis, model checking},
location = {Nice, France},
series = {Programming '18}
}

@inproceedings{10.1145/2554850.2554964,
author = {te Brinke, Steven and Malakuti, Somayeh and Bockisch, Christoph and Bergmans, Lodewijk and Ak\c{s}it, Mehmet and Katz, Shmuel},
title = {A Tool-Supported Approach for Modular Design of Energy-Aware Software},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554964},
doi = {10.1145/2554850.2554964},
abstract = {The reduction of energy usage by software-controlled systems has many advantages, including prolonged battery life and reduction of greenhouse gas emissions. Thus, being able to implement energy optimization in software is essential. This requires a model of the energy utilization---or more general resource utilization---for each component in the system. Optimizer components, then, analyze resource utilization of other components in terms of such a model and adapt their behavior accordingly. We have devised a notation for Resource-Utilization Models (RUMs) that can be part of a component's application programming interface (API) to facilitate the modular implementation of optimizers. In this paper, we present tools for extracting such RUMs from components with an existing implementation.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1206–1212},
numpages = {7},
keywords = {modularity, CEGAR, minimal abstraction, model checking, resource-utilization model, energy-aware software},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/2039252.2039253,
author = {Bhattacharya, Suparna and Rajamani, Karthick and Gopinath, K. and Gupta, Manish},
title = {The Interplay of Software Bloat, Hardware Energy Proportionality and System Bottlenecks},
year = {2011},
isbn = {9781450309813},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2039252.2039253},
doi = {10.1145/2039252.2039253},
abstract = {In large flexible software systems, bloat occurs in many forms, causing excess resource utilization and resource bottlenecks. This results in lost throughput and wasted joules. However, mitigating bloat is not easy; efforts are best applied where savings would be substantial. To aid this we develop an analytical model establishing the relation between bottleneck in resources, bloat, performance and power.Analyses with the model places into perspective results from the first experimental study of the power-performance implications of bloat. In the experiments we find that while bloat reduction can provide as much as 40% energy savings, the degree of impact depends on hardware and software characteristics. We confirm predictions from our model with selected results from our experimental study.Our findings show that a software-only view is inadequate when assessing the effects of bloat. The impact of bloat on physical resource usage and power should be understood for a full systems perspective to properly deploy bloat reduction solutions and reap their power-performance benefits.},
booktitle = {Proceedings of the 4th Workshop on Power-Aware Computing and Systems},
articleno = {1},
numpages = {5},
location = {Cascais, Portugal},
series = {HotPower '11}
}

@inproceedings{10.1145/1921705.1921709,
author = {Podgorelec, Vili},
title = {Assessing the Current State of Software Evolution and Intellectual Energy Spent},
year = {2010},
isbn = {9781450305396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1921705.1921709},
doi = {10.1145/1921705.1921709},
abstract = {In this paper we use a sequential study approach to empirical software engineering to study a novel idea about assessing the current phase of software evolution, based on the fractal metrics a and the logistic map equation parameter π. It is shown how the current software evolution phase can be determined from the logistic map equation when the complexity of the successive versions of software being evolved is measured by the fractal complexity measure α. Based on α and software functional size measures from the successive phases of a software product it is possible to assess the intellectual energy built into the software, which represents the effort spent while developing the software. A case study is performed to demonstrate the usage of the introduced approach.},
booktitle = {Proceedings of the Workshop on Advances in Functional Size Measurement and Effort Estimation},
articleno = {4},
numpages = {8},
keywords = {intellectual energy, software evolution, logistic maps, effort calculation, fractal metrics, complexity theory, functional size measurement},
location = {Maribor, Slovenia},
series = {FSM '10}
}

@inproceedings{10.5555/1266366.1266607,
author = {Gro\ss{}sch\"{a}dl, Johann and Tillich, Stefan and Rechberger, Christian and Hofmann, Michael and Medwed, Marcel},
title = {Energy Evaluation of Software Implementations of Block Ciphers under Memory Constraints},
year = {2007},
isbn = {9783981080124},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Software implementations of modern block ciphers often require large lookup tables along with code size increasing optimizations like loop unrolling to reach peak performance on general-purpose processors. Therefore, block ciphers are difficult to implement efficiently on embedded devices like cell phones or sensor nodes where run-time memory and program ROM are scarce resources. In this paper we analyze and compare the performance, energy consumption, run-time memory requirements, and code size of the five block ciphers RC6, Rijndael, Serpent, Twofish, and XTEA on the StrongARM SA-1100 processor. Most previous evaluations of block ciphers considered performance as the sole metric of interest and did not care about memory requirements or code size. In contrast to previous work, our study of the performance and energy characteristics of block ciphers has been conducted with "lightweight" implementations which restrict the size of lookup tables to 1 kB and also impose constraints on the code size. We found that Rijndael and RC6 can be well optimized for high performance and energy efficiency, while at the same time meeting the demand for low memory (RAM and ROM) footprint. In addition, we discuss the impact of key expansion and modes of operation on the overall performance and energy consumption of each block cipher. Our simulation results show that RC6 is the most energy-efficient block cipher under memory constraints and thus the best choice for resource-restricted devices.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {1110–1115},
numpages = {6},
keywords = {energy optimization, code size reduction, memory footprint, lightweight cryptography, symmetric cipher},
location = {Nice, France},
series = {DATE '07}
}

@inproceedings{10.1109/ICSE-NIER.2019.00026,
author = {Monni, Cristina and Pezz\`{e}, Mauro},
title = {Energy-Based Anomaly Detection a New Perspective for Predicting Software Failures},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2019.00026},
doi = {10.1109/ICSE-NIER.2019.00026},
abstract = {The ability of predicting failures before their occurrence is a fundamental enabler for reducing field failures and improving the reliability of complex software systems. Recent research proposes many techniques to detect anomalous values of system metrics, and demonstrates that collective anomalies are a good symptom of failure-prone states.In this paper (i) we observe the analogy of complex software systems with multi-particle and network systems, (ii) propose to use energy-based models commonly exploited in physics and statistical mechanics to precisely reveal failure-prone behaviors without training with seeded errors, and (iii) present some preliminary experimental results that show the feasibility of our approach.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {69–72},
numpages = {4},
keywords = {complex systems, failure prediction, anomaly detection},
location = {Montreal, Quebec, Canada},
series = {ICSE-NIER '19}
}

@inproceedings{10.5555/3018076.3018086,
author = {Sch\"{o}ne, Robert and Ilsche, Thomas and Bielert, Mario and Molka, Daniel and Hackenberg, Daniel},
title = {Software Controlled Clock Modulation for Energy Efficiency Optimization on Intel Processors},
year = {2016},
isbn = {9781509038565},
publisher = {IEEE Press},
abstract = {Current Intel processors implement a variety of power saving features like frequency scaling and idle states. These mechanisms limit the power draw and thereby decrease the thermal dissipation of the processors. However, they also have an impact on the achievable performance. The various mechanisms significantly differ regarding the amount of power savings, the latency of mode changes, and the associated overhead. In this paper, we describe and closely examine the so-called software controlled clock modulation mechanism for different processor generations. We present results that imply that the available documentation is not always correct and describe when this feature can be used to improve energy efficiency. We additionally compare it against the more popular feature of dynamic voltage and frequency scaling and develop a model to decide which feature should be used to optimize inter-process synchronizations on Intel Haswell-EP processors.},
booktitle = {Proceedings of the 4th International Workshop on Energy Efficient Supercomputing},
pages = {69–76},
numpages = {8},
keywords = {microprocessors, dynamic voltage scaling, performance analysis, systems modeling},
location = {Salt Lake City, Utah},
series = {E2SC '16}
}

@inproceedings{10.1145/2387027.2387039,
author = {H\"{o}rmann, Leander B. and Glatz, Philipp M. and Hein, Karima B. and Steger, Christian and Weiss, Reinhold},
title = {A Hardware/Software Simulation Environment for Energy Harvesting Wireless Sensor Networks},
year = {2012},
isbn = {9781450316217},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2387027.2387039},
doi = {10.1145/2387027.2387039},
abstract = {Wireless sensor networks (WSNs) consist of wirelessly communicating nodes with an autarkic power supply for each node. Typically, the consumable energy of these nodes is very limited. Energy harvesting systems (EHSs) can be used to extend the lifetime or even enable perpetual operation of the sensor nodes. Applicable energy-aware WSN protocols and applications usually raise the complexity such that rough calculations are not sufficient any more. Simulation-based analysis is needed to cope with the complexity of hardware/software interaction and its implications.This work presents a simulation environment which enables combined simulation and performance evaluation of complete WSNs including the sensor nodes' application software, the energy harvesting enhanced hardware, the wireless network communication, and the environment of the sensor nodes.},
booktitle = {Proceedings of the 9th ACM Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, and Ubiquitous Networks},
pages = {61–68},
numpages = {8},
keywords = {wireless sensor networks, energy harvesting, simulation environment},
location = {Paphos, Cyprus},
series = {PE-WASUN '12}
}

@inproceedings{10.1145/2983468.2983504,
author = {Peytchev, Evtim and Lyaskov, Mihail and Popovski, Kostadin and Spasov, Grisha},
title = {Home Energy Monitoring System Based on Open Source Software and Hardware},
year = {2016},
isbn = {9781450341820},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983468.2983504},
doi = {10.1145/2983468.2983504},
abstract = {The current paper presents the development and realisation of a home based energy monitoring system that provides detailed information about the electric energy consumption of home appliances. The system is based on WIFI connection and LAN (Local Area Network) preconfigured in the house. It consists of wireless energy monitoring nodes and a Linux based single-board computer, used as a server, which can be accessed from the Internet. The main purpose for the development of this system is to deliver a low-cost and efficient open source solution to determine exactly how is electric energy used in our homes. This work has been carried out under the auspices of the REMOURBAN EU H2020 project.},
booktitle = {Proceedings of the 17th International Conference on Computer Systems and Technologies 2016},
pages = {145–150},
numpages = {6},
keywords = {open source, energy efficiency, Smart home, Energy monitoring, single-board computer},
location = {Palermo, Italy},
series = {CompSysTech '16}
}

@inproceedings{10.1145/2742854.2747286,
author = {Raffin, Erwan and Hamidouche, Wassim and Nogues, Erwan and Pelcat, Maxime and Menard, Daniel and Tomperi, Seppo},
title = {Energy Efficiency of a Parallel HEVC Software Decoder for Embedded Devices},
year = {2015},
isbn = {9781450333580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742854.2747286},
doi = {10.1145/2742854.2747286},
abstract = {In the context of fast adoption and deployment of recent video compression standard and thanks to recent high performance embedded processors, software video decoding can be performed in real time. But, it becomes among the most energy-intensive applications. Current embedded processors are based on multi-core architecture with advanced convenient features such as Dynamic Voltage Frequency Scaling (DVFS) in order to reduce their power consumption, allowing low power video decoding when no hardware decoding support is available for a given device. This paper deals with energy efficiency impact of different parallelization strategies of a software High Efficiency Video Coding (HEVC) decoder on multi-core ARM big.LITTLE processor. These strategies include the exploitation of data and task-level parallelism, as well as the use of different available DVFS policies.},
booktitle = {Proceedings of the 12th ACM International Conference on Computing Frontiers},
articleno = {62},
numpages = {6},
keywords = {video decoder, WPP, DVFS, embedded systems, HEVC, SIMD, low power, H.265, frame-based parallelism},
location = {Ischia, Italy},
series = {CF '15}
}

@inproceedings{10.1145/566408.566442,
author = {Unsal, Osman S. and Koren, Israel and Krishna, C. Mani},
title = {Towards Energy-Aware Software-Based Fault Tolerance in Real-Time Systems},
year = {2002},
isbn = {1581134754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/566408.566442},
doi = {10.1145/566408.566442},
abstract = {Many real-time systems employed in defense, space, and consumer applications have power constraints and high reliability requirements. In this paper, we focus on the relationship between fault tolerance techniques and energy consumption. In particular, we establish the energy efficiency of Application Level Fault Tolerance (ALFT) over other software-based fault tolerance methods. We then develop sensible energy-aware heuristics for ALFT schemes. The heuristics yield up to 40% energy savings.},
booktitle = {Proceedings of the 2002 International Symposium on Low Power Electronics and Design},
pages = {124–129},
numpages = {6},
keywords = {fault-tolerance, low-power, real-time systems},
location = {Monterey, California, USA},
series = {ISLPED '02}
}

@inproceedings{10.1145/2684080.2684081,
author = {Colmant, Maxime and Rouvoy, Romain and Seinturier, Lionel},
title = {Improving the Energy Efficiency of Software Systems for Multi-Core Architectures},
year = {2014},
isbn = {9781450332217},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2684080.2684081},
doi = {10.1145/2684080.2684081},
abstract = {The ICT has an huge impact on the world CO2 emissions and recent study estimates its account to 2% of these emissions. This growing account emissions makes IT energy efficiency an important challenge. State-of-the-art has proven that the processor is the main power consumer. Processor are nowadays more and more complex and they are used in many hardware systems, such as computers or smartphones. This thesis is thus focusing on the software energy efficiency for multi-core systems. In this paper, we therefore report our motivations to understand deeply their architectures for improving their energy efficiencies. Manufacturers have worked tremendously to improve performance and reduce power consumption of their processors. However a lot of things remains to do in the software side. We claim that energy-efficient softwares can play a deterministic role to reduce the IT carbon footprint. To answer this challenge, we are believing on the software-metric approach with a minimal hardware investment. For this purpose, an efficient, scalable and non-invasive tool is needed. As a result, we created PowerAPI, to provide fine-grained power estimations at process and code-level for optimizing the software enegergy efficiency automatically. This solution will help to identify clearly the energy leaks for optimizing automatically the power consumed by software.},
booktitle = {Proceedings of the 11th Middleware Doctoral Symposium},
articleno = {1},
numpages = {4},
keywords = {CPU power model, power monitoring, middleware toolkit},
location = {Bordeaux, France},
series = {MDS '14}
}

@article{10.1145/2822893,
author = {Tan, Li and Chen, Zizhong and Song, Shuaiwen Leon},
title = {Scalable Energy Efficiency with Resilience for High Performance Computing Systems: A Quantitative Methodology},
year = {2015},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/2822893},
doi = {10.1145/2822893},
abstract = {Ever-growing performance of supercomputers nowadays brings demanding requirements of energy efficiency and resilience, due to rapidly expanding size and duration in use of the large-scale computing systems. Many application/architecture-dependent parameters that determine energy efficiency and resilience individually have causal effects with each other, which directly affect the trade-offs among performance, energy efficiency and resilience at scale. To enable high-efficiency management for large-scale High-Performance Computing (HPC) systems nowadays, quantitatively understanding the entangled effects among performance, energy efficiency, and resilience is thus required. While previous work focuses on exploring energy-saving and resilience-enhancing opportunities separately, little has been done to theoretically and empirically investigate the interplay between energy efficiency and resilience at scale. In this article, by extending the Amdahl’s Law and the Karp-Flatt Metric, taking resilience into consideration, we quantitatively model the integrated energy efficiency in terms of performance per Watt and showcase the trade-offs among typical HPC parameters, such as number of cores, frequency/voltage, and failure rates. Experimental results for a wide spectrum of HPC benchmarks on two HPC systems show that the proposed models are accurate in extrapolating resilience-aware performance and energy efficiency, and capable of capturing the interplay among various energy-saving and resilience factors. Moreover, the models can help find the optimal HPC configuration for the highest integrated energy efficiency, in the presence of failures and applied resilience techniques.},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
articleno = {35},
numpages = {27},
keywords = {failures, performance, undervolting, HPC, scalability, checkpoint and restart, DVFS, power, Energy, resilience}
}

@inproceedings{10.1109/DS-RT.2014.12,
author = {Forshaw, Matthew and Thomas, Nigel and McGough, A. Stephen},
title = {Trace-Driven Simulation for Energy Consumption in High Throughput Computing Systems},
year = {2014},
isbn = {9781479961443},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/DS-RT.2014.12},
doi = {10.1109/DS-RT.2014.12},
abstract = {High Throughput Computing (HTC) is a powerful paradigm allowing vast quantities of independent work to be performed simultaneously. However, until recently little evaluation has been performed on the energy impact of HTC. Many organisations now seek to minimise energy consumption across their IT infrastructure though it is unclear how this will affect the usability of HTC systems. We present here HTC-Sim, a simulation system which allows the evaluation of different energy reduction policies across an HTC system comprising a collection of computational resources dedicated to HTC work and resources provided through cycle scavenging--a Desktop Grid. We demonstrate that our simulation software scales linearly with increasing HTC workload.},
booktitle = {Proceedings of the 2014 IEEE/ACM 18th International Symposium on Distributed Simulation and Real Time Applications},
pages = {27–34},
numpages = {8},
series = {DS-RT '14}
}

@inproceedings{10.5555/2648668.2648738,
author = {Cong, Jason and Ercegovac, Milos and Huang, Muhuan and Li, Sen and Xiao, Bingjun},
title = {Energy-Efficient Computing Using Adaptive Table Lookup Based on Nonvolatile Memories},
year = {2013},
isbn = {9781479912353},
publisher = {IEEE Press},
abstract = {Table lookup based function computation can significantly save energy consumption. However existing table lookup methods are mostly used in ASIC designs for some fixed functions. The goal of this paper is to enable table lookup computation in general-purpose processors, which requires adaptive lookup tables for different applications. We provide a complete design flow to support this requirement. We propose a novel approach to build the reconfigurable lookup tables based on emerging nonvolatile memories (NVMs), which takes full advantages of NVMs over conventional SRAMs and avoids the limitation of NVMs. We provide compiler support to optimize table resource allocation among functions within a program. We also develop a runtime table manager that can learn from history and improve its arbitration of the limited on-chip table resources among programs.},
booktitle = {Proceedings of the 2013 International Symposium on Low Power Electronics and Design},
pages = {280–285},
numpages = {6},
location = {Beijing, China},
series = {ISLPED '13}
}

@inproceedings{10.1145/3583781.3590254,
author = {Moitra, Abhishek and Yin, Ruokai and Panda, Priyadarshini},
title = {Hardware Accelerators for Spiking Neural Networks for Energy-Efficient Edge Computing},
year = {2023},
isbn = {9798400701252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583781.3590254},
doi = {10.1145/3583781.3590254},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2023},
pages = {137–138},
numpages = {2},
keywords = {in-memory computing, area &amp; energy-efficiency, non-idealities, hybrid-device architecture},
location = {Knoxville, TN, USA},
series = {GLSVLSI '23}
}

@article{10.1109/TNET.2015.2502580,
author = {Roy, Nirmalya and Misra, Archan and Das, Sajal K. and Julien, Christine},
title = {Determining Quality- and Energy-Aware Multiple Contexts in Pervasive Computing Environments},
year = {2016},
issue_date = {October 2016},
publisher = {IEEE Press},
volume = {24},
number = {5},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2015.2502580},
doi = {10.1109/TNET.2015.2502580},
abstract = {In pervasive computing environments, understanding the context of an entity is essential for adapting the application behavior to changing situations. In our view, context is a high-level representation of a user or entity's state and can capture location, activities, social relationships, capabilities, etc. Inherently, however, these high-level context metrics are difficult to capture using uni-modal sensors only and must therefore be inferred using multi-modal sensors. A key challenge in supporting context-aware pervasive computing is how to determine multiple high-level context metrics simultaneously and energy-efficiently using low-level sensor data streams collected from the environment and the entities present therein. A key challenge is addressing the fact that the algorithms that determine different high-level context metrics may compete for access to low-level sensors. In this paper, we first highlight the complexities of determining multiple context metrics as compared to a single context and then develop a novel framework and practical implementation for this problem. The proposed framework captures the tradeoff between the accuracy of estimating multiple context metrics and the overhead incurred in acquiring the necessary sensor data streams. In particular, we develop two variants of a heuristic algorithm for multi-context search that compute the optimal set of sensors contributing to the multi-context determination as well as the associated parameters of the sensing tasks e.g., the frequency of data acquisition. Our goal is to satisfy the application requirements for a specified accuracy at a minimum cost. We compare the performance of our heuristics with a brute-force based approach for multi-context determination. Experimental results with SunSPOT, Shimmer and Smartphone sensors in smart home environments demonstrate the potential impact of the proposed framework.},
journal = {IEEE/ACM Trans. Netw.},
month = {oct},
pages = {3026–3042},
numpages = {17}
}

@inproceedings{10.1145/2206781.2206851,
author = {Rahmani, Kamran and Mishra, Prabhat and Bhunia, Swarup},
title = {Memory-Based Computing for Performance and Energy Improvement in Multicore Architectures},
year = {2012},
isbn = {9781450312448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2206781.2206851},
doi = {10.1145/2206781.2206851},
abstract = {Memory-based computing (MBC) is promising for improving performance and energy efficiency in both data- and compute-intensive applications. In this paper, we propose a novel reconfigurable MBC framework for multicore architectures where each core uses caches for computation using Look Up Tables (LUTs). Experimental results demonstrate that on-demand memory-based computing in each core can significantly improve performance (up to 4.7X, 3.3X on average) as well as reduce energy consumption (up to 4.7X, 2X on average) in multicore architectures.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI},
pages = {287–290},
numpages = {4},
keywords = {energy optimization, multicore systems, acceleration, memory-based computing},
location = {Salt Lake City, Utah, USA},
series = {GLSVLSI '12}
}

@inproceedings{10.1145/3479242.3487325,
author = {Zhang, Yu and Gorlatch, Sergei},
title = {Optimizing Energy Efficiency of QoS-Based Routing in Software-Defined Networks},
year = {2021},
isbn = {9781450390804},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479242.3487325},
doi = {10.1145/3479242.3487325},
abstract = {We address the routing optimization problem in Software-Defined Networks (SDN) to minimize the energy consumption while satisfying multiple QoS constraints of network services. In this paper, we: 1) formally define the problem of routing optimization in SDN under multiple QoS constraints, and 2) propose a novel routing optimization algorithm that improves the classical Shuffled Frog Leaping Algorithm (SFLA). We develop a two-phase procedure for implementing our proposed routing optimization algorithm in an SDN environment. We report the results of experiments using the Mininet simulation framework that confirm the advantages of our proposed QoS routing optimization algorithm as compared to the state-of-the-art solutions.},
booktitle = {Proceedings of the 17th ACM Symposium on QoS and Security for Wireless and Mobile Networks},
pages = {87–94},
numpages = {8},
keywords = {routing optimization, software-defined networking, quality of service (qos), energy efficiency, multiple qos constraints, shuffled frog leaping algorithm},
location = {Alicante, Spain},
series = {Q2SWinet '21}
}

@inproceedings{10.1145/3570361.3615727,
author = {G\'{o}mez, Blas and Bayhan, Suzan and Coronado, Estefan\'{\i}a and Villal\'{o}n, Jos\'{e} and Garrido, Antonio},
title = {MintEDGE: Multi-Tier SImulator for ENergy-Aware STrategies in Edge Computing},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570361.3615727},
doi = {10.1145/3570361.3615727},
abstract = {Edge computing has transformed cellular networks, offering fast response times by moving computing resources to the network's edge. This not only reduces the burden on the Wide Area Network (WAN) but also enables latency-sensitive applications. However, the widespread deployment of edge computing raises concerns regarding its sustainability. In this work, we present MintEDGE, a simulation framework that models a fully configurable edge-enabled cellular network. MintEDGE empowers researchers and practitioners to design and assess energy-saving strategies for edge computing. We discuss the details of the simulator and its customizable elements like user mobility, the possibility to use predictive workload algorithms, and diverse application scenarios at scale. MintEDGE is released under a permissive MIT license.},
booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
articleno = {120},
numpages = {3},
keywords = {edge computing, 5G, network simulator, energy efficiency},
location = {Madrid, Spain},
series = {ACM MobiCom '23}
}

@inproceedings{10.1145/3318216.3363453,
author = {Bai, Kangjun and Liu, Shiya and Yi, Yang},
title = {High Speed and Energy Efficient Deep Neural Network for Edge Computing},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363453},
doi = {10.1145/3318216.3363453},
abstract = {Edge computing enables data-stream acceleration with real-time data processing without latency, and allows for efficient data processing in that large amounts of data can be processed near the source with the ability to process data without ever putting it into a public cloud adds a useful layer of security for sensitive data. The edge computing-based architecture design and analysis play key impacts for the future Internet of Things (IoT) infrastructure development. In this work, we design a low power hybrid structured deep neural network (Hybrid-DNN), which employs memristive synapses working in a hierarchical information processing fashion and delay-based spiking neural network (SNN) modules as the readout layer, and provide a novel data layout method to allow the Hybrid DNN running a computationally intensive deep learning algorithm on limited resource edge devices. Motivated by the recent findings in neuromorphic computing and edge computing, we design a hybrid structured DNN combining both depth-in-space (spatial) and depth-in-time (temporal) deep learning architectures. Our Hybrid-DNN employs memristive synapses working in a hierarchical information processing fashion and delay-based spiking neural network modules as the readout layer.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {347–349},
numpages = {3},
keywords = {edge computing, spiking neural network, deep learning},
location = {Arlington, Virginia},
series = {SEC '19}
}

@article{10.1145/3359622,
author = {Mondal, Ankit and Srivastava, Ankur},
title = {Energy-Efficient Design of MTJ-Based Neural Networks with Stochastic Computing},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/3359622},
doi = {10.1145/3359622},
abstract = {Hardware implementations of Artificial Neural Networks (ANNs) using conventional binary arithmetic units are computationally expensive, energy-intensive, and have large area overheads. Stochastic Computing (SC) is an emerging paradigm that replaces these conventional units with simple logic circuits and is particularly suitable for fault-tolerant applications. We propose an energy-efficient use of Magnetic Tunnel Junctions (MTJs), a spintronic device that exhibits probabilistic switching behavior, as Stochastic Number Generators (SNGs), which forms the basis of our NN implementation in the SC domain. Further, the error resilience of target applications of NNs allows approximating the synaptic weights in our MTJ-based NN implementation, in ways brought about by properties of the MTJ-SNG, to achieve energy-efficiency. An algorithm is designed that, given an error tolerance, can perform such approximations in a single-layer NN in an optimal way owing to the convexity of the problem formulation. We then use this algorithm and develop a heuristic approach for approximating multi-layer NNs. Classification problems were evaluated on the optimized NNs and results showed substantial savings in energy for little loss in accuracy.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {oct},
articleno = {7},
numpages = {27},
keywords = {regularization, energy efficiency, approximate computing, Magnetic tunnel junctions}
}

@inproceedings{10.1145/1791314.1791337,
author = {Somavat, Pavel and Jadhav, Shraddha and Namboodiri, Vinod},
title = {Accounting for the Energy Consumption of Personal Computing Including Portable Devices},
year = {2010},
isbn = {9781450300421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1791314.1791337},
doi = {10.1145/1791314.1791337},
abstract = {In light of the increased awareness of global energy consumption, questions are also being asked about the contribution of computing equipment. Though studies have documented the share of energy consumption due to these equipment over the years, these have rarely characterized the increasing share contributed by the rapidly growing portable computing segment. The portable computing device segment is widely predicted to be a dominant mode of computing and communication, and accounting for its energy consumption is necessary for energy-efficient computing in the future. This work takes a fresh and updated look at the energy consumption due to computing devices in perspective of global consumption, and pays special attention to the contribution of portable computing devices. We further quantify the impact of energy consumed by the computing sector on the environment, as well as on the electricity cost to an average residential consumer. Finally, based on the results of the study, recommendations targeted at the computer networking community are made.},
booktitle = {Proceedings of the 1st International Conference on Energy-Efficient Computing and Networking},
pages = {141–149},
numpages = {9},
keywords = {energy, environment, computing, networking, electricity, portable devices},
location = {Passau, Germany},
series = {e-Energy '10}
}

@article{10.1145/2544375.2544392,
author = {Das, Anup and Kumar, Akash and Veeravalli, Bharadwaj},
title = {Energy-Aware Task Mapping and Scheduling for Reliable Embedded Computing Systems},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2s},
issn = {1539-9087},
url = {https://doi.org/10.1145/2544375.2544392},
doi = {10.1145/2544375.2544392},
abstract = {Task mapping and scheduling are critical in minimizing energy consumption while satisfying the performance requirement of applications enabled on heterogeneous multiprocessor systems. An area of growing concern for modern multiprocessor systems is the increase in the failure probability of one or more component processors. This is especially critical for applications where performance degradation (e.g., throughput) directly impacts the quality of service requirement. This article proposes a design-time (offline) multi-criterion optimization technique for application mapping on embedded multiprocessor systems to minimize energy consumption for all processor fault-scenarios. A scheduling technique is then proposed based on self-timed execution to minimize the schedule storage and construction overhead at runtime. Experiments conducted with synthetic and real applications from streaming and nonstreaming domains on heterogeneous MPSoCs demonstrate that the proposed technique minimizes energy consumption by 22% and design space exploration time by 100x, while satisfying the throughput requirement for all processor fault-scenarios. For scalable throughput applications, the proposed technique achieves 30% better throughput per unit energy, compared to the existing techniques. Additionally, the self-timed execution-based scheduling technique minimizes schedule construction time by 95% and storage overhead by 92%.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {jan},
articleno = {72},
numpages = {27},
keywords = {energy consumption, Task mapping and scheduling, multimedia applications, synchronous dataflow graphs, fault tolerance}
}

@inproceedings{10.5555/3433701.3433823,
author = {Bertagna, Luca and Guba, Oksana and Taylor, Mark A. and Foucar, James G. and Larkin, Jeff and Bradley, Andrew M. and Rajamanickam, Sivasankaran and Salinger, Andrew G.},
title = {A Performance-Portable Nonhydrostatic Atmospheric Dycore for the Energy Exascale Earth System Model Running at Cloud-Resolving Resolutions},
year = {2020},
isbn = {9781728199986},
publisher = {IEEE Press},
abstract = {We present an effort to port the nonhydrostatic atmosphere dynamical core of the Energy Exascale Earth System Model (E3SM) to efficiently run on a variety of architectures, including conventional CPU, many-core CPU, and GPU. We specifically target cloud-resolving resolutions of 3 km and 1 km. To express on-node parallelism we use the C++ library Kokkos, which allows us to achieve a performance portable code in a largely architecture-independent way. Our C++ implementation is at least as fast as the original Fortran implementation on IBM Power9 and Intel Knights Landing processors, proving that the code refactor did not compromise the efficiency on CPU architectures. On the other hand, when using the GPUs, our implementation is able to achieve 0.97 Simulated Years Per Day, running on the full Summit supercomputer. To the best of our knowledge, this is the most achieved to date by any global atmosphere dynamical core running at such resolutions.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {92},
numpages = {14},
keywords = {multicore processing, atmospheric modeling, high performance computing},
location = {Atlanta, Georgia},
series = {SC '20}
}

@inproceedings{10.1145/3344341.3368822,
author = {Jayanetti, Amanda and Buyya, Rajkumar},
title = {J-OPT: A Joint Host and Network Optimization Algorithm for Energy-Efficient Workflow Scheduling in Cloud Data Centers},
year = {2019},
isbn = {9781450368940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344341.3368822},
doi = {10.1145/3344341.3368822},
abstract = {Workflows are a popular application model used for representing scientific as well as commercial applications, and cloud data centers are increasingly used in the execution of workflow applications. Existing approaches to energy-efficient workflow scheduling in cloud computing environments have primarily focused on the optimization of server utilization. The majority of works have ignored the impact of scheduling decisions on the data center network (DCN). However, studies have revealed that the DCN consumes 10-20% of the total data center power, and this percentage could rise much higher depending on the utilization level of the data center. This paper proposes an energy-efficient workflow scheduling approach (J-OPT) that jointly optimizes the power consumption of servers and networking elements in cloud data centers. J-OPT considers precedence constraints and data dependencies among workflow tasks as well as communication requirements among task instances in the formulation of topology-aware scheduling decisions. The proposed approach is evaluated using synthetic and real world workflow traces in a simulated environment. Results of the experiments demonstrate that J-OPT outperforms state-of-the-art algorithms in terms of total power savings by 8% and 30% under high and low data center utilization levels, respectively.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing},
pages = {199–208},
numpages = {10},
keywords = {energy efficiency, cloud computing, workflow scheduling, topology-aware scheduling},
location = {Auckland, New Zealand},
series = {UCC'19}
}

@inproceedings{10.5555/3400397.3400606,
author = {Ahmed, Kishwar and Liu, Jason},
title = {Simulation of Energy-Efficient Demand Response for High Performance Computing Systems},
year = {2020},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {Energy consumption is a critical issue for high-performance computing (HPC) systems. Demand response is a program offered by power service providers to reduce energy consumption. In this paper, we present the simulation of an energy-efficient economic demand-response model based on contract theory. Simulation is developed to examine the effectiveness of the demand-response model in a variety of real-world scenarios. Results from simulation show that the model can achieve energy efficiency through the rewarding mechanism of the contract-based design. In particular, the HPC users can be properly compensated to ensure their willing participation in energy reduction.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2560–2571},
numpages = {12},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@inproceedings{10.1145/1005847.1005863,
author = {Tamai, Morihiko and Sun, Tao and Yasumoto, Keiichi and Shibata, Naoki and Ito, Minoru},
title = {Energy-Aware Video Streaming with QoS Control for Portable Computing Devices},
year = {2004},
isbn = {1581138016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1005847.1005863},
doi = {10.1145/1005847.1005863},
abstract = {We propose an energy-aware video streaming system for portable computing devices, in which the video can be played back for the specified duration within the remaining battery amount. To save power, we introduce techniques (i) to reduce playback quality of a video at an intermediate proxy and (ii) to shorten working time of the network I/F card using periodic bulk transfer of the video data on the wireless LAN. To enable playback for the specified duration, we have developed a power consumption model for portable devices using parameters on playback quality, playback duration, battery amount, and so on. We have also developed an algorithm to assign different playback quality among multiple video segments based on the user's preference.within the battery amount. Our experiments using PDAs and laptop PCs on 802.11b WLAN show that our system achieves less than 6 prediction error in playback duration while adapting playback quality among video segments.},
booktitle = {Proceedings of the 14th International Workshop on Network and Operating Systems Support for Digital Audio and Video},
pages = {68–73},
numpages = {6},
keywords = {video streaming, wireless LANs, QoS, energy-aware systems},
location = {Cork, Ireland},
series = {NOSSDAV '04}
}

@inproceedings{10.1145/3128128.3128129,
author = {Talei, Hanaa and Essaaidi, Mohamed and Benhaddou, Driss},
title = {Smart Campus Energy Management System: Advantages, Architectures, and the Impact of Using Cloud Computing},
year = {2017},
isbn = {9781450352819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3128128.3128129},
doi = {10.1145/3128128.3128129},
abstract = {A Microgrid is a subset of smart grid, a small-scale electrical system powered with renewable energy resources that can operate either in a connected or a disconnected mode to/from the main grid. Given that universities are very important electricity consumers, using an academic Microgrid will solve many problems regarding energy usage[1]. The purpose of this paper, is to describe Microgrid components with an emphasis on energy management (EMS). Given its vital role, the paper presents different architectures of an EMS and discusses how cloud computing can be incorporated to the Microgrid architecture to improve the EMS efficiency. The paper concludes with presenting results of EMS data collection using Kaa IoT platform.},
booktitle = {Proceedings of the 2017 International Conference on Smart Digital Environment},
pages = {1–7},
numpages = {7},
keywords = {energy management system, IoT, microgrid, cloud computing, agent},
location = {Rabat, Morocco},
series = {ICSDE '17}
}

@inproceedings{10.1145/3207677.3277931,
author = {Cheng, Yulun and Sun, Lili and Liu, Xiaoyun},
title = {User-Oriented Energy-Saving Offloading for Wireless Virtualization Aided Mobile Edge Computing},
year = {2018},
isbn = {9781450365123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3207677.3277931},
doi = {10.1145/3207677.3277931},
abstract = {Mobile1 edge computing (MEC) is a promising solution to reduce latency and improve user experience. Moreover, by appropriately offloading computation intensive tasks to MEC node other than user equipment (UE), the energy consumption of computing is transferred to MEC node, so that the lifetime of UE can be prolonged. However, offloading will increase additional delay and energy consumption. To address this issue, the task offloading is formulated as an optimization problem to minimize energy consumption of UE, as well as maintain the latency constraints. The convexity of the problem is theoretically proved. On the basis of that, a heuristic algorithm is proposed to reduce the complexity. Simulation results show that the proposed algorithm is effective to reduce energy consumption of the user.},
booktitle = {Proceedings of the 2nd International Conference on Computer Science and Application Engineering},
articleno = {51},
numpages = {5},
keywords = {mobile edge computing, computation offloading, wireless virtualization, convex optimization},
location = {Hohhot, China},
series = {CSAE '18}
}

@inproceedings{10.1145/3436829.3436860,
author = {Moussa, Rania R. and Moawad, Dina Rushdy M.},
title = {Investigating the Efficiency of Building Energy Simulation Software on Architectural Design Process},
year = {2021},
isbn = {9781450377218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3436829.3436860},
doi = {10.1145/3436829.3436860},
abstract = {New designing techniques are used recently during the design phases of buildings to adapt the environment and achieve human thermal comfort, one of these designing techniques is using energy simulation software's. However, architects need to understand the capabilities of these software's and its operation systems, when it comes to designing and modelling passive buildings. Moreover the validity of the design outcomes which is the main concern of this research. These energy simulation software's helps architects to estimate the building's energy efficiency in order to achieve human thermal comfort. This study will focus on studding and analyzing one of the well-known simulation software's used for building's energy simulations which is called "Design-Builder". The presented research will measure the accuracy of Design-Builder outcomes by comparing the accuracy of the thermal simulation in Design-Builder software to the results obtained from the experimental data. A Bookstore kiosk located in El-Sherouk city, Cairo, Egypt was chosen to be the study area of this research. The research will compare the simulation results of this Kiosk to the field's experimental measurements obtained from site visit. The results reveled that there is differences between the field measurements and the simulation ranged between 1 to 5°C. The study analyzed the causes of these differences and provided some proposals to improve Design-Builder software in order to provide more accurate data in simulating hot arid climates.},
booktitle = {Proceedings of the 9th International Conference on Software and Information Engineering},
pages = {37–40},
numpages = {4},
keywords = {Climatic analysis, hot and arid climate, Thermal simulation, Design-Builder software},
location = {Cairo, Egypt},
series = {ICSIE '20}
}

@inproceedings{10.1145/3207719.3207736,
author = {Papadopoulos, Lazaros and Marantos, Charalampos and Digkas, Georgios and Ampatzoglou, Apostolos and Chatzigeorgiou, Alexander and Soudris, Dimitrios},
title = {Interrelations between Software Quality Metrics, Performance and Energy Consumption in Embedded Applications},
year = {2018},
isbn = {9781450357807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3207719.3207736},
doi = {10.1145/3207719.3207736},
abstract = {Source code refactorings and transformations are extensively used by embedded system developers to improve the quality of applications, often supported by various open source and proprietary tools. They either aim at improving the design time quality such as the maintainability and reusability of software artifacts, or the runtime quality such as performance and energy efficiency. However, an inherent trade-off between design- and run-time qualities is often present posing challenges to embedded software development. This work is a first step towards the investigation of the impact of transformations for improving the performance and the energy efficiency on software quality metrics and the impact of refactorings for increasing the design time quality on the execution time, the memory and the energy consumption. Based on a set of embedded applications from widely used benchmark suites and typical transformations and refactorings, we identify interrelations and trade-offs between the aforementioned metrics.},
booktitle = {Proceedings of the 21st International Workshop on Software and Compilers for Embedded Systems},
pages = {62–65},
numpages = {4},
location = {Sankt Goar, Germany},
series = {SCOPES '18}
}

@inproceedings{10.1145/2934583.2953982,
author = {Chiou, Derek},
title = {Heterogeneous Computing and Infrastructure for Energy Efficiency in Microsoft Data Centers: Extended Abstract},
year = {2016},
isbn = {9781450341851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934583.2953982},
doi = {10.1145/2934583.2953982},
abstract = {This paper describes some of the ways heterogeneous computing, specifically FPGAs, is used in Microsoft data centers to improve energy efficiency and performance. Improved energy efficiency can have a significant effect on the viability of the data center in question. We discuss the Bing ranking application along with Azure networking infrastructure production projects.},
booktitle = {Proceedings of the 2016 International Symposium on Low Power Electronics and Design},
pages = {150–151},
numpages = {2},
keywords = {data center, energy efficiency, FPGA},
location = {San Francisco Airport, CA, USA},
series = {ISLPED '16}
}

@inproceedings{10.1145/2688500.2688546,
author = {Vassiliadis, Vassilis and Parasyris, Konstantinos and Chalios, Charalambos and Antonopoulos, Christos D. and Lalis, Spyros and Bellas, Nikolaos and Vandierendonck, Hans and Nikolopoulos, Dimitrios S.},
title = {A Programming Model and Runtime System for Significance-Aware Energy-Efficient Computing},
year = {2015},
isbn = {9781450332057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2688500.2688546},
doi = {10.1145/2688500.2688546},
abstract = {We introduce a task-based programming model and runtime system that exploit the observation that not all parts of a program are equally significant for the accuracy of the end-result, in order to trade off the quality of program outputs for increased energy-efficiency. This is done in a structured and flexible way, allowing for easy exploitation of different points in the quality/energy space, without adversely affecting application performance. The runtime system can apply a number of different policies to decide whether it will execute less-significant tasks accurately or approximately. The experimental evaluation indicates that our system can achieve an energy reduction of up to 83% compared with a fully accurate execution and up to 35% compared with an approximate version employing loop perforation. At the same time, our approach always results in graceful quality degradation.},
booktitle = {Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {275–276},
numpages = {2},
keywords = {programming model, Energy saving, runtime system, approximate computing},
location = {San Francisco, CA, USA},
series = {PPoPP 2015}
}

@inproceedings{10.1145/3545947.3569594,
author = {Prasad, Sushil and Weems, Charles and Sussman, Alan and Gupta, Anshul and Estrada, Trilce and Vaidyanathan, Ramachandran and Ghafoor, Sheikh and Kant, Krishna and Stunkel, Craig},
title = {NSF/IEEE-TCPP Curriculum on Parallel and Distributed Computing for Undergraduates - Version II - Big Data, Energy, and Distributed Computing},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3569594},
doi = {10.1145/3545947.3569594},
abstract = {This special session will report on the updated NSF/IEEE-TCPP Curriculum on Parallel and Distributed Computing released in Nov 2020 by the Center for Parallel and Distributed Computing Curriculum Development and Educational Resources (CDER). The purpose of the special session is to obtain SIGCSE community feedback on this curriculum in a highly interactive manner employing the hybrid modality and supported by a full-time CDER booth for the duration of SIGCSE. In this era of big data, cloud, and multi- and many-core systems, it is essential that the computer science (CS) and computer engineering (CE) graduates have basic skills in parallel and distributed computing (PDC). The topics are primarily organized into the areas of architecture, programming, and algorithms topics. A set of pervasive concepts that percolate across area boundaries are also identified. Version 1 of this curriculum was released in December 2012. That curriculum guideline has over 140 early adopter institutions worldwide and has been incorporated into the 2013 ACM/IEEE Computer Science curricula. This Version-II represents a major revision. The updates have focused on enhancing coverage related to the topical aspects of Big Data, Energy, and Distributed Computing.The session will also report on related CDER activities including a workshop series on a PDC institute conceptualization, developing a CE-oriented version of the curriculum, and identifying a minimal set of PDC topics aligned with ABET's exposure-level PDC requirements. The interested SIGCSE audience includes educators, authors, publishers, curriculum committee members, department chairs and administrators, professional societies, and the computing industry.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1220–1221},
numpages = {2},
keywords = {education, undergraduate curriculum, learning outcomes, parallel and distributed computing, bloom's classification},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3589737.3605976,
author = {R. Kulkarni, Shruti and Young, Aaron and Date, Prasanna and Rao Miniskar, Narasinga and Vetter, Jeffrey and Fahim, Farah and Parpillon, Benjamin and Dickinson, Jennet and Tran, Nhan and Yoo, Jieun and Mills, Corrinne and Swartz, Morris and Maksimovic, Petar and Schuman, Catherine and Bean, Alice},
title = {On-Sensor Data Filtering Using Neuromorphic Computing for High Energy Physics Experiments},
year = {2023},
isbn = {9798400701757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589737.3605976},
doi = {10.1145/3589737.3605976},
abstract = {This work describes the investigation of neuromorphic computing-based spiking neural network (SNN) models used to filter data from sensor electronics in high energy physics experiments conducted at the High Luminosity Large Hadron Collider (HL-LHC). We present our approach for developing a compact neuromorphic model that filters out the sensor data based on the particle's transverse momentum with the goal of reducing the amount of data being sent to the downstream electronics. The incoming charge waveforms are converted to streams of binary-valued events, which are then processed by the SNN. We present our insights on the various system design choices---from data encoding to optimal hyperparameters of the training algorithm---for an accurate and compact SNN optimized for hardware deployment. Our results show that an SNN trained with an evolutionary algorithm and an optimized set of hyperparameters obtains a signal efficiency of about 91% with nearly half as many parameters as a deep neural network.},
booktitle = {Proceedings of the 2023 International Conference on Neuromorphic Systems},
articleno = {3},
numpages = {8},
keywords = {spike encoding, spiking neural networks, evolutionary optimization, neuromorphic computing},
location = {Santa Fe, NM, USA},
series = {ICONS '23}
}

@inproceedings{10.1145/2660859.2660959,
author = {Fujita, Masahiro},
title = {Highly-Pipelined and Energy-Saved Computing with Arrays of Non-Volatile Memories},
year = {2014},
isbn = {9781450329088},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660859.2660959},
doi = {10.1145/2660859.2660959},
abstract = {In this paper, we propose circuit structures with arrays of non-volatile memories and their compilation method including layout which realizes highly parallel/pipelined computations. A number of small memories are interconnected with predetermined topology in such a way that memory data lines can drive memory address lines, which realizes multi-level Look Up Table (LUT) based computations. As signal values are propagated in nonoverlap ways, all LUTs can retrieve their data in parallel. That is, memories are synchronous with the same clock signal and retrieve data in exactly one lock cycle. LUTs in the same level are computing things in parallel, while LUTs in different levels are processing things in pipelined ways. We present the proposed architecture as well as a compilation method which can generate target arrays of memories with layout from general sequential logic circuits. As pipeline computations with very large numbers of pipelined stages can automatically be realized, varieties of computation including various operations in big data analysis as well as embedded systems can be significantly faster with energy efficient ways. Also, as the total architecture is based on non-volatile memories, it can realize quick power-gating mechanisms, which keep the energy consumptions at the minimum level. With power gating mechanisms, highly efficient real time scheduling can also be achieved. Moreover, by extending the mechanisms for state restoration when power gating, varieties of multiple interruption can also be accommodated.},
booktitle = {Proceedings of the 2014 International Conference on Interdisciplinary Advances in Applied Computing},
articleno = {46},
numpages = {6},
keywords = {Layout/area-based programming and synthesis, Look up Table, Non-volatile memory, Wave pipeline, Stream processing},
location = {Amritapuri, India},
series = {ICONIAAC '14}
}

@inproceedings{10.1145/2347655.2347669,
author = {Ogras, Umit Y. and Emre, Yunus and Xu, Jianping and Kam, Timothy and Kishinevsky, Michael},
title = {Energy-Guided Exploration of on-Chip Network Design for Exa-Scale Computing},
year = {2012},
isbn = {9781450314374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2347655.2347669},
doi = {10.1145/2347655.2347669},
abstract = {Designing energy-efficient systems under tight performance and energy constraints becomes increasingly challenging for exascale computing. In particular, interconnecting hundreds of cores, caches, integrated memory and I/O controllers in energy efficient way stands out as a new challenge. This paper proposes hierarchical on-chip networks that take the proximity advantage between the cores in smaller clusters as a promising approach toward energy-efficient high performance computing. The design trade-offs of hierarchical interconnect architectures are studied using a fast and scalable design space exploration tool for exascale systems with number of cores in the order of thousands. In particular, we consider a system with 720 processing nodes and two-level network hierarchy. By supporting both traditional cache-based memory model and scratch pad memory (SPM) model, the target system architecture proves to be a good testbed for energy-guided exploration of hierarchical networks.},
booktitle = {Proceedings of the International Workshop on System Level Interconnect Prediction},
pages = {24–31},
numpages = {8},
location = {San Francisco, California},
series = {SLIP '12}
}

@inproceedings{10.1145/2380445.2380456,
author = {Hung, Shih-Hao and Shih, Chi-Sheng and Kuo, Tei-Wei and Tu, Chia-Heng and Chang, Che-Wei},
title = {A Real-Time, Energy-Efficient System Software Suite for Heterogeneous Multicore Platforms},
year = {2012},
isbn = {9781450314268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380445.2380456},
doi = {10.1145/2380445.2380456},
abstract = {Heterogeneous multicore systems have become the trend for the embedded market due to its advantage of power/performance over traditional designs. However, monitoring the workload, scheduling the tasks, and managing the energy consumption to enable energy-efficient, real-time applications are increasingly challenging on such systems as both the applications and systems become complex. In this paper, we introduce a comprehensive approach to address the key problems and accelerate the design of a heterogeneous multicore embedded system by providing a suite of energy-aware system software with tightly coupled real-time support and performance/power modeling facilities. We start with a rapid full system modeling/simulation framework to characterize the application workload, design energy-saving algorithms, and verify if performance requirements are met by hardware specifications during the early design stage.With special considerations on today's multicore embedded systems, we developed several key components and integrated them as a system software suite: a portable, efficient library to support inter-core communications and multicore programming, a lightweight kernel for dynamically monitoring and sharing the workload among the processor cores, and a dynamic voltage and frequency scaling scheme to adjust the setting of the processors to save energy. The system software has been implemented on the PAC Duo system as a case study, with experimental results to demonstrate the effectiveness of the proposed approach. This paper discusses the novel techniques included in this system software and shares the lessons that we have learned from this work.},
booktitle = {Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},
pages = {23–32},
numpages = {10},
keywords = {multicore emulator, inter-core communication library, energy saving algorithm, load sharing kernel},
location = {Tampere, Finland},
series = {CODES+ISSS '12}
}

@inproceedings{10.5555/2485288.3250212,
author = {Merrett, Geoff and Garipelli, Gangadhar},
title = {Session Details: Energy-Efficient Architectures and Software Design for Power-Constrained Systems},
year = {2013},
isbn = {9781450321532},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
location = {Grenoble, France},
series = {DATE '13}
}

@inproceedings{10.1145/3592149.3592160,
author = {Monteiro, Rui Pedro C. and Silva, Jo\~{a}o Marco C.},
title = {Flexcomm Simulator: Exploring Energy Flexibility in Software Defined Networks with Ns-3},
year = {2023},
isbn = {9798400707476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3592149.3592160},
doi = {10.1145/3592149.3592160},
abstract = {The digitalization of energy generation and distribution systems opens new opportunities for devising network operation and traffic engineering strategies capable of adapting to the energy availability and sources. Despite the potential, developing and testing new approaches are challenging in production environments. Furthermore, no simulators support such integration between the communication infrastructure and the power grid. Thus, this paper introduces Flexcomm Simulator, a tool based on ns-3 that supports developing and assessing multiple strategies toward green networking and communications driven by real-time information from the power grid (i.e., Energy Flexibility). The proof-of-concept results demonstrate this contribution’s potential by implementing an energy-aware routing algorithm that adapts to real-world Energy Flexibility&nbsp;data in a Metropolitan Area Network (MAN). Also, it showcases the simulator’s capacity to deal with large-scale simulations through MPI-based distributed environments.},
booktitle = {Proceedings of the 2023 Workshop on Ns-3},
pages = {94–101},
numpages = {8},
keywords = {Software Defined Networking, ns-3, Energy Flexibility, Simulation},
location = {Arlington, VA, USA},
series = {WNS3 '23}
}

@inproceedings{10.1145/2380445.2380528,
author = {Brandolese, Carlo and Fornaciari, William},
title = {Software Energy Optimization through Fine-Grained Function-Level Voltage and Frequency Scaling},
year = {2012},
isbn = {9781450314268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380445.2380528},
doi = {10.1145/2380445.2380528},
abstract = {This paper presents a methodology and a toolchain to perform estimation and optimization of the energy consumption associated to software execution on tiny embedded systems. The estimation phase is based on an ISA-level characterization of the target processor, while the optimization phase is made combining the estimation process with design space exploration in order to exploit fine-grained dynamic voltage and frequency scaling. The proposed approach operates at compile-time, with the granularity of single C functions and almost automatically augments the source code.},
booktitle = {Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},
pages = {539–546},
numpages = {8},
keywords = {power optimization, embedded systems},
location = {Tampere, Finland},
series = {CODES+ISSS '12}
}

@inproceedings{10.5555/2523721.2523737,
author = {Wang, Bin and Wu, Bo and Li, Dong and Shen, Xipeng and Yu, Weikuan and Jiao, Yizheng and Vetter, Jeffrey S.},
title = {Exploring Hybrid Memory for GPU Energy Efficiency through Software-Hardware Co-Design},
year = {2013},
isbn = {9781479910212},
publisher = {IEEE Press},
abstract = {Hybrid memory designs, such as DRAM plus Phase Change Memory (PCM), have shown some promise for alleviating power and density issues faced by traditional memory systems. But previous studies have concentrated on CPU systems with a modest level of parallelism. This work studies the problem in a massively parallel setting. Specifically, it investigates the special implications to hybrid memory imposed by the massive parallelism in GPU. It empirically shows that, contrary to promising results demonstrated for CPU, previous designs of PCM-based hybrid memory result in significant degradation to the energy efficiency of GPU. It reveals that the fundamental reason comes from a multi-facet mismatch between those designs and the massive parallelism in GPU. It presents a solution that centers around a close cooperation between compiler-directed data placement and hardware-assisted runtime adaptation. The co-design approach helps tap into the full potential of hybrid memory for GPU without requiring dramatic hardware changes over previous designs, yielding 6% and 49% energy saving on average compared to pure DRAM and pure PCM respectively, and keeping performance loss less than 2%.},
booktitle = {Proceedings of the 22nd International Conference on Parallel Architectures and Compilation Techniques},
pages = {93–102},
numpages = {10},
keywords = {energy efficiency, co-design, NVRAM, GPU},
location = {Edinburgh, Scotland, UK},
series = {PACT '13}
}

@inproceedings{10.5555/1266366.1266610,
author = {Aaraj, Najwa and Raghunathan, Anand and Ravi, Srivaths and Jha, Niraj K.},
title = {Energy and Execution Time Analysis of a Software-Based Trusted Platform Module},
year = {2007},
isbn = {9783981080124},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Trusted platforms have been proposed as a promising approach to enhance the security of general-purpose computing systems. However, for many resource-constrained embedded systems, the size and cost overheads of a separate Trusted Platform Module (TPM) chip are not acceptable. One alternative is to use a software-based TPM (SW-TPM), which implements TPM functions using software that executes in a protected execution domain on the embedded processor itself. However, since many embedded systems have limited processing capabilities and are battery-powered, it is also important to ensure that the computational and energy requirements for SW-TPMs are acceptable.In this work, we perform an evaluation of the energy and execution time overheads for a SW-TPM implementation on a Sharp Zaurus PDA. We characterize the execution time and energy required by each TPM command through actual measurements on the target platform. In addition, we also evaluate the overheads of using SW-TPM in the context of various end applications, including trusted boot of the Linux operating system (OS), secure file storage, secure VoIP client, and secure web browser. Furthermore, we observe that for most TPM commands, the overheads are primarily due to the use of 2048-bit RSA operations that are performed within SW-TPM. In order to alleviate SW-TPM overheads, we evaluate the use of Elliptic Curve Cryptography (ECC) as a replacement for the RSA algorithm specified in the Trusted Computing Group (TCG) standards. Our experiments indicate that this optimization can significantly reduce SW-TPM overheads (an average of 6.51X execution time reduction and 6.75X energy consumption reduction for individual TPM commands, and an average of 10.25X execution time reduction and 10.75X energy consumption reduction for applications). Our work demonstrates that ECC-based SW-TPMs are a viable approach to realizing the benefits of trusted computing in resource-constrained embedded systems.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {1128–1133},
numpages = {6},
location = {Nice, France},
series = {DATE '07}
}

@inproceedings{10.1145/3579895.3579920,
author = {Hao, Yuanyuan and Zhang, Qian and Zheng, Zhong and Miao, Zhongyu and Zheng, Hanyu},
title = {Energy Efficient Computation Offloading and Resource Allocation for Satellite Multi-Access Edge Computing},
year = {2023},
isbn = {9781450398039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579895.3579920},
doi = {10.1145/3579895.3579920},
abstract = {In this article, the energy-efficient computation offloading and resource allocation for satellite multi-access edge computing (MEC) is studied. The problem is formulated to minimize the sum energy consumption of users while ensuring the task tolerance latency requirement. The formulated problem is divided into two subproblems, which are solved by exploring the convex structure and applying Lagrangian dual decomposition, respectively. Based on the obtained solutions of the two subproblems, we design an iterative algorithm for satellite MEC, and theoretically analyze its effectiveness, convergence and complexity. Simulation results verify that our proposed algorithm converges fast, and outperforms both full offloading and local computing algorithms. Besides, it is also observed that improving the computing capacities of satellite MEC servers helps to save the energy of users.},
booktitle = {Proceedings of the 2022 11th International Conference on Networks, Communication and Computing},
pages = {161–166},
numpages = {6},
keywords = {computation offloading, multi-access edge computing, resource allocation, Satellite networks},
location = {Beijing, China},
series = {ICNCC '22}
}

@inproceedings{10.1145/3545008.3545079,
author = {Cui, Guangming and He, Qiang and Xia, Xiaoyu and Chen, Feifei and Yang, Yun},
title = {Energy-Efficient Edge Server Management for Edge Computing: A Game-Theoretical Approach},
year = {2023},
isbn = {9781450397339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545008.3545079},
doi = {10.1145/3545008.3545079},
abstract = {Similar to cloud servers which are well-known energy consumers, edge servers running 24/7 jointly consume a tremendous amount of energy and thus require energy-saving management. However, the unique characteristics of edge computing make it a new and challenging problem to manage edge servers in an energy-efficient manner. First, an individual edge server is usually used to serve a specific region. The temporal distribution of end-users in the area impacts the edge server’s energy utilization. Second, multiple base stations may cover an end-user simultaneously and the end-user can be served by the physical machines attached to any of the base stations. Serving the end-users in an area with minimum physical machines can minimize the edge servers’ overall energy consumption. Third, physical machines facilitating an edge server can be powered off individually when not needed to minimize the edge server’s energy consumption. We formulate this Energy-efficient Edge Server Management (EESM) problem and analyze its problem hardness. Next, a game-theoretical approach, i.e., EESM-G, is proposed to address EESM problems efficiently. The superior performance of EESM-G is tested on a public real-world dataset.},
booktitle = {Proceedings of the 51st International Conference on Parallel Processing},
articleno = {69},
numpages = {11},
keywords = {edge computing, Energy-efficient Edge Server Management, potential game, energy consumption},
location = {Bordeaux, France},
series = {ICPP '22}
}

@inproceedings{10.1145/2600212.2600216,
author = {Mittal, Sparsh and Vetter, Jeffrey S. and Li, Dong},
title = {Improving Energy Efficiency of Embedded DRAM Caches for High-End Computing Systems},
year = {2014},
isbn = {9781450327497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600212.2600216},
doi = {10.1145/2600212.2600216},
abstract = {The number of cores in a single chip in the nodes of high-end computing systems is on rise, due, in part, to a number of constraints, such as power consumption. With this, the size of the last level cache (LLC) has also increased significantly. Since LLCs built with SRAM consume high leakage power, power consumption of LLCs is becoming a significant fraction of processor power consumption. To address this issue, researchers have used embedded DRAM (eDRAM) LLCs which consume low leakage power. However, eDRAM caches consume a significant amount of energy in the form of refresh energy. In this paper, we propose ESTEEM, an energy saving technique for embedded DRAM caches. ESTEEM uses dynamic cache reconfiguration to turn off a portion of the cache to save both leakage and refresh energy. It logically divides the cache sets into multiple modules and turns off possibly different number of ways in each module. Microarchitectural simulations confirm that ESTEEM is effective in improving performance and energy efficiency and provides better results compared to a recently-proposed eDRAM cache energy saving technique, namely Refrint. For single and dual-core simulations, the average energy saving in memory subsystem (LLC+main memory) with ESTEEM is 25.8% and 32.6% respectively, and the average weighted speedup is 1.09x and 1.22x respectively. Additional experiments confirm that ESTEEM works well for a wide-range of system and algorithm parameters.},
booktitle = {Proceedings of the 23rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {99–110},
numpages = {12},
keywords = {low-power, leakage energy saving, embedded dram (edram) cache, cache reconfiguration, refresh energy saving},
location = {Vancouver, BC, Canada},
series = {HPDC '14}
}

@proceedings{10.1145/1791314,
title = {e-Energy '10: Proceedings of the 1st International Conference on Energy-Efficient Computing and Networking},
year = {2010},
isbn = {9781450300421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Passau, Germany}
}

@inproceedings{10.1145/2980147.2980157,
author = {Ravindran, Kaliappa and Iannelli, Michael},
title = {Data-Oriented Abstraction of Virtual Sensors for Energy-Aware Embedded Software Systems},
year = {2016},
isbn = {9781450342544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2980147.2980157},
doi = {10.1145/2980147.2980157},
abstract = {We analyze the computing and communications as incorporated in networked objects (IoT): such as sensors, with focus on the performance and QoS aspects (e.g., latency of sensor data delivery to end-user). We advocate the offloading of complex computational tasks from the field-deployed low-capability sensor devices to cloud-based remote machines when feasible. In addition to the improved latency performance, the offloading of complex sensor tasks lowers the energy consumption of sensor devices. A key element of our IoT system architecture is the use of layered sensing techniques to determine the offloading of sensor tasks and the network transfer of sensor data. The computational cycles expended and network data transfer overhead vis-a-vis the energy consumption incurred therein, are factored in the partitioning of sensor tasks. Given the large-dimensionality of sensor input data, our architecture incorporates the accuracy and timeliness of sensor outputs as the controllable application-level quality parameters. The paper describes a case study of Optical Character Recognition to corroborate our approach.},
booktitle = {Proceedings of the 2nd Workshop on Experiences in the Design and Implementation of Smart Objects},
pages = {53–58},
numpages = {6},
keywords = {sensor replication systems, sensor faults &amp; data errors, large-dimensional data, distributed control &amp; management, adaptive sensing, replica voting},
location = {New York City, New York},
series = {SmartObjects '16}
}

@inproceedings{10.1145/3482632.3482695,
author = {Chen, Lifang and Ding, Wei},
title = {Green Clothing Design Based on Computer Aided Design in Ecological Times},
year = {2021},
isbn = {9781450390255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3482632.3482695},
doi = {10.1145/3482632.3482695},
abstract = {With the continuous development of society and economy, people's living standards have also been continuously improved, and the ecological and environmental problems have gradually attracted everyone's attention. With the popularization of green ecology, consumers have new requirements for clothing, from the traditional emphasis on beauty and practicality to the emphasis on environmental protection and health. The clothing industry has integrated the concept of green life into the clothing design, taking nature as the clothing design concept, and from the perspective of environmental protection, designing a kind of healthy clothing with zero pollution and beneficial to human body. Green clothing design is to save resources and energy as much as possible and reduce pollution in the production of clothing under the condition of ensuring the application function, quality and use time of clothing products. The relationship between computer aided design and fashion design is very close. The application of computer aided design in fashion design can promote the scientific development of fashion design in China. This paper mainly analyzes the concept of green clothing design based on computer aided design in ecological era, and puts forward corresponding design strategies.},
booktitle = {2021 4th International Conference on Information Systems and Computer Aided Education},
pages = {302–306},
numpages = {5},
location = {Dalian, China},
series = {ICISCAE 2021}
}

@inproceedings{10.1145/3289602.3293989,
author = {Azari, Elham and Dengi, Aykut and Vrudhula, Sarma},
title = {An Energy-Efficient FPGA Implementation of an LSTM Network Using Approximate Computing},
year = {2019},
isbn = {9781450361378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3289602.3293989},
doi = {10.1145/3289602.3293989},
abstract = {Long Short-Term Memory (LSTM) Recurrent Neural network (RNN) is known for its capability in modeling temporal aspects of data and has been shown to produce promising results in sequence learning tasks such as language modeling. However, due to the large number of model parameters and compute-intensive operations, existing FPGA implementations of LSTM cells are not sufficiently energy-efficient as they require large area and exhibit high power consumption. This work describes a substantially different hardware implementation of an LSTM which includes several architectural innovations to achieve high throughput and energy-efficiency. This paper includes extensive exploration of the design trade-offs and demonstrates the advantages for one common application - language modeling. Implementation of the design on a Xilinx Zynq XC7Z030 FPGA for language modeling shows significant improvements in throughput and energy-efficiency as compared to the state-of-the-art designs. It is worth mentioning that the proposed LSTM hardware architecture is also applicable to other applications that use LSTM as part of the neural network model (e.g., CNN-RNN models) or in whole (e.g., RNN models).},
booktitle = {Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {305–306},
numpages = {2},
keywords = {recurrent neural network, long short-term memory, fpga, hardware acceleration},
location = {Seaside, CA, USA},
series = {FPGA '19}
}

@inproceedings{10.1145/2897937.2898011,
author = {Kim, Kyounghoon and Kim, Jungki and Yu, Joonsang and Seo, Jungwoo and Lee, Jongeun and Choi, Kiyoung},
title = {Dynamic Energy-Accuracy Trade-off Using Stochastic Computing in Deep Neural Networks},
year = {2016},
isbn = {9781450342360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897937.2898011},
doi = {10.1145/2897937.2898011},
abstract = {This paper presents an efficient DNN design with stochastic computing. Observing that directly adopting stochastic computing to DNN has some challenges including random error fluctuation, range limitation, and overhead in accumulation, we address these problems by removing near-zero weights, applying weight-scaling, and integrating the activation function with the accumulator. The approach allows an easy implementation of early decision termination with a fixed hardware design by exploiting the progressive precision characteristics of stochastic computing, which was not easy with existing approaches. Experimental results show that our approach outperforms the conventional binary logic in terms of gate area, latency, and power consumption.},
booktitle = {Proceedings of the 53rd Annual Design Automation Conference},
articleno = {124},
numpages = {6},
keywords = {energy efficiency, deep learning, stochastic computing, deep neural networks},
location = {Austin, Texas},
series = {DAC '16}
}

@article{10.1145/3511094,
author = {Muralidhar, Rajeev and Borovica-Gajic, Renata and Buyya, Rajkumar},
title = {Energy Efficient Computing Systems: Architectures, Abstractions and Modeling to Techniques and Standards},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {11s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3511094},
doi = {10.1145/3511094},
abstract = {Computing systems have undergone a tremendous change in the last few decades with several inflexion points. While Moore’s law guided the semiconductor industry to cram more and more transistors and logic into the same volume, the limits of instruction-level parallelism (ILP) and the end of Dennard’s scaling drove the industry towards multi-core chips. More recently, we have entered the era of domain-specific architectures (DSA) and chips for new workloads like artificial intelligence (AI) and machine learning (ML). These trends continue, arguably with other limits, along with challenges imposed by tighter integration, extreme form factors and increasingly diverse workloads, making systems more complex to architect, design, implement and optimize from an energy efficiency perspective. Energy efficiency has now become a first order design parameter and constraint across the entire spectrum of computing devices.Many research surveys have gone into different aspects of energy efficiency techniques implemented in hardware and microarchitecture across devices, servers, HPC/cloud, data center systems along with improved software, algorithms, frameworks, and modeling energy/thermals. Somewhat in parallel, the semiconductor industry has developed techniques and standards around specification, modeling/simulation, benchmarking and verification of complex chips; these areas have not been addressed in detail by previous research surveys. This survey aims to bring these domains holistically together, present the latest in each of these areas, highlight potential gaps and challenges, and discuss opportunities for the next generation of energy efficient systems. The survey is composed of a systematic categorization of key aspects of building energy efficient systems - (1) specification - the ability to precisely specify the power intent, attributes or properties at different layers (2) modeling and simulation of the entire system or subsystem (hardware or software or both) so as to be able to experiment with possible options and perform what-if analysis, (3) techniques used for implementing energy efficiency at different levels of the stack, (4) verification techniques used to provide guarantees that the functionality of complex designs are preserved, and (5) energy efficiency benchmarks, standards and consortiums that aim to standardize different aspects of energy efficiency, including cross-layer optimizations.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {236},
numpages = {37},
keywords = {low power, low power optimizations, specification, Energy efficiency, platform-level power management, modeling, dynamic power management}
}

@inproceedings{10.1145/3185768.3186313,
author = {McGough, A. Stephen and Forshaw, Matthew},
title = {Evaluation of Energy Consumption of Replicated Tasks in a Volunteer Computing Environment},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185768.3186313},
doi = {10.1145/3185768.3186313},
abstract = {High Throughput Computing allows workloads of many thousands of tasks to be performed efficiently over many distributed resources and frees the user from the laborious process of managing task deployment, execution and result collection. However, in many cases the High Throughput Computing system is comprised from volunteer computational resources where tasks may be evicted by the owner of the resource. This has two main disadvantages. First, tasks may take longer to run as they may require multiple deployments before finally obtaining enough time on a resource to complete. Second, the wasted computation time will lead to wasted energy. We may be able to reduce the effect of the first disadvantage here by submitting multiple replicas of the task and take the results from the first one to complete. This, though, could lead to a significant increase in energy consumption. Thus we desire to only ever submit the minimum number of replicas required to run the task in the allocated time whilst simultaneously minimising energy. In this work we evaluate the use of fixed replica counts and Reinforcement Learning on the proportion of task which fail to finish in a given time-frame and the energy consumed by the system.},
booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {85–90},
numpages = {6},
keywords = {machine learning, simulation, trace-driven, energy},
location = {Berlin, Germany},
series = {ICPE '18}
}

@proceedings{10.1145/2318716,
title = {e-Energy '11: Proceedings of the 2nd International Conference on Energy-Efficient Computing and Networking},
year = {2011},
isbn = {9781450313131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {e-Energy 2011 is the second instance of a new conference exploring the intersection of networking and energy efficiency, organized in cooperation with ACM SIGCOMM. The first conference took place in Passau, Germany in April 2010.This year, we received a total of sixteen full papers and twelve discussion papers. After a careful review process in which each paper received, on average, three reviews, we selected nine regular and four discussion papers for presentation. The authors represent a broad range of countries, with authors from Europe, North America and Asia.The papers illustrate the range of research problems in this field, from characterizing data center energy consumption to motivating general energy efficiency, from low-level video decoding to system level issues, and from backbone efficiency to LTE.e-Energy attempts to bridge the gap between academic research and industrial practice. We invited five industrial talks, organized by Jaafar Elmirghani. In addition, we offered the opportunity for last-minute work-in-progress posters to encourage the exchange of ideas among participants. Eight such posters were presented.},
location = {New York, New York, USA}
}

@inproceedings{10.1145/3125502.3125554,
author = {Burke, Dave and Jenkus, Dainius and Qiqieh, Issa and Shafik, Rishad and Das, Shidhartha and Yakovlev, Alex},
title = {Significance-Driven Adaptive Approximate Computing for Energy-Efficient Image Processing Applications: Special Session Paper},
year = {2017},
isbn = {9781450351850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3125502.3125554},
doi = {10.1145/3125502.3125554},
abstract = {With increasing resolutions the volume of data generated by image processing applications is escalating dramatically. When coupled with real-time performance requirements, reducing energy consumption for such a large volume of data is proving challenging.},
booktitle = {Proceedings of the Twelfth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis Companion},
articleno = {28},
numpages = {2},
location = {Seoul, Republic of Korea},
series = {CODES '17}
}

@article{10.1145/3620671,
author = {Liang, Dehua and Awano, Hiromitsu and Miura, Noriyuki and Shiomi, Jun},
title = {A Robust and Energy Efficient Hyperdimensional Computing System for Voltage-Scaled Circuits},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1539-9087},
url = {https://doi.org/10.1145/3620671},
doi = {10.1145/3620671},
abstract = {Voltage scaling is one of the most promising approaches for energy efficiency improvement but also brings challenges to fully guaranteeing stable operation in modern VLSI. To tackle such issues, we further extend the DependableHD to the second version DependableHDv2, a HyperDimensional Computing (HDC) system that can tolerate bit-level memory failure in the low voltage region with high robustness. DependableHDv2 introduces the concept of margin enhancement for model retraining and utilizes noise injection to improve the robustness, which is capable of application in most state-of-the-art HDC algorithms. We additionally propose the dimension-swapping technique, which aims at handling the stuck-at errors induced by aggressive voltage scaling in the memory cells. Our experiment shows that under 8% memory stuck-at error, DependableHDv2 exhibits a 2.42% accuracy loss on average, which achieves a 14.1 \texttimes{} robustness improvement compared to the baseline HDC solution. The hardware evaluation shows that DependableHDv2 supports the systems to reduce the supply voltage from 430mV to 340mV for both item Memory and Associative Memory, which provides a 41.8% energy consumption reduction while maintaining competitive accuracy performance.},
note = {Just Accepted},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
keywords = {embedded systems, SRAMs, voltage-scaling, hyper-dimensional computing, energy efficiency, neural networks, fault tolerance}
}

@inproceedings{10.1145/3576842.3589179,
author = {Schulthess, Lukas and Salzmann, Tiago and Vogt, Christian and Magno, Michele},
title = {Poster Abstract: A LoRa-Based Energy-Efficient Sensing System for Urban Computing},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576842.3589179},
doi = {10.1145/3576842.3589179},
abstract = {Public space architecture requires reliable data to optimize city resources and enhance their attractiveness. The feedback on acceptance of these changes by the population currently relies on subjective questionnaires or objective but cost-intensive observations, mobile data usage, or video surveillance, which does not preserve privacy. To collect data on public square utilization and usage anonymously for urban computing, this work presents a low-cost, low-power, and privacy-preserving sensing system based on low-power sensor nodes. It is capable of tracking the usage of public chairs in squares and parks by monitoring environmental noise, chair utilization, chair position, temperature, and humidity while keeping maintenance costs low. The final sensing system’s robust operation is proven by field tests at two public squares in a city, providing real-time measurements over a city-wide LoRaWAN network. The custom-developed sensor node consumes 33.65 mWh per day under worst-case conditions. Depending on the weather condition, the sensor can increase its overall battery lifetime by a minimum of 20 percent and can temporarily reach full self-sustainability which allows data collection over the time period of interest.},
booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
pages = {481–482},
numpages = {2},
keywords = {urban computing, Smart city, smart sensing, IoT, WWAN},
location = {San Antonio, TX, USA},
series = {IoTDI '23}
}

@inproceedings{10.1145/3479239.3485692,
author = {Tian, Xianzhong and Zhou, Lu and Xu, Ting},
title = {Global Energy Optimization Strategy Based on Delay Constraints in Edge Computing Environment},
year = {2021},
isbn = {9781450390774},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479239.3485692},
doi = {10.1145/3479239.3485692},
abstract = {Edge Computing is one of the core technology of 5G networks. Edge computing deploys servers at the edge of the wireless access network, sinking cloud computing capabilities to the edge of the network, sharing the computing pressure of mobile users nearby, and improving the computing power of the entire network. Energy consumption is one of the important research issues of edge computing. At present, research on edge computing focuses on the energy consumption of terminal device, while little attention is paid to the energy consumption of edge servers. In this paper, considering the above two kinds of energy consumption, a global energy optimization strategy based on delay constraint in edge computing environment is proposed. Specifically, first, we use queuing theory to analyze the average delay of each terminal device and edge cloud processing computing tasks in the Internet of Things network, and the average delay of the entire system processing computing tasks. Secondly, we use the average delay as a constraint to establish a mathematical model for minimizing the total energy consumption of the device and the server. Then, we design a genetic algorithm-based offloading computation optimization algorithm to solve the above problems, so as to obtain the number of running servers in the edge cloud and the offload probability of IoT devices. Finally, the goal of minimizing the energy consumption of the overall system under the time delay constraint is achieved. The simulation experiment verifies the effectiveness of the energy optimization strategy.},
booktitle = {Proceedings of the 24th International ACM Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {33–40},
numpages = {8},
keywords = {edge computing, IoT, computing offloading, SDN},
location = {Alicante, Spain},
series = {MSWiM '21}
}

@inproceedings{10.1145/3394885.3431612,
author = {Ergun, Kazim and Ayoub, Raid and Mercati, Pietro and Liu, Dancheng and Rosing, Tajana},
title = {Energy and QoS-Aware Dynamic Reliability Management of IoT Edge Computing Systems},
year = {2021},
isbn = {9781450379991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394885.3431612},
doi = {10.1145/3394885.3431612},
abstract = {The Internet of Things (IoT) systems, as any electronic or mechanical system, are prone to failures. Hard failures in hardware due to aging and degradation are particularly important since they are irrecoverable, requiring maintenance for the replacement of defective parts, at high costs. In this paper, we propose a novel dynamic reliability management (DRM) technique for IoT edge computing systems to satisfy the Quality of Service (QoS) and reliability requirements while maximizing the remaining energy of the edge device batteries. We formulate a state-space optimal control problem with a battery energy objective, QoS, and terminal reliability constraints. We decompose the problem into low-overhead subproblems and solve it employing a hierarchical and multi-timescale control approach, distributed over the edge devices and the gateway. Our results, based on real measurements and trace-driven simulation demonstrate that the proposed scheme can achieve a similar battery lifetime compared to the state-of-the-art approaches while satisfying reliability requirements, where other approaches fail to do so.},
booktitle = {Proceedings of the 26th Asia and South Pacific Design Automation Conference},
pages = {561–567},
numpages = {7},
keywords = {Edge Computing, Internet of Things, Dynamic Reliability Management},
location = {Tokyo, Japan},
series = {ASPDAC '21}
}

@inproceedings{10.1145/2593069.2593132,
author = {Rahimi, Abbas and Ghofrani, Amirali and Lastras-Montano, Miguel Angel and Cheng, Kwang-Ting and Benini, Luca and Gupta, Rajesh K.},
title = {Energy-Efficient GPGPU Architectures via Collaborative Compilation and Memristive Memory-Based Computing},
year = {2014},
isbn = {9781450327305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593069.2593132},
doi = {10.1145/2593069.2593132},
abstract = {Thousands of deep and wide pipelines working concurrently make GPGPU high power consuming parts. Energy-efficiency techniques employ voltage overscaling that increases timing sensitivity to variations and hence aggravating the energy use issues. This paper proposes a method to increase spatiotemporal reuse of computational effort by a combination of compilation and micro-architectural design. An associative memristive memory (AMM) module is integrated with the floating point units (FPUs). Together, we enable fine-grained partitioning of values and find high-frequency sets of values for the FPUs by searching the space of possible inputs, with the help of application-specific profile feedback. For every kernel execution, the compiler pre-stores these high-frequent sets of values in AMM modules -- representing partial functionality of the associated FPU-- that are concurrently evaluated over two clock cycles. Our simulation results show high hit rates with 32-entry AMM modules that enable 36% reduction in average energy use by the kernel codes. Compared to voltage overscaling, this technique enhances robustness against timing errors with 39% average energy saving.},
booktitle = {Proceedings of the 51st Annual Design Automation Conference},
pages = {1–6},
numpages = {6},
keywords = {memory-based computing, compiler, timing errors, GPGPUs, memristor, Energy efficiency, variations},
location = {San Francisco, CA, USA},
series = {DAC '14}
}

@inproceedings{10.1145/1629501.1629557,
author = {Herrick, Dan R. and Ritschard, Mark R.},
title = {Greening Your Computing Technology, the near and Far Perspectives},
year = {2009},
isbn = {9781605584775},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629501.1629557},
doi = {10.1145/1629501.1629557},
abstract = {"Green" computing has become a popular and trendy topic. Many companies are exploring methods and policies to use green technologies. Most policies merely scratch the surface, however, of greening computing technology, often seen as a necessary energy evil. At Colorado State University, we have gone beyond the surface polish and explored some practical solutions to energy efficiency, consumption reduction, and environmental stewardship. Sensitive to the current economic climate, we will discuss how going green can have a significant positive impact on your budget as well. We will present a cafeteria-style plan that campus IT administrators can use to reduce energy use and to reduce or more efficiently use consumables. Projects range from server room (re)design and rethinking computing infrastructure, to energy-wise purchasing decisions and software performance controls. Thin client technology, facility planning, vendor collaboration, client base buy-in, virtualization, energy audits, and using software to balance performance and efficiency will all be on the menu. Wait until you hear how we incorporate the power of the bicycle into computing technology support!},
booktitle = {Proceedings of the 37th  Annual ACM SIGUCCS Fall Conference: Communication and Collaboration},
pages = {297–304},
numpages = {8},
keywords = {energy efficiency, green computing},
location = {St. Louis, Missouri, USA},
series = {SIGUCCS '09}
}

@inproceedings{10.1145/3193092.3193103,
author = {Jamali, Hossein and Karimi, Abbas and Haghighizadeh, Mehdi},
title = {A New Method of Cloud-Based Computation Model for Mobile Devices: Energy Consumption Optimization in Mobile-to-Mobile Computation Offloading},
year = {2018},
isbn = {9781450363600},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3193092.3193103},
doi = {10.1145/3193092.3193103},
abstract = {Today, cell phones have great important role in everyday lives. They are the most effective and achievable communication and computation devices that necessitate no exact time or location. Fast development of movable calculation created an energetic power to develop a synchronous technology in the markets. Anyhow movable devices are encountering with various challenges concerning available resources such as: battery, storage, bandwidth, security, and mobility. On the other side, limitation of resources in these phones has a great effect on the quality of the services. The most important limitation is the energy consuming that leads us to use the device for calculation, in spite of the accessibility of other sources. The best suggested solutions are getting rid of computation on the cloud and use of portable cloud for computation. But If there was no accessible cloud or an accurace of disconnection with the cloud, cell phones are the best to use. According to a mathematical algorithm based on Lyapunov optimization and regarding the requirement time for suitable program, we will try to introduce a dynamic way which its limitation analysis reveals that offlooding the computation considering the limitation of time leads to a less spending of power and energy resembled the current algorithm.},
booktitle = {Proceedings of the 6th International Conference on Communications and Broadband Networking},
pages = {32–37},
numpages = {6},
keywords = {Energy consuming, Mobile cloud computing, Cloud computing, computation offloading, energy minimization},
location = {Singapore, Singapore},
series = {ICCBN '18}
}

@article{10.1109/TNET.2018.2841758,
author = {Chen, Lixing and Zhou, Sheng and Xu, Jie},
title = {Computation Peer Offloading for Energy-Constrained Mobile Edge Computing in Small-Cell Networks},
year = {2018},
issue_date = {August 2018},
publisher = {IEEE Press},
volume = {26},
number = {4},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2018.2841758},
doi = {10.1109/TNET.2018.2841758},
abstract = {The ultra-dense deployment of small-cell base stations SBSs endowed with cloud-like computing functionalities paves the way for pervasive mobile edge computing, enabling ultra-low latency and location-awareness for a variety of emerging mobile applications and the Internet of Things. To handle spatially uneven computation workloads in the network, cooperation among SBSs via workload peer offloading is essential to avoid large computation latency at overloaded SBSs and provide high quality of service to end users. However, performing effective peer offloading faces many unique challenges due to limited energy resources committed by self-interested SBS owners, uncertainties in the system dynamics, and co-provisioning of radio access and computing services. This paper develops a novel online SBS peer offloading framework, called online peer offloading OPEN, by leveraging the Lyapunov technique, in order to maximize the long-term system performance while keeping the energy consumption of SBSs below individual long-term constraints. OPEN works online without requiring information about future system dynamics, yet provides provably near-optimal performance compared with the oracle solution that has the complete future information. In addition, this paper formulates a peer offloading game among SBSs and analyzes its equilibrium and efficiency loss in terms of the price of anarchy to thoroughly understand SBSs’ strategic behaviors, thereby enabling decentralized and autonomous peer offloading decision making. Extensive simulations are carried out and show that peer offloading among SBSs dramatically improves the edge computing performance.},
journal = {IEEE/ACM Trans. Netw.},
month = {aug},
pages = {1619–1632},
numpages = {14}
}

@inproceedings{10.1145/3577065.3577094,
author = {Li, Dejian and Cui, Bingrong and Li, Kaixin and Shen, Tianjun and Sun, Yi and Chang, Shaonan},
title = {Energy Efficient Offloading Strategy Faced to Edge Computing-Enhanced Distributed Photovoltaic Smart Meter},
year = {2023},
isbn = {9781450397797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577065.3577094},
doi = {10.1145/3577065.3577094},
abstract = {With the rapid development of Power Internet of Things and the increase in the number of distributed photovoltaic smart meter (DPSM) technology, edge computing is required to support the low-latency computing service. Current works mainly focus on task offloading, the cooperation among smart meter devices is lack of attention. In order to reduce the task execution delay in of the network, a computing resource sharing architecture based on D2D is proposed. In order to reduce the processing delay and energy consumption of DPSM, we propose a task offloading model faced to DPSM. To minimize the total task execution delay, we formulate a Mixed-Integer Non-Linear Programming (MINLP) problem which optimizing task offloading and resource allocation jointly. Then, a generalized Benders decomposition algorithm combined with particle swarm optimization is proposed to solve the problem. Simulation results show that the proposed strategy can effectively improve the measurement efficiency and reduce the computational cost.},
booktitle = {Proceedings of the 2022 5th International Conference on Telecommunications and Communication Engineering},
pages = {161–164},
numpages = {4},
keywords = {Task offloading, Cost optimization, Edge computing, Smart meter},
location = {Chengdu, China},
series = {ICTCE '22}
}

@inproceedings{10.5555/2492708.2492956,
author = {Hankendi, Can and Coskun, Ayse K.},
title = {Reducing the Energy Cost of Computing through Efficient Co-Scheduling of Parallel Workloads},
year = {2012},
isbn = {9783981080186},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Future computing clusters will prevalently run parallel workloads to take advantage of the increasing number of cores on chips. In tandem, there is a growing need to reduce energy consumption of computing. One promising method for improving energy efficiency is co-scheduling applications on compute nodes. Efficient consolidation for parallel workloads is a challenging task as a number of factors, such as scalability, inter-thread communication patterns, or memory access frequency of the applications affect the energy/performance tradeoffs. This paper evaluates the impact of co-scheduling parallel workloads on the energy consumed per useful work done on real-life servers. Based on this analysis, we propose a novel multi-level technique that selects the best policy to co-schedule multiple workloads on a multi-core processor. Our measurements demonstrate that the proposed multi-level co-scheduling method improves the overall energy per work savings of the multi-core system up to 22% compared to state-of-the-art techniques.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {994–999},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '12}
}

@inproceedings{10.1145/1851290.1851296,
author = {Chen, Yanpei and Ganapathi, Archana and Katz, Randy H.},
title = {To Compress or Not to Compress - Compute vs. IO Tradeoffs for Mapreduce Energy Efficiency},
year = {2010},
isbn = {9781450301961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851290.1851296},
doi = {10.1145/1851290.1851296},
abstract = {Compression enables us to shift resource bottlenecks between IO and CPU. In modern datacenters, where energy efficiency is a growing concern, the benefits of using compression have not been completely exploited. As MapReduce represents a common computation framework for Internet datacenters, we develop a decision algorithm that helps MapReduce users identify when and where to use compression. For some jobs, using compression gives energy savings of up to 60%. We believe our findings will provide signficant impact on improving datacenter energy efficiency.},
booktitle = {Proceedings of the First ACM SIGCOMM Workshop on Green Networking},
pages = {23–28},
numpages = {6},
keywords = {Hadoop, compression, MapReduce},
location = {New Delhi, India},
series = {Green Networking '10}
}

@article{10.1145/3507906,
author = {Chavhan, Suresh and Gupta, Deepak and Gochhayat, Sarada Prasad and N., Chandana B. and Khanna, Ashish and Shankar, K. and Rodrigues, Joel J. P. C.},
title = {Edge Computing AI-IoT Integrated Energy-Efficient Intelligent Transportation System for Smart Cities},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {4},
issn = {1533-5399},
url = {https://doi.org/10.1145/3507906},
doi = {10.1145/3507906},
abstract = {With the advancement of information and communication technologies (ICTs), there has been high-scale utilization of IoT and adoption of AI in the transportation system to improve the utilization of energy, reduce greenhouse gas (GHG) emissions, increase quality of services, and provide many extensive benefits to the commuters and transportation authorities. In this article, we propose a novel edge-based AI-IoT integrated energy-efficient intelligent transport system for smart cities by using a distributed multi-agent system. An urban area is divided into multiple regions, and each region is sub-divided into a finite number of zones. At each zone an optimal number of RSUs are installed along with the edge computing devices. The MAS deployed at each RSU collects a huge volume of data from the various sensors, devices, and infrastructures. The edge computing device uses the collected raw data from the MAS to process, analyze, and predict. The predicted information will be shared with the neighborhood RSUs, vehicles, and cloud by using MAS with the help of IoT. The predicted information can be used by freight vehicles to maintain smooth and steady movement, which results in reduction in GHG emissions and energy consumption, and finally improves the freight vehicles’ mileage by reducing traffic congestion in the urban areas. We have exhaustively carried out the simulation results and demonstrated the effectiveness of the proposed system.},
journal = {ACM Trans. Internet Technol.},
month = {nov},
articleno = {106},
numpages = {18},
keywords = {ITS, cloud computing, edge computing, Internet of Things, MAS, Artificial intelligence, cyber physical systems}
}

@inproceedings{10.5555/3539845.3540079,
author = {Varshika, M. Lakshmi and Balaji, Adarsha and Corradi, Federico and Das, Anup and Stuijt, Jan and Catthoor, Francky},
title = {Design of Many-Core Big Little μbrains for Energy-Efficient Embedded Neuromorphic Computing},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {As spiking-based deep learning inference applications are increasing in embedded systems, these systems tend to integrate neuromorphic accelerators such as μBrain to improve energy efficiency. We propose a μBrain-based scalable many-core neuromorphic hardware design to accelerate the computations of spiking deep convolutional neural networks (SDCNNs). To increase energy efficiency, cores are designed to be heterogeneous in terms of their neuron and synapse capacity (i.e., big vs. little cores), and they are interconnected using a parallel segmented bus interconnect, which leads to lower latency and energy compared to a traditional mesh-based Network-on-Chip (NoC). We propose a system software framework called SentryOS to map SDCNN inference applications to the proposed design. SentryOS consists of a compiler and a run-time manager. The compiler compiles an SDCNN application into sub-networks by exploiting the internal architecture of big and little μBrain cores. The run-time manager schedules these sub-networks onto cores and pipeline their execution to improve throughput. We evaluate the proposed big little many-core neuromorphic design and the system software framework with five commonly-used SDCNN inference applications and show that the proposed solution reduces energy (between 37% and 98%), reduces latency (between 9% and 25%), and increases application throughput (between 20% and 36%). We also show that SentryOS can be easily extended for other spiking neuromorphic accelerators such as Loihi and DYNAPs.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {1011–1016},
numpages = {6},
keywords = {many-core, spiking deep convolutional neural networks, μbrain, neuromorphic computing, embedded systems},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3093338.3093381,
author = {Dennis, Harold E.B. and Ward, Adam S. and Balson, Tyler and Li, Yuwei and Henschel, Robert and Slavin, Shawn and Simms, Stephen and Brunst, Holger},
title = {High Performance Computing Enabled Simulation of the Food-Water-Energy System: Simulation of Intensively Managed Landscapes},
year = {2017},
isbn = {9781450352727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3093338.3093381},
doi = {10.1145/3093338.3093381},
abstract = {Domain science experts are commonly limited by computational efficiency of their code and hardware resources available for execution of desired simulations. Here, we detail a collaboration between domain scientists focused on simulating an ensemble of climate and human management decisions to drive environmental (e.g., water quality) and economic (e.g., crop yield) outcomes. Briefly, the domain scientists developed a message passing interface to execute the formerly serial code across a number of processors, anticipating significant performance improvement by moving to a cluster computing environment from their desktop machines. The code is both too complex to efficiently re-code from scratch and has a shared codebase that must continue to function on desktop machines as well as the parallel implementation. However, inefficiencies in the code caused the LUSTRE filesystem to bottleneck performance for all users. The domain scientists collaborated with Indiana University's Science Applications and Performance Tuning and High Performance File System teams to address the unforeseen performance limitations. The non-linear process of testing software advances and hardware performance is a model of the failures and successes that can be anticipated in similar applications. Ultimately, through a series of iterative software and hardware advances the team worked collaboratively to increase performance of the code, cluster, and file system to enable more than 100-fold increases in performance. As a result, the domain science is able to assess ensembles of climate and human forcing on the model, and sensitivities of ecologically and economically important outcomes of intensively managed agricultural landscapes.},
booktitle = {Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact},
articleno = {43},
numpages = {10},
keywords = {filesystems, hpc, computer cluster, agro-ecosystem, Agro-IBIS, performance, vampir, benchmarking, case study, scaling, parallel computing, mpi, meta-data, modeling, lustre},
location = {New Orleans, LA, USA},
series = {PEARC '17}
}

@inproceedings{10.1145/3501409.3501525,
author = {Du, XinXin and Hu, XiaoHui and Zhao, JiaNan},
title = {Energy Efficient Routing Protocol for Internet of Vehicles Based on Software-Defined Network},
year = {2022},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501409.3501525},
doi = {10.1145/3501409.3501525},
abstract = {With the significant application and expansion of the Vehicle Ad Hoc Network (VANET), how to ensure routing data transmission between vehicles with limited energy resources is one of the most critical challenges in this network. To solve this problem, introducing software-defined network (SDN) architecture, the SDN is applied to form VANET SDN-VANET structure. And we use the advantages of genetic algorithms to propose an energy-saving routing algorithm (EEGA), which sends data from the source to the target vehicle with minimum energy cost and provides better QoS for the communication between vehicles. Finally, the SDN-VANET environment is built on the NS3 simulator, and validates the routing algorithm. The results show that EEGA can effectively select the relay node that meets the service requirements in the routing process, reduce the average E2E delay, reduce the packet loss rate and balance the network energy.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {642–646},
numpages = {5},
keywords = {Vehicle Ad-Hoc Network, software-defined network, QoS, Routing},
location = {Xiamen, China},
series = {EITCE '21}
}

@inproceedings{10.1145/3345312.3345467,
author = {Lemic, Filip and Akbar, Raja Usman and Marquez-Barja, Johann and Famaey, Jeroen},
title = {Assessing the Reliability of Energy Harvesting Terahertz Nanonetworks for Controlling Software-Defined Metamaterials},
year = {2019},
isbn = {9781450368971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345312.3345467},
doi = {10.1145/3345312.3345467},
abstract = {Electromagnetic nanonetworks operating in the terahertz (THz) frequency band are emerging as a promising technology for supporting a variety of nanoscale applications. At such scales, the use of batteries is in many cases infeasible, thus the nanonodes are envisioned to operate using only capacitors that rely on energy harvesting. This will result in constrained energy storage capacity with unpredictable charging rate, which will in turn yield non-periodic intermittent on-off behavior of the nanonodes. This paradigm is currently largely unexplored, hence it is challenging to make claims about the achievable network reliability. To provide initial insights, we investigate the reliability of nanoscale THz communication in a one-hop downlink broadcast scenario in face of intermittent on-off behavior of the receiving nanonodes. We do that because we believe that the reliable communication will be highly relevant for software-controlled metamaterial applications. Our results demonstrate the need for intelligent selection of energy levels for turning on and off the battery-less nanonodes. In addition and perhaps counter-intuitively, we demonstrate that the repetitions of packets substantially degrade the reliability of the considered nanonetwork.},
booktitle = {Proceedings of the Sixth Annual ACM International Conference on Nanoscale Computing and Communication},
articleno = {13},
numpages = {6},
keywords = {energy-harvesting, metamaterials, THz, nanonetwork, reliability},
location = {Dublin, Ireland},
series = {NANOCOM '19}
}

@inproceedings{10.5555/2442691.2442707,
author = {Bouhenguel, Redjem and Mahgoub, Imad and llyas, Mohammad},
title = {An Energy Efficient Model for Monitoring and Detecting Atrial Fibrillation in Wearable Computing},
year = {2012},
isbn = {9781936968602},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
abstract = {Current portable healthcare monitoring systems are small, battery-operated electrocardiograph devices that are used to record the heart's rhythm and activity. These on-body healthcare devices fall short on delivering real-time continuous monitoring of early detection of cardiac atrial fibrillation (A-Fib) when the symptoms last only a short period of time and require a long battery life. The focus of this paper is the design of an energy efficient model for real-time early detection of A-Fib in a wearable computing device. The design is realized by incorporating an A-Fib risk factor and a real-time A-Fib incidence-based detection algorithm. The results of the design show that the proposed energy efficient model performs better than a telemetry energy model. The design shows promising results in meeting the energy needs of real-time monitoring, detecting and reporting required in wearable computing healthcare applications.},
booktitle = {Proceedings of the 7th International Conference on Body Area Networks},
pages = {59–65},
numpages = {7},
keywords = {logistic regression model of atrial fibrillation, wearable computing, energy-aware model, real-time detection of cardiac atrial fibrillation, real-time monitoring},
location = {Oslo, Norway},
series = {BodyNets '12}
}

@article{10.1145/1151074.1151078,
author = {Hua, Shaoxiong and Qu, Gang and Bhattacharyya, Shuvra S.},
title = {Energy-Efficient Embedded Software Implementation on Multiprocessor System-on-Chip with Multiple Voltages},
year = {2006},
issue_date = {May 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1539-9087},
url = {https://doi.org/10.1145/1151074.1151078},
doi = {10.1145/1151074.1151078},
abstract = {This paper develops energy-driven completion ratio guaranteed scheduling techniques for the implementation of embedded software on multiprocessor systems with multiple supply voltages. We leverage application's performance requirements, uncertainties in execution time, and tolerance for reasonable execution failures to scale each processor's supply voltage at run-time to reduce the multiprocessor system's total energy consumption. Specifically, we study how to trade the difference between the system's highest achievable completion ratio Qmax and the required completion ratio Q0 for energy saving. First, we propose a best-effort energy minimization algorithm (BEEM1) that achieves Qmax with the provably minimum energy consumption. We then relax its unrealistic assumption on the application's real execution time and develop algorithm BEEM2 that only requires the application's best- and worst-case execution times. Finally, we propose a hybrid offline on-line completion ratio guaranteed energy minimization algorithm (QGEM) that provides the required Q0 with further energy reduction based on the probabilistic distribution of the application's execution time. We implement the proposed algorithms and verify their energy efficiency on real-life DSP applications and the TGFF random benchmark suite. BEEM1, BEEM2, and QGEM all provide the required completion ratio with average energy reduction of 28.7, 26.4, and 35.8%, respectively.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {may},
pages = {321–341},
numpages = {21},
keywords = {hardware/software co-design, multi-processor, Energy minimization, completion ratio, multiple voltage}
}

@inproceedings{10.5555/2755753.2755881,
author = {Zhao, Mengying and Li, Qingan and Xie, Mimi and Liu, Yongpan and Hu, Jingtong and Xue, Chun Jason},
title = {Software Assisted Non-Volatile Register Reduction for Energy Harvesting Based Cyber-Physical System},
year = {2015},
isbn = {9783981537048},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Wearable devices are important components as information collector in many cyber-physical systems. Energy harvesting instead of battery is a better power source for these wearable devices due to many advantages. However, harvested energy is naturally unstable and program execution will be interrupted frequently. Non-volatile processors demonstrate promising advantages to back up volatile state before the system energy is depleted. However, it also introduces non-negligible energy and area overhead. Since the chip size is a vital factor for wearable devices, in this work, we target non-volatile register reduction for application-specific systems. We propose to analyze the application program and determine efficient backup positions, by which the necessary non-volatile register file size can be significantly reduced. The evaluation results deliver an average of 62.9% reduction on non-volatile register file size for stack backup, with negligible storage overheads.},
booktitle = {Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition},
pages = {567–572},
numpages = {6},
location = {Grenoble, France},
series = {DATE '15}
}

@inproceedings{10.1109/UCC.2014.10,
author = {Maio, Vincenzo De and Nae, Vlad and Prodan, Radu},
title = {Evaluating Energy Efficiency of Gigabit Ethernet and Infiniband Software Stacks in Data Centres},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.10},
doi = {10.1109/UCC.2014.10},
abstract = {Reducing energy consumption has become a key issue for data centres, not only because of economical benefits but also for environmental and marketing reasons. Many approaches tackle this problem from the point of view of different hardware components, such as CPUs, storage and network interface cards (NIC). To this date, few works focused on the energy consumption of network transfers at the software level comprising their complete stacks with different energy characteristics, and the way the NIC selection impacts the energy consumption of applications. Since data centres often install multiple NICs on each node, investigating and comparing them at the software level has high potential to enhance the energy efficiency of applications on Cloud infrastructures. We present a comparative analysis of the energy consumption of the software stack of two of today's most used NICs in data centres, Ethernet and Infiniband. We carefully design for this purpose a set of benchmark experiments to assess the impact of different traffic patterns and interface settings on energy consumption. Using our benchmark results, we derive an energy consumption model for network transfers and evaluate its accuracy for a virtual machine migration scenario. Finally, we propose guidelines for NIC selection from an energy efficiency perspective for different application classes.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {21–28},
numpages = {8},
keywords = {ethernet, green computing, infiniband, energy awareness, data centres, green networking},
series = {UCC '14}
}

@inproceedings{10.1145/2961111.2962593,
author = {Rajan, Ajitha and Noureddine, Adel and Stratis, Panagiotis},
title = {A Study on the Influence of Software and Hardware Features on Program Energy},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962593},
doi = {10.1145/2961111.2962593},
abstract = {Software energy consumption has emerged as a growing concern in recent years. Managing the energy consumed by a software is, however, a difficult challenge due to the large number of factors affecting it -- namely, features of the processor, memory, cache, and other hardware components, characteristics of the program and the workload running, OS routines, compiler optimisations, among others. In this paper we study the relevance of numerous architectural and program features (static and dynamic) to the energy consumed by software. The motivation behind the study is to gain an understanding of the features affecting software energy and to provide recommendations on features to optimise for energy efficiency.In our study we used 58 subject desktop programs, each with their own workload, and from different application domains. We collected over 100 hardware and software metrics, statically and dynamically, using existing tools for program analysis, instrumentation and run time monitoring. We then performed statistical feature selection to extract the features relevant to energy consumption. We discuss potential optimisations for the selected features. We also examine whether the energy-relevant features are different from those known to affect software performance. The features commonly selected in our experiments were execution time, cache accesses, memory instructions, context switches, CPU migrations, and program length (Halstead metric). All of these features are known to affect software performance, in terms of running time, power consumed and latency.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {37},
numpages = {10},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@article{10.1145/1324177.1324180,
author = {Ma, Xiaojun and Huang, Jing and Lombardi, Fabrizio},
title = {A Model for Computing and Energy Dissipation of Molecular QCA Devices and Circuits},
year = {2008},
issue_date = {January 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/1324177.1324180},
doi = {10.1145/1324177.1324180},
abstract = {Quantum-dot Cellular Automata is an emerging technology that offers significant improvements over CMOS. Recently QCA has been advocated as a technology for implementing reversible computing. However, existing tools for QCA design and evaluation have limited capabilities. This paper presents a new mechanical-based model for computing in QCA. By avoiding a full quantum-thermodynamical calculation, it offers a classical view of the principles of QCA operation and can be used in evaluating energy dissipation for reversible computing. The proposed model is mechanically based and is applicable to six-dot (neutrally charged) QCA cells for molecular implementation. The mechanical model consists of a sleeve of changing shape; four electrically charged balls are connected by a stick that rotates around an axle in the sleeve. The sleeve acts as a clocking unit, while the angular position of the stick within the changing shape of the sleeve, identifies the phase for quasi-adiabatic switching. A thermodynamic analysis of the proposed model is presented. The behaviors of various QCA basic devices and circuits are analyzed using the proposed model. It is shown that the proposed model is capable of evaluating the energy consumption for reversible computing at device and circuit levels for molecular QCA implementation. As applicable to QCA, two clocking schemes are also analyzed for energy dissipation and performance (in terms of number of clocking zones).},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {jan},
articleno = {3},
numpages = {30},
keywords = {thermodynamic analysis, reversible computing, emerging technology, QCA}
}

@inproceedings{10.5555/2872599.2872614,
author = {Shoukourian, Hayk and Wilde, Torsten and Auweter, Axel and Bode, Arndt and Tafani, Daniele},
title = {Predicting Energy Consumption Relevant Indicators of Strong Scaling HPC Applications for Different Compute Resource Configurations},
year = {2015},
isbn = {9781510801011},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Finding the best energy-performance tradeoffs for High Performance Computing (HPC) applications is a major challenge for many modern supercomputing centers. With the increased focus on data center energy efficiency and the emergence of possible data center power constraints, making the right decision at a given time is becoming more important. A real-world situation like "can a given 1000 compute node application be executed at a maximum of 2.7 GHz CPU frequency without going over the energy provider defined power band, or the available monthly energy limit?" is just one example of the types of decisions HPC data centers will face. The previously developed Adaptive Energy and Power Consumption Prediction (AEPCP) model answers this question for the case of a fixed CPU frequency. This paper will extend the AEPCP process to enable the development of analytical models for estimating application execution time, power, and energy consumptions as functions of the number of compute nodes and maximum operating CPU frequency. Based on these analytical models, an adaptive model (Lightweight Adaptive Consumption Prediction (LACP)) is presented that implements the extended prediction process. This information allows for improved estimation of potential energy-performance costs and tradeoffs of applications and thus identifies the optimal resource configuration for specific data center boundary conditions.},
booktitle = {Proceedings of the Symposium on High Performance Computing},
pages = {115–126},
numpages = {12},
keywords = {power and energy capping, LACP, consumption modeling and prediction, HPC, compute node number and CPU frequency},
location = {Alexandria, Virginia},
series = {HPC '15}
}

@inproceedings{10.1145/3477314.3508388,
author = {Idrees, Ali Kadhum and Ali-Yahiya, Tara and Idrees, Sara Kadhum and Couturier, Raphael},
title = {Energy-Efficient Fog Computing-Enabled Data Transmission Protocol in Tactile Internet-Based Applications},
year = {2022},
isbn = {9781450387132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477314.3508388},
doi = {10.1145/3477314.3508388},
abstract = {Sensor nodes are one of the basic elements in the Tactile Internet-based fog computing architecture. They provide a huge amount of data to the network due to the widespread real-world applications that use these types of wireless devices. This huge number of data, transmitted by the sensor devices to the fog gateway and then to the cloud, leads to high communication costs, increased power consumption, and high latency at the fog gateway. These challenges would be considered as a hurdle in the Tactile Internet-based fog system. To tackle these challenges, this paper proposes an Energy-efficient Fog Computing-enabled Data Transmission (EFoCoD) protocol in Tactile Internet-based Applications. The protocol works on sensor devices level in the Tactile Internet-based fog computing architecture. EFoCoD protocol executes a Lightweight Data Redundancy Elimination (LiDaRE) Algorithm at the sensor level to reduce the collected data before transferring them to the smart fog gateway. To study the performance of the EFoCoD, it was compared to its counterpart protocols in the literature just like ATP and PFF. Simulation results show that EFoCoD outperforms these protocols in terms of energy consumption, transmitted data, and data accuracy.},
booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
pages = {206–209},
numpages = {4},
keywords = {data reduction, clustering, smart sensor nodes, fog computing, tactile internet, energy-efficiency},
location = {Virtual Event},
series = {SAC '22}
}

@inproceedings{10.1145/3069593.3069611,
author = {Nik, Wan Nor Shuhadah Wan and Zhou, Bing Bing},
title = {Energy-Aware Resource Selection for Asynchronous Replicated System in Utility-Based Computing Environments},
year = {2017},
isbn = {9781450348683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3069593.3069611},
doi = {10.1145/3069593.3069611},
abstract = {This paper addresses the problem of energy-aware resource selection for applications that update data in utility-based computing systems. The problem is complex to be solved, especially in asynchronous replicated system, since one should first provide a good prediction scheme on the performance evaluation of resource selection model in the presence of job that update data before the energy-efficiency issue can be addressed. With this in mind and by observing that simplicity implies efficiency and scalability, two approaches of energy-aware resource selection are proposed and developed. The main objective is to minimize the energy consumption while still preserves a minimum system performance degradation trade-offs. The proposed approaches exploit both the presence and the absence of knowledge on resource energy usage to select the best resources to run the job. Also, they take advantage on the nature of high performance of job execution in asynchronous replicated system in its resource selection decision making process. The experimental results proved that the proposed approaches are able to minimize resource energy usage while preserving minimum performance degradation trade-offs.},
booktitle = {Proceedings of the International Conference on High Performance Compilation, Computing and Communications},
pages = {11–16},
numpages = {6},
keywords = {Energy-efficient, Asynchronous Replication, Utility Computing, Resource Selection, Grid/Cloud Computing},
location = {Kuala Lumpur, Malaysia},
series = {HP3C-2017}
}

@inproceedings{10.1145/3242840.3242852,
author = {Zhang, Yunxiang and Yang, Xiaokun and Wu, Lei and Lu, Jiang and Sha, Kewei and Gajjar, Archit and He, Han},
title = {Exploring Slice-Energy Saving on an Video Processing FPGA Platform with Approximate Computing},
year = {2018},
isbn = {9781450365093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3242840.3242852},
doi = {10.1145/3242840.3242852},
abstract = {This paper proposes a scalable video processing platform on Field Programmable Gate Array (FPGA), providing several slice-energy cost solutions corresponding to different application constrains. Specifically three approximations of multipliers and two approximations of adders, along with the exact designs as well, are presented and integrated as twelve benchmarks to implement RGB to grayscale conversion as a case study. Experimental results show that the minimum slice-energy cost, integrated with approximate#2 adder and approximate#3 multiplier, achieves 25.17% slice-energy saving compared with the exact design by sacrificing the quality of results as 5.69% error for multiplier and 2.85% for adder.},
booktitle = {Proceedings of the 2nd International Conference on Algorithms, Computing and Systems},
pages = {138–143},
numpages = {6},
keywords = {Field Programmable Gate Array (FPGA), slice-energy cost, Approximate design},
location = {Beijing, China},
series = {ICACS '18}
}

@inproceedings{10.1145/3566097.3567859,
author = {Li, Yueting and Zhang, He and Wang, Xueyan and Cai, Hao and Zhang, Yundong and Lv, Shuqin and Liu, Renguang and Zhao, Weisheng},
title = {Toward Energy-Efficient Sparse Matrix-Vector Multiplication with near STT-MRAM Computing Architecture},
year = {2023},
isbn = {9781450397834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3566097.3567859},
doi = {10.1145/3566097.3567859},
abstract = {Sparse Matrix-Vector Multiplication (SpMV) is one of the vital computational primitives used in modern workloads. SpMV performs memory access, leading to unnecessary data transmission, massive data access, and redundant multiplicative accumulators. Therefore, we propose the near spin-transfer torque magnetic random access memory (STT-MRAM) processing architecture from three optimization perspectives. These optimizations include (1) the NMP controller receives the instruction through the AXI4 bus to implement the SpMV operation in the following steps, identifies valid data, and encodes the index depending on the kernel size, (2) the NMP controller uses high-level synthesis dataflow in the shared buffer for achieving better performance throughput while do not consume bus bandwidth, and (3) the configurable MACs are implemented in the NMP core without matching step entirely during the multiplication. Using these optimizations, the NMP architecture can access the pipelined STT-MRAM (read bandwidth is 26.7GB/s). The experimental simulation results show that this design achieves up to 66x and 28x speedup compared with state-of-the-art ones and 69x speedup without sparse optimization.},
booktitle = {Proceedings of the 28th Asia and South Pacific Design Automation Conference},
pages = {222–227},
numpages = {6},
keywords = {near memory processing, STT-MRAM, SpMV, energy efficient},
location = {Tokyo, Japan},
series = {ASPDAC '23}
}

@article{10.1145/3415580,
author = {Do, Jaeyoung and Ferreira, Victor C. and Bobarshad, Hossein and Torabzadehkashi, Mahdi and Rezaei, Siavash and Heydarigorji, Ali and Souza, Diego and Goldstein, Brunno F. and Santiago, Leandro and Kim, Min Soo and Lima, Priscila M. V. and Fran\c{c}a, Felipe M. G. and Alves, Vladimir},
title = {Cost-Effective, Energy-Efficient, and Scalable Storage Computing for Large-Scale AI Applications},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1553-3077},
url = {https://doi.org/10.1145/3415580},
doi = {10.1145/3415580},
abstract = {The growing volume of data produced continuously in the Cloud and at the Edge poses significant challenges for large-scale AI applications to extract and learn useful information from the data in a timely and efficient way. The goal of this article is to explore the use of computational storage to address such challenges by distributed near-data processing. We describe Newport, a high-performance and energy-efficient computational storage developed for realizing the full potential of in-storage processing. To the best of our knowledge, Newport is the first commodity SSD that can be configured to run a server-like operating system, greatly minimizing the effort for creating and maintaining applications running inside the storage. We analyze the benefits of using Newport by running complex AI applications such as image similarity search and object tracking on a large visual dataset. The results demonstrate that data-intensive AI workloads can be efficiently parallelized and offloaded, even to a small set of Newport drives with significant performance gains and energy savings. In addition, we introduce a comprehensive taxonomy of existing computational storage solutions together with a realistic cost analysis for high-volume production, giving a good big picture of the economic feasibility of the computational storage technology.},
journal = {ACM Trans. Storage},
month = {oct},
articleno = {21},
numpages = {37},
keywords = {in-storage processing, Computational storage, object tracking, solid-state drive, neural network, similarity search}
}

@article{10.1145/3342239,
author = {Jiang, Li and Song, Zhuoran and Song, Haiyue and Xu, Chengwen and Xu, Qiang and Jing, Naifeng and Zhang, Weifeng and Liang, Xiaoyao},
title = {Energy-Efficient and Quality-Assured Approximate Computing Framework Using a Co-Training Method},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {6},
issn = {1084-4309},
url = {https://doi.org/10.1145/3342239},
doi = {10.1145/3342239},
abstract = {Approximate computing is a promising design paradigm that introduces a new dimension—error—into the original design space. By allowing the inexact computation in error-tolerance applications, approximate computing can gain both performance and energy efficiency. A neural network&nbsp;(NN) is a universal approximator in theory and possesses a high level of parallelism. The emerging deep neural network accelerators deployed with NN-based approximator is thereby a promising candidate for approximate computing. Nevertheless, the approximation result must satisfy the users’ requirement, and the approximation result varies across different applications. We normally deploy an NN-based classifier to ensure the approximation quality. Only the inputs predicted to meet the quality requirement can be executed by the approximator. The potential of these two NNs, however, is fully explored; the involving of two NNs in approximate computing imposes critical optimization questions, such as two NNs’ distinct views of the input data space, how to train the two correlated NNs, and what are their topologies.In this article, we propose a novel NN-based approximate computing framework with quality insurance. We advocate a co-training approach that trains the classifier and the approximator alternately to maximize the agreement of the two NNs on the input space. In each iteration, we coordinate the training of the two NNs with a judicious selection of training data. Next, we explore different selection policies and propose to select training data from multiple iterations, which can enhance the invocation of the approximate accelerator. In addition, we optimize the classifier by integrating a dynamic threshold tuning algorithm to improve the invocation of the approximate accelerator further. The increased invocation of accelerator leads to higher energy efficiency under the same quality requirement. We propose two efficient algorithms to explore the smallest topology of the NN-based approximator and the classifier to achieve the quality requirement. The first algorithm straightforward searches the minimum topology using a greedy strategy. However, the first algorithm incurs too much training overhead. To solve this issue, the second one gradually grows the topology of NNs to match the quality requirement by transferring the learned parameters. Experimental results show significant improvement on the quality and the energy efficiency compared to the existing NN-based approximate computing frameworks.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {aug},
articleno = {59},
numpages = {25},
keywords = {Approximate computing, error control}
}

@inproceedings{10.1145/1450095.1450124,
author = {Chakrapani, Lakshmi N.B. and Muntimadugu, Kirthi Krishna and Lingamneni, Avinash and George, Jason and Palem, Krishna V.},
title = {Highly Energy and Performance Efficient Embedded Computing through Approximately Correct Arithmetic: A Mathematical Foundation and Preliminary Experimental Validation},
year = {2008},
isbn = {9781605584690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1450095.1450124},
doi = {10.1145/1450095.1450124},
abstract = {We develop a theoretical foundation to characterize a novel methodology for low energy and high performance dsp for embedded computing. Computing elements are operated at a frequency higher than that permitted by a conventionally correct circuit design, enabling a trade-off between error that is deliberately introduced, and the energy consumed. Similar techniques considered previously were relevant to deeply scaled future technology generations. Our work extends this idea to be applicable to current-day designs through: (i) a mathematically rigorous foundation characterizing a tradeoff between energy consumed and the quality of solution, and (ii) a means of achieving this trade off through very aggressive voltage scaling beyond that of a conventionally designed circuit. Through our "cmos inspired" mathematical model, we show that our approach is better (by an exponential factor) than the conventional uniform voltage scaling approach for comparable computational speed or performance. We further establish through experimental study that a similar improvement by a factor of 3.4x to the snr over conventional voltage-scaled approaches can be achieved in the context of the ubiquitous discrete Fourier transform.},
booktitle = {Proceedings of the 2008 International Conference on Compilers, Architectures and Synthesis for Embedded Systems},
pages = {187–196},
numpages = {10},
keywords = {voltage overscaling, digital signal pocessing},
location = {Atlanta, GA, USA},
series = {CASES '08}
}

@inproceedings{10.1145/973620.973698,
author = {Gabrovska, Katerina and Mihailov, Nicolay},
title = {Software System for Calculation and Analysis of Electrical Power, Derived from Renewable Energy Sources},
year = {2003},
isbn = {9549641333},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/973620.973698},
doi = {10.1145/973620.973698},
abstract = {The software system for modeling and analysis of the processes of electric power conversion of renewable energy sources (solar radiation and wind velocity) is described. The characteristics of the generators and specific climatic conditions of the geographical region are considered. The application of the developed system is for research of the processes of electricity supply and is intended for agricultural farms. It can be utilized in designing of the real farms as well as in the process of students' education.},
booktitle = {Proceedings of the 4th International Conference Conference on Computer Systems and Technologies: E-Learning},
pages = {464–469},
numpages = {6},
keywords = {graphical dependences, photovoltaics and wind turbine generators, programme models},
location = {Rousse, Bulgaria},
series = {CompSysTech '03}
}

@inproceedings{10.1145/1542130.1542156,
author = {Moore, Jo Ellen and Schoenecker, Tim and Yager, Susan E.},
title = {Harnessing IT Student Insight and Energy Tounderstand and Address the IT Enrollment Issue},
year = {2009},
isbn = {9781605584270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1542130.1542156},
doi = {10.1145/1542130.1542156},
abstract = {Much has been written about the steep decline in enrollments in university-based information technology (IT) programs. Not only is this phenomenon important to employers of graduates of these programs, it is also of great importance to the academic units that house these programs. This paper describes one university's novel approach to investigate the causes of this decline and to develop tactics to reverse this trend.},
booktitle = {Proceedings of the Special Interest Group on Management Information System's 47th Annual Conference on Computer Personnel Research},
pages = {129–138},
numpages = {10},
keywords = {student projects, it enrollment},
location = {Limerick, Ireland},
series = {SIGMIS CPR '09}
}

@inproceedings{10.1145/3471593,
author = {Hao, Cong},
title = {Session Details: Session 8A: Towards Energy-Efficient Machine Learning: Algorithm, Hardware and Computing Paradigm},
year = {2021},
isbn = {9781450383936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3471593},
doi = {10.1145/3471593},
booktitle = {Proceedings of the 2021 on Great Lakes Symposium on VLSI},
location = {Virtual Event, USA},
series = {GLSVLSI '21}
}

@inproceedings{10.1145/3477314.3507353,
author = {Guam\'{a}n, Daniel and P\'{e}rez, Jennifer and Valdiviezo-Diaz, Priscila and Canas, Norberto},
title = {Estimating the Energy Consumption of Software Components from Size, Complexity and Code Smells Metrics},
year = {2022},
isbn = {9781450387132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477314.3507353},
doi = {10.1145/3477314.3507353},
abstract = {Software quality may influence energy consumption. This work presents the CCsEM green model based on Size, Complexity and Code Smells to estimate energy consumption of architecture software components without being executed. This paper details the definition of this multiple linear regression model constructed from 42 applications, and its results.},
booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
pages = {1456–1459},
numpages = {4},
keywords = {energy consumption estimation, software architectures, green software},
location = {Virtual Event},
series = {SAC '22}
}

@article{10.1145/972627.972637,
author = {Stitt, Greg and Vahid, Frank and Nematbakhsh, Shawn},
title = {Energy Savings and Speedups from Partitioning Critical Software Loops to Hardware in Embedded Systems},
year = {2004},
issue_date = {February 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {1539-9087},
url = {https://doi.org/10.1145/972627.972637},
doi = {10.1145/972627.972637},
abstract = {We present results of extensive hardware/software partitioning experiments on numerous benchmarks. We describe our loop-oriented partitioning methodology for moving critical code from hardware to software. Our benchmarks included programs from PowerStone, MediaBench, and NetBench. Our experiments included estimated results for partitioning using an 8051 8-bit microcontroller or a 32-bit MIPS microprocessor for the software, and using on-chip configurable logic or custom application-specific integrated circuit hardware for the hardware. Additional experiments involved actual measurements taken from several physical implementations of hardware/software partitionings on real single-chip microprocessor/configurable-logic devices. We also estimated results assuming voltage scalable processors. We provide performance, energy, and size data for all of the experiments. We found that the benchmarks spent an average of 80% of their execution time in only 3% of their code, amounting to only about 200 bytes of critical code. For various experiments, we found that moving critical code to hardware resulted in average speedups of 3 to 5 and average energy savings of 35% to 70%, with average hardware requirements of only 5000 to 10,000 gates. To our knowledge, these experiments represent the most comprehensive hardware/software partitioning study published to date.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {feb},
pages = {218–232},
numpages = {15},
keywords = {synthesis, platforms, embedded systems, speedup, low energy, Hardware/software partitioning, FPGA}
}

@inproceedings{10.1109/ICSE48619.2023.00177,
author = {Weber, Max and Kaltenecker, Christian and Sattler, Florian and Apel, Sven and Siegmund, Norbert},
title = {Twins or False Friends? A Study on Energy Consumption and Performance of Configurable Software},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00177},
doi = {10.1109/ICSE48619.2023.00177},
abstract = {Reducing energy consumption of software is an increasingly important objective, and there has been extensive research for data centers, smartphones, and embedded systems. However, when it comes to software, we lack working tools and methods to directly reduce energy consumption. For performance, we can resort to configuration options for tuning response time or throughput of a software system. For energy, it is still unclear whether the underlying assumption that runtime performance correlates with energy consumption holds, especially when it comes to optimization via configuration. To evaluate whether and to what extent this assumption is valid for configurable software systems, we conducted the largest empirical study of this kind to date. First, we searched the literature for reports on whether and why runtime performance correlates with energy consumption. We obtained a mixed, even contradicting picture from positive to negative correlation, and that configurability has not been considered yet as a factor for this variance. Second, we measured and analyzed both the runtime performance and energy consumption of 14 real-world software systems. We found that, in many cases, it depends on the software system's configuration whether runtime performance and energy consumption correlate and that, typically, only few configuration options influence the degree of correlation. A fine-grained analysis at the function level revealed that only few functions are relevant to obtain an accurate proxy for energy consumption and that, knowing them, allows one to infer individual transfer factors between runtime performance and energy consumption.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2098–2110},
numpages = {13},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/584369.584390,
author = {Daylight, E. G. and Fermentel, T. and Ykman-Couvreur, C. and Catthoor, F.},
title = {Incorporating Energy Efficient Data Structures into Modular Software Implementations for Internet-Based Embedded Systems},
year = {2002},
isbn = {1581135637},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/584369.584390},
doi = {10.1145/584369.584390},
abstract = {In current day software design of Internet applications, a lot of attention is paid to the reusability and extensibility of the design. However, due to an increased participation of embedded, hand-held devices in Internet activity, migrating code on the Internet has to be designed and implemented well in terms of energy consumption, execution speed, and on-chip memory space consumption. These parameters should be treated equally with respect to other more common design criteria. This paper introduces tradeoffs between energy consumption and on-chip memory space consumption during the implementation phase of such a system. The content-aware knowledge of the designer is exploited during the implementation so that energy efficient data structures are implemented in a relatively easy way. We also show that optimizing for energy consumption is not necessarily the same as optimizing for execution speed (or vice versa).Gains in energy consumption and/or execution speed are presented for only a relatively small overhead in on-chip memory space consumption. Depending on the behaviour of the adjacent software modules (of the module under investigation) on the one hand, and some general platform related criteria on the other hand, we show that non-trivial data structure implementations can lead to a better matching of the software onto the platform.},
booktitle = {Proceedings of the 3rd International Workshop on Software and Performance},
pages = {134–141},
numpages = {8},
keywords = {energy consumption, partitioned data structure, on-chip memory footprint},
location = {Rome, Italy},
series = {WOSP '02}
}

@inproceedings{10.1145/2305484.2305521,
author = {Pereira, Lucas and Quintal, Filipe and Nunes, Nuno and Berg\'{e}s, Mario},
title = {The Design of a Hardware-Software Platform for Long-Term Energy Eco-Feedback Research},
year = {2012},
isbn = {9781450311687},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2305484.2305521},
doi = {10.1145/2305484.2305521},
abstract = {Researchers often face engineering problems, such as optimizing prototype costs and ensuring easy access to the collected data, which are not directly related to the research problems being studied. This is especially true when dealing with long-term studies in real world scenarios. This paper describes the engineering perspective of the design, development and deployment of a long-term real word study on energy eco-feedback, where a non-intrusive home energy monitor was deployed in 30 houses for 18 months. Here we report on the efforts required to implement a cost-effective non-intrusive energy monitor and, in particular, the construction of a local network to allow remote access to multiple monitors and the creation of a RESTful web-service to enable the integration of these monitors with social media and mobile software applications. We conclude with initial results from a few eco-feedback studies that were performed using this platform.},
booktitle = {Proceedings of the 4th ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {221–230},
numpages = {10},
keywords = {hardware-software platform, sustainability, eco-feedback, non-intrusive load monitoring},
location = {Copenhagen, Denmark},
series = {EICS '12}
}

@inproceedings{10.1145/3488423.3519323,
author = {Nguyen, Duy-Thanh and Ho, Nhut-Minh and Chang, Ik-Joon},
title = {SoftRefresh: Targeted Refresh for Energy-Efficient DRAM Systems via Software and Operating Systems Support},
year = {2023},
isbn = {9781450385701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488423.3519323},
doi = {10.1145/3488423.3519323},
abstract = {Due to its capacitive nature, DRAM cells must be refreshed regularly to retain their information. However, due to the scale of DRAM deployment in modern computer systems, the energy overhead of DRAM refresh operations is becoming significant. The crux in managing DRAM refresh is knowing if the data in particular cells are valid or not. Previous works have suggested many hardware schemes that effectively try to guess this. In this paper, we propose modifications to allow software involvement in regulating refresh operations. This opens the door for targeted, and hence minimal, refresh operations. Only valid pages having potential bit errors will be refreshed. Compared to conventionally refreshing the whole DRAM, our SoftRefresh saves up to 43% energy on average. Our proposal can work on all types of modern DRAM with only minor modifications to the existing hardware and software systems.},
booktitle = {Proceedings of the International Symposium on Memory Systems},
articleno = {17},
numpages = {6},
keywords = {DRAM, SoftRefresh, DDR4, DDR5 ACM},
location = {Washington DC, DC, USA},
series = {MEMSYS '21}
}

@inproceedings{10.1145/3259258,
author = {Dutt, Nikil},
title = {Session Details: Software-Driven Techniques for Energy Efficiency in Embedded and Multi-Core Systems},
year = {2012},
isbn = {9781450312493},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3259258},
doi = {10.1145/3259258},
booktitle = {Proceedings of the 2012 ACM/IEEE International Symposium on Low Power Electronics and Design},
location = {Redondo Beach, California, USA},
series = {ISLPED '12}
}

@inproceedings{10.1145/1403375.1403550,
author = {Novo, D. and Bougard, B. and Lambrechts, A. and Van der Perre, L. and Catthoor, F.},
title = {Scenario-Based Fixed-Point Data Format Refinement to Enable Energy-Scalable Software Defined Radios},
year = {2008},
isbn = {9783981080131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1403375.1403550},
doi = {10.1145/1403375.1403550},
abstract = {User demand, standards and products for digital nomadic communications are evolving quickly. The combination of this changing environment together with the need for short time-to-market pushes for more flexible implementations. Software Defined Radios (SDR) have been introduced as the ultimate way to achieve such flexibility. The reduced energy budget required by battery-powered solutions makes the typical worst-case static dimensioning unaffordable under highly dynamic operating conditions. Instead, more energy-scalable algorithms and implementations are entailed to provide flexibility while maintaining the required energy efficiency. Particularly, energy-scalable implementations can exploit data format properties to offer different tradeoffs between accuracy and energy. In this paper, such a technique is developed and applied to the SDR implementation of a 2 antennas 200 Mbps+ OFDM (Orthogonal Frequency-Division Multiplexing) inner modem receiver on a C-programmable CGA (Coarse Grain Array) processor with extensive SIMD (Single Instruction Multiple Data) support. By defining separate implementations for different combinations of modulation scheme and coding rate, up to 3-fold gains can be achieved in the average energy consumption.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {722–727},
numpages = {6},
location = {Munich, Germany},
series = {DATE '08}
}

@inproceedings{10.1145/3227609.3227652,
author = {Pe\v{s}i\'{c}, Sa\v{s}a and To\v{s}i\'{c}, Milenko and Ikovi\'{c}, Ognjen and Radovanovi\'{c}, Milo\v{s} and Ivanovi\'{c}, Mirjana and Bo\v{s}kovi\'{c}, Dragan},
title = {Bluetooth Low Energy Microlocation Asset Tracking (BLEMAT) in a Context-Aware Fog Computing System},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227652},
doi = {10.1145/3227609.3227652},
abstract = {In this paper we present a Bluetooth Low Energy Microlocation Asset Tracking system (BLEMAT) that performs real-time position estimation and asset tracking based on BLE beacons and scanners. It is built on a context-aware fog computing system comprising Internet of Things controllers, sensors and a cloud platform, helped by machine-learning models and techniques. The BLEMAT system offers detecting signal propagation obstacles, performing signal perturbation correction and beacon paths exploration as well as auto discovery and onboarding of fog controller devices. These are the key characteristics of semi-supervised indoor position estimation services. In this paper we have shown there are solid basis that a fog computing system can efficiently carry out semi-supervised machine learning procedures for high-precision indoor position estimation and space modeling without the need for detailed input information (i.e. floor plan, signal propagation map, scanner position). In addition, the fog computing system inherently brings high level of system robustness, integrity, privacy and trust.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {23},
numpages = {11},
keywords = {indoor positioning, machine learning, space modeling, Fog computing},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3452940.3453028,
author = {Zhu, Yingtong},
title = {Application of Computer Technology in Green Technology Innovation of Small and Medium-Sized Enterprises},
year = {2021},
isbn = {9781450388665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452940.3453028},
doi = {10.1145/3452940.3453028},
abstract = {In recent years, with the rapid development of China's small and medium-sized enterprises, for China's national economic level has brought a huge impact, but there are still many problems in the process of development, among which technological innovation has become an important link in the development and progress of China's small and medium-sized enterprises. This paper mainly analyzes and studies the influence of computer technology on small and medium-sized enterprises, and analyzes and studies the innovation ability and improvement direction of small and medium-sized technology, so as to provide basis for the investment risk of small and medium-sized enterprises.},
booktitle = {Proceedings of the 3rd International Conference on Information Technologies and Electrical Engineering},
pages = {458–461},
numpages = {4},
keywords = {Small and medium-sized enterprises, Enterprise green, Technology innovation, Computer technology},
location = {Changde City, Hunan, China},
series = {ICITEE '20}
}

@article{10.1145/3129738,
author = {Nelson, Barry L.},
title = {Replicated Computations Results (RCR) Report for “Green Simulation: Reusing the Output of Repeated Experiments”},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {1049-3301},
url = {https://doi.org/10.1145/3129738},
doi = {10.1145/3129738},
abstract = {“Green Simulation: Reusing the Output of Repeated Experiments” by Feng and Staum describes methods based on likelihood ratio or importance sampling theory for reusing the outputs of simulation experiments at previous parameter settings to augment and improve (by reducing the estimator variance) simulation experiments at new parameter settings. The article presents empirical results for two realistic examples in the area of finance; Matlab code for these examples was made available by the authors. The examples were straightforward to run without extensive knowledge of Matlab, and both experiment and scenario parameters can be altered easily. All experiment results in the article were reproduced.},
journal = {ACM Trans. Model. Comput. Simul.},
month = {oct},
articleno = {24},
numpages = {2},
keywords = {variance reduction, financial engineering, Importance sampling}
}

@inproceedings{10.1145/3053600.3053612,
author = {McGough, A. Stephen and Al Moubayed, Noura and Forshaw, Matthew},
title = {Using Machine Learning in Trace-Driven Energy-Aware Simulations of High-Throughput Computing Systems},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053612},
doi = {10.1145/3053600.3053612},
abstract = {When performing a trace-driven simulation of a High Throughput Computing system we are limited to the knowledge which should be available to the system at the current point within the simulation. However, the trace-log contains information we would not be privy to during the simulation. Through the use of Machine Learning we can extract the latent patterns within the trace-log allowing us to accurately predict characteristics of tasks based only on the information we would know. These characteristics will allow us to make better decisions within simulations allowing us to derive better policies for saving energy.We demonstrate that we can accurately predict (up-to 99% accuracy), using oversampling and deep learning, those tasks which will complete while at the same time provide accurate predictions for the task execution time and memory footprint using Random Forest Regression.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {55–60},
numpages = {6},
keywords = {machine learning, trace-driven, simulation},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/3259225,
author = {Brooks, David},
title = {Session Details: Hot Chips Running Cool - Energy Efficient near-Threshold Computing and Its Barriers},
year = {2012},
isbn = {9781450311991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3259225},
doi = {10.1145/3259225},
booktitle = {Proceedings of the 49th Annual Design Automation Conference},
location = {San Francisco, California},
series = {DAC '12}
}

@inproceedings{10.1145/3579371.3589064,
author = {Ma, Tianrui and Feng, Yu and Zhang, Xuan and Zhu, Yuhao},
title = {CAMJ: Enabling System-Level Energy Modeling and Architectural Exploration for In-Sensor Visual Computing},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579371.3589064},
doi = {10.1145/3579371.3589064},
abstract = {CMOS Image Sensors (CIS) are fundamental to emerging visual computing applications. While conventional CIS are purely imaging devices for capturing images, increasingly CIS integrate processing capabilities such as Deep Neural Network (DNN). Computational CIS expand the architecture design space, but to date no comprehensive energy model exists. This paper proposes CamJ, a detailed energy modeling framework that provides a component-level energy breakdown for computational CIS and is validated against nine recent CIS chips. We use CamJ to demonstrate three use-cases that explore architectural trade-offs including computing in vs. off CIS, 2D vs. 3D-stacked CIS design, and analog vs. digital processing inside CIS. The code of CamJ is available at: https://github.com/horizon-research/CamJ.},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
articleno = {29},
numpages = {14},
keywords = {analog modeling, energy modeling, in-sensor computing},
location = {Orlando, FL, USA},
series = {ISCA '23}
}

@inproceedings{10.1145/3555776.3577598,
author = {Fernandez Blanco, David and Le Mouel, Frederic and Lin, Trista and Ponge, Julien},
title = {An Energy-Efficient FaaS Edge Computing Platform over IoT Nodes: Focus on Consensus Algorithm},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577598},
doi = {10.1145/3555776.3577598},
abstract = {With the increasing computing needs of the new systems and applications, cloud offloading has become a popular choice for constructors to keep the prices of their devices affordable. However, this solution only shifts the scaling problem from the end devices to the cloud, increasingly enhancing the capacities of cloud infrastructures. As a way to reinforce the cloud capabilities on the edge without needing to add extra computing resources, we propose PyCloudIoT, a collaborative energy-efficient Function-as-a-Service (FaaS) computing platform (pltf.) with low-to-medium availability targeting the execution of punctual stateless functions over the already deployed IoTs and gateways. As these resources are extremely dynamic, with intermittent availability, heterogeneity and faultiness, the addition of strong control mechanisms is key to efficient operation. In this paper, we discuss the PyCloudIoT Consensus Model (PCM), which enables the coordination and orchestration of resources dynamically and compensates for the faults of the IoT computing farm. Compared to SOTA, PCM shows promising results with a performance and energy consumption improvement of 20% and 66% and 37% and 65% respectively compared to the best configurations of Raft and Pirogue (4+1 quorum), achieving at the same time a slightly stronger fault tolerance level.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {661–670},
numpages = {10},
keywords = {FaaS edge computing, consensus algorithms, resource orchestration, distributed computing, internet of things},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.5555/3408352.3408380,
author = {Reis, Dayane and Laguna, Ann Franchesca and Niemier, Michael and Hu, Xiaobo Sharon},
title = {A Fast and Energy Efficient Computing-in-Memory Architecture for Few-Shot Learning Applications},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Among few-shot learning methods, prototypical networks (PNs) are one of the most popular approaches due to their excellent classification accuracies and network simplicity. Test examples are classified based on their distances from class prototypes. Despite the application-level advantages of PNs, the latency of transferring data from memory to compute units is much higher than the PN computation time. Thus, PNs performance is limited by memory bandwidth. Computing-in-memory addresses this bandwidth-bottleneck problem by bringing a subset of compute units closer to memory. In this work, we propose a CiM-PN framework that enables the computation of distance metrics and prototypes inside the memory. CiM-PN replaces the computationally intensive Euclidean distance metric by the CiM-friendly Manhattan distance metric. Additionally, prototypes are computed using an in-memory mean operation realized by accumulation and division by powers of two, which enables few-shot learning implementations where "shots" are powers of two. The CiM-PN hardware uses CMOS memory cells, as well as CMOS peripherals such as customized sense amplifiers, carry-look-ahead adders, in-place copy buffers and a logarithmic shifter. Compared with a GPU implementation, a CMOS-based CiM-PN achieves speedups of 2808x/111x and energy savings of 2372x/5170x at iso-accuracy for the prototype and nearest-neighbor computation, respectively, and over 2x end-to-end speedup and energy improvements. We also gain 3--14% accuracy improvement when compared to existing non-GPU hardware approaches due to the floating-point CiM operations.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {127–132},
numpages = {6},
keywords = {few-shot learning, computing-in-memory, prototypical networks},
location = {Grenoble, France},
series = {DATE '20}
}

@proceedings{10.1145/2480347,
title = {EEHPDC '13: Proceedings of the 2013 Workshop on Energy Efficient High Performance Parallel and Distributed Computing},
year = {2013},
isbn = {9781450319805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2013 ACM International Workshop on Energy Efficient High Performance Parallel and Distributed Computing - EEHPDC'1). This workshop aims to provide a timely forum for presenting novel ideas and latest findings as well as to discuss research directions and challenges related to Energy Efficient for High Performance Computing Parallel and Distributed Computing. EEHPDC'13 gives researchers and practitioners a unique opportunity to share their perspectives with others interested in the various aspects of the design, implementation, evaluation, and the use of parallel and distributed systems for high-end computing with the focus on energy efficiency.The program comprises a keynote speech by Laurent Lefevre on the impact of application and service knowledge for energy efficiency in HPC, a technical session with technical papers on energy efficient communications, cloud computing systems, task scheduling, and multi-core and heterogeneous architectures, and an industry session. We hope that these proceedings will serve as a valuable reference for energy efficiency researchers and developers.},
location = {New York, New York, USA}
}

@inproceedings{10.1145/3583781.3590258,
author = {Thakkar, Ishan and Sri Vatsavai, Sairam and Karempudi, Venkata Sai Praneeth},
title = {High-Speed and Energy-Efficient Non-Binary Computing with Polymorphic Electro-Optic Circuits and Architectures},
year = {2023},
isbn = {9798400701252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583781.3590258},
doi = {10.1145/3583781.3590258},
abstract = {In this paper, we present microring resonator (MRR) based polymorphic E-O circuits and architectures that can be employed for high-speed and energy-efficient non-binary reconfigurable computing. Our polymorphic E-O circuits can be dynamically programmed to implement different logic and arithmetic functions at different times. They can provide compactness and polymorphism to consequently improve operand handling, reduce idle time, and increase amortization of area and static power overheads. When combined with flexible photodetectors with the innate ability to accumulate a high number of optical pulses in situ, our circuits can support energy-efficient processing of data in non-binary formats such as stochastic/unary and high-dimensional reservoir formats. Furthermore, our polymorphic E-O circuits enable configurable E-O computing accelerator architectures for processing binarized and integer quantized convolutional neural networks (CNNs). We compare our designed polymorphic E-O circuits and architectures to several circuits and architectures from prior works in terms of area, latency, and energy consumption.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2023},
pages = {545–550},
numpages = {6},
keywords = {electro-optic polymorphic circuits, microring resonators (mrrs), non-binary computing},
location = {Knoxville, TN, USA},
series = {GLSVLSI '23}
}

@inproceedings{10.1145/2768177.2768179,
author = {Kim, Kyu Yeun and Kim, Seunghoe and Baek, Woongki},
title = {On the Feasibility of Advanced Cache Indexing for High-Performance and Energy-Efficient GPGPU Computing},
year = {2015},
isbn = {9781450334082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2768177.2768179},
doi = {10.1145/2768177.2768179},
abstract = {To achieve higher performance and energy efficiency, GPGPU architectures have recently begun to employ hardware caches. Adding hardware caches to GPGPUs, however, does not automatically guarantee improved performance and energy efficiency due to the thrashing in small hardware caches shared by thousands of threads. While prior work has proposed warp scheduling and cache bypassing techniques to address this issue, relatively little work has been done in the context of advanced cache indexing. To bridge this gap, this work investigates the feasibility of advanced cache indexing for high-performance and energy-efficient GPGPU computing. We first discuss the design and implementation of static and adaptive cache indexing schemes for GPGPUs. We then quantify the effectiveness of the advanced indexing schemes using GPGPU benchmarks. Our quantitative evaluation demonstrates that the advanced cache indexing schemes are promising in that they significantly outperform the conventional cache indexing scheme. In addition, for a subset of cache-sensitive benchmarks, the adaptive indexing scheme substantially outperforms the static indexing scheme by effectively identifying and utilizing high-quality indexing bits based on runtime information. Finally, our evaluation shows that the effectiveness of advanced cache indexing is sensitive to different warp schedulers, motivating further research on coordinated cache indexing and warp scheduling techniques.},
booktitle = {Proceedings of the 3rd International Workshop on Many-Core Embedded Systems},
pages = {1–8},
numpages = {8},
keywords = {Advanced cache indexing, cache optimization, energy efficiency, GPGPU memory hierarchy, high performance},
location = {Portland, OR, USA},
series = {MES '15}
}

@inproceedings{10.1145/1542275.1542279,
author = {Grice, Donald},
title = {The Roadrunner Project and the Importance of Energy Efficiency on the Road to Exascale Computing},
year = {2009},
isbn = {9781605584980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1542275.1542279},
doi = {10.1145/1542275.1542279},
abstract = {The cost of the energy required to run ultrascale supercomputers is becoming a large portion of the operating budgets of many facilities and it has the potential of limiting the scale of computers that can be deployed. The Roadrunner project was started as a development project aimed at finding a way to scale up applications but at a significantly more efficient energy usage than the current systems. Heterogeneous core types allow single thread performance to remain high while reducing the energy required for a given computation by eliminating the circuits and associated power that are not needed for the computation. This optimizes the energy cost per operation but puts a burden on the software to deal with heterogeneous core types.The Roadrunner system was the first to reach a sustained Petaflop on the Linpack benchmark and it involved some interesting new Hardware but the bulk of the effort was in Software development including programming models and applications. Several applications were ported to the new structure with relatively little difficulty and the expected performance and energy efficiency improvements were attained.This talk will cover an overview of the Roadrunner project, including the fundamental Cell BE building block and the software structure and methods that were included. The success of the energy efficiency improvement has lead to a broader view of the utility of heterogeneous computing in the Computationally Intensive Workload area.},
booktitle = {Proceedings of the 23rd International Conference on Supercomputing},
pages = {2},
numpages = {1},
keywords = {petaflop, exascale computing, cell broadband engine, heterogeneous multicore architectures, exaflop},
location = {Yorktown Heights, NY, USA},
series = {ICS '09}
}

@inproceedings{10.1145/2821650.2821660,
author = {Batra, Nipun and Singh, Amarjeet and Whitehouse, Kamin},
title = {If You Measure It, Can You Improve It? Exploring The Value of Energy Disaggregation},
year = {2015},
isbn = {9781450339810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2821650.2821660},
doi = {10.1145/2821650.2821660},
abstract = {Over the past few years, dozens of new techniques have been proposed for more accurate energy disaggregation, but the jury is still out on whether these techniques can actually save energy and, if so, whether higher accuracy translates into higher energy savings. In this paper, we explore both of these questions. First, we develop new techniques that use disaggregated power data to provide actionable feedback to residential users. We evaluate these techniques using power traces from 240 homes and find that they can detect homes that need feedback with as much as 84% accuracy. Second, we evaluate whether existing energy disaggregation techniques provide power traces with sufficient fidelity to support the feedback techniques that we created and whether more accurate disaggregation results translate into more energy savings for the users. Results show that feedback accuracy is very low even while disaggregation accuracy is high. These results indicate a need to revisit the metrics by which disaggregation is evaluated.},
booktitle = {Proceedings of the 2nd ACM International Conference on Embedded Systems for Energy-Efficient Built Environments},
pages = {191–200},
numpages = {10},
keywords = {nilm, energy disaggregation, metrics},
location = {Seoul, South Korea},
series = {BuildSys '15}
}

@article{10.1145/3511210,
author = {Boroujerdian, Behzad and Genc, Hasan and Krishnan, Srivatsan and Duisterhof, Bardienus Pieter and Plancher, Brian and Mansoorshahi, Kayvan and Almeida, Marcelino and Cui, Wenzhi and Faust, Aleksandra and Reddi, Vijay Janapa},
title = {The Role of Compute in Autonomous Micro Aerial Vehicles: Optimizing for Mission Time and Energy Efficiency},
year = {2022},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1–4},
issn = {0734-2071},
url = {https://doi.org/10.1145/3511210},
doi = {10.1145/3511210},
abstract = {Autonomous and mobile cyber-physical machines are becoming an inevitable part of our future. In particular, Micro Aerial Vehicles (MAVs) have seen a resurgence in activity. With multiple use cases, such as surveillance, search and rescue, package delivery, and more, these unmanned aerial systems are on the cusp of demonstrating their full potential. Despite such promises, these systems face many challenges, one of the most prominent of which is their low endurance caused by their limited onboard energy. Since the success of a mission depends on whether the drone can finish it within such duration and before it runs out of battery, improving both the time and energy associated with the mission are of high importance. Such improvements have traditionally been arrived at through the use of better algorithms. But our premise is that more powerful and efficient onboard compute can also address the problem. In this article, we investigate how the compute subsystem, in a cyber-physical mobile machine such as a Micro Aerial Vehicle, can impact mission time (time to complete a mission) and energy. Specifically, we pose the question as what is the role of computing for cyber-physical mobile robots? We show that compute and motion are tightly intertwined, and as such a close examination of cyber and physical processes and their impact on one another is necessary. We show different “impact paths” through which compute impacts mission metrics and examine them using a combination of analytical models, simulation, and micro and end-to-end benchmarking. To enable similar studies, we open sourced MAVBench, our tool-set, which consists of (1) a closed-loop real-time feedback simulator and (2) an end-to-end benchmark suite composed of state-of-the-art kernels. By combining MAVBench, analytical modeling, and an understanding of various compute impacts, we show up to 2X and 1.8X improvements for mission time and mission energy for two optimization case studies, respectively. Our investigations, as well as our optimizations, show that cyber-physical co-design, a methodology with which both the cyber and physical processes/quantities of the robot are developed with consideration of one another, similar to hardware-software co-design, is necessary for arriving at the design of the optimal robot.},
journal = {ACM Trans. Comput. Syst.},
month = {jul},
articleno = {3},
numpages = {44},
keywords = {system design, drones, autonomous machines, Simulators}
}

@inproceedings{10.1145/3077839.3077857,
author = {Singh, Nitin and Dayama, Pankaj and Randhawa, Sukanya and Dasgupta, Kalyan and Padmanaban, Manikandan and Kalyanaraman, Shivkumar and Hazra, Jagabondhu},
title = {Photonic Energy Harvesting: Boosting Energy Yield of Commodity Solar Photovoltaic Systems via Software Defined IoT Controls},
year = {2017},
isbn = {9781450350365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3077839.3077857},
doi = {10.1145/3077839.3077857},
abstract = {Solar photovoltaic (PV) systems have a utilization (or capacity) factor of 15-20% worldwide. We propose to enhance the energy yield in a software-defined manner by complementing commodity solar PV systems with cloud-based IoT-controlled reflectors. We also propose designs for brownfield and greenfield settings in solar farms. We study a number of practical engineering issues including effect of solar azimuth, shadowing effects, ground coverage ratio (GCR) tradeoff, constraints on angular control etc. Our designs can raise solar PV energy yield between 50-100% with modest tradeoffs on operational complexity, land requirements (ground coverage ratio) etc. The software-defined IoT control allows a variety of current and future operational or business constraints to be flexibly factored in to tradeoff these factors versus economic gain (eg: levelized cost of energy, LCOE). The paper presents both simulation and experimental evidence for our system. We are actively piloting this technology with solar PV developers and engineering, procurement, construction (EPC) companies in emerging markets.},
booktitle = {Proceedings of the Eighth International Conference on Future Energy Systems},
pages = {56–66},
numpages = {11},
keywords = {Solar Energy, LCOE, Analytics, Photonic Harvesting},
location = {Shatin, Hong Kong},
series = {e-Energy '17}
}

@inproceedings{10.5555/1898699.1898715,
author = {Kwok, Tyrone Tai-On and Kwok, Yu-Kwong},
title = {Practical Design of a Computation and Energy Efficient Hardware Task Scheduler in Embedded Reconfigurable Computing Systems},
year = {2006},
isbn = {1424400546},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {By utilizing massively parallel circuit design in FPGAs, the overall system efficiency, in terms of computation efficiency and energy efficiency, can be greatly enhanced by offloading some computation-intensive tasks which are originally executed in the instruction set processor to the FPGA fabric. In essence, a hardware task scheduler is needed. However, most of the work in the literature considers scheduling algorithms which are unable or difficult to be implemented using the design flows in current development platform. Moreover, little of the work takes energy consumption into consideration. In this paper, we present the design of a hardware task scheduler which takes energy consumption into consideration, and can be readily implemented using current design flows.},
booktitle = {Proceedings of the 20th International Conference on Parallel and Distributed Processing},
pages = {218},
numpages = {1},
location = {Rhodes Island, Greece},
series = {IPDPS'06}
}

@inproceedings{10.1145/3297280.3297295,
author = {Mendes, Seundefinedgio and Sim\~{a}o, Jos\'{e} and Veiga, Lu\'{\i}s},
title = {Oversubscribing Micro-Clouds with Energy-Aware Containers Scheduling},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297295},
doi = {10.1145/3297280.3297295},
abstract = {Cloud computation is being pushed to the edge of the network, towards Micro-clouds, to promote more energy efficiency and less latency when compared to heavy resourced centralized datacenters. This trend will enable new markets and providers to fill the current gap. There are however challenges in this design: (i) devices have less resources, leading to a frequent use of oversubscription (ii) lack of economic incentives to both provider and application owner to cope with less than full requests fulfilled. To support this trend, the virtualization layer of Micro-clouds is currently dominated by containers, which have a small memory footprint and strong isolation properties. We propose an extension to Docker Swarm, a widely used containers orchestrator, with an oversubscribing scheduling algorithm, based on improving resources utilization to levels where the energy efficiency is maximized. This solution improves CPU and memory utilization over Spread and Binpack (Docker Swarm strategies). Although we introduce a small overhead in scheduling times, our solution manages to allocate more requests, with a successful allocation rate of 83% against 57% of current solutions, measured on the scheduling of real CPU- and memory-intensive workloads (e.g. Video encoding, Key-value storages and a Deep-learning algorithm).},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {130–137},
numpages = {8},
keywords = {oversubscription, containers orchestration, energy efficienct},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3339186.3339213,
author = {Bautista, Elizabeth and Romanus, Melissa and Davis, Thomas and Whitney, Cary and Kubaska, Theodore},
title = {Collecting, Monitoring, and Analyzing Facility and Systems Data at the National Energy Research Scientific Computing Center},
year = {2019},
isbn = {9781450371964},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339186.3339213},
doi = {10.1145/3339186.3339213},
abstract = {As high-performance computing (HPC) resources continue to grow in size and complexity, so too does the volume and velocity of the operational data that is associated with them. At such scales, new mechanisms and technologies are required to continuously gather, store, and analyze this data in near-real time from heterogeneous and distributed sources without impacting the underlying data center operations or HPC resource utilization. In this paper, we describe our experiences in designing and implementing an infrastructure for extreme-scale operational data collection, known as the Operations Monitoring and Notification Infrastructure (OMNI) at the National Energy Research Scientific Computing (NERSC) center at Lawrence Berkeley National Laboratory. OMNI currently holds over 522 billion records of online operational data (totaling over 125TB) and can ingest new data points at an average rate of 25,000 data points per second. Using OMNI as a central repository, facilities and environmental data can be seamlessly integrated and correlated with machine metrics, job scheduler information, network errors, and more, providing a holistic view of data center operations. To demonstrate the value of real-time operational data collection, we present a number of real-world case studies for which having OMNI data readily available led to key operational insights at NERSC. The case results include a reduction in the downtime of an HPC system during a facility transition, as well as a $2.5 million electrical substation savings for the next-generation Perlmutter HPC system.},
booktitle = {Workshop Proceedings of the 48th International Conference on Parallel Processing},
articleno = {10},
numpages = {9},
keywords = {high-performance computing, monitoring, Green HPC, data centers, operations, time series data, operational data analytics, data collection},
location = {Kyoto, Japan},
series = {ICPP Workshops '19}
}

@inproceedings{10.1145/2535753.2535757,
author = {Castro, M\'{a}rcio and Francesquini, Emilio and Ngu\'{e}l\'{e}, Thomas M. and M\'{e}haut, Jean-Fran\c{c}ois},
title = {Analysis of Computing and Energy Performance of Multicore, NUMA, and Manycore Platforms for an Irregular Application},
year = {2013},
isbn = {9781450325035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2535753.2535757},
doi = {10.1145/2535753.2535757},
abstract = {The exponential growth in processor performance seems to have reached a turning point. Nowadays, energy efficiency is as important as performance and has become a critical aspect to the development of scalable systems. These strict energy constraints paved the way for the development of multi and manycore processors. Research on the performance and the energy efficiency of numerical kernels on multicores are common but studies in the context of manycores are sparse. Unlike these works, in this paper we analyze a well-known irregular NP-complete problem, the Traveling-Salesman Problem (TSP). This study investigates two aspects of the TSP on multicore, NUMA, and manycore processors. First, we concentrate on the nontrivial task of adapting this application to a manycore, specifically the novel MPPA-256 manycore processor. Then, we analyze its performance and energy consumption on different platforms that comprise general-purpose and low-power multicores, a NUMA machine, and the MPPA-256 manycore. Our results show that applications able to fully use the resources of a manycore can have better performance and may consume 9.8 and 13 times less energy when compared to low-power and general-purpose multicore processors, respectively.},
booktitle = {Proceedings of the 3rd Workshop on Irregular Applications: Architectures and Algorithms},
articleno = {5},
numpages = {8},
keywords = {energy, manycore, multicore, performance, NUMA, TSP},
location = {Denver, Colorado},
series = {IA<sup>3</sup> '13}
}

@inproceedings{10.1145/3583781.3590220,
author = {Lou, Jie and Freye, Florian and Lanius, Christian and Gemmeke, Tobias},
title = {Scalable Time-Domain Compute-in-Memory BNN Engine with 2.06 POPS/W Energy Efficiency for Edge-AI Devices},
year = {2023},
isbn = {9798400701252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583781.3590220},
doi = {10.1145/3583781.3590220},
abstract = {Time-domain (TD) computing has attracted attention for its high computing efficiency and suitability for applications on energy-constrained edge devices. In this paper, we present a time-domain compute-in-memory (TDCIM) macro for binary neural networks (BNNs) realized by standard as well as custom delay cells. Multiply-and-accumulate (MAC) operations, batch normalization (BN) and binarization (Bin) are all processed in the time-domain, avoiding costly digital domain post-processing. In addition, it supports flexible mapping for different kernel sizes, achieving 100% utilization. Starting from a standard cell-based implementation, we propose two custom cells that provide interesting trade-offs between energy efficiency, area and accuracy. The two proposed custom designs can achieve 1.5 and 2.06 POPS/W energy efficiencies at 0.5V and 0.6V with less cell area while maintaining model test accuracy.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2023},
pages = {665–670},
numpages = {6},
keywords = {time-domain computing, double-edge operation, binary neural networks, compute-in-memory},
location = {Knoxville, TN, USA},
series = {GLSVLSI '23}
}

@inproceedings{10.1109/CCGrid.2015.77,
author = {Nurminen, Jukka K. and Strandman, Johan and Koskela, Kalle and Niemi, Tapio},
title = {Computing Heaters: An Energy-Efficient Way to Provide Computing Services},
year = {2015},
isbn = {9781479980062},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2015.77},
doi = {10.1109/CCGrid.2015.77},
abstract = {New data centers for cloud services rapidly increase energy consumption of IT services. Now electricity is used both to power the computing hardware and to remove the heat computing generates. On the other hand, heating is needed e.g. for buildings and for hot water. However, reusing heat from data centers, e.g. for district heating, is complicated and expensive because of relatively low temperature of exhaust heat and a need for expensive infrastructure investments. In this paper, we will study the feasibility and the technical solutions for distributing computing to where heating is needed. For this purpose compact and reliable computing-heating units are developed. Computing tasks are distributed to these units based on the heating requirements in their environment. In this way the electricity used for computing is substituting the energy of the heating elements.},
booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {935–942},
numpages = {8},
keywords = {energy, green ICT, distributed computing},
location = {Shenzhen, China},
series = {CCGRID '15}
}

@article{10.1109/TNET.2015.2404576,
author = {Han, Tao and Ansari, Nirwan},
title = {A Traffic Load Balancing Framework for Software-Defined Radio Access Networks Powered by Hybrid Energy Sources},
year = {2016},
issue_date = {April 2016},
publisher = {IEEE Press},
volume = {24},
number = {2},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2015.2404576},
doi = {10.1109/TNET.2015.2404576},
abstract = {Dramatic mobile data traffic growth has spurred a dense deployment of small cell base stations (SCBSs). Small cells enhance the spectrum efficiency and thus enlarge the capacity of mobile networks. Although SCBSs consume much less power than macro BSs (MBSs) do, the overall power consumption of a large number of SCBSs is phenomenal. As the energy harvesting technology advances, base stations (BSs) can be powered by green energy to alleviate the on-grid power consumption. For mobile networks with high BS density, traffic load balancing is critical in order to exploit the capacity of SCBSs. To fully utilize harvested energy, it is desirable to incorporate the green energy utilization as a performance metric in traffic load balancing strategies. In this paper, we have proposed a traffic load balancing framework that strives a balance between network utilities, e.g., the average traffic delivery latency, and the green energy utilization. Various properties of the proposed framework have been derived. Leveraging the software-defined radio access network architecture, the proposed scheme is implemented as a virtually distributed algorithm, which significantly reduces the communication overheads between users and BSs. The simulation results show that the proposed traffic load balancing framework enables an adjustable trade-off between the on-grid power consumption and the average traffic delivery latency, and saves a considerable amount of on-grid power, e.g., 30%, at a cost of only a small increase, e.g., 8%, of the average traffic delivery latency.},
journal = {IEEE/ACM Trans. Netw.},
month = {apr},
pages = {1038–1051},
numpages = {14},
keywords = {hetnet, software-defined radio access networks, green communications, renewable energy, traffic load balancing}
}

@inproceedings{10.5555/3108009.3108086,
author = {Utrilla, Ramiro and Rozas, Alba and Blesa, Javier and Araujo, Alvaro},
title = {A Hybrid Approach to Enhance Cognitive Wireless Sensor Networks with Energy-Efficient Software-Defined Radio Capabilities},
year = {2017},
isbn = {9780994988614},
publisher = {Junction Publishing},
address = {USA},
abstract = {The loss of efficiency and dependability in wireless communications, caused by the increasing spectrum scarcity problem, is particularly critical for battery-powered devices such as sensor nodes. Cognitive Wireless Sensor Networks (CWSNs) arise in order to mitigate this situation by adding cognitive radio capabilities to them. However, the closed architecture and limited resources of traditional nodes represent a major constraint to perform certain required cognitive tasks. On the other hand, Software-Defined Radios (SDRs), which have the flexibility and performance needed to overcome the aforementioned limitations, currently have a power consumption too high for these networks. In this work, we propose a hybrid methodology of operation that consists of exploiting SDR technology only for those actions that strictly require its high flexibility, using traditional fixed hardware transceivers, which demand less node’s resources, for the remaining tasks. Then, we present the architecture and the main electronic components of a platform able to operate according to this methodology. This solution constitutes a significant reduction in power consumption compared with existing low-power SDRs, while maintaining the functionality needed for research in CWSNs.},
booktitle = {Proceedings of the 2017 International Conference on Embedded Wireless Systems and Networks},
pages = {294–299},
numpages = {6},
keywords = {Spectrum scarcity, software-defined radio, low-power platform, cognitive wireless sensor networks},
location = {Uppsala, Sweden},
series = {EWSN ’17}
}

@inproceedings{10.1145/3590837.3590950,
author = {V, Vanjipriya and Annamalai, Suresh},
title = {Machine Learning Technique for Energy, Performance and Cost-Effective Resource Management in Multi-Access Edge Computing},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590950},
doi = {10.1145/3590837.3590950},
abstract = {Modern cloud interconnects on efficient resource allocation and provisioning to reduce their energy footprint. Resource management is complicated by factors such as data centre energy utilisation, virtual machine migration, operating expense, and overhead. Researchers have been using virtualized technologies and methods as optimal-Multi-objective particle swarm optimization, Dynamic Power Saving Resource Allocation (DPRA), Least Squares Regression, etc. to improve the management of their study. Accurately allocating resources to cloud users to meet their requests and offer QoS is a difficult task because of the preceding steps. Allocating cloud infrastructure's resources in the most efficient way possible benefits both users and service providers. The difficulties of resource management are tackled in this study by employing novel approaches, heuristics, authentication, and virtualization. In order to distribute workloads over several physical nodes, cloud computing relies on dynamic scheduling with load balancing. Using the help of host load prediction and a Markov chain model with Particle Swarm Optimization (PSO), VM resources are dynamically allocated to appropriate input requests. High quality of service (QoS) for cloud applications is achieved by SLA-based resource optimization with deadline, cost, storage, and bandwidth targets. Compliance with Service Level Agreements (SLAs), efficient use of resources, and low energy consumption are all achieved using a prioritisation technique based on SLAs. Scheduled users can receive resources in a predetermined order thanks to queuing. We developed the M/M/c/K queuing paradigm for numerous users per server to lessen the burden on data centres. Hardware resource models, such as CPU, I/O, and memory use, reveal VM resource allocation. Information gathering enhances resource utilisation and reduces energy consumption.},
booktitle = {Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence},
articleno = {113},
numpages = {7},
keywords = {Virtual machine, Dynamic Power Saving Resource Allocation, Quality of Service, Load balancing, Service Level Agreements},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@article{10.1145/3558553,
author = {Qiu, Meikang and Xu, Ke and Zhang, Cheng and Zhang, Tianwei},
title = {Introduction to the Special Section on Energy-Efficient and Secure Computing for Artificial Intelligence and Beyond},
year = {2023},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1550-4859},
url = {https://doi.org/10.1145/3558553},
doi = {10.1145/3558553},
journal = {ACM Trans. Sen. Netw.},
month = {mar},
articleno = {51e},
numpages = {3}
}

@article{10.1145/2390191.2390192,
author = {Coskun, Ayse Kivilcim and Lu, Yung-Hsiang and Qiu, Qinru},
title = {Introduction to the Special Section on Adaptive Power Management for Energy and Temperature-Aware Computing Systems},
year = {2013},
issue_date = {January 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1084-4309},
url = {https://doi.org/10.1145/2390191.2390192},
doi = {10.1145/2390191.2390192},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {jan},
articleno = {1},
numpages = {2}
}

@inproceedings{10.5555/2190025.2190070,
author = {Wu, Youfeng and Hu, Shiliang and Borin, Edson and Wang, Cheng},
title = {A HW/SW Co-Designed Heterogeneous Multi-Core Virtual Machine for Energy-Efficient General Purpose Computing},
year = {2011},
isbn = {9781612843568},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {It is increasingly challenging to improve single thread performance because power/energy consumption becomes a major barrier to achieve significantly higher performance for general purpose cores. General purpose processors are designed to perform well in a wide variety of market segments, at the cost of having significantly lower performance-per-watt than special purpose processors targeting limited applications or market segments. In this paper, we propose a HW/SW co-designed heterogeneous multi-core virtual machine, called TwinPeaks, which integrates a set of less general but power efficient cores and uses dynamic binary optimization to schedule code regions to run on the most efficient cores. Our experiment and analysis indicate that TwinPeaks with a wide in-order core and a narrow out-of-order core may achieve 108% performance at ˜71% energy of a big 4-wide out-of-order core.},
booktitle = {Proceedings of the 9th Annual IEEE/ACM International Symposium on Code Generation and Optimization},
pages = {236–245},
numpages = {10},
series = {CGO '11}
}

@inproceedings{10.1145/2208828.2208853,
author = {Borgetto, Damien and Maurer, Michael and Da-Costa, Georges and Pierson, Jean-Marc and Brandic, Ivona},
title = {Energy-Efficient and SLA-Aware Management of IaaS Clouds},
year = {2012},
isbn = {9781450310550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2208828.2208853},
doi = {10.1145/2208828.2208853},
abstract = {Cloud computing utilizes arbitrary mega-scale computing infrastructures and is currently revolutionizing the ICT landscape by allowing remote access to computing power and data over the Internet. Besides the huge economical impact Cloud technology exhibits a high potential to be a cornerstone of a new generation of sustainable and energy-efficient ICT. The challenging issue thereby is the energy-efficient utilization of physical machines (PMs) and the resource-efficient management of virtual machines (VMs) while attaining promised non-functional qualities of service expressed by means of Service Level Agreements (SLAs). Currently, there exist solutions for PM power management, VM migrations, and dynamic reconfiguration of VMs. However, most of the existing approaches consider each of them alone, and only use rudimentary concepts for migration costs or disrespect the nature of the highly volatile workloads. In this paper we present an integrated approach for VM migration and reconfiguration, and PM power management. Thereby, we incorporate an autonomic management loop, where proactive actions are suggested for all three areas in a hierarchically structured way. We evaluate our approach with both, synthetic workload data and real-word monitoring data of a Next Generation Sequencing (NGS) application used for the protein folding in the bioinformatics area. The efficacy of our approach is evaluated by considering classical algorithms like First Fit, Monte Carlo and Vector Packing, adapted for energy-efficient reallocation. The results show energy savings up to 61.6% while keeping acceptably low SLA violation rates.},
booktitle = {Proceedings of the 3rd International Conference on Future Energy Systems: Where Energy, Computing and Communication Meet},
articleno = {25},
numpages = {10},
keywords = {clouds, IaaS, reallocation, energy-efficiency, virtual machine, migration, algorithms},
location = {Madrid, Spain},
series = {e-Energy '12}
}

@inproceedings{10.1109/CCGrid.2015.63,
author = {Li, Weidong and Liu, Xi and Zhang, Xuejie and Cai, Xiaobo},
title = {A Task-Type-Based Algorithm for the Energy-Aware Profit Maximizing Scheduling Problem in Heterogeneous Computing Systems},
year = {2015},
isbn = {9781479980062},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2015.63},
doi = {10.1109/CCGrid.2015.63},
abstract = {In this paper, we design an efficient algorithm for the energy-aware profit maximizing scheduling problem, where the high performance computing system administrator is to maximize the profit per unit time. The running time of the proposed algorithm is depending on the number of task types, while the running time of the previous algorithm is depending on the number of tasks. Moreover, we prove that the worst-case performance ratio is close to 2, which maybe the best result. Simulation experiments show that the proposed algorithm is more accurate than the previous method.},
booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {1107–1110},
numpages = {4},
keywords = {bag-of-tasks, high performance computing, scheduling, resource allocation, approximation algorithm},
location = {Shenzhen, China},
series = {CCGRID '15}
}

@inproceedings{10.1145/3576842.3589175,
author = {Helal Uddin, Mohammad and Baidya, Sabur},
title = {Optimizing Neural Network Efficiency with Hybrid Magnitude-Based and Node Pruning for Energy-Efficient Computing in IoT},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576842.3589175},
doi = {10.1145/3576842.3589175},
abstract = {The Deep Neural Networks (DNN) are computationally intensive in terms of processing, energy and memory which becomes a bottleneck to run these models on edge devices. This research study provides a technique for pruning the neural networks to enhance the performance of deep learning models in IoT devices. The proposed method combines magnitude-based pruning, which merges insignificant weights based on their magnitude, with node pruning, which eliminates insignificant nodes based on their contribution to the network. The hybrid pruning technique is designed to be energy-efficient, reducing the computational overhead of deep learning models while maintaining their accuracy. The experimental results demonstrate that the proposed method can achieve significant reductions in model size and energy consumption with minimal loss in accuracy. The technique has the potential to enable the deployment of deep learning models on resource constrained IoT devices.},
booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
pages = {474–476},
numpages = {3},
keywords = {Hybrid pruning, Model optimization, Energy-efficient computing, Internet of Things (IoT)., Neural network pruning},
location = {San Antonio, TX, USA},
series = {IoTDI '23}
}

@inproceedings{10.5555/2016802.2016821,
author = {Sabharwal, Manuj R.},
title = {Software Power Optimization: Analysis and Optimization for Energy-Efficient Software},
year = {2011},
isbn = {9781612846606},
publisher = {IEEE Press},
abstract = {Software is increasingly becoming a central issue in low power consumer based system. The amount of energy consumed by software has severe battery impact on the system. Minimizing power consumption is one of the primary challenges that today's developers faces due to lack of instrumentation functionality in the system. This tutorial will cover different prospect of energy usage and energy aware software design in system ranging from notebooks to smartphones/tablets. This tutorial will give special importance on the role of idle software in attain overall system energy efficiency. In Summary, this tutorial will give overview of software impact on hardware, quantify the impact and fix the issues in applications to extend the battery life.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Low-Power Electronics and Design},
pages = {63–64},
numpages = {2},
keywords = {power optimization, energy-aware computing, software optimization},
location = {Fukuoka, Japan},
series = {ISLPED '11}
}

@inproceedings{10.1145/3555661.3560872,
author = {Miglani, Arzoo and Kumar, Neeraj and Kishore, Avadh and Mohammad, Nazeeruddin},
title = {UAV-Enabled Edge Computing and Blockchain Based Secure Charging Station Selection for Energy Trading in V2G Environment},
year = {2022},
isbn = {9781450395144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555661.3560872},
doi = {10.1145/3555661.3560872},
abstract = {Vehicle-to-Grid (V2G) networks have emerged as a promising solution in the modern electric power transmission network. By leveraging the bidirectional energy trading capabilities of V2G, demand-supply mismatch is managed in wide range of applications. However, performing energy trading decisions at cloud centers leads to increased delay and overhead. The demand to process the 3V's (variety, volume, and velocity) of data generated by V2G with low latency necessitates the usage of edge computing services. Although with the growth of edge computing resources, the trust issue of collaboration also grows among different stakeholders and service providers. Therefore, to deal with the aforementioned issues, this paper presents blockchain and UAV-enabled edge computing based energy trading services for the V2G environment. The decision of selecting a charging station (CS) by an electric vehicle (EV) is processed close to the EV movement via edge nodes. To secure and validate energy trading transactions and automation of the whole system, the blockchain technology is used in the proposal. The result section depicts that the proposed scheme has minimal computational and communicational overhead along with reduced latency in comparison to the existing schemes.},
booktitle = {Proceedings of the 5th International ACM Mobicom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {103–108},
numpages = {6},
keywords = {blockchain, edge computing, UAV, energy trading, vehicle-to-grid},
location = {Sydney, NSW, Australia},
series = {DroneCom '22}
}

@inproceedings{10.1145/3060403.3060459,
author = {Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
title = {Energy Efficient In-Memory Computing Platform Based on 4-Terminal Spin Hall Effect-Driven Domain Wall Motion Devices},
year = {2017},
isbn = {9781450349727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3060403.3060459},
doi = {10.1145/3060403.3060459},
abstract = {In this paper, we propose an energy efficient in-memory computing platform based on novel 4-terminal spin Hall effect-driven domain wall motion devices that could be employed as both non-volatile memory cell and in-memory logic unit. The proposed designs lead to unity of memory and logic. The device to architecture level simulation results show that, with 45% area increase, the proposed in-memory computing platform achieves the write energy 15.6 ~ fJ/bit which is more than one order lower than that of standard 1-transistor 1-magnetic tunnel junction counterpart while keeping the identical 1ns writing speed. In addition, the proposed in-memory logic scheme improves the operating energy by 61.3% as compared with the conventional nonvolatile in-memory logic designs.},
booktitle = {Proceedings of the on Great Lakes Symposium on VLSI 2017},
pages = {77–82},
numpages = {6},
keywords = {in-memory computing, spin hall effect, domain wall motion device},
location = {Banff, Alberta, Canada},
series = {GLSVLSI '17}
}

@inproceedings{10.5555/789083.1022860,
author = {Tan, T. K. and Raghunathan, A. and Jha, N. K.},
title = {Software Architectural Transformations: A New Approach to Low Energy Embedded Software},
year = {2003},
isbn = {0769518702},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Previous work on software optimization for low energy has focussed on instruction-level optimizations and compiler techniques. We argue, and demonstrate, that significant energy saviings could be "left on the table" if energy is not considered during the design of the software architecture. As a first step towards addressing this gap, we propose a systematic framework for software architectural transformations to reduce energy consumption. We consider software architectural transformations in the context of the multi-process software style driven by an operating system (OS), which is very commonly employed in energy-sensitive embedded systems. Our methodology for applying software architectural transformations consists of: (i) constructing a software architecture graph representation, (ii) deriving initial energy and performance statistics using a detailed energy simulation framework, (iii) constructing sequences of atomic software architectural transformations, guided by energy change estimates derived from high-level energy macro-models, that result in maximal energy reduction, and (iv) generation of program source code to reflect the optimized software architecture. We employ a wide suite of software architectural transformations whose effects span the application-OS boundary, including how the program functionality is structured into architectural components (e.g., Application processes, signal handlers, and device drivers), and connectors between them (inter-component synchronization and communication mechanisms). We present experimental results on several multi-process embedded software programs, in the context of an embedded system that features the Intel StrongARM processor and the embedded Linux OS. The presented results clearly underscore the potential of the proposed methodology (up to 66.1% reduction in energy is obtained). In a broader sense, our work demonstrates the impact of considering energy during the earlier stages of the software design process.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe - Volume 1},
pages = {11046},
series = {DATE '03}
}

@article{10.1145/3266229,
author = {Srinivasan, Gopalakrishnan and Panda, Priyadarshini and Roy, Kaushik},
title = {STDP-Based Unsupervised Feature Learning Using Convolution-over-Time in Spiking Neural Networks for Energy-Efficient Neuromorphic Computing},
year = {2018},
issue_date = {October 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3266229},
doi = {10.1145/3266229},
abstract = {Brain-inspired learning models attempt to mimic the computations performed in the neurons and synapses constituting the human brain to achieve its efficiency in cognitive tasks. In this work, we propose Spike Timing Dependent Plasticity-based unsupervised feature learning using convolution-over-time in Spiking Neural Network (SNN). We use shared weight kernels that are convolved with the input patterns over time to encode representative input features, thereby improving the sparsity as well as the robustness of the learning model. We show that the Convolutional SNN self-learns several visual categories for object recognition with limited number of training patterns while yielding comparable classification accuracy relative to the fully connected SNN. Further, we quantify the energy benefits of the Convolutional SNN over fully connected SNN on neuromorphic hardware implementation.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {nov},
articleno = {44},
numpages = {12},
keywords = {convolution-over-time, energy-efficient neuromorphic computing, Convolutional spiking neural network, stdp, unsupervised feature learning}
}

@inproceedings{10.1109/CCGRID.2017.92,
author = {Li, Yunbo and Orgerie, Anne-C\'{e}cile and Rodero, Ivan and Parashar, Manish and Menaud, Jean-Marc},
title = {Leveraging Renewable Energy in Edge Clouds for Data Stream Analysis in IoT},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.92},
doi = {10.1109/CCGRID.2017.92},
abstract = {The emergence of Internet of Things (IoT) is participating to the increase of data- and energy-hungry applications. As connected devices do not yet offer enough capabilities for sustaining these applications, users perform computation offloading to the cloud. To avoid network bottlenecks and reduce the costs associated to data movement, edge cloud solutions have started being deployed, thus improving the Quality of Service. In this paper, we advocate for leveraging on-site renewable energy production in the different edge cloud nodes to green IoT systems while offering improved QoS compared to core cloud solutions. We propose an analytic model to decide whether to offload computation from the objects to the edge or to the core Cloud, depending on the renewable energy availability and the desired application QoS. This model is validated on our application use-case that deals with video stream analysis from vehicle cameras.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {186–195},
numpages = {10},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@article{10.1145/3584745,
author = {Garc\'{I}a-D\'{I}az, Vicente and Lin, Jerry Chun-Wei and Molinera, Juan Antonio Morente},
title = {Introduction to the Special Section on Edge Computing AI-IoT Integrated Energy Efficient Intelligent Transportation System for Smart Cities},
year = {2023},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {4},
issn = {1533-5399},
url = {https://doi.org/10.1145/3584745},
doi = {10.1145/3584745},
journal = {ACM Trans. Internet Technol.},
month = {mar},
articleno = {105},
numpages = {2}
}

@inproceedings{10.5555/3021955.3021979,
author = {Hinz, Mauro and Miers, Charles C. and Pillon, Mauricio A. and Koslovski, Guilherme P.},
title = {A Cost Model for IaaS Clouds Based on Virtual Machine Energy Consumption},
year = {2016},
isbn = {9788576693178},
publisher = {Brazilian Computer Society},
address = {Porto Alegre, BRA},
abstract = {Reduction in data center energy consumption is a constant motivation for IaaS providers. Among all components, CPU appears as a main energy consumer. Although there is a strong relationship between CPU load and its energy consumption, pricing models of popular IaaS providers do not consider this information as a primary and variable element. This paper quantifies the relationship by identifying the individual consumption of virtual CPUs, which form the basis for an allocation cost model. The proposed model, termed Virtual Power, is faced with Amazon EC2 pricing model pointing a cost reduction for IaaS provider and a proportional sharing between users.},
booktitle = {Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1},
pages = {136–143},
numpages = {8},
keywords = {Cost, Model, Virtual Machine, IaaS},
location = {Florianopolis, Santa Catarina, Brazil},
series = {SBSI '16}
}

@inproceedings{10.1145/3152178.3152193,
author = {Wendel, Jochen and Simons, Alexander and Nichersu, Alexandru and Murshed, Syed Monjur},
title = {Rapid Development of Semantic 3D City Models for Urban Energy Analysis Based on Free and Open Data Sources and Software},
year = {2017},
isbn = {9781450354950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152178.3152193},
doi = {10.1145/3152178.3152193},
abstract = {Geospatial data, specifically semantic 3D building data, plays a crucial role in urban energy analysis as spatial calculations using 3D geometries usually form the basis for energy simulation and modelling needed for numerous smart cities applications. Additional information describing the building stock, such as building materials and energetic properties but also data not directly linked to urban morphology such as weather data, environmental data, vegetation or socio-demographic data sets are required for these applications. A major drawback in the widespread applicability of urban energy analysis is the lack of available data sets as well as the costly and lengthy labor-intensive process of generation of those data sets (e.g. 3D city models or LIDAR data). While recent years have seen an opening up of urban data sets through free and open data portals, web services, and APIs that are used for urban energy analysis, data standardization and varying data quality still raises big challenges. This research explores different methodologies for the generation and usage of semantic 3D city models based on free and open data sources and software. In this paper, we describe four different methodologies for the generation of semantic 3D city models from available open data (geospatial data portals, LIDAR data, Open Street Map data, and remote sensing) and the tools required to achieve the task. To evaluate the suitability of these open-data sets for smart cities applications, multiple energy models, such as an energy performance model and a vertical solar radiation tool, previously developed in EIFER, have been applied to evaluate the applicability of these generated city models.},
booktitle = {Proceedings of the 3rd ACM SIGSPATIAL Workshop on Smart Cities and Urban Analytics},
articleno = {15},
numpages = {7},
keywords = {Urban energy analysis, Free and open data and software, Smart and sustainable cities, 3D city models, CityGML},
location = {Redondo Beach, CA, USA},
series = {UrbanGIS'17}
}

@inproceedings{10.1145/1980022.1980296,
author = {Baruah, S.},
title = {Designing and Implementing a Computer Interactive Network Embedded System for Monitoring and Controlling of Humidity and Temperature for Using in a Green House},
year = {2011},
isbn = {9781450304498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1980022.1980296},
doi = {10.1145/1980022.1980296},
abstract = {Device itself is interfaced with computer using COM ports of device and the Connecting computer. This makes it possible to use computer monitor as user friendly display instead of LCD at the same time use of computer keyboard instead of push button keys enhance the interactive use. Using the other hardware and software features of computer it is possible to store huge amount of data with easy retrieval of same using appropriate database software. Designing user interactive computer front end it will make the system user friendly. Further computer itself is connected to LAN using TCP/IP protocol making monitoring and controlling feasible from remote locations using similar interactive front ends at dispersed locations. This feature eliminate the limitation of monitoring and operating from the place of its installation.Developed system is capable of maintaining a fixed temperature and humidity at desired level as required by the Green House. System will continuously monitor the sense value of temperature against some user defined limit value. If sense value goes beyond limit value system will automatically start some hardware device to bring the sense values at desired level.This paper explores the possibility of controlling and monitoring of temperature and humidity together in a broad interactive way by connecting the system in a personal computer which itself is connected with LAN/IntranetIn many research and Industrial setup monitoring and controlling of temperature and humidity is very essential. Though Microcontroller based embedded systems are found to be very much effective most of such devices are generally provided with LCD and push button keys for monitoring and controlling. Such devices are having its limitations in Display, userfriedliness and monitoring and operating from the place of its installation. In the stated approach effort has been made for effective use of the system eliminating the above stated difficulties.},
booktitle = {Proceedings of the International Conference &amp; Workshop on Emerging Trends in Technology},
pages = {1247–1250},
numpages = {4},
keywords = {COM port, intranet, front-end, LAN, RTOS},
location = {Mumbai, Maharashtra, India},
series = {ICWET '11}
}

@inproceedings{10.1145/3401335.3401684,
author = {Penzenstadler, Birgit},
title = {Where Attention Goes, Energy Flows: Enhancing Individual Sustainability in Software Engineering},
year = {2020},
isbn = {9781450375955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3401335.3401684},
doi = {10.1145/3401335.3401684},
abstract = {Software engineers are plagued by the same troubles as many others in highly skilled jobs and digitized environments: Ever-expanding to-do lists, time to market pressure from management, deadline-driven development, continuous interruption during working tasks, and the juggle of balancing that with other areas of life (physical, mental and emotional health, family, household, finance, friends, hobbies and community service). These demands of life in combination with a seemingly ever-increasing pace wear or burn out many people in the long run. Specifically, as software engineers, this also leads to decreased creativity and less efficiency in problem-solving. Generally offered solutions are reducing screen time and spending more time outdoors, both of which are hard to do within the work of a software engineer. On a meta level, if the developers of the systems that run most of our world do not develop individual sustainability with a balanced pace of life, that imbalance propagates into the systems we develop (similar to Conway's Law). We argue that mindfulness practices like yoga poses (asanas), breathing practices, and meditation exercises can help individually, and even more effectively in combination. In this exploratory paper, we discuss related work that explores the application of these mitigations in other application domains and propose a research agenda to explore their use within software engineering education and practice.Engaging with mindfulness practices in the context of software engineering promises to enhance creativity and cognitive problem-solving skills, leading to more efficiency and effectiveness during software development and increased individual sustainability. This, in turn, leads to better team spirit as well as increased economic profit, both in terms of maintaining human capital and customer contract deliverables.},
booktitle = {Proceedings of the 7th International Conference on ICT for Sustainability},
pages = {139–146},
numpages = {8},
keywords = {breath-work, individual sustainability, yoga, meditation, software engineering},
location = {Bristol, United Kingdom},
series = {ICT4S2020}
}

@inproceedings{10.1109/CCGRID.2017.130,
author = {Altomare, Albino and Cesario, Eugenio},
title = {A Data-Driven Approach Based on Auto-Regressive Models for Energy-Efficient Clouds},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.130},
doi = {10.1109/CCGRID.2017.130},
abstract = {The steadily increasing success of Cloud Computing is causing a huge rise in its electrical power consumption, contributing to higher energy costs, as well as to the greenhouse effect and the global warming. One of the most common key strategies to reduce the power consumption of data centers is the consolidation of virtual machines, whose effectiveness strongly depends on a reliable forecasting of future computational resource needs. In fact, servers are typically configured to handle peak workload conditions even if they are often under-utilized, that results in a wastefulness of resources and inefficient energy consumption. Motivated by these issues, this paper describes a data-driven approach based on autoregressive models to dynamically forecast virtual machine workloads, for energy-aware allocations of virtual machines on Cloud physical nodes. Virtual machine migrations across physical servers are periodically done on the basis of the estimated virtual machine demands, by minimizing the number of active servers. Experimental results show encouraging benefits in terms of energy saving, while satisfying performance constraints and service level agreement established with users.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {1062–1069},
numpages = {8},
keywords = {data-driven approaches for energy-aware Cloud, Cloud computing, forecasting, energy efficiency},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@inproceedings{10.1145/2627369.2627646,
author = {Sartori, John and Kumar, Rakesh},
title = {Software Canaries: Software-Based Path Delay Fault Testing for Variation-Aware Energy-Efficient Design},
year = {2014},
isbn = {9781450329750},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2627369.2627646},
doi = {10.1145/2627369.2627646},
abstract = {Software-based path delay fault testing (SPDFT) has been used to identify faulty chips that cannot meet timing constraints due to gross delay defects. In this paper, we propose using SPDFT for a new purpose -- aggressively selecting the operating point of a variation-affected design. In order to use SPDFT for this purpose, test routines must provide high coverage of potentially-critical paths and must have low dynamic performance overhead. We describe how to apply SPDFT for selecting an energy-efficient operating point for a variation-affected processor and demonstrate that our test routines achieve ample coverage and low overhead.},
booktitle = {Proceedings of the 2014 International Symposium on Low Power Electronics and Design},
pages = {159–164},
numpages = {6},
keywords = {software-based path delay fault testing, software canaries, energy-efficiency},
location = {La Jolla, California, USA},
series = {ISLPED '14}
}

@inproceedings{10.1145/2818613.2818744,
author = {Stanley-Marbell, Phillip},
title = {How Device Properties Influence Energy-Delay Metrics and the Energy-Efficiency of Parallel Computations},
year = {2015},
isbn = {9781450339469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2818613.2818744},
doi = {10.1145/2818613.2818744},
abstract = {Semiconductor device engineers are hard-pressed to relate observed device-level properties of potential CMOS replacements to computation performance. We address this challenge by developing a model linking device properties to algorithm parallelism, total computational work, and degree of voltage and frequency scaling. We then use the model to provide insight into how device properties influence execution time, average power dissipation, and overall energy usage of parallel algorithms executing in the presence of hardware concurrency. The model facilitates studying tradeoffs: It lets researchers formulate joint energy-delay metrics that account for device properties.We support our analysis with data from a dozen large digital circuit designs, and we validate the models we present using performance and power measurements of a parallel algorithm executing on a state-of-the-art low-power multicore processor.},
booktitle = {Proceedings of the Workshop on Power-Aware Computing and Systems},
pages = {31–35},
numpages = {5},
keywords = {energy-efficiency, transistors, power, parallelism, measurement},
location = {Monterey, California},
series = {HotPower '15}
}

@article{10.1145/3154384,
author = {Pinto, Gustavo and Castor, Fernando},
title = {Energy Efficiency: A New Concern for Application Software Developers},
year = {2017},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {60},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3154384},
doi = {10.1145/3154384},
abstract = {Development of energy-efficient software is hindered by a lack of knowledge and a lack of tools.},
journal = {Commun. ACM},
month = {nov},
pages = {68–75},
numpages = {8}
}

@inproceedings{10.1145/3387906.3388628,
author = {Couto, Marco and Maia, Daniel and Saraiva, Jo\~{a}o and Pereira, Rui},
title = {On Energy Debt: Managing Consumption on Evolving Software},
year = {2020},
isbn = {9781450379601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387906.3388628},
doi = {10.1145/3387906.3388628},
abstract = {This paper introduces the concept of energy debt: a new metric, reflecting the implied cost in terms of energy consumption over time, of choosing a flawed implementation of a software system rather than a more robust, yet possibly time consuming, approach. A flawed implementation is considered to contain code smells, known to have a negative influence on the energy consumption.Similar to technical debt, if energy debt is not properly addressed, it can accumulate an energy "interest". This interest will keep increasing as new versions of the software are released, and eventually reach a point where the interest will be higher than the initial energy debt. Addressing the issues/smells at such a point can remove energy debt, at the cost of having already consumed a significant amount of energy which can translate into high costs. We present all underlying concepts of energy debt, bridging the connection with the existing concept of technical debt and show how to compute the energy debt through a motivational example.},
booktitle = {Proceedings of the 3rd International Conference on Technical Debt},
pages = {62–66},
numpages = {5},
keywords = {energy debt, code analysis, green software},
location = {Seoul, Republic of Korea},
series = {TechDebt '20}
}

@inproceedings{10.1145/2630602.2630606,
author = {Aggarwal, Dippy and Curry, Edward and Davis, Karen C.},
title = {Employing Virtual Power Analytics and Linked Data for Enterprise IT Energy Informatics},
year = {2014},
isbn = {9781450329941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2630602.2630606},
doi = {10.1145/2630602.2630606},
abstract = {The paper provides a solution to an organization's challenge for reducing its ecological footprint. We develop a framework for visualizing information concerning power consumption of IT devices in real-time using power metering approaches and leverage semantic web technologies to weave information that is dispersed across different data sources, ranging from an organization's asset databases to excel spreadsheets to the data available on manufacturer's websites. Visualizing the aforementioned information and bringing it together in one application can help organizations in understanding and adapting their energy consumption behavior in order to better support environmentally sustainable practices. The purpose of this project, from a power analytics standpoint, is twofold: (1) it aims to provide users with insight into their device's current power consumption without leaving a footprint on their machine, and (2) to analyze if one method gives more accurate results than others. We performed analysis using Microsoft Joulemeter and power estimation using software design methodologies (with numbers from smart meters as our benchmark).},
booktitle = {Proceedings of Semantic Web Information Management on Semantic Web Information Management},
pages = {1–4},
numpages = {4},
keywords = {Green IT, Energy Informatics, Data Integration, Semantic Web, Power Analytics, Linked Data},
location = {Snowbird, UT, USA},
series = {SWIM'14}
}

@inproceedings{10.1145/2859889.2859892,
author = {Gregory, Adam and Majumdar, Shikharesh},
title = {A Constraint Programming Based Energy Aware Resource Management Middleware for Clouds Processing MapReduce Jobs with Deadlines},
year = {2016},
isbn = {9781450341479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2859889.2859892},
doi = {10.1145/2859889.2859892},
abstract = {This paper concerns guarantees on system performance through Service Level Agreement (SLA) compliance and focuses on devising energy aware resource management techniques based on Dynamic Voltage and Frequency Scaling (DVFS) used by resource management middleware in clouds that handle MapReduce jobs. This research formulates the resource management problem as an optimization problem using Constraint Programming (CP). Experimental results presented in the paper demonstrate the effectiveness of the technique.},
booktitle = {Companion Publication for ACM/SPEC on International Conference on Performance Engineering},
pages = {15–20},
numpages = {6},
keywords = {energy management, MapReduce with deadlines, constraint programming, resource management on clouds, big data},
location = {Delft, The Netherlands},
series = {ICPE '16 Companion}
}

@inproceedings{10.1145/3482632.3487547,
author = {Qin, Qihong and Li, Yutong},
title = {Research on the Curriculum System of Software Engineering Specialty in Engineering Colleges in the Process of Transformation of New and Old Kinetic Energy},
year = {2021},
isbn = {9781450390255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3482632.3487547},
doi = {10.1145/3482632.3487547},
abstract = {The transformation of old and new kinetic energy emphasizes that Chinese universities should actively set up and develop a number of new engineering majors on the one hand, and promote the reform and innovation of existing engineering majors on the other hand. The transformation of new and old kinetic energy is essentially the innovation and transformation of talent training mode. Software engineering is a course offered by most colleges and universities. However, each school's talent training program, specific implementation process and final training effect are different. Starting from the teaching practice of software engineering education, based on the analysis of international software engineering professional norms and teaching practice, this paper gives the curriculum system of software engineering major in engineering colleges, focuses on setting up the teaching concept of software engineering and cultivating the ability of software system construction, and discusses the innovative setting scheme of software engineering courses in detail, which can provide reference for international and domestic software engineering teaching plan designers.},
booktitle = {2021 4th International Conference on Information Systems and Computer Aided Education},
pages = {2953–2957},
numpages = {5},
location = {Dalian, China},
series = {ICISCAE 2021}
}

@inproceedings{10.1145/2934583.2934604,
author = {Gu, Hongxiang and Xu, Teng and Potkonjak, Miodrag},
title = {An Energy-Efficient PUF Design: Computing While Racing},
year = {2016},
isbn = {9781450341851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934583.2934604},
doi = {10.1145/2934583.2934604},
abstract = {Physical unclonable functions (PUFs) take advantage of the effect of process variation on hardware to obtain their unclonability. Traditional PUF design only focuses on the analog signals of circuits. An arbiter PUF, for example, generates responses by racing delay signals. Implementations of such PUFs usually employ large area and power consumption while providing very low throughput.To address this problem, we propose an energy efficient PUF design in such a way that it races analog signals and computes digital logic simultaneously. More importantly, the analog portion of the circuit (racing) shares a large amount of hardware resources with the digital portion of the circuit (computing) by introducing only small overhead in terms of area and power. Our test results on Spartan-6 field-programmable gate array (FPGA) platforms indicate that by combining the two outputs, our design enables much larger PUF output throughput, better randomness and less power consumption compared to traditional PUFs.},
booktitle = {Proceedings of the 2016 International Symposium on Low Power Electronics and Design},
pages = {142–147},
numpages = {6},
keywords = {random number generator, FPGA, PUF},
location = {San Francisco Airport, CA, USA},
series = {ISLPED '16}
}

@inproceedings{10.1145/3077839.3084027,
author = {Kueh, Paul J. and Mashaly, Maggie Ezzat},
title = {Load Balancing in Distributed Cloud Data Center Configurations: Performance and Energy-Efficiency},
year = {2017},
isbn = {9781450350365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3077839.3084027},
doi = {10.1145/3077839.3084027},
abstract = {In this contribution two cloud server clusters are considered which process virtualized user service requests defined as Virtual Machines (VM) operated under the Hypervisor control. Load Balancing (LB) is applied to avoid temporary overloads and to enforce negotiated Service Level Agreements (SLA) defined by means and percentiles of processing delays. Two novel LB strategies are defined through which the two server clusters perfform job processing cooperatively through mutual job overflows by a "Local Server System First" (LSSF) and through a "Shortest Response Time First" (SRTF) strategy, respectively. The cooperation operation is performed by VM migration at the instant of VM scheduling by the Hypervisor. Both LB models are defined by queuing systems which are analyzed by the method of Markov-Chains. Energy efficiency has been analyzed by the authors through server consolidation, server sleep modes, and through Dynamic Voltage and Frequency Scaling (DVFS), c.f. [1-5]. In this contribution another method is studied which is based on a flexible VM migration to a common server cluster by which the total number of servers can be reduced making use of the effect of the economy of scale by server aggregation.},
booktitle = {Proceedings of the Eighth International Conference on Future Energy Systems},
pages = {296–301},
numpages = {6},
keywords = {Cloud Data Centers, Performance Analysis, Service Level Agreements, Task Modeling &amp; Scheduling &amp; Queuing, VM Migration},
location = {Shatin, Hong Kong},
series = {e-Energy '17}
}

@inproceedings{10.1145/2598394.2605693,
author = {Ren, Yi and Suzuki, Junichi and Lee, Chonho and Vasilakos, Athanasios V. and Omura, Shingo and Oba, Katsuya},
title = {Balancing Performance, Resource Efficiency and Energy Efficiency for Virtual Machine Deployment in DVFS-Enabled Clouds: An Evolutionary Game Theoretic Approach},
year = {2014},
isbn = {9781450328814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2598394.2605693},
doi = {10.1145/2598394.2605693},
abstract = {This paper proposes and evaluates a multiobjective evolutionary game theoretic framework for adaptive and stable application deployment in clouds that support dynamic voltage and frequency scaling (DVFS) for CPUs. The proposed framework, called Cielo, aids cloud operators to adapt the resource allocation to applications and their locations according to the operational conditions in a cloud (e.g., workload and resource availability) with respect to multiple conflicting objectives such as response time performance, recourse utilization and power consumption. Moreover, Cielo theoretically guarantees that each application performs an evolutionarily stable deployment strategy, which is an equilibrium solution under given operational conditions. Simulation results verify this theoretical analysis; applications seek equilibria to perform adaptive and evolutionarily stable deployment strategies. Cielo allows applications to successfully leverage DVFS to balance their response time performance, resource utilization and power consumption.},
booktitle = {Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation},
pages = {1205–1212},
numpages = {8},
keywords = {evolutionary game theory, multiobjective optimization, power-aware virtual machine placement, cloud computing},
location = {Vancouver, BC, Canada},
series = {GECCO Comp '14}
}

@inproceedings{10.5555/963600.963603,
author = {Dunstan, Neil and Hodgson, Stephen},
title = {A Processor Array for Computing Wavelet Energies},
year = {2003},
publisher = {Trinity College Dublin},
abstract = {Efficient remediation of sites contaminated with buried unexploded ordnance (UXO) requires highly accurate discrimination between intact ordnance and fragments or other objects. The energies at each level of the discrete wavelet transformation (DWT) of electromagnetic signal responses from subsurface objects have been shown to be characteristic of some types of ordnance. This paper investigates low-level parallel processing of energy calculations that may form part of a classification system that uses energies as characteristic features. Existing designs for the DWT are discussed as well as specific architectural requirements for the remediation application. The proposed design is described in terms of space-time diagrams, recurrence equations, scheduling and allocation functions.},
booktitle = {Proceedings of the 1st International Symposium on Information and Communication Technologies},
pages = {15–20},
numpages = {6},
location = {Dublin, Ireland},
series = {ISICT '03}
}

@inproceedings{10.1145/3291533.3291566,
author = {Karanikolas, Nikitas N. and Liaramantzas, Antonios and Theodorakopoulos, Leonidas},
title = {Cheap and Efficient Solar Energy: Software and Electronics},
year = {2018},
isbn = {9781450366106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3291533.3291566},
doi = {10.1145/3291533.3291566},
abstract = {We have suggested the creation of a Small Efficient Energy Production Systems with reduced cost. The idea was to integrate machining technology; microcontrollers and software in order to create Efficient Electricity Production with reduced cost. The machining technology permitted us to construct a teeterboard that could (turn / move and) follow the sun, controlled by an Arduino Uno microcontroller. Here we examine the electronics and the software that controls the teeterboard. A rigorous analysis of the cost for system's creation and the power produced by the system justifies that it is worth for further examining idea.},
booktitle = {Proceedings of the 22nd Pan-Hellenic Conference on Informatics},
pages = {139–143},
numpages = {5},
keywords = {single axis solar tracker, solar energy},
location = {Athens, Greece},
series = {PCI '18}
}

@inproceedings{10.1145/2380403.2380409,
author = {Mock, Randolf and Neukirchner, Moritz and Ernst, Rolf and Wijtvliet, Ruud and Huetwohl, Michael and Urard, Pascal and Vermesan, Ovidiu},
title = {Internet-of-Energy: Combining Embedded Computing and Communication for the Smart Grid},
year = {2012},
isbn = {9781450314244},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380403.2380409},
doi = {10.1145/2380403.2380409},
abstract = {Driven by increasing cost of energy and by the inclusion of re-newable but time variant sources of energy on the production side, and by new requirements from electromobility, building and home automation on the consumption side, the energy grid has moved in the focus of research, industry and infrastructure development. One of the key challenges is the interaction of the numerous em-bedded systems controlling energy producing and consuming devices using an "internet of energy".This session will provide different views on this development towards a smart energy grid. The first talk given by a leading pro-vider of energy grid equipment will give an overview on the new developments and challenges in modeling and simulating local grid behavior. The second talk discusses building energy management at the interface between home automation and the smart grid, both from the application and the embedded platform perspective. The third talk addresses home automation which serves many objectives, besides being a terminal network of the smart grind. Last not least, the fourth talk presents new development in wireless sensor devices as an important component of future home and energy networks.},
booktitle = {Proceedings of the 2012 International Conference on Compilers, Architectures and Synthesis for Embedded Systems},
pages = {7–8},
numpages = {2},
keywords = {smart grid, smart energy},
location = {Tampere, Finland},
series = {CASES '12}
}

@inproceedings{10.1109/SC.2014.8,
author = {Cassidy, Andrew S. and Alvarez-Icaza, Rodrigo and Akopyan, Filipp and Sawada, Jun and Arthur, John V. and Merolla, Paul A. and Datta, Pallab and Tallada, Marc Gonzalez and Taba, Brian and Andreopoulos, Alexander and Amir, Arnon and Esser, Steven K. and Kusnitz, Jeff and Appuswamy, Rathinakumar and Haymes, Chuck and Brezzo, Bernard and Moussalli, Roger and Bellofatto, Ralph and Baks, Christian and Mastro, Michael and Schleupen, Kai and Cox, Charles E. and Inoue, Ken and Millman, Steve and Imam, Nabil and McQuinn, Emmett and Nakamura, Yutaka Y. and Vo, Ivan and Guo, Chen and Nguyen, Don and Lekuch, Scott and Asaad, Sameh and Friedman, Daniel and Jackson, Bryan L. and Flickner, Myron D. and Risk, William P. and Manohar, Rajit and Modha, Dharmendra S.},
title = {Real-Time Scalable Cortical Computing at 46 Giga-Synaptic OPS/Watt with ~100\texttimes{} Speedup in Time-to-Solution and ~100,000\texttimes{} Reduction in Energy-to-Solution},
year = {2014},
isbn = {9781479955008},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC.2014.8},
doi = {10.1109/SC.2014.8},
abstract = {Drawing on neuroscience, we have developed a parallel, event-driven kernel for neurosynaptic computation, that is efficient with respect to computation, memory, and communication. Building on the previously demonstrated highly-optimized software expression of the kernel, here, we demonstrate TrueNorth, a co-designed silicon expression of the kernel. TrueNorth achieves five orders of magnitude reduction in energy-to-solution and two orders of magnitude speedup in time-to-solution, when running computer vision applications and complex recurrent neural network simulations. Breaking path with the von Neumann architecture, TrueNorth is a 4,096 core, 1 million neuron, and 256 million synapse brain-inspired neurosynaptic processor, that consumes 65mW of power running at real-time and delivers performance of 46 Giga-Synaptic OPS/Watt. We demonstrate seamless tiling of TrueNorth chips into arrays, forming a foundation for cortex-like scalability. TrueNorth's unprecedented time-to-solution, energy-to-solution, size, scalability, and performance combined with the underlying flexibility of the kernel enable a broad range of cognitive applications.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
pages = {27–38},
numpages = {12},
location = {New Orleans, Louisana},
series = {SC '14}
}

@inproceedings{10.1145/3147213.3147227,
author = {Hasan, MD Sabbir and Alvares, Frederico and Ledoux, Thomas},
title = {GPaaScaler: Green Energy Aware Platform Scaler for Interactive Cloud Application},
year = {2017},
isbn = {9781450351492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147213.3147227},
doi = {10.1145/3147213.3147227},
abstract = {Recently, smart usage of renewable energy has been a hot topic in the Cloud community. In this vein, we have recently proposed the creation of green energy awareness around Interactive Cloud Applications, but in static amount of underlying resources. This paper adds to previous ones as it considers elastic underlying infrastructure, that is, we propose a PaaS solution which efficiently utilize the elasticity nature at both infrastructure and application levels, by leveraging adaptation in facing to changing condition i.e., workload burst, performance degradation, quality of energy, etc. While applications are adapted by dynamically re-configuring their service level based on performance and/or green energy availability, the infrastructure takes care of addition/removal of resources based on application's resource demand. Both adaptive behaviors are implemented in separated modules and are coordinated in a sequential manner.We validate our approach by extensive experiments and results obtained over Grid'5000 test bed. Results show that, application can reduce significant amount of brown energy consumption by 35% and daily instance hour cost by 37% compared to a baseline approach when green energy aware adaptation is considered.},
booktitle = {Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {79–89},
numpages = {11},
keywords = {paas, energy consumption, interactive cloud application, autonomic computing, sustainable computing., green it},
location = {Austin, Texas, USA},
series = {UCC '17}
}

@inproceedings{10.1145/286498.286519,
author = {Rencsok, Charles},
title = {Activation Energy Required with Classroom Computers},
year = {1998},
isbn = {1581130287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/286498.286519},
doi = {10.1145/286498.286519},
booktitle = {CHI 98 Conference Summary on Human Factors in Computing Systems},
pages = {40–41},
numpages = {2},
keywords = {technology introduction, computer support, risks versus benefits, instructional technology, classroom computers, instructional tools, initiating change},
location = {Los Angeles, California, USA},
series = {CHI '98}
}

@inproceedings{10.1145/2380445.2380451,
author = {Mock, Randolf and Neukirchner, Moritz and Ernst, Rolf and Wijtvliet, Ruud and Huetwohl, Michael and Urard, Pascal and Vermesan, Ovidiu},
title = {Internet-of-Energy: Combining Embedded Computing and Communication for the Smart Grid},
year = {2012},
isbn = {9781450314268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380445.2380451},
doi = {10.1145/2380445.2380451},
abstract = {Driven by increasing cost of energy and by the inclusion of re-newable but time variant sources of energy on the production side, and by new requirements from electromobility, building and home automation on the consumption side, the energy grid has moved in the focus of research, industry and infrastructure development. One of the key challenges is the interaction of the numerous em-bedded systems controlling energy producing and consuming devices using an "internet of energy".This session will provide different views on this development towards a smart energy grid. The first talk given by a leading pro-vider of energy grid equipment will give an overview on the new developments and challenges in modeling and simulating local grid behavior. The second talk discusses building energy management at the interface between home automation and the smart grid, both from the application and the embedded platform perspective. The third talk addresses home automation which serves many objectives, besides being a terminal network of the smart grind. Last not least, the fourth talk presents new development in wireless sensor devices as an important component of future home and energy networks.},
booktitle = {Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},
pages = {7–8},
numpages = {2},
keywords = {smart grid, smart energy},
location = {Tampere, Finland},
series = {CODES+ISSS '12}
}

@inproceedings{10.1145/2380356.2380362,
author = {Mock, Randolf and Neukirchner, Moritz and Ernst, Rolf and Wijtvliet, Ruud and Huetwohl, Michael and Urard, Pascal and Vermesan, Ovidiu},
title = {Internet-of-Energy: Combining Embedded Computing and Communication for the Smart Grid},
year = {2012},
isbn = {9781450314251},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2380356.2380362},
doi = {10.1145/2380356.2380362},
abstract = {Driven by increasing cost of energy and by the inclusion of re-newable but time variant sources of energy on the production side, and by new requirements from electromobility, building and home automation on the consumption side, the energy grid has moved in the focus of research, industry and infrastructure development. One of the key challenges is the interaction of the numerous em-bedded systems controlling energy producing and consuming devices using an "internet of energy".This session will provide different views on this development towards a smart energy grid. The first talk given by a leading pro-vider of energy grid equipment will give an overview on the new developments and challenges in modeling and simulating local grid behavior. The second talk discusses building energy management at the interface between home automation and the smart grid, both from the application and the embedded platform perspective. The third talk addresses home automation which serves many objectives, besides being a terminal network of the smart grind. Last not least, the fourth talk presents new development in wireless sensor devices as an important component of future home and energy networks.},
booktitle = {Proceedings of the Tenth ACM International Conference on Embedded Software},
pages = {7–8},
numpages = {2},
keywords = {smart grid, smart energy},
location = {Tampere, Finland},
series = {EMSOFT '12}
}

@inproceedings{10.1145/2897937.2898019,
author = {Madhavan, Advait and Sherwood, Timothy and Strukov, Dmitri},
title = {Energy Efficient Computation with Asynchronous Races},
year = {2016},
isbn = {9781450342360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897937.2898019},
doi = {10.1145/2897937.2898019},
abstract = {By encoding information as digital signal propagation delay, rather than conventional logic levels, some basic processing operations become exceedingly energy efficient to implement. The result of such a computation can then be observed by relative timing differences between injected signals. We demonstrate the embodiment of such an approach utilizing current starved inverters as delay elements and characterize application-level artifacts of circuit-level variance. Specifically we chose the well-studied DNA sequence alignment problem for comparison and we show that, for the synthesized design, asynchronous races are 10\texttimes{} more energy efficient and 4\texttimes{} denser at comparable speeds as compared to prior approaches.},
booktitle = {Proceedings of the 53rd Annual Design Automation Conference},
articleno = {108},
numpages = {6},
location = {Austin, Texas},
series = {DAC '16}
}

@inproceedings{10.5555/2561828.2561894,
author = {Wang, Hao and Sinkar, Abhishek A. and Kim, Nam Sung},
title = {Improving Platform Energy: Chip Area Trade-off in near-Threshold Computing Environment},
year = {2013},
isbn = {9781479910694},
publisher = {IEEE Press},
abstract = {Recent studies on near-threshold computing (NTC) investigated an optimum supply voltage which yields minimum energy per operation (Emin), and proposed various optimization techniques at the device, circuit, and architecture levels to further minimize Emin. However, most of these studies often overlooked the significance of (i) energy consumption of off-chip memory accesses; (ii) energy loss of voltage regulators (VRs); and (iii) the cost of chip area in NTC environment. In this paper, we first demonstrate the increasing significance of (i) and (ii) in NTC environment with a comprehensive set of device, circuit, and architectural-level models. Second, we explore technology optimization to improve the trade-off between platform energy and chip area considering (iii) in NTC environment. The experimental results show that our optimized technology achieves 4% to 21% energy reduction for various chip area constraints, achieving significant improvement in trade-off between platform energy and chip area for a wide range of parallel benchmarks.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
pages = {318–325},
numpages = {8},
location = {San Jose, California},
series = {ICCAD '13}
}

@inproceedings{10.1145/505306.505330,
author = {P\'{e}nzes, Paul I and Martin, Alain J.},
title = {Energy-Delay Efficiency of VLSI Computations},
year = {2002},
isbn = {1581134622},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/505306.505330},
doi = {10.1145/505306.505330},
abstract = {In this paper we introduce an energy-delay efficiency metric that captures any trade-off between the energy and the delay of the computation.We apply this new concept to the parallel and sequential composition of circuits in general and in particular to circuits optimized through transistor sizing. We bound the delay and energy of the optimized circuit and we give necessary and sufficient conditions under which these bounds are reached. We also give necessary and sufficient conditions under which subcomponents of a design can be optimized independently so as to yield global optimum when recomposed.We demonstrate the utility of a minimum-energy function to capture high level compositional properties of circuits. The use of this minimum-energy function yields practical insight into ways of improving the overall energy-delay efficiency of circuits.},
booktitle = {Proceedings of the 12th ACM Great Lakes Symposium on VLSI},
pages = {104–111},
numpages = {8},
keywords = {transistor sizing, energy-delay optimization},
location = {New York, New York, USA},
series = {GLSVLSI '02}
}

@inproceedings{10.1145/344166.344612,
author = {Esakkimuthu, G. and Vijaykrishnan, N. and Kandemir, M. and Irwin, M. J.},
title = {Memory System Energy (Poster Session): Influence of Hardware-Software Optimizations},
year = {2000},
isbn = {1581131909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/344166.344612},
doi = {10.1145/344166.344612},
abstract = {Memory system usually consumes a significant amount of energy in many battery-operated devices. In this paper, we provide a quantitative comparison and evaluation of the interaction of two hardware cache optimization mechanisms (block buffering and sub-banking) and three widely used compiler optimization techniques (linear loop transformation, loop tiling, and loop unrolling). Our results show that the pure hardware optimizations (eight block buffers and four sub-banks in a 4K, 2-way cache) provided up to 4% energy saving, with an average saving of 2% across all benchmarks. In contrast, the pure software optimization approach that uses all three compiler optimizations, provided at least 23% energy saving, with an average of 62%. However, a closer observation reveals that hardware optimization becomes more critical for on-chip cache energy reduction when executing optimized codes.},
booktitle = {Proceedings of the 2000 International Symposium on Low Power Electronics and Design},
pages = {244–246},
numpages = {3},
location = {Rapallo, Italy},
series = {ISLPED '00}
}

@article{10.1145/1698223.1698225,
author = {Saxe, Eric},
title = {Power-Efficient Software: Power-Manageable Hardware Can Help Save Energy, but What Can Software Developers Do to Address the Problem?},
year = {2010},
issue_date = {January 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
issn = {1542-7730},
url = {https://doi.org/10.1145/1698223.1698225},
doi = {10.1145/1698223.1698225},
abstract = {The rate at which power-management features have evolved is nothing short of amazing. Today almost every size and class of computer system, from the smallest sensors and handheld devices to the "big iron" servers in data centers, offers a myriad of features for reducing, metering, and capping power consumption. Without these features, fan noise would dominate the office ambience, and untethered laptops would remain usable for only a few short hours (and then only if one could handle the heat), while data-center power and cooling costs and capacity would become unmanageable.},
journal = {Queue},
month = {jan},
pages = {10–17},
numpages = {8}
}

@article{10.1145/297049.297057,
author = {Popov, Atanas},
title = {Symbolic Computation of Potential Energy Functions},
year = {1998},
issue_date = {June 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {2},
issn = {0163-5824},
url = {https://doi.org/10.1145/297049.297057},
doi = {10.1145/297049.297057},
abstract = {We derive potential energy functions for a shallow cylindrical panel. The starting point is a system of two coupled partial differential equations based on Donnell's shallow shell theory. The total potential energy is approximated using a finite number of degrees of freedom. All calculations are performed by computer algebra routines. Two applications of potential energy functions are discussed: the analysis of shell buckling and the derivation of systems of ordinary differential equations that govern dynamic behaviour.},
journal = {SIGSAM Bull.},
month = {jun},
pages = {12–18},
numpages = {7}
}

@inproceedings{10.1145/3231053.3231131,
author = {Adebisi, Bamidele},
title = {Transactive Energy Systems: What Has Communications Got to Do with It?},
year = {2018},
isbn = {9781450364287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3231053.3231131},
doi = {10.1145/3231053.3231131},
abstract = {The smart grid vision is unveiling new possibilities in the ways utilities and consumers interact with energy; transactive energy (TE) being one of them. In TE system, economic and control mechanisms are combined in such a way as to allow dynamic balance of supply and demand across the entire electrical infrastructure using value as a key operational parameter. The central theme of TE is that by actively engaging prosumers and exploiting their roles in the energy value chain the grid can become more flexible; this adds economic and social dimensions to the grid operations. Although TE is currently at nascent stage, its development and delivery are being shaped by the emergence of distributed energy management techniques such as Virtual Power Plant (VPP) and Peer-2-Peer (P2P) energy trading. In these systems, rather than the vertical hierarchical flow of electricity found in traditional grid, the TE element also allows market-driven horizontal interactions between energy producers and consumers.In this talk, the various challenges that the industry stakeholders must confront in a bid to maintain technical, social and economic equilibrium in the TE sector will be discussed. This includes definition of TE scenarios and reference design, development of common platform model and the requisite regulatory framework to accommodate TE services in the grid. These challenges are not trivial, adequately addressing them will inspire new economic processes and business models that not only rewards prosumers but also protects the utilities from abrupt or unexpected contingencies. For the market makers, one of the key questions is to determine how VPP and P2P create new opportunities for TE. Overlaying the TE services over the power network suggests that ICT-driven trading platform must be available to provide the needed interface between energy buyers and potential sellers within the network. Therefore, in order to maximize the benefits of TE to the operators and prosumers, communication network design paradigms must be developed to support the transactive exchanges between producers and consumers. A rethinking of existing ICT infrastructure and technologies with a view to retrofitting them for TE is be presented.},
booktitle = {Proceedings of the 2nd International Conference on Future Networks and Distributed Systems},
articleno = {64},
numpages = {1},
keywords = {reliable wireless sensing systems, internet of things, wireless sensor networks},
location = {Amman, Jordan},
series = {ICFNDS '18}
}

@article{10.1145/382075.1037256,
author = {Robb, J. A.},
title = {Review of "Certification of Secondary School Computer Science Teachers, Some Issues and Viewpoints by Statz, Joyce; and Miller, Leland (Bowling Green Unv., Ohio)". [in Proc. ACM 1975 Annual Conf. (Minneapolis, Minn., Oct. 1975), 71-73},
year = {1977},
issue_date = {Winter 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {0160-2497},
url = {https://doi.org/10.1145/382075.1037256},
doi = {10.1145/382075.1037256},
journal = {SIGCPR Comput. Pers.},
month = {dec},
pages = {16},
numpages = {1}
}

@inproceedings{10.1145/2442942.2442947,
author = {Storandt, Sabine},
title = {Quick and Energy-Efficient Routes: Computing Constrained Shortest Paths for Electric Vehicles},
year = {2012},
isbn = {9781450316934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2442942.2442947},
doi = {10.1145/2442942.2442947},
abstract = {In this paper we study multi-criteria routing problems related to Electric Vehicles (EVs). Because EVs still suffer from a rather small cruising range restricted by the battery's capacity, and loading stations are sparse and reloading is time intensive, previous work focused on computing the most energy-efficient routes efficiently. Unfortunately these approaches do not guarantee anything in terms of distance or travel time. But even a very eco-friendly driver might not be willing to accept a tour three times as long as the quickest one to save some energy. Therefore we present new types of queries considering energy-consumption and distance or travel time and reloading effort, e.g. computing the shortest or quickest path on which the EV does not run out of energy while requiring at most k recharging events (with k being an input parameter). The respective optimization problems are instances of the constrained shortest path problem, which is NP-hard. Nevertheless we will provide preprocessing techniques that allow for fast query answering even in large street graphs.},
booktitle = {Proceedings of the 5th ACM SIGSPATIAL International Workshop on Computational Transportation Science},
pages = {20–25},
numpages = {6},
keywords = {route planning, constrained shortest path, e-mobility},
location = {Redondo Beach, California},
series = {IWCTS '12}
}

@inproceedings{10.5555/2561828.2561868,
author = {Kim, Younghyun and Shin, Donghwa and Petricca, Massimo and Park, Sangyoung and Poncino, Massimo and Chang, Naehyuck},
title = {Computer-Aided Design of Electrical Energy Systems},
year = {2013},
isbn = {9781479910694},
publisher = {IEEE Press},
abstract = {Electrical energy systems (EESs) include energy generation, distribution, storage, and consumption, and involve many diverse components and sub-systems to implement these tasks. This paper represents a first step towards the computer-aided design for EESs, encompassing modeling, simulation, design and optimization of these systems. CAD for EESs is a challenging task that mandates a multidisciplinary and heterogeneous approach. We identify similarities and differences between electrical energy systems and electronics systems in order to inherit as much as possible the profound legacy resources of electronic design automation (EDA). We introduce fundamental concepts, from the general problem formulation to the development and deployment of efficient, scalable, and versatile CAD and EDA methods and framework for the optimal or near-optimal EESs.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
pages = {194–201},
numpages = {8},
location = {San Jose, California},
series = {ICCAD '13}
}

@inproceedings{10.1145/1067170.1067197,
author = {Zhong, Lin and Jha, Niraj K.},
title = {Energy Efficiency of Handheld Computer Interfaces: Limits, Characterization and Practice},
year = {2005},
isbn = {1931971315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1067170.1067197},
doi = {10.1145/1067170.1067197},
abstract = {Energy efficiency has become a critical issue for battery-driven computers. Significant work has been devoted to improving it through better software and hardware. However, the human factors and user interfaces have often been ignored. Realizing their extreme importance, we devote this work to a comprehensive treatment of their role in determining and improving energy efficiency. We analyze the minimal energy requirements and overheads imposed by known human sensory/speed limits. We then characterize energy efficiency for state-of-the-art interfaces available on two commercial handheld computers. Based on the characterization, we offer a comparative study for them.Even with a perfect user interface, computers will still spend most of their time and energy waiting for user responses due to an increasingly large speed gap between users and computers in their interactions. Such a speed gap leads to a bottleneck in system energy efficiency. We propose a low-power low-cost cache device, to which the host computer can outsource simple tasks, as an interface solution to overcome the bottleneck. We discuss the design and prototype implementation of a low-power wireless wrist-watch for use as a cache device for interfacing.With this work, we wish to engender more interest in the mobile system design community in investigating the impact of user interfaces on system energy efficiency and to harvest the opportunities thus exposed.},
booktitle = {Proceedings of the 3rd International Conference on Mobile Systems, Applications, and Services},
pages = {247–260},
numpages = {14},
location = {Seattle, Washington},
series = {MobiSys '05}
}

@inproceedings{10.1145/2556288.2556968,
author = {Bates, Oliver and Hazas, Mike and Friday, Adrian and Morley, Janine and Clear, Adrian K.},
title = {Towards an Holistic View of the Energy and Environmental Impacts of Domestic Media and IT},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2556968},
doi = {10.1145/2556288.2556968},
abstract = {To date, research in sustainable HCI has dealt with eco-feedback, usage and recycling of appliances within the home, and longevity of portable electronics such as mobile phones. However, there seems to be less awareness of the energy and greenhouse emissions impacts of domestic consumer electronics and information technology. Such awareness is needed to inform HCI sustainability researchers on how best to prioritise efforts around digital media and IT. Grounded in inventories, interview and plug energy data from 33 undergraduate student participants, our findings provide the context for assessing approaches to reducing the energy and carbon emissions of media and IT in the home. In the paper, we use the findings to discuss and inform more fruitful directions that sustainable HCI research might take, and we quantify how various strategies might have modified the energy and emissions impacts for our participants.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1173–1182},
numpages = {10},
keywords = {sustainability, home energy, life cycle assessment, embodied emissions},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/344166.344188,
author = {Sinha, Amit and Wang, Alice and Chandrakasan, Anantha P.},
title = {Algorithmic Transforms for Efficient Energy Scalable Computation},
year = {2000},
isbn = {1581131909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/344166.344188},
doi = {10.1145/344166.344188},
abstract = {We introduce the notion of energy scalable computation on general purpose processors. The principle idea is to maximize computational qualityfor a given energy constraint. Teh desirable energy-quality behavior of algorithms is discussed. subsequently the energy-quality scalability of three distinct categories of commonly used signal processing algorithms (viz. filtering, frequency domain transforms and classification) are analyzed on the StrongARM SA-1100 processor and transformations are described which obtain significant improvements in the energy-quality scalability of the algorithm.},
booktitle = {Proceedings of the 2000 International Symposium on Low Power Electronics and Design},
pages = {31–36},
numpages = {6},
location = {Rapallo, Italy},
series = {ISLPED '00}
}

@inproceedings{10.1145/3123024.3123144,
author = {Ko, Jaejun and Lee, Jongwon and Choi, Young-June},
title = {Computation Offloading for Energy Efficiency of Smart Devices},
year = {2017},
isbn = {9781450351904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123024.3123144},
doi = {10.1145/3123024.3123144},
abstract = {Computation offloading provides efficiency of computation time and energy but at the cost of additional communication from wearable devices to servers, which may drain more energy of wearable devices. To derive the condition of computation offloading, we use a workload measurement model based on DMIPS (Dhrystone Millions of Instructions per Second) and compare the energy in offloading with the energy in not offloading. Using such a computation offloading decision model, in this paper, we propose a double computation offloading technique that offloads from wearable devices to smartphones and further offloads to cloud servers. For three experimental scenarios, we measured the energy consumption of each wearable or smart device and analyzed the energy efficiency of our model.},
booktitle = {Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers},
pages = {109–112},
numpages = {4},
keywords = {smart device, smartphone, computation offloading, energy management, wearable device},
location = {Maui, Hawaii},
series = {UbiComp '17}
}

@inproceedings{10.1145/951710.951742,
author = {Zhong, Lin and Jha, Niraj K.},
title = {Graphical User Interface Energy Characterization for Handheld Computers},
year = {2003},
isbn = {1581136765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/951710.951742},
doi = {10.1145/951710.951742},
abstract = {A significant fraction of the software and resource usage of a modern handheld computer is devoted to its graphical user interface (GUI). Moreover, GUIs are direct users of the display and also determine how users interact with software. Given that displays consume a significant fraction of system energy, it is very important to optimize GUIs for energy consumption. This work presents the first GUI energy characterization methodology. Energy consumption is characterized for three popular GUI platforms (Windows, X Window system, and Qt) from the hardware, software, and application perspectives. Based on this characterization, insights are offered for improving GUI platforms, and designing GUIs in an energy-efficient and aware fashion. Such a characterization also provides a firm basis for further research on GUI energy optimization.},
booktitle = {Proceedings of the 2003 International Conference on Compilers, Architecture and Synthesis for Embedded Systems},
pages = {232–242},
numpages = {11},
keywords = {energy characterization, GUI, low power design, graphical user interface, low power, handheld computers},
location = {San Jose, California, USA},
series = {CASES '03}
}

@inproceedings{10.1145/3359061.3362775,
author = {Seewald, Adam and Schultz, Ulrik Pagh and Roeder, Julius and Rouxel, Benjamin and Grelck, Clemens},
title = {Component-Based Computation-Energy Modeling for Embedded Systems},
year = {2019},
isbn = {9781450369923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359061.3362775},
doi = {10.1145/3359061.3362775},
abstract = {Computational energy-efficiency is a critical aspect of many modern embedded devices as it impacts the level of autonomy for numerous scenarios. We present a component-based energy modeling approach to abstract per-component energy in a dataflow computational network executed according to a given scheduling policy. The approach is based on a modeling tool and ultimately relies on battery state to support a wider range of energy-optimization strategies for power-critical devices.},
booktitle = {Proceedings Companion of the 2019 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
pages = {5–6},
numpages = {2},
keywords = {Energy Profiling, Embedded Platforms, Energy Modeling, Component-Based Development},
location = {Athens, Greece},
series = {SPLASH Companion 2019}
}

@inproceedings{10.5555/1870926.1871039,
author = {Fettweis, Gerhard},
title = {The Road to Energy-Efficient Systems: From Hardware-Driven to Software-Defined},
year = {2010},
isbn = {9783981080162},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Innovations in micro and nano technology form the basis of modern ICT. However, the steady growth in the ICT sector has meanwhile a significant ecological footprint: 2% of global CO2 emissions are due to ICT systems already today - one fourth of the emissions caused by cars. The energy costs for running ICT infrastructure have turned into a significant economical factor. The most urgent challenge in the area of micro and nanotechnology is therefore to massively increase energy efficiency, in particular for ICT as a key sector for economic growth. Significant improvements in this area can only be achieved through disruptive innovations and new system approaches, which rely on a combination of excellent research &amp; development and world leading know-how of semiconductor production.But will hardware be the driver to fulfill these requirements and software has to adapt to whatever hardware concepts are developed? Or should the ability to program systems energy-efficiently define the design of the hardware architecture? This session will present the different perspectives on the problem and try to bring both sides together.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {477},
numpages = {1},
location = {Dresden, Germany},
series = {DATE '10}
}

@inproceedings{10.1145/3308560.3317075,
author = {Debattista, Jeremy and Attard, Judie and Brennan, Rob and O'Sullivan, Declan},
title = {Is the LOD Cloud at Risk of Becoming a Museum for Datasets? Looking Ahead towards a Fully Collaborative and Sustainable LOD Cloud},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3317075},
doi = {10.1145/3308560.3317075},
abstract = {The Linked Open Data (LOD) cloud has been around since 2007. Throughout the years, this prominent depiction served as the epitome for Linked Data and acted as a starting point for many. In this article we perform a number of experiments on the dataset metadata provided by the LOD cloud, in order to understand better whether the current visualised datasets are accessible and with an open license. Furthermore, we perform quality assessment of 17 metrics over accessible datasets that are part of the LOD cloud. These experiments were compared with previous experiments performed on older versions of the LOD cloud. The results showed that there was no improvement on previously identified problems. Based on our findings, we therefore propose a strategy and architecture for a potential collaborative and sustainable LOD cloud.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {850–858},
numpages = {9},
keywords = {metadata quality, Linked Data, data quality, sustainable services, LOD cloud},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/2751205.2751245,
author = {Zou, Yun and Rajopadhye, Sanjay},
title = {Automatic Energy Efficient Parallelization of Uniform Dependence Computations},
year = {2015},
isbn = {9781450335591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2751205.2751245},
doi = {10.1145/2751205.2751245},
abstract = {Energy is now a critical concern in all aspects of computing. We address a class of programs that includes the so-called "stencil computations" that have already been optimized for speed. We target the energy expended in dynamic memory accesses, since most other components of the total energy are usually already reduced when optimizing for speed alone. For a standard shared memory multi-core processor, we seek to minimize the total number of off-chip memory accesses without sacrificing execution time. Our strategy uses two-level tiling with multiple pipelined passes. Because of the sophisticated tiling and parallelization, such codes are difficult to write by hand, especially for parametric tile sizes. They are also beyond the capability of current code generators because the schedules used are polynomial functions, more general than multidimensional schedules. We implement a parametric tiled code generator to support this strategy, and also develop a simple quantitative linear regression model for the energy consumed by a program. We experimentally validate our techniques on a set of benchmarks including those from the Polybench suite on two platforms. Our experiments show that about 78% (resp. 80%) of the dynamic memory energy consumption on an 8-core Xeon E5-2650 v2 (resp. 6-core Xeon E5-2620 v2) based machine can be avoided. This leads to a reduction in the total energy of the program by 2% to 14%.},
booktitle = {Proceedings of the 29th ACM on International Conference on Supercomputing},
pages = {373–382},
numpages = {10},
keywords = {automatic parallelization, polyhedral model, hierarchical tiling, o-chip memory access, energy consumption},
location = {Newport Beach, California, USA},
series = {ICS '15}
}

@inproceedings{10.1145/1667780.1667784,
author = {Katz, Randy H.},
title = {A Computer Scientist Looks at the Energy Problem},
year = {2009},
isbn = {9781605586410},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1667780.1667784},
doi = {10.1145/1667780.1667784},
booktitle = {Proceedings of the 3rd International Universal Communication Symposium},
pages = {14–21},
numpages = {8},
location = {Tokyo, Japan},
series = {IUCS '09}
}

@inproceedings{10.1109/CHASE.2019.00039,
author = {de Souza, M\'{a}rio Rosado and Haines, Robert and Vigo, Markel and Jay, Caroline},
title = {What Makes Research Software Sustainable? An Interview Study with Research Software Engineers.},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CHASE.2019.00039},
doi = {10.1109/CHASE.2019.00039},
abstract = {Software is now a vital scientific instrument, providing the tools for data collection and analysis across disciplines from bioinformatics and computational physics, to the humanities. The software used in research is often home-grown and bespoke: it is constructed for a particular project, and rarely maintained beyond this, leading to rapid decay, and frequent 'reinvention of the wheel'. Understanding how to develop sustainable research software, such that it is suitable for future reuse, is therefore of interest to both researchers and funders, but how to achieve this remains an open question. Here we report the results of an interview study examining how research software engineers - the people actively developing software in an academic research environment - subjectively define software sustainability. Thematic analysis of the data reveals two interacting dimensions: intrinsic sustainability, which relates to internal qualities of software, such as modularity, encapsulation and testability, and extrinsic sustainability, concerning cultural and organisational factors, including how software is resourced, supported and shared. Research software engineers believe an increased focus on quality and discoverability are key factors in increasing the sustainability of academic research software.},
booktitle = {Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {135–138},
numpages = {4},
location = {Montreal, Quebec, Canada},
series = {CHASE '19}
}

@inproceedings{10.1145/3523286.3524537,
author = {Guo, Junjun and Chen, Qingchang and An, Zhongfang and Zhu, Xuanyu},
title = {Research on Intelligent Energy-Saving Design Strategy of Building Thermal Comfort Experience in Western Sichuan Based on Climate Consultant Software——Take the Unlimited Bookstore of Santai Middle School in Mianyang City as an Example},
year = {2022},
isbn = {9781450395755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3523286.3524537},
doi = {10.1145/3523286.3524537},
abstract = {Nowadays, cultural self-confidence is increasingly emphasized. The architectural field is also paying more and more attention to traditional Chinese architecture. The contemporary expression of the spatial characteristics of traditional buildings is especially valued. This article discusses the modern architectural space creation strategy based on the traditional architectural space composition of Western Sichuan. In addition, it was verified in practice with the unlimited bookstore project of Santai Middle School in Mianyang City. First, we conducted an analysis of climate adaptability in western Sichuan region through the Climate Consultant software. Then we adopted a combination of modern construction technology and materials to make the building sustainable. Finally, we come up with the modern translation strategy, which is based on the space of traditional buildings in Western Sichuan. That is, the modern translation of column and tie construction, reproduction of life scenes in the space under the eaves, and construction of the core space of the courtyard [1]. It is expected to provide a certain reference for the inheritance and development of traditional architecture in Western Sichuan.},
booktitle = {2022 2nd International Conference on Bioinformatics and Intelligent Computing},
pages = {173–178},
numpages = {6},
location = {Harbin, China},
series = {BIC 2022}
}

@article{10.1145/3391893,
author = {Ahmed, Saad and Nawaz, Muhammad and Bakar, Abu and Bhatti, Naveed Anwar and Alizai, Muhammad Hamad and Siddiqui, Junaid Haroon and Mottola, Luca},
title = {Demystifying Energy Consumption Dynamics in Transiently Powered Computers},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {6},
issn = {1539-9087},
url = {https://doi.org/10.1145/3391893},
doi = {10.1145/3391893},
abstract = {Transiently powered computers (TPCs) form the foundation of the battery-less Internet of Things, using energy harvesting and small capacitors to power their operation. This kind of power supply is characterized by extreme variations in supply voltage, as capacitors charge when harvesting energy and discharge when computing. We experimentally find that these variations cause marked fluctuations in clock speed and power consumption. Such a deceptively minor observation is overlooked in existing literature. Systems are thus designed and parameterized in overly conservative ways, missing on a number of optimizations.We rather demonstrate that it is possible to accurately model and concretely capitalize on these fluctuations. We derive an energy model as a function of supply voltage and prove its use in two settings. First, we develop EPIC, a compile-time energy analysis tool. We use it to substitute for the constant power assumption in existing analysis techniques, giving programmers accurate information on worst-case energy consumption of programs. When using EPIC with existing TPC system support, run-time energy efficiency drastically improves, eventually leading up to a 350% speedup in the time to complete a fixed workload. Further, when using EPIC with existing debugging tools, it avoids unnecessary program changes that hurt energy efficiency. Next, we extend the MSPsim emulator and explore its use in parameterizing a different TPC system support. The improvements in energy efficiency yield up to more than 1000% time speedup to complete a fixed workload.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
articleno = {47},
numpages = {25},
keywords = {intermittent computing, Transiently powered computers, energy modelling}
}

@inproceedings{10.1145/1851476.1851523,
author = {Kaushik, Rini T. and Cherkasova, Ludmila and Campbell, Roy and Nahrstedt, Klara},
title = {Lightning: Self-Adaptive, Energy-Conserving, Multi-Zoned, Commodity Green Cloud Storage System},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851523},
doi = {10.1145/1851476.1851523},
abstract = {The objective of this research is to present an energy-conserving, self-adaptive Commodity Green Cloud Storage, called Lightning. Lightning's File System dynamically configures the servers in the Cloud Storage into logical Hot and Cold Zones. Lightning uses data-classification driven data placement to realize guaranteed, substantially long, periods (several days) of idleness in a significant subset of servers designated as the Cold Zone, in the commodity datacenter backing the Cloud Storage. These servers are then transitioned to inactive power modes and the resulting energy savings substantially reduce the operating costs of the datacenter. Furthermore, the energy savings allow Lightning to improve the data access performance by incorporation of high-performance, though high-cost Solid State Drives (SSD) without exceeding the total cost of ownership (TCO) of the datacenter. Analytical cost model analysis of Lightning suggests savings in the upwards of $24 million in the TCO of a 20,000 server datacenter. The simulation results show that Lightning can achieve 46% energy costs reduction even when the datacenter is at 80% capacity utilization.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {332–335},
numpages = {4},
keywords = {performance, energy management, cloud storage},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@article{10.1145/3213762,
author = {Kugler, Logan},
title = {Why Cryptocurrencies Use so Much Energy: And What to Do about It},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {61},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/3213762},
doi = {10.1145/3213762},
abstract = {The electricity consumption of mining for cryptocurrencies is becoming a real concern. Here's what to do about it.},
journal = {Commun. ACM},
month = {jun},
pages = {15–17},
numpages = {3}
}

@article{10.1145/3365394,
author = {Torres, Frank Sill and Niemann, Philipp and Wille, Robert and Drechsler, Rolf},
title = {Near Zero-Energy Computation Using Quantum-Dot Cellular Automata},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/3365394},
doi = {10.1145/3365394},
abstract = {Near zero-energy computing describes the concept of executing logic operations below the (kBT ln 2) energy limit. Landauer discussed that it is impossible to break this limit as long as the computations are performed in the conventional, non-reversible way. But even if reversible computations were performed, the basic energy needed for operating circuits realized in conventional technologies is still far above the (kBT ln 2) energy limit (i.e., the circuits do not operate in a physically reversible manner). In contrast, novel nanotechnologies like Quantum-dot Cellular Automata (QCA) allow for computations with very low energy dissipation and hence are promising candidates for breaking this limit. Accordingly, the design of reversible QCA circuits is an active field of research. But whether QCA in general and the proposed circuits in particular are indeed able to operate in a logically and physically reversible fashion is unknown thus far, because neither physical realizations nor appropriate simulation approaches are available. In this work, we address this gap by utilizing an established theoretical model that has been implemented in a physics simulator enabling a precise consideration of how energy is dissipated in QCA designs. Our results provide strong evidence that QCA is indeed a suitable technology for near zero-energy computing. Further, the first design of a logically and physically reversible adder circuit is presented, which serves as proof of concept for future circuits with the ability of near zero-energy computing.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {nov},
articleno = {11},
numpages = {16},
keywords = {Emerging technology, field-coupled nanocomputing, reversible computing}
}

@inproceedings{10.1145/2742854.2742889,
author = {Wang, Jing and Zhu, Xiaoyan and Liu, Yanjun and Zhang, Jiaqi and Wu, Minhua and Zhang, Weigong and Qiu, Keni},
title = {Heterogeneous Energy-Efficient Cache Design in Warehouse Scale Computers},
year = {2015},
isbn = {9781450333580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742854.2742889},
doi = {10.1145/2742854.2742889},
abstract = {Energy efficiency is becoming the key design concern for modern warehouse-scale computer (WSC) systems, where tens of thousands of server processors consume a significant portion of the total power. Voltage scaling is one of the most effective mechanisms to improve energy efficiency at the cost of cell failures in large cache arrays. In this paper, we leverage the observation that there exists a diverse spectrum of tolerance to cache errors in large internet services to design a heterogeneous energy-efficient cache enforced by variable-strength error-correcting codes. The operating system may use the page coloring mechanism to control mapping applications to cache regions with differential reliability.},
booktitle = {Proceedings of the 12th ACM International Conference on Computing Frontiers},
articleno = {35},
numpages = {2},
keywords = {error-correcting codes, cache design, energy efficiency, page coloring, datacenter},
location = {Ischia, Italy},
series = {CF '15}
}

@article{10.1145/1559755.1559758,
author = {Liu, Yang and Wang, Wenping and L\'{e}vy, Bruno and Sun, Feng and Yan, Dong-Ming and Lu, Lin and Yang, Chenglei},
title = {On Centroidal Voronoi Tessellation—energy Smoothness and Fast Computation},
year = {2009},
issue_date = {August 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/1559755.1559758},
doi = {10.1145/1559755.1559758},
abstract = {Centroidal Voronoi tessellation (CVT) is a particular type of Voronoi tessellation that has many applications in computational sciences and engineering, including computer graphics. The prevailing method for computing CVT is Lloyd's method, which has linear convergence and is inefficient in practice. We develop new efficient methods for CVT computation and demonstrate the fast convergence of these methods. Specifically, we show that the CVT energy function has 2nd order smoothness for convex domains with smooth density, as well as in most situations encountered in optimization. Due to the 2nd order smoothness, it is possible to minimize the CVT energy functions using Newton-like optimization methods and expect fast convergence. We propose a quasi-Newton method to compute CVT and demonstrate its faster convergence than Lloyd's method with various numerical examples. It is also significantly faster and more robust than the Lloyd-Newton method, a previous attempt to accelerate CVT. We also demonstrate surface remeshing as a possible application.},
journal = {ACM Trans. Graph.},
month = {sep},
articleno = {101},
numpages = {17},
keywords = {constrained CVT, numerical optimization, Centroidal Voronoi tessellation, Lloyd's method, remeshing, quasi-Newton methods}
}

@inproceedings{10.1145/2739482.2768420,
author = {Bruce, Bobby R.},
title = {Energy Optimisation via Genetic Improvement: A SBSE Technique for a New Era in Software Development},
year = {2015},
isbn = {9781450334884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739482.2768420},
doi = {10.1145/2739482.2768420},
abstract = {The discipline of Software Engineering has arisen during a time in which developers rarely concerned themselves with the energy efficiency of their software. Due to the growth in both mobile devices and large server clusters this period is undoubtedly coming to an end and, as such, new tools for creating energy-efficient software are required. This paper takes the position that Genetic Improvement, a Search-Based Software Engineering technique, has the potential to aid developers in refactoring their software to a more energy-efficient state; allowing focus to remain on functional requirements while leaving concerns over energy consumption to an automated process.},
booktitle = {Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {819–820},
numpages = {2},
keywords = {search based software engineering, gi, genetic improvement, energy consumption, sbse, energy optimisation, energy efficiency},
location = {Madrid, Spain},
series = {GECCO Companion '15}
}

@inproceedings{10.1145/1594233.1594296,
author = {Kumar, Karthik and Nimmagadda, Yamini and Lu, Yung-Hsiang},
title = {Ranking Servers Based on Energy Savings for Computation Offloading},
year = {2009},
isbn = {9781605586847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1594233.1594296},
doi = {10.1145/1594233.1594296},
abstract = {Offloading may save energy for battery-powered devices by migrating computation to grid-powered servers. Offloading can be provided as a service and the servers charge the devices' users based on the consumed resources. In this paper, we propose a scheme to rank the servers based on the amounts of energy savings. The ranking depends on two factors: (1) the energy saved due to offloading and (2) the energy consumed while waiting for the results. We instrument the offloaded programs to estimate the amounts of computation performed by the servers, and use this information to determine the amounts of saved energy. When the servers perform the offloaded computation, the battery-powered devices wait for the results and consume energy. The ratio of the two factors determines the rank of a server. If a server performs more computation within a shorter duration, the server is ranked higher. We implement our method on an HP iPAQ and demonstrate that our method can effectively rank servers based on energy savings.},
booktitle = {Proceedings of the 2009 ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {267–272},
numpages = {6},
keywords = {ranking servers, energy savings, computation offloading},
location = {San Fancisco, CA, USA},
series = {ISLPED '09}
}

@inproceedings{10.5555/800292.811704,
author = {Schiler, Marc and Greenberg, Donald P.},
title = {Computer Simulation of Foliage Shading in Building Energy Loads},
year = {1979},
publisher = {IEEE Press},
abstract = {The calculation of building thermal loads using the computer has been an accepted practice for several years. A substantial amount of research and theoretical investigation has been expended in attempts to accurately quantify a building's thermal behavior. A number of existing simulation packages acceptably model this behavior.1,2,3,4,5,6The advantages of simulation are obvious, not only for the predictive information with respect to operating costs or fuel consumption, but as a potential aid for preliminary design. The influence and tradeoffs of a large number of design variables such as siting, orientation, window area, thermal resistivity, surface/volume ratios, and cost can all be examined at an early stage in the design process.},
booktitle = {Proceedings of the 16th Design Automation Conference},
pages = {142–148},
numpages = {7},
location = {San Diego, CA, USA},
series = {DAC '79}
}

@inproceedings{10.1145/3578477,
author = {Najafi, M. Hasan and Chabria, Vidya},
title = {Session Details: Energy Efficient Neural Networks via Approximate Computations},
year = {2022},
isbn = {9781450392174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578477},
doi = {10.1145/3578477},
booktitle = {Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design},
location = {San Diego, California},
series = {ICCAD '22}
}

@inproceedings{10.1145/502217.502257,
author = {Li, Zhiyuan and Wang, Cheng and Xu, Rong},
title = {Computation Offloading to Save Energy on Handheld Devices: A Partition Scheme},
year = {2001},
isbn = {1581133995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/502217.502257},
doi = {10.1145/502217.502257},
abstract = {We consider handheld computing devices which are connected to a server (or a powerful desktop machine) via a wireless LAN. On such devices, it is often possible to save the energy on the handheld by offloading its computation to the server. In this work, based on profiling information on computation time and data sharing at the level of procedure calls, we construct a cost graph for a given application program. We then apply a partition scheme to statically divide the program into server tasks and client tasks such that the energy consumed by the program is minimized. Experiments are performed on a suite of multimedia benchmarks. Results show considerable energy saving for several programs through offloading.},
booktitle = {Proceedings of the 2001 International Conference on Compilers, Architecture, and Synthesis for Embedded Systems},
pages = {238–246},
numpages = {9},
location = {Atlanta, Georgia, USA},
series = {CASES '01}
}

@inproceedings{10.5555/2820656.2820662,
author = {Chitchyan, Ruzanna and Noppen, Joost and Groher, Iris},
title = {What Can Software Engineering Do for Sustainability: Case of Software Product Lines},
year = {2015},
publisher = {IEEE Press},
abstract = {Sustainable living, i.e., living within the bounds of the available environmental, social, and economic resources, is the focus of many present-day social and scientific discussions. But what does sustainability mean within the context of Software Product Line Engineering (SPLE)? And what does SPLE do for sustainable living? In this paper we take the first step towards identification of the sustainability-related characteristics relevant to SPLE. The paper also discusses how the key areas of interest to the current SPL community (as reflected by what is measured and optimised in SPLs today) relate to these sustainability characteristics.},
booktitle = {Proceedings of the Fifth International Workshop on Product LinE Approaches in Software Engineering},
pages = {11–14},
numpages = {4},
location = {Florence, Italy},
series = {PLEASE '15}
}

@article{10.1145/3573074.3573098,
author = {Werder, Karl and Hyrynsalmi, Sami and Wang, Xiaofeng},
title = {ACM SIGSOFT Towards Sustainable Software Business: 5th International Workshop on Software-Intensive Business},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3573074.3573098},
doi = {10.1145/3573074.3573098},
abstract = {Software producing organizations face the challenges of changing demands, rapidly evolving technology, and a dynamic ecosystem in which their products and services need to operate. These challenges hinder software organizations being sustainable. The 5th International Workshop on Software-Intensive Business (IWSiB) brought researchers and practitioners together to discuss contributions within the emerging field of sustainable software businesses. The workshop was hosted by the 44th International Conference for Software Engineering. Birgit Penzenstadler's keynote on software-intensive business supporting resilience and sustainability for people, sparked the interest of the participating 30 researchers that continued to discuss 12 submissions.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {91–94},
numpages = {4},
keywords = {software startups, software ecosystem, agile projects, software engineering economics, organizational management, continuous practices, software business, software platform, software portfolio management, software product management}
}

@inproceedings{10.1145/3278161.3278170,
author = {Mollova, Stoyanka and Simionov, Radoslav and Seymenliyski, Kamen},
title = {A Study of the Energy Efficiency of a Computer Cluster},
year = {2018},
isbn = {9781450365802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278161.3278170},
doi = {10.1145/3278161.3278170},
abstract = {Cluster systems bring with them many advantages of scalable parallel calculations. Many of these benefits are a result of the cost /performance ratio of large supercomputers. Other important aspects are related to the structure and method of implementation of the cluster structure. Every cluster system is characterized by high performance and fault - tolerance. The issue associated with energy efficiency of a cluster system is discussed in the present work.},
booktitle = {Proceedings of the Seventh International Conference on Telecommunications and Remote Sensing},
pages = {51–54},
numpages = {4},
keywords = {raspberry, high performance cluster, energy efficiency},
location = {Barcelona, Spain},
series = {ICTRS '18}
}

@inproceedings{10.1145/1840845.1840887,
author = {Liu, Jibang and Kumar, Karthik and Lu, Yung-Hsiang},
title = {Tradeoff between Energy Savings and Privacy Protection in Computation Offloading},
year = {2010},
isbn = {9781450301466},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1840845.1840887},
doi = {10.1145/1840845.1840887},
abstract = {Offloading can save energy on mobile systems for computation-intensive applications. The mobile systems send programs and data to grid-powered servers where computation is performed. Offloading, however, causes privacy concerns because sensitive data may be sent to servers. This paper investigates how to protect privacy in computation offloading. We use steganography to hide data before sending them to servers. This paper evaluates the tradeoff between energy savings and privacy protection for content-based image retrieval with different steganographic techniques. We implement these methods on a PDA and compare their energy consumption, performance, and effectiveness of protecting privacy.},
booktitle = {Proceedings of the 16th ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {213–218},
numpages = {6},
keywords = {steganography, privacy protection, computation offloading, image retrieval, energy saving},
location = {Austin, Texas, USA},
series = {ISLPED '10}
}

@inproceedings{10.1145/3107411.3107499,
author = {Qiao, Wanli and Maximova, Tatiana and Plaku, Erion and Shehu, Amarda},
title = {Statistical Analysis of Computed Energy Landscapes to Understand Dysfunction in Pathogenic Protein Variants},
year = {2017},
isbn = {9781450347228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3107411.3107499},
doi = {10.1145/3107411.3107499},
abstract = {The energy landscape underscores the inherent nature of proteins as dynamic systems interconverting between structures with varying energies. The protein energy landscape contains much of the information needed to characterize protein equilibrium dynamics and relate it to function. It is now possible to reconstruct energy landscapes of medium-size proteins with sufficient prior structure data. These developments turn the focus to tools for analysis and comparison of energy landscapes as a means of formulating hypotheses on the impact of sequence mutations on (dys)function via altered landscape features. We present such a method here and provide a detailed evaluation of its capabilities on an enzyme central to human biology. The work presented here opens up an interesting avenue into automated analysis and summarization of landscapes that yields itself to machine learning approaches at the energy landscape level.},
booktitle = {Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics},
pages = {679–684},
numpages = {6},
keywords = {dysfunction, basins, saddle points, barriers, protein energy landscape, mutation, landscape analysis},
location = {Boston, Massachusetts, USA},
series = {ACM-BCB '17}
}

@inproceedings{10.1145/1815396.1815468,
author = {Luntovskyy, Andriy and Vasyutynskyy, Volodymyr},
title = {On Computer-Aided Design of Energy Efficient Wireless Sensor Networks},
year = {2010},
isbn = {9781450300629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1815396.1815468},
doi = {10.1145/1815396.1815468},
abstract = {The paper discusses different aspect of the energy efficiency in wireless sensor networks (WSN), which is a critical precondition for long life, reduced modification costs and increased reliability of WSN. At first, a brief overview of wide-spread WSN systems is provided. Further, the most important tradeoffs between different factors influencing energy efficiency and quality-of-control at different network layers are discussed. Further, a computer-aided design (CAD) of WSN is demonstrated on the example of the planning tool CANDY Wireless Site Finder that provides the design of optimal topology for WSN under considering of transmitted power, frequencies, propagation environments (in-door/out-door) and obstacles given in CAD-compatible formats. The tool is integrated within the framework of further CANDY tools aimed to efficient planning of heterogeneous wired-wireless networks.},
booktitle = {Proceedings of the 6th International Wireless Communications and Mobile Computing Conference},
pages = {311–315},
numpages = {5},
keywords = {computer-aided design, topology optimization, wireless sensor networks, heterogeneous wired-wireless networks, cross-layered design, energy efficient protocols},
location = {Caen, France},
series = {IWCMC '10}
}

@inproceedings{10.1145/1774088.1774245,
author = {Mulas, Fabrizio and Acquaviva, Andrea and Carta, Salvatore and Fenu, Gianni and Quaglia, Davide and Fummi, Franco},
title = {Network-Adaptive Management of Computation Energy in Wireless Sensor Networks},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774245},
doi = {10.1145/1774088.1774245},
abstract = {Today's sensor nodes can be equipped with powerful microcontrollers to address the increasing need of real-time processing of sensed data. For instance, body sensor networks for gesture recognition require filtering of acceleration values at line rate. This requirement imposes a paradigm shift with regard to more traditional sensor networks characterized by low activity duty cycles. Therefore, energy conservation strategies applied to wireless sensor nodes to increase their lifetime must take into account computation power rather than focusing only on communication power. In this paper we present a novel approach which aims at exploiting the knowledge of network status to optimize the power consumption of the node microcontroller. The proposed approach is tested in various network conditions, both synthetic and realistic, in the context of IEEE 802.15.4 standard. Experimental results demonstrate that the proposed approach allows to achieve power savings of up to 70% with minimum performance penalty.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {756–763},
numpages = {8},
keywords = {wireless sensor networks, low-power},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/2627369.2627664,
author = {Nahlus, Ihab and Kim, Eric P. and Shanbhag, Naresh R. and Blaauw, David},
title = {Energy-Efficient Dot Product Computation Using a Switched Analog Circuit Architecture},
year = {2014},
isbn = {9781450329750},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2627369.2627664},
doi = {10.1145/2627369.2627664},
abstract = {In this paper, we present switched analog circuit (SAC), a new circuit architecture, to implement an energy-efficient mixed-signal dot product (DP) kernel for machine learning and signal processing applications. SAC operates by fast switching the analog inputs to output via variable width digital pulses. The output accuracy and energy consumption of SAC is analyzed and verified for an average and Gaussian blur filter. Simulations in a commercial 130 nm process for a 120 x 120 image show energy savings of 19x-to-32x compared to a digital implementation for signal-to-noise ratios (SNRs) of 30 dB-to-24 dB, respectively.},
booktitle = {Proceedings of the 2014 International Symposium on Low Power Electronics and Design},
pages = {315–318},
numpages = {4},
keywords = {switched analog circuit, low-power, mixed-signal, dot product},
location = {La Jolla, California, USA},
series = {ISLPED '14}
}

@article{10.1145/3487025,
author = {Servais, Jason and Atoofian, Ehsan},
title = {Adaptive Computation Reuse for Energy-Efficient Training of Deep Neural Networks},
year = {2021},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1539-9087},
url = {https://doi.org/10.1145/3487025},
doi = {10.1145/3487025},
abstract = {In recent years, Deep Neural Networks (DNNs) have been deployed into a diverse set of applications from voice recognition to scene generation mostly due to their high-accuracy. DNNs are known to be computationally intensive applications, requiring a significant power budget. There have been a large number of investigations into energy-efficiency of DNNs. However, most of them primarily focused on inference while training of DNNs has received little attention.This work proposes an adaptive technique to identify and avoid redundant computations during the training of DNNs. Elements of activations exhibit a high degree of similarity, causing inputs and outputs of layers of neural networks to perform redundant computations. Based on this observation, we propose Adaptive Computation Reuse for Tensor Cores (ACRTC) where results of previous arithmetic operations are used to avoid redundant computations. ACRTC is an architectural technique, which enables accelerators to take advantage of similarity in input operands and speedup the training process while also increasing energy-efficiency. ACRTC dynamically adjusts the strength of computation reuse based on the tolerance of precision relaxation in different training phases. Over a wide range of neural network topologies, ACRTC accelerates training by 33% and saves energy by 32% with negligible impact on accuracy.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {oct},
articleno = {114},
numpages = {24},
keywords = {performance, energy, training, accelerator, DNNs, Computation reuse}
}

@inproceedings{10.1145/3505170.3506720,
author = {Lu, Chien-Pang and Jiang, Iris Hui-Ru and Yang, Chih-Wen},
title = {Clock Design Methodology for Energy and Computation Efficient Bitcoin Mining Machines},
year = {2022},
isbn = {9781450392105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3505170.3506720},
doi = {10.1145/3505170.3506720},
abstract = {Bitcoin mining machines become a new driving force to push the physical limitation of semiconductor process technology. Instead of peak performance, mining machines pursue energy and computation efficiency of implementing cryptographic hash functions. Therefore, the state-of-the-art ASIC design of mining machines adopts near-threshold computing, deep pipelines, and uni-directional data flow. According to these design properties, in this paper, we propose a novel clock reversing tree design methodology for bitcoin mining machines. In the clock reversing tree, the clock of global tree is fed from the last pipeline stage backward to the first one, and the clock latency difference between the local clock roots of two consecutive stages maintains a constant delay. The local tree of each stage is well balanced and keeps the same clock latency. The special clock topology naturally utilizes setup time slacks to gain hold time margins. Moreover, to alleviate the incurred on-chip variations due to near-threshold computing, we maximize the common clock path shared by flip-flops of each individual stage. Finally, we perform inverter pair swap to maintain duty cycle. Experimental results show that our methodology is promising for industrial bitcoin mining designs: Compared with two variation-aware clock network synthesis approaches widely used in modern ASIC designs, our approach can reduce up to 64% clock buffer/inverter usage, 12% clock power, decrease 99% hold time violating paths, and achieve 85% area saving for timing fixing. The proposed clock design methodology is general and applicable to blockchain and other ASICs with deep pipelines and strong data flow.},
booktitle = {Proceedings of the 2022 International Symposium on Physical Design},
pages = {13–20},
numpages = {8},
keywords = {secure hash algorithms, blockchain, clock network synthesis, data flow, ai chips, near-threshold computing, bitcoin mining machines, deep pipelines},
location = {Virtual Event, Canada},
series = {ISPD '22}
}

@inproceedings{10.1145/2716282.2716288,
author = {Haidar, Azzam and Dong, Tingxing and Luszczek, Piotr and Tomov, Stanimire and Dongarra, Jack},
title = {Optimization for Performance and Energy for Batched Matrix Computations on GPUs},
year = {2015},
isbn = {9781450334075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2716282.2716288},
doi = {10.1145/2716282.2716288},
abstract = {As modern hardware keeps evolving, an increasingly effective approach to develop energy efficient and high-performance solvers is to design them to work on many small size independent problems. Many applications already need this functionality, especially for GPUs, which are known to be currently about four to five times more energy efficient than multicore CPUs. We describe the development of the main one-sided factorizations that work for a set of small dense matrices in parallel, and we illustrate our techniques on the LU and Cholesky factorizations. We refer to this mode of operation as a batched factorization. Our approach is based on representing the algorithms as a sequence of batched BLAS routines for GPU-only execution. The goal of avoiding multicore CPU use, e.g., as in the hybrid CPU-GPU algorithms, is to exclusively benefit from the GPU's significantly higher energy efficiency, as well as from the removal of the costly CPU-to-GPU communications. Furthermore, we do not use a single symmetric multiprocessor (on the GPU) to factorize a single problem at a time. We illustrate how our performance analysis and the use of profiling and tracing tools guided the development and optimization of batched factorizations to achieve up to 2-fold speedup and $3$-fold better energy efficiency compared to our highly optimized batched CPU implementations based on the MKL library (when using two sockets of Intel Sandy Bridge CPUs). Compared to a batched LU factorization featured in the CUBLAS library for GPUs, we achieved up to 2.5 speedup on the K40 GPU.},
booktitle = {Proceedings of the 8th Workshop on General Purpose Processing Using GPUs},
pages = {59–69},
numpages = {11},
keywords = {numerical linear algebra, numerical software libraries, batched factorization, one-sided factorization algorithms, hardware accelerators},
location = {San Francisco, CA, USA},
series = {GPGPU-8}
}

@inproceedings{10.1145/3386263.3407595,
author = {Ma, Dongning and Yin, Xunzhao and Niemier, Michael and Hu, X. Sharon and Jiao, Xun},
title = {AxR-NN: Approximate Computation Reuse for Energy-Efficient Convolutional Neural Networks},
year = {2020},
isbn = {9781450379441},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386263.3407595},
doi = {10.1145/3386263.3407595},
abstract = {The recent success of convolutional neural networks (CNN) has led its implementation in specialized accelerators such as graphics processing unit (GPUs). However, the intensive computing workloads of CNNs remain a challenge to existing accelerators. By leveraging the error tolerance of CNNs, we propose a novel method to design energy-efficient CNN accelerators using approximate computation reuse (ACR), referred to as AxRNN. Computation reuse aims to reuse the previously computed results to avoid redundant executions. However, it cannot be applied directly to CNNs because CNNs do not have enough data locality. Thus, AxRNN performs approximate computation reuse under relaxed precision requirements on input patterns and design a reconfigurable architecture to support the ACR. This reconfigurable pattern matching is central to achieve a "controllable approximation". We implement the AxRNN using content addressable memory and integrate them with floating point units. Simulation results show that AxRNN reduces the computation energy by 30-58% with only 1-2.5% accuracy degradation on MNIST, EMNIST, and CIFAR-10 dataset.},
booktitle = {Proceedings of the 2020 on Great Lakes Symposium on VLSI},
pages = {363–368},
numpages = {6},
keywords = {content addressable memory, computation reuse, neural networks},
location = {Virtual Event, China},
series = {GLSVLSI '20}
}

@inproceedings{10.1145/1118299.1118342,
author = {Chen, G. and Kandemir, M. and Li, F.},
title = {Energy-Aware Computation Duplication for Improving Reliability in Embedded Chip Multiprocessors},
year = {2006},
isbn = {0780394518},
publisher = {IEEE Press},
url = {https://doi.org/10.1145/1118299.1118342},
doi = {10.1145/1118299.1118342},
abstract = {Compilers designed for current embedded systems must be capable of addressing multiple constraints such as low power, high performance, small memory footprint and form factor, and high reliability at the same time. In particular, optimizing for one constraint should be performed carefully, considering its impact on other constraints. Recent trends indicate that transient errors are becoming increasingly important in embedded systems. Focusing on an embedded chip multiprocessor and array-intensive applications, this paper demonstrates how reliability against transient errors can be improved without impacting execution time by utilizing idle processors for duplicating some of the computations of the active processors. It also shows how a balance between power savings and reliability improvement can be struck using a metric called the energy-delay-fallibility product. Our experimental results indicate that the "percentage of duplicated computations" is a useful high-level metric for studying the tradeoffs among performance, power, and reliability.},
booktitle = {Proceedings of the 2006 Asia and South Pacific Design Automation Conference},
pages = {134–139},
numpages = {6},
location = {Yokohama, Japan},
series = {ASP-DAC '06}
}

@inproceedings{10.1145/2024724.2024861,
author = {Shoaib, Mohammed and Jha, Niraj and Verma, Naveen},
title = {A Low-Energy Computation Platform for Data-Driven Biomedical Monitoring Algorithms},
year = {2011},
isbn = {9781450306362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2024724.2024861},
doi = {10.1145/2024724.2024861},
abstract = {A key challenge in closed-loop chronic biomedical systems is the ability to detect complex physiological states from patient signals within a constrained power budget. Data-driven machine-learning techniques are major enablers for the modeling and interpretation of such states. Their computational energy, however, scales with the complexity of the required models. In this paper, we propose a low-energy, biomedical computation platform optimized through the use of an accelerator for data-driven classification. The accelerator retains selective flexibility through hardware reconfiguration and exploits voltage scaling and parallelism to operate at a sub-threshold minimum-energy point. Using cardiac arrhythmia detection algorithms with patient data from the MIT-BIH database, classification is achieved in 2.96 μJ (at Vdd = 0.4 V), over four orders of magnitude smaller than that on a low-power general-purpose processor. The energy of feature extraction is 148 μJ while retaining flexibility for a range of possible biomarkers.},
booktitle = {Proceedings of the 48th Design Automation Conference},
pages = {591–596},
numpages = {6},
keywords = {electrocardiograph (ECG), support vector machine (SVM)},
location = {San Diego, California},
series = {DAC '11}
}

@inproceedings{10.1145/2712386.2712387,
author = {Anzt, Hartwig and Tomov, Stanimire and Dongarra, Jack},
title = {Energy Efficiency and Performance Frontiers for Sparse Computations on GPU Supercomputers},
year = {2015},
isbn = {9781450334044},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2712386.2712387},
doi = {10.1145/2712386.2712387},
abstract = {In this paper we unveil some energy efficiency and performance frontiers for sparse computations on GPU-based supercomputers. To do this, we consider state-of-the-art implementations of the sparse matrix-vector (SpMV) product in libraries like cuSPARSE, MKL, and MAGMA, and their use in the LOBPCG eigen-solver. LOBPCG is chosen as a benchmark for this study as it combines an interesting mix of sparse and dense linear algebra operations with potential for hardware-aware optimizations. Most notably, LOBPCG includes a blocking technique that is a common performance optimization for many applications. In particular, multiple memory-bound SpMV operations are blocked into a SpM-matrix product (SpMM), that achieves significantly higher performance than a sequence of SpMVs. We provide details about the GPU kernels we use for the SpMV, SpMM, and the LOBPCG implementation design, and study performance and energy consumption compared to CPU solutions. While a typical sparse computation like the SpMV reaches only a fraction of the peak of current GPUs, we show that the SpMM achieves up to a 6x performance improvement over the GPU's SpMV, and the GPU-accelerated LOBPCG based on this kernel is 3 to 5x faster than multicore CPUs with the same power draw, e.g., a K40 GPU vs. two Sandy Bridge CPUs (16 cores). In practice though, we show that currently available CPU implementations are much slower due to missed optimization opportunities. These performance results translate to similar improvements in energy consumption, and are indicative of today's frontiers in energy efficiency and performance for sparse computations on supercomputers.},
booktitle = {Proceedings of the Sixth International Workshop on Programming Models and Applications for Multicores and Manycores},
pages = {1–10},
numpages = {10},
keywords = {blocked sparse matrix vector product, energy efficiency, GPU supercomputer, sparse eigensolver, LOBPCG},
location = {San Francisco, California},
series = {PMAM '15}
}

@inproceedings{10.1109/DATE.2005.148,
author = {Loghi, Mirko and Poncino, Massimo},
title = {Exploring Energy/Performance Tradeoffs in Shared Memory MPSoCs: Snoop-Based Cache Coherence vs. Software Solutions},
year = {2005},
isbn = {0769522882},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/DATE.2005.148},
doi = {10.1109/DATE.2005.148},
abstract = {Shared memory is a common interprocessor communication paradigm for single-chip multi-processor platforms. Snoop-based cache coherence is a very successful technique that provides a clean shared-memory programming abstraction in general-purpose chip multi-processors, but there is no consensus on its usage in resource-constrained multiprocessor systems on chips (MPSoCs) for embedded applications. This work aims at providing a comparative energy and performance analysis of cache coherence support schemes in MPSoCs. Thanks to the use of a complete multi-processor simulation platform, which relies on accurate technology-homogeneous power models, we were able to explore different cache-coherent shared-memory communication schemes for a number of cache configurations and workloads.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe - Volume 1},
pages = {508–513},
numpages = {6},
series = {DATE '05}
}

@inproceedings{10.1145/3386164.3389078,
author = {Aljarallah, Sulaiman and Lock, Russell},
title = {A Comparison of Software Quality Characteristics and Software Sustainability Characteristics},
year = {2020},
isbn = {9781450376617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386164.3389078},
doi = {10.1145/3386164.3389078},
abstract = {Software sustainability has generated much interest in the software engineering field in recent times, and has been widely investigated across different fields and from different standpoints. The relationship between software quality and software sustainability is still an open question. In this study, a literature survey and comparison was conducted using three-phases, having as a starting point the comparison of basic models for software quality. A follow-up study, conducted at a more comprehensive level to cover both basic models and the most cited tailored models., Software sustainability literature is investigated to find the most frequent characteristics. Finally, data gathered from these studies and a comparison shows a similarity in the top level of these characteristics between software sustainability and software quality, and the emphasis on sustainability, maintainability and portability. The study suggests that ISO 25010 can be utilised by software sustainability. As a future work, the findings will be investigated empirically to support designing software sustainability framework identifying the most important criteria in the technical dimension.},
booktitle = {Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control},
articleno = {26},
numpages = {11},
keywords = {Software Sustainability Characteristics, Software Sustainability, Software Quality, Quality Models, Quality Characteristics},
location = {Amsterdam, Netherlands},
series = {ISCSIC 2019}
}

@inproceedings{10.5555/2648668.2648695,
author = {Shafique, Muhammad and Khan, Muhammad Usman Karim and Henkel, J\"{o}rg},
title = {Content-Driven Adaptive Computation Offloading for Energy-Aware Hybrid Distributed Video Coding},
year = {2013},
isbn = {9781479912353},
publisher = {IEEE Press},
abstract = {Hybrid Distributed Video Coding (Hybrid-DVC) is an emerging compression paradigm for resource-constrained embedded devices, like wireless video sensor nodes. This paper presents a low-overhead energy-aware Hybrid-DVC with an adaptive computation offloading scheme. Our scheme offloads the workload of multiple video encoding devices concurrently to a high-end decoder device to minimize the overall system energy under constraints of compute capabilities. It leverages video content knowledge to determine regions in the video frames that are offloaded to the remote decoder device. It jointly minimizes the transmission and communication energy and provides a high video quality. Our scheme provides up to 39% energy savings compared to state-of-the-art Hybrid-DVC schemes.},
booktitle = {Proceedings of the 2013 International Symposium on Low Power Electronics and Design},
pages = {106–113},
numpages = {8},
location = {Beijing, China},
series = {ISLPED '13}
}

@inproceedings{10.1145/2751504.2751508,
author = {Cavelan, Aur\'{e}lien and Robert, Yves and Sun, Hongyang and Vivien, Fr\'{e}d\'{e}ric},
title = {Voltage Overscaling Algorithms for Energy-Efficient Workflow Computations With Timing Errors},
year = {2015},
isbn = {9781450335690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2751504.2751508},
doi = {10.1145/2751504.2751508},
abstract = {We propose a software-based approach using dynamic voltage overscaling to reduce the energy consumption of HPC applications. This technique aggressively lowers the supply voltage below nominal voltage, which introduces timing errors, and we use Algorithm-Based Fault-Tolerance (ABFT) to provide fault tolerance for matrix operations. We introduce a formal model, and we design optimal polynomial-time solutions, to execute a linear chain of tasks. Evaluation results obtained for matrix multiplication demonstrate that our approach indeed leads to significant energy savings, compared to the standard algorithm that always operates at nominal voltage.},
booktitle = {Proceedings of the 5th Workshop on Fault Tolerance for HPC at EXtreme Scale},
pages = {27–34},
numpages = {8},
keywords = {timing errors, voltage overscaling, energy efficiency, abft},
location = {Portland, Oregon, USA},
series = {FTXS '15}
}

@article{10.1145/1274858.1274865,
author = {Carta, Salvatore and Alimonda, Andrea and Pisano, Alessandro and Acquaviva, Andrea and Benini, Luca},
title = {A Control Theoretic Approach to Energy-Efficient Pipelined Computation in MPSoCs},
year = {2007},
issue_date = {September 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {1539-9087},
url = {https://doi.org/10.1145/1274858.1274865},
doi = {10.1145/1274858.1274865},
abstract = {In this work, we describe a control theoretic approach to dynamic voltage/frequency scaling (DVFS) in a pipelined MPSoC architecture with soft real-time constraints, aimed at minimizing energy consumption with throughput guarantees. Theoretical analysis and experiments carried out on a cycle-accurate, energy-aware, and multiprocessor simulation platform are provided. We give a dynamic model of the system behavior which allows to synthesize linear and nonlinear feedback control schemes for the run-time adjustment of the core frequencies. We study the characteristics of the proposed techniques in both transient and steady-state conditions. Finally, we compare the proposed feedback approaches and local DVFS policies from an energy consumption viewpoint.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
pages = {27–es},
numpages = {28},
keywords = {feedback-control techniques, DVFS, MPSoC, parallel systems}
}

@article{10.1145/3450612,
author = {Scott, Art and Lewis, Ted G.},
title = {Sustainable Computing},
year = {2021},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2021},
number = {February},
url = {https://doi.org/10.1145/3450612},
doi = {10.1145/3450612},
abstract = {Energy consumption by computers is expanding exponentially along with big data and AI processing. The trend can be broken by adopting alternate approaches to CPU and GPU design. Specifically, Adiabatic Reversible Logic (ARL) has been proposed as the solution. This essay surveys the technology of ARL and gives early examples of actual reversible machines.},
journal = {Ubiquity},
month = {mar},
articleno = {2},
numpages = {10}
}

@inproceedings{10.1109/MOBILESoft.2017.1,
author = {Banerjee, Abhijeet and Roychoudhury, Abhik},
title = {Future of Mobile Software for Smartphones and Drones: Energy and Performance},
year = {2017},
isbn = {9781538626696},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MOBILESoft.2017.1},
doi = {10.1109/MOBILESoft.2017.1},
abstract = {The need for performance and energy efficiency in mobile devices is apparent with the obvious shifting of more intensive computation to mobile platforms. In this paper, we first make a clear distinction between performance and energy issues. Apart from showing that performance efficiency is neither co-related with energy-efficiency nor inefficiency, we focus on programming methodologies and software validation approaches for producing energy efficient mobile software. These include reviewing recent works on energy-aware programming and nonfunctional testing to expose energy and performance issues in mobile software. As mobile platforms continue to evolve, new scenarios and use-cases involving mobile devices are on the rise. We speculate on scenarios involving energy hungry mobile software in near future, and how existing software engineering techniques can evolve to combat energy inefficiency in such scenarios. These include the need to effectively manage the energy-consumption of software-controlled personal drones which are likely to become main-stream in near future. We suggest integration of concepts from price theory in Economics to build a distributed energy management framework for software-controlled personal drones.},
booktitle = {Proceedings of the 4th International Conference on Mobile Software Engineering and Systems},
pages = {1–12},
numpages = {12},
keywords = {energy consumption, performance, drones, mobile apps},
location = {Buenos Aires, Argentina},
series = {MOBILESoft '17}
}

@article{10.1145/3508467.3508471,
author = {Wang, Nan and Chau, Sid Chi-Kin and Zhou, Yue},
title = {Privacy-Preserving Energy Storage Sharing with Blockchain and Secure Multi-Party Computation},
year = {2022},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3508467.3508471},
doi = {10.1145/3508467.3508471},
abstract = {Energy storage provides an effective way of shifting temporal energy demands and supplies, which enables significant cost reduction under time-of-use energy pricing plans. Despite its promising benefits, the cost of present energy storage remains expensive, presenting a major obstacle to practical deployment. A more viable solution to improve the cost-effectiveness is by sharing energy storage, such as community sharing, cloud energy storage and peer-to-peer sharing. However, revealing private energy demand data to an external energy storage operator may compromise user privacy, and is susceptible to data misuses and breaches. In this paper, we explore a novel approach to support energy storage sharing with privacy protection, based on privacy-preserving blockchain and secure multi-party computation. We present an integrated solution to enable privacy-preserving energy storage sharing, such that energy storage service scheduling and cost-sharing can be attained without the knowledge of individual users' demands. It also supports auditing and verification by the grid operator via blockchain. Furthermore, our privacy-preserving solution can safeguard against a majority of dishonest users, who may collude in cheating, without requiring a trusted third-party. We implemented our solution as a smart contract on real-world Ethereum blockchain platform, and provided empirical evaluation in this paper1.},
journal = {SIGENERGY Energy Inform. Rev.},
month = {jan},
pages = {32–50},
numpages = {19},
keywords = {privacy-preserving, blockchain, secure multi-party computation, energy storage sharing}
}

@inproceedings{10.1145/1774088.1774141,
author = {Liu, Shu and Cheng, Xu and Guan, Xuetao and Tong, Dong},
title = {Energy Efficient Management Scheme for Heterogeneous Secondary Storage System in Mobile Computers},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774141},
doi = {10.1145/1774088.1774141},
abstract = {Flash memory is widely used because of its shock-resistance and power-efficient features. However, it cannot replace hard disks as secondary storage devices due to their greater cost per unit storage and low capability. In this paper, we propose an energy efficient heterogeneous secondary storage system management scheme for mobile systems. We employ flash memory device as a file cache of hard disk and extend existing data cache management algorithms to distribute files between two devices with consideration of file level cache restrictions. As a result, most file accesses are conducted in flash memory device and disk is spun-down to save energy. We develop a trace-driven simulator to evaluate our scheme in comparison with other alternatives. Results demonstrate that with the help of our scheme, energy consumption of secondary storage system can be saved by up to 90% and I/O access time is improved. Furthermore, the file cache management algorithms can result in high hit ratios.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {251–257},
numpages = {7},
keywords = {heterogeneous secondary storage, hard disk, flash memory, energy saving},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/2335755.2335852,
author = {Ramamurthy, Bina and Poulin, Jessica and Dittmar, Katharina},
title = {Cloud-Enabling Biological Simulations for Scalable and Sustainable Access: An Experience Report},
year = {2012},
isbn = {9781450316026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2335755.2335852},
doi = {10.1145/2335755.2335852},
abstract = {We present our experiences with cloud-enabling an Evolutionary Genetics learning environment for achieving sustainability and scalability. The project called Pop!World features three major levels: (i) the Gateway module for catering to K-12 students, (ii) the Discovery module for undergraduates and (ii) the Research module for advanced learners and researchers. The Discovery module of Pop!World is currently in use in the introductory Biological Sciences course at UB (BIO 200). The project that began as a design and development of prototype tool for learning and teaching soon faced two major issues: scalability and sustainability. Scalability in our case is about the ability to service thousands of users at a fairly reasonable quality of service. Sustainability is about accessibility and availability beyond the classroom. Learners are often introduced to useful tools and environments during their enrollment in a course. Yet, continued access to the tools beyond the duration of the course is critical for sustaining the learning that happened during the course and to enable experimentation, discovery and application of the knowledge they acquired. Therefore, we used cloud cyber-infrastructure to address successfully the dual issues of scalability and sustainability. In this paper we discuss the details of the cloud deployment of Pop!World and our experiences in using it in an educational setting. The tool is currently deployed on Google App Engine (GAE).Significance to XSEDE: We expect the learning model we have developed for Evolutionary Biology simulations can be transformed to disseminate capabilities of XSEDE and to serve as an educational and training model for XSEDE.},
booktitle = {Proceedings of the 1st Conference of the Extreme Science and Engineering Discovery Environment: Bridging from the EXtreme to the Campus and Beyond},
articleno = {54},
numpages = {2},
keywords = {simulation, evolutionary biology, cyber-infrastructure, cloud, population genetics},
location = {Chicago, Illinois, USA},
series = {XSEDE '12}
}

@article{10.1145/3530908,
author = {Ghasemi, Mehdi and Rakhmatov, Daler and Wu, Carole-Jean and Vrudhula, Sarma},
title = {EdgeWise: Energy-Efficient CNN Computation on Edge Devices under Stochastic Communication Delays},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {5},
issn = {1539-9087},
url = {https://doi.org/10.1145/3530908},
doi = {10.1145/3530908},
abstract = {This article presents a framework to enable the energy-efficient execution of convolutional neural networks (CNNs) on edge devices. The framework consists of a pair of edge devices connected via a wireless network: a performance and energy-constrained device D as the first recipient of data and an energy-unconstrained device N as an accelerator for D. Device D decides on-the-fly how to distribute the workload with the objective of minimizing its energy consumption while accounting for the inherent uncertainty in network delay and the overheads involved in data transfer. These challenges are tackled by adopting the data-driven modeling framework of Markov Decision Processes, whereby an optimal policy is consulted by D in O(1) time to make layer-by-layer assignment decisions. As a special case, a linear-time dynamic programming algorithm is also presented for finding optimal layer assignment at once, under the assumption that the network delay is constant throughout the execution of the application. The proposed framework is demonstrated on a platform comprised of a Raspberry PI 3 as D and an NVIDIA Jetson TX2 as N. An average improvement of 31% and 23% in energy consumption is achieved compared to the alternatives of executing the CNNs entirely on D and N. Two state-of-the-art methods were also implemented and compared with the proposed methods.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {oct},
articleno = {66},
numpages = {27},
keywords = {Internet of Things (IoT), energy-efficient, edge computing}
}

@inproceedings{10.1145/1275633.1275644,
author = {P\'{e}rez, Alicia As\'{\i}n and Gracia, Dar\'{\i}o Su\'{a}rez and Y\'{u}fera, Victor Vi\~{n}als},
title = {A Proposal to Introduce Power and Energy Notions in Computer Architecture Laboratories},
year = {2007},
isbn = {9781595937971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1275633.1275644},
doi = {10.1145/1275633.1275644},
abstract = {Power has emerged as a major concern in the microprocessor industry. From embedded to high-performance processors, all designs employ several power optimizations at the circuit and the architectural levels.While introductory computer architecture books and courses are starting to cover power concepts, proposals to offer students a practical experience with power issues are still scarce. To do so, we advocate the inclusion of energy and power concepts in computer architecture courses by means of laboratory experiments. These experiments build upon concepts presented in preceding physics and/or electronics courses.This paper outlines our experience with the development of such hardware-based energy laboratories. We propose experiments on a simple, yet powerful hardware-software platform capable of live energy measurements in a desktop computer processor. The proposed laboratory setup can help to teach students the basics of power-aware computer architectures. The performed experiments demonstrate the viability of our approach. For example, our experiments show that students can deduce the dynamic and static power dissipation of the Intel Pentium 4. Information that is not documented in the processor's datasheet.},
booktitle = {Proceedings of the 2007 Workshop on Computer Architecture Education},
pages = {52–57},
numpages = {6},
keywords = {platform, power, education, processor, measurements, computer architecture, energy},
location = {San Diego, California},
series = {WCAE '07}
}

@inproceedings{10.1109/UCC.2014.162,
author = {McBay, Conor and Parr, Gerard and McClean, Sally},
title = {Sustainable Communications Infrastructures in the Cloud - Supporting the Information Economy},
year = {2014},
isbn = {9781479978816},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UCC.2014.162},
doi = {10.1109/UCC.2014.162},
abstract = {In recent years energy consumption from ICT has increased due to the popularity of cloud computing. This consumption is also estimated to double every five years. A key topic of recent research is the focus on increasing the energy efficiency of ICT, in particular the area of cloud computing. In our research we aim to improve the energy efficiency of cloud computing data centres while maintaining the Quality-of-Service (QoS) expected. A literature review has been conducted into various methods of increasing energy efficiency and the beginnings of experimentation into our own research and theories have been documented in this paper.},
booktitle = {Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing},
pages = {986–991},
numpages = {6},
keywords = {Green ICT, Green routing, Virtualisation, Quality-of-service, Cloud computing, Dynamic speed scaling, DVFS},
series = {UCC '14}
}

@inproceedings{10.1145/3139367.3139445,
author = {Karanikolas, Nikitas and Liaramantzas, Antonios},
title = {Affiance Computer Science and Machining Technology for Cheap and Efficient Solar Energy},
year = {2017},
isbn = {9781450353557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3139367.3139445},
doi = {10.1145/3139367.3139445},
abstract = {Our purpose is to investigate / inspirate methods for creating Small Energy Production Systems with reduced cost1. We suggest the integration of machining technology, microcontrollers and software for creating cheap Small Energy Production Systems. Here we investigate the creation of an electricity production small system based on simple machining technology (teeterboard), simple microcontroller (arduino uno) and solar panels. elevation},
booktitle = {Proceedings of the 21st Pan-Hellenic Conference on Informatics},
articleno = {54},
numpages = {4},
keywords = {photovoltaic system, Solar energy, single axis tracker, machining technology, solar tracking},
location = {Larissa, Greece},
series = {PCI '17}
}

@article{10.1145/335043.335046,
author = {Hwang, Chi-Hong and Wu, Allen C.-H.},
title = {A Predictive System Shutdown Method for Energy Saving of Event-Driven Computation},
year = {2000},
issue_date = {April 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/335043.335046},
doi = {10.1145/335043.335046},
abstract = {This paper presents a system-level power management technique for energy savings of event-driven application. We present a new predictive system-shutdown method to exploit sleep mode operations for energy saving. We use an exponential-average approach to predict the upcoming idle period. We introduce two mechanisms, prediction-miss correction and prewake-up, to improve the hit ratio and to reduce the delay overhead. Experiments on four different event-driven applications show that our proposed method achieves high hit ratios in a wide range of delay overheads, which results in a high degree of energy with low delay penaties.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {apr},
pages = {226–241},
numpages = {16},
keywords = {system shutdown, power management, predictive, sleep mode, event-drive}
}

@inproceedings{10.5555/3014904.3014981,
author = {Chen, Jieyang and Tan, Li and Wu, Panruo and Tao, Dingwen and Li, Hongbo and Liang, Xin and Li, Sihuan and Ge, Rong and Bhuyan, Laxmi and Chen, Zizhong},
title = {GreenLA: Green Linear Algebra Software for GPU-Accelerated Heterogeneous Computing},
year = {2016},
isbn = {9781467388153},
publisher = {IEEE Press},
abstract = {While many linear algebra libraries have been developed to optimize their performance, no linear algebra library considers their energy efficiency at the library design time. In this paper, we present GreenLA - an energy efficient linear algebra software package that leverages linear algebra algorithmic characteristics to maximize energy savings with negligible overhead. GreenLA is (1) energy efficient: it saves up to several times more energy than the best existing energy saving approaches that do not modify library source codes; (2) high performance: its performance is comparable to the highly optimized linear algebra library MAGMA; and (3) transparent to applications: with the same programming interface, existing MAGMA users do not need to modify their source codes to benefit from GreenLA. Experimental results demonstrate that GreenLA is able to save up to three times more energy than the best existing energy saving approaches while delivering similar performance compared to the state-of-the-art linear algebra library MAGMA.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {57},
numpages = {11},
keywords = {DVFS, algorithmic slack prediction, CPU, dense matrix factorizations, GPU, critical path, energy},
location = {Salt Lake City, Utah},
series = {SC '16}
}

@inproceedings{10.1145/3396851.3402658,
author = {Chi, Ce and Ji, Kaixuan and Marahatta, Avinab and Song, Penglei and Zhang, Fa and Liu, Zhiyong},
title = {Jointly Optimizing the IT and Cooling Systems for Data Center Energy Efficiency Based on Multi-Agent Deep Reinforcement Learning},
year = {2020},
isbn = {9781450380096},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3396851.3402658},
doi = {10.1145/3396851.3402658},
abstract = {With the development and application of cloud computing, the increasing amount of data centers has resulted in huge energy consumption and severe environmental problems. Improving the energy efficiency of data centers has become a necessity. In this paper, in order to improve the energy efficiency of both IT and cooling systems for data centers, a model-free deep reinforcement learning (DRL) based joint optimization approach MACEEC is proposed. To improve the cooperation between IT and cooling system while handling the high-dimensional state space and the large hybrid discrete-continuous action space, a hybrid AC-DDPG multi-agent structure is developed. A scheduling baseline comparison method is proposed to enhance the stability of the architecture. And an asynchronous control optimization algorithm is developed to solve the different responding time issue between IT and cooling system. Experiments based on real-world traces data validate that MACEEC can effectively improve the overall energy efficiency for data centers while ensuring the temperature constraint and service quality compared with existing joint optimization approaches.},
booktitle = {Proceedings of the Eleventh ACM International Conference on Future Energy Systems},
pages = {489–495},
numpages = {7},
keywords = {data center, scheduling algorithm, multiagent, cooling system, energy efficiency, deep reinforcement learning},
location = {Virtual Event, Australia},
series = {e-Energy '20}
}

@inproceedings{10.5555/266388.266410,
author = {Hwang, Chi-Hong and Wu, Allen C.-H.},
title = {A Predictive System Shutdown Method for Energy Saving of Event-Driven Computation},
year = {1997},
isbn = {0818682000},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {We present a system-level power management technique for power saving of event-driven applications. We present a new predictive system shutdown method to exploit sleep mode operations for power saving. We use an exponential-average approach to predict the upcoming idle period. We introduce two mechanisms, prediction-miss correction and pre-wakeup, to improve the hit ratio and to reduce the delay overhead. Experiments on four different event-driven applications show that our proposed method achieves high hit ratios in a wide range of delay overheads, which results in a high degree of power saving with low delay penalties.},
booktitle = {Proceedings of the 1997 IEEE/ACM International Conference on Computer-Aided Design},
pages = {28–32},
numpages = {5},
keywords = {VLSI, low delay penalties, idle period, pre-wakeup, delay overhead, sleep mode operations, logic CAD, energy saving, system-level power management, finite state machine, prediction-miss correction, hit ratio, power saving, VLSI circuit design, predictive system shutdown method, event-driven computation, exponential-average approach},
location = {San Jose, California, USA},
series = {ICCAD '97}
}

@inproceedings{10.5555/2755753.2755925,
author = {Arumugam, Guru Prakash and Srikanthan, Prashanth and Augustine, John and Palem, Krishna and Upfal, Eli and Bhargava, Ayush and Parishkrati and Yenugula, Sreelatha},
title = {Novel Inexact Memory Aware Algorithm Co-Design for Energy Efficient Computation: Algorithmic Principles},
year = {2015},
isbn = {9783981537048},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {It is increasingly accepted that energy savings can be achieved by trading the accuracy of a computing system for energy gains---quite often significantly. This approach is referred to as inexact or approximate computing. Given that a significant portion of the energy in a modern general purpose processor is spent on moving data to and from storage, and that increasingly data movement contributes significantly to activity during the execution of applications, it is important to be able to develop techniques and methodologies for inexact computing in this context. To accomplish this to its fullest level, it is important to start with algorithmic specifications and alter their intrinsic design to take advantage of inexactness. This calls for a new approach to inexact memory aware algorithm design (IMAD) or co-design. In this paper, we provide the theoretical foundations which include novel models as well as technical results in the form of upper and lower bounds for IMAD in the context of universally understood and canonical problems: variations of sorting, and string matching. Surprisingly, IMAD allowed us to design entirely error-free algorithms while achieving energy gain factors of 1.5 and 5 in the context of sorting and string matching when compared to their traditional (textbook) algorithms. IMAD is also amenable to theoretical analysis and we present several asymptotic bounds on energy gains.},
booktitle = {Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition},
pages = {752–757},
numpages = {6},
location = {Grenoble, France},
series = {DATE '15}
}

@inproceedings{10.1145/3301551.3301608,
author = {Zhu, Huafei and Keong, Ng Wee},
title = {Sustainable Data Management Strategies and Systems in Untrust Cloud Environments},
year = {2018},
isbn = {9781450366298},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3301551.3301608},
doi = {10.1145/3301551.3301608},
abstract = {The state-of-the-art strategies for the data privacy (e.g., personal information, user key, data sharing and exchanging management) are far from satisfied; Worse, a large number of data service providers are running in the "both athletes and referees" business model. We break the unfair "both athletes and referees" rule by introducing a distributed homomorphic key management service provider who collaborates with cloud service providers to provide fair data management for users. We then provide a construction of homomorphic key protocol to dispense user keys to cloud service providers and we are able to show that if the underlying El Gamal encryption is semantically secure then the proposed homomorphic key management protocol is secure against semi-honest adversary. Finally, a multi-tenant keyword search in cloud is presented as an immediate application of our homomorphic key management protocol.},
booktitle = {Proceedings of the 6th International Conference on Information Technology: IoT and Smart City},
pages = {163–167},
numpages = {5},
keywords = {key management protocol, homomorphic encryption, semantic security, keyword search},
location = {Hong Kong, Hong Kong},
series = {ICIT '18}
}

@inproceedings{10.1145/3575813.3595191,
author = {Bashir, Noman and Chandio, Yasra and Irwin, David and Anwar, Fatima M. and Gummeson, Jeremy and Shenoy, Prashant},
title = {Jointly Managing Electrical and Thermal Energy in Solar- and Battery-Powered Computer Systems},
year = {2023},
isbn = {9798400700323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575813.3595191},
doi = {10.1145/3575813.3595191},
abstract = {Environmentally-powered computer systems operate on renewable energy harvested from their environment, such as solar or wind, and stored in batteries. While harvesting environmental energy has long been necessary for small-scale embedded systems without access to external power sources, it is also increasingly important in designing sustainable larger-scale systems for edge applications. For sustained operations, such systems must consider not only the electrical energy but also the thermal energy available in the environment in their design and operation. Unfortunately, prior work generally ignores the impact of thermal effects, and instead implicitly assumes ideal temperatures. To address the problem, we develop a thermodynamic model that captures the interplay of electrical and thermal energy in environmentally-powered computer systems. The model captures the effect of environmental conditions, the system’s physical properties, and workload scheduling on performance. In evaluating our model, we distill the thermal effects that impact these systems using a small-scale prototype and a programmable incubator. We then leverage our model to show how considering these thermal effects in designing and operating environmentally-powered computer systems of varying scales can improve their energy-efficiency, performance, and availability.},
booktitle = {Proceedings of the 14th ACM International Conference on Future Energy Systems},
pages = {132–143},
numpages = {12},
keywords = {energy-efficiency, performance, thermal effects, batteries., Environmentally-powered computer systems},
location = {Orlando, FL, USA},
series = {e-Energy '23}
}

@inproceedings{10.1145/339331.339421,
author = {Farkas, Keith I. and Flinn, Jason and Back, Godmar and Grunwald, Dirk and Anderson, Jennifer M.},
title = {Quantifying the Energy Consumption of a Pocket Computer and a Java Virtual Machine},
year = {2000},
isbn = {1581131941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/339331.339421},
doi = {10.1145/339331.339421},
abstract = {In this paper, we examine the energy consumption of a state-of-the-art pocket computer. Using a data acquisition system, we measure the energy consumption of the Itsy Pocket Computer, developed by Compaq Computer Corporation's Palo Alto Research Labs. We begin by showing that the energy usage characteristics of the Itsy differ markedly from that of a notebook computer. Then, since we expect that flexible software environments will become increasingly prevalent on pocket computers, we consider applications running in a Java environment. In particular, we explain some of the Java design tradeoffs applicable to pocket computers, and quantify their energy costs. For the design options we considered and the three workloads we studied, we find a maximum change in energy use of 25%.},
booktitle = {Proceedings of the 2000 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {252–263},
numpages = {12},
location = {Santa Clara, California, USA},
series = {SIGMETRICS '00}
}

@article{10.1145/3442632.3447956,
author = {Frazelle, Jessie},
title = {Let's Play Global Thermonuclear Energy: It's Important to Know Where Your Power Comes From.},
year = {2021},
issue_date = {November-December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {6},
issn = {1542-7730},
url = {https://doi.org/10.1145/3442632.3447956},
doi = {10.1145/3442632.3447956},
abstract = {For us to grow and progress as a civilization, we need more investment in providing electricity to the world through clean, safe, and efficient processes. Thermonuclear energy is a huge step forward. This article is mostly focused on the use cases around grid-scale reactors. It's hard to see a future without some sort of thermonuclear energy powering all sorts of things around us.},
journal = {Queue},
month = {jan},
pages = {5–20},
numpages = {16}
}

@inproceedings{10.1109/ISCA.2018.00063,
author = {Park, Eunhyeok and Kim, Dongyoung and Yoo, Sungjoo},
title = {Energy-Efficient Neural Network Accelerator Based on Outlier-Aware Low-Precision Computation},
year = {2018},
isbn = {9781538659847},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA.2018.00063},
doi = {10.1109/ISCA.2018.00063},
abstract = {Owing to the presence of large values, which we call outliers, conventional methods of quantization fail to achieve significantly low precision, e.g., four bits, for very deep neural networks, such as ResNet-101. In this study, we propose a hardware accelerator, called the outlier-aware accelerator (OLAccel). It performs dense and low-precision computations for a majority of data (weights and activations) while efficiently handling a small number of sparse and high-precision outliers (e.g., amounting to 3% of total data). The OLAccel is based on 4-bit multiply-accumulate (MAC) units and handles outlier weights and activations in a different manner. For outlier weights, it equips SIMD lanes of MAC units with an additional MAC unit, which helps avoid cycle overhead for the majority of outlier occurrences, i.e., a single occurrence in the SIMD lanes. The OLAccel performs computations using outlier activation on dedicated, high-precision MAC units. In order to avoid coherence problem due to updates from low-and high-precision computation units, both units update partial sums in a pipelined manner. Our experiments show that the OLAccel can reduce by 43.5% (27.0%), 56.7% (36.3%), and 62.2% (49.5%) energy consumption for AlexNet, VGG-16, and ResNet-18, respectively, compared with a 16-bit (8-bit) state-of-the-art zero-aware accelerator. The energy gain mostly comes from the memory components, the DRAM, and on-chip memory due to reduced precision.},
booktitle = {Proceedings of the 45th Annual International Symposium on Computer Architecture},
pages = {688–698},
numpages = {11},
keywords = {accelerator, quantization, neural network},
location = {Los Angeles, California},
series = {ISCA '18}
}

@article{10.1145/3430503,
author = {Lin, Weiwei and Huang, Tiansheng and Li, Xin and Shi, Fang and Wang, Xiumin and Hsu, Ching-Hsien},
title = {Energy-Efficient Computation Offloading for UAV-Assisted MEC: A Two-Stage Optimization Scheme},
year = {2021},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
issn = {1533-5399},
url = {https://doi.org/10.1145/3430503},
doi = {10.1145/3430503},
abstract = {In addition to the stationary mobile edge computing (MEC) servers, a few MEC surrogates that possess a certain mobility and computation capacity, e.g., flying unmanned aerial vehicles (UAVs) and private vehicles, have risen as powerful counterparts for service provision. In this article, we design a two-stage online scheduling scheme, targeting computation offloading in a UAV-assisted MEC system. On our stage-one formulation, an online scheduling framework is proposed for dynamic adjustment of mobile users' CPU frequency and their transmission power, aiming at producing a socially beneficial solution to users. But the major impediment during our investigation lies in that users might not unconditionally follow the scheduling decision released by servers as a result of their individual rationality. In this regard, we formulate each step of online scheduling on stage one into a non-cooperative game with potential competition over the limited radio resource. As a solution, a centralized online scheduling algorithm, called ONCCO, is proposed, which significantly promotes social benefit on the basis of the users' individual rationality. On our stage-two formulation, we are working towards the optimization of UAV computation resource provision, aiming at minimizing the energy consumption of UAVs during such a process, and correspondingly, another algorithm, called WS-UAV, is given as a solution. Finally, extensive experiments via numerical simulation are conducted for an evaluation purpose, by which we show that our proposed algorithms achieve satisfying performance enhancement in terms of energy conservation and sustainable service provision.},
journal = {ACM Trans. Internet Technol.},
month = {oct},
articleno = {4},
numpages = {23},
keywords = {unmanned aerial vehicles, non-cooperative game, nash equilibrium, Computation offloading, mobile edge computing}
}

@article{10.1145/2460216.2460227,
author = {Lin, Colin Yu and So, Hayden Kwok-Hay Kwok-Hay},
title = {Energy-Efficient Dataflow Computations on FPGAs Using Application-Specific Coarse-Grain Architecture Synthesis},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {5},
issn = {0163-5964},
url = {https://doi.org/10.1145/2460216.2460227},
doi = {10.1145/2460216.2460227},
abstract = {Compiling high-level user applications to execute on FPGAbased reconfigurable computers often involve synthesizing dataflow graphs beyond the capacity of the available hardware resources. A framework that provides rapid and energyefficient compilation of such dataflow graphs on FPGAs using an array of pre-placed configurable processing elements is proposed. The mapping schedule of the compute operations on the CPEs and the direct network among the CPEs are co-synthesized on a per-application basis to provide the targeted power-performance tradeoff. Compared to the use of a fixed generic topology, the use of an application-specific topology derived by a genetic algorithm can achieve up to 28% improvement in energy-delay product. As the CPEs are pre-placed, compiling for a new application involve only the generation of a new operation schedule, which is stored in on-chip memory, and the new routes among the CPEs. With optimization in operation scheduling and mapping and application-specific interconnect network, the proposed framework achieved up to 199X better energy-delay product compared to a traditional FPGA high-level synthesis tool xPilot. The use of such framework is anticipated to serve as part of a high-level application compiler for hybrid CPU-FPGA computation.},
journal = {SIGARCH Comput. Archit. News},
month = {mar},
pages = {58–63},
numpages = {6}
}

@inproceedings{10.1145/1118299.1118324,
author = {Tsui, Chi-Ying and Shao, Hui and Ki, Wing-Hung and Su, Feng},
title = {Ultra-Low Voltage Power Management Circuit and Computation Methodology for Energy Harvesting Applications},
year = {2006},
isbn = {0780394518},
publisher = {IEEE Press},
url = {https://doi.org/10.1145/1118299.1118324},
doi = {10.1145/1118299.1118324},
abstract = {A power management and computation methodology is proposed for ultra-low power energy harvesting applications. An integrated exponential charge pump that accepts an input voltage of around 150mV and provides an unregulated output voltage of more than 1.5V serves as the power supply. To cater with the fluctuated energy source and unregulated power supply, a supply side charge-based computation methodology is proposed, of which the computation activity tracks with the fluctuation of the available energy. The idea is demonstrated in a test chip fabricated using a 0.35μm technology.},
booktitle = {Proceedings of the 2006 Asia and South Pacific Design Automation Conference},
pages = {96–97},
numpages = {2},
location = {Yokohama, Japan},
series = {ASP-DAC '06}
}

@inproceedings{10.1145/3449726.3463185,
author = {Carvalho, Samuel and Sullivan, Joe and Dias, Douglas Mota and Naredo, Enrique and Ryan, Conor},
title = {Using Grammatical Evolution for Modelling Energy Consumption on a Computer Numerical Control Machine},
year = {2021},
isbn = {9781450383516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449726.3463185},
doi = {10.1145/3449726.3463185},
abstract = {Discrete manufacturing is known to be a high consumer of energy and much work has been done in continuous improvement and energy saving methods addressing this issue. Computer Numerical Control (CNC) machines, commonly used in the manufacturing of metal parts, are highly energy-demanding because of many required sub-systems, such as cooling, lubrication, logical interfaces and electric motors. For this reason, there is a large body of work focusing on modelling the energy needs of this class of machine.This paper applies Grammatical Evolution (GE) for developing auto-regressive models for the energy consumption of a CNC machine. Empirical data from three 24-hour work shifts comprising three different types of products are used as inputs. We also introduce an autocorrelation-informed approach for the grammar, which benefits from a prior analysis of the training data for better capturing periodic or close to periodic behaviour. Finally, we compare the outcomes from real and predicted energy profiles through the use of an existing analysis tool, which is capable of extracting production-related information such as total and average KW consumption, number of parts produced and breakdown of production and idle hours. Results show that GE yields accurate and explainable models for the analysed scenario.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1557–1563},
numpages = {7},
keywords = {grammatical evolution, real-world applications, energy consumption, CNC machines},
location = {Lille, France},
series = {GECCO '21}
}

@inproceedings{10.1145/2897937.2897974,
author = {Hong, Injoon and Clemons, Jason and Venkatesan, Rangharajan and Frosio, Iuri and Khailany, Brucek and Keckler, Stephen W.},
title = {A Real-Time Energy-Efficient Superpixel Hardware Accelerator for Mobile Computer Vision Applications},
year = {2016},
isbn = {9781450342360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897937.2897974},
doi = {10.1145/2897937.2897974},
abstract = {Superpixel generation is a common preprocessing step in vision processing aimed at dividing an image into non-overlapping regions. Simple Linear Iterative Clustering (SLIC) is a commonly used superpixel algorithm that offers a good balance between performance and accuracy. However, the algorithm's high computational and memory bandwidth requirements result in performance and energy efficiency that do not meet the requirements of real-time embedded applications. In this work, we explore the design of an energy-efficient superpixel accelerator for real-time computer vision applications. We propose a novel algorithm, Subsampled SLIC (S-SLIC), that uses pixel subsampling to reduce the memory bandwidth by 1.8\texttimes{}. We integrate S-SLIC into an energy-efficient superpixel accelerator and perform an in-depth design space exploration to optimize the design. We completed a detailed design in a 16nm FinFET technology using commercially-available EDA tools for high-level synthesis to map the design automatically from a C-based representation to a gate-level implementation. The proposed S-SLIC accelerator achieves real-time performance (30 frames per second) with 250\texttimes{} better energy efficiency than an optimized SLIC software implementation running on a mobile GPU.},
booktitle = {Proceedings of the 53rd Annual Design Automation Conference},
articleno = {95},
numpages = {6},
location = {Austin, Texas},
series = {DAC '16}
}

@inproceedings{10.1145/3422575.3422777,
author = {Adavally, Shashank and Gulur, Nagendra and Kavi, Krishna and Weaver, Alex and Dutta, Pranoy and Wang, Benjamin},
title = {ExPress: Simultaneously Achieving Storage, Execution and Energy Efficiencies in Moderately Sparse Matrix Computations},
year = {2021},
isbn = {9781450388993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422575.3422777},
doi = {10.1145/3422575.3422777},
abstract = {Sparse matrix computations have witnessed a resurgence with the pervasive use of deep neural networks. Leveraging sparsity enables efficiency of storage by avoiding storing zeroes. However, sparse representations incur metadata computational overheads – software needs to process the metadata (or indexe) that describes row/column locations of non-zero values before it can access the corresponding data values. There have been several formats proposed for representing sparse matrices including Compressed Sparse Row (CSR), Coordinate (COO), Bitmaps, Run-length encoding, &amp; hierarchical representations. Each representation achieves different levels of memory compression and incurs different levels of computational complexity depending on the sparsity (percentage of zero values). We seek answers to the following: (i) at what sparsity levels is it worth eliminating compressed representation of matrices and use the dense representation that includes both zeros and non-zero values, and (ii) even if we use compressed data representation, will it be useful to expand the matrices internally to eliminate metadata processing overheads? In this paper we propose the use of a special hardware called ExPress that expands compressed matrices into dense data, eliminating metadata computations from the main processing element. Our ExPress hardware is configurable so that it can expand from different compressed formats. Our experiments for matrix-vector multiplication using several DNN workloads show performance gains of 43%, 33% and 11% on average over software implementations that use CSR, Bitmap and Run-length encoding respectively. ExPress shows performance gains over sparse software codes for sparsity up to 70%. Further, ExPress simultaneously achieves energy improvement by reducing the instruction overhead of sparsity-aware computations.},
booktitle = {Proceedings of the International Symposium on Memory Systems},
pages = {46–60},
numpages = {15},
location = {Washington, DC, USA},
series = {MEMSYS '20}
}

@inproceedings{10.1145/3130265.3130318,
author = {Yokota, Minato and Saso, Kaoru and Hara-Azumi, Yuko},
title = {One-Instruction Set Computer-Based Multicore Processors for Energy-Efficient Streaming Data Processing},
year = {2017},
isbn = {9781450354189},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3130265.3130318},
doi = {10.1145/3130265.3130318},
abstract = {For architecture designs, flexibility of application-dependent optimization for better performance and energy-efficiency and productivity enhanced by application-independent versatility and reusability are both crucial but contradicting issues. In the IoT era, due to a more stringent energy constraint and more application diversity, such issues are becoming more difficult to satisfy. Even recent embedded processors prioritize the design-productivity over flexibility, leading to a lot of energy waste in unused resources for some applications. This paper proposes novel multicore processors to address the above two issues. Our processors are composed of application-independent tiny cores and application-dependent optimizable inter-core communications, which efficiently execute applications on a large amount of streaming data, in a pipeline manner. In this work, we utilize one of the simplest RISC processors, One-Instruction Set Computer (OISC), as a core. Our evaluation demonstrates that our processors outperform an existing RISC processor in terms of performance (throughput) and energy-efficiency, while having sufficient scalability, for two different types of applications.},
booktitle = {Proceedings of the 28th International Symposium on Rapid System Prototyping: Shortening the Path from Specification to Prototype},
pages = {71–77},
numpages = {7},
keywords = {one-instruction set computer, stream-data processing, OISC, multicore processor},
location = {Seoul, South Korea},
series = {RSP '17}
}

@inproceedings{10.1145/2669711.2669886,
author = {Roppestad, Robert and Fyhn, Per-Gunnar and Colomo-Palacios, Ricardo},
title = {A Test Bed for Smart Energy Education in the Field of Computer Engineering},
year = {2014},
isbn = {9781450328968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2669711.2669886},
doi = {10.1145/2669711.2669886},
abstract = {Smart energy settings are changing the way undergraduate and graduate programs are conceived in both civil and computer engineering fields. As a result of this, many universities around the world are beginning to offer courses on the topic. This paper presents the initiative that is taking place in the IT department of the \O{}stfold University College in the scope of the Computer Engineering bachelor studies. The initiative consists in a set of labs devoted to smart homes, smart buildings and smart cities designed to be bridge the gap between theory and practice on the field from the perspective of information technology education and more specifically from the prism of computer engineering. Results show a remarkable success of the initiative that is improving employability of students integrating them in companies in the area and serving also the overall objective of the institution, aligned with energy efficiency in education, research and practice.},
booktitle = {Proceedings of the Second International Conference on Technological Ecosystems for Enhancing Multiculturality},
pages = {101–105},
numpages = {5},
keywords = {smart grid, smart energy, smart homes, smart buildings, education, smart cities},
location = {Salamanca, Spain},
series = {TEEM '14}
}

@inproceedings{10.1145/3472883.3487009,
author = {Bashir, Noman and Guo, Tian and Hajiesmaili, Mohammad and Irwin, David and Shenoy, Prashant and Sitaraman, Ramesh and Souza, Abel and Wierman, Adam},
title = {Enabling Sustainable Clouds: The Case for Virtualizing the Energy System},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3487009},
doi = {10.1145/3472883.3487009},
abstract = {Cloud platforms' growing energy demand and carbon emissions are raising concern about their environmental sustainability. The current approach to enabling sustainable clouds focuses on improving energy-efficiency and purchasing carbon offsets. These approaches have limits: many cloud data centers already operate near peak efficiency, and carbon offsets cannot scale to near zero carbon where there is little carbon left to offset. Instead, enabling sustainable clouds will require applications to adapt to when and where unreliable low-carbon energy is available. Applications cannot do this today because their energy use and carbon emissions are not visible to them, as the energy system provides the rigid abstraction of a continuous, reliable energy supply. This vision paper instead advocates for a "carbon first" approach to cloud design that elevates carbon-efficiency to a firs--class metric. To do so, we argue that cloud platforms should virtualize the energy system by exposing visibility into, and software-defined control of, it to applications, enabling them to define their own abstractions for managing energy and carbon emissions based on their own requirements.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {350–358},
numpages = {9},
keywords = {cloud computing, edge, virtualization, Carbon-efficiency},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@inproceedings{10.1145/1163610.1163612,
author = {Cano, Juan-Carlos and Cano, Jos\'{e}-Manuel and Gonz\'{a}lez, Eva and Calafate, Carlos and Manzoni, Pietro},
title = {Evaluation of the Energetic Impact of Bluetooth Low-Power Modes for Ubiquitous Computing Applications},
year = {2006},
isbn = {1595934871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1163610.1163612},
doi = {10.1145/1163610.1163612},
abstract = {In order to further increase the applicability of Bluetooth in real applications, reducing the energy consumption and hardware cost are important research topics. In this paper we present a wireless communication prototype to support ubiquitous computing, which has been implemented based on commercial Bluetooth off-the-shelf components. It allows every object to be augmented with processing and communication capabilities in order to make them "smart". We investigate on the power characteristics of our Bluetooth prototype which supports the use of low-power modes providing helpful information for protocol developers and software designers. We assess if Bluetooth modules implementing low-power modes can significantly alleviate the power consumption of Bluetooth enabled devices. Our prototype has been used in a museum application to support spontaneous and ubiquitous connections between devices without requiring a priori knowledge of each other},
booktitle = {Proceedings of the 3rd ACM International Workshop on Performance Evaluation of Wireless Ad Hoc, Sensor and Ubiquitous Networks},
pages = {1–8},
numpages = {8},
keywords = {Bluetooth measurements, power consumption, ubiquitous computing, Bluetooth},
location = {Terromolinos, Spain},
series = {PE-WASUN '06}
}

@article{10.1145/3365999,
author = {Esmaili, Amirhossein and Nazemi, Mahdi and Pedram, Massoud},
title = {Energy-Aware Scheduling of Task Graphs with Imprecise Computations and End-to-End Deadlines},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {1084-4309},
url = {https://doi.org/10.1145/3365999},
doi = {10.1145/3365999},
abstract = {Imprecise computations allow scheduling algorithms developed for energy-constrained computing devices to trade off output quality with utilization of system resources. The goal of such scheduling algorithms is to utilize imprecise computations to find a feasible schedule for a given task graph while maximizing the quality of service (QoS) and satisfying a hard deadline and an energy bound. This work presents a heuristic for scheduling tasks with potentially imprecise computations, represented with directed acyclic graphs, on multiprocessor platforms. Furthermore, it presents a mixed integer linear program formulation of the same problem, which provides the optimal reference scheduling solutions, enabling evaluation of the efficacy of the proposed heuristic. Both the heuristic and mathematical program take account of potentially imprecise inputs of tasks on their output quality. Furthermore, the presented heuristic is capable of finding feasible schedules even under tight energy budgets. Through extensive experiments, it is shown that in some cases, the proposed heuristic is capable of finding the same QoS as the ones found by MILP. Furthermore, for those task graphs that MILP outperforms the proposed heuristic, QoS values obtained with the proposed heuristic are, on average, within 1.24% of the optimal solutions while improving the runtime by a factor of 100 or so. This clearly demonstrates the advantage of the proposed heuristic over the exact solution, especially for large task graphs where solving the mathematical problem is hampered by its lengthy runtime.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {nov},
articleno = {11},
numpages = {21},
keywords = {imprecise computations, input error, real-time MPSoCs, Task scheduling}
}

@inproceedings{10.1145/3297280.3297646,
author = {Din, Sadia},
title = {Human-Enabled Sustainable Management of Mobile Cloud on 5G Network: Student Research Abstract},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297646},
doi = {10.1145/3297280.3297646},
abstract = {This paper presents a hierarchical system architecture for Mobile Cloud Computing based on a novel 5G system architecture. Initially, a hierarchical system architecture is divided into three phases, i.e., foglet layer, service layer, and communication layer. Foglet layers provide the functionality of efficient resource sharing, the service layers assist the network by providing cloud services, and finally, the communication layers help in providing energy efficient communication using 5G system architecture. Simulation results show that the proposed scheme outperforms the existing cloud computing example scenario regarding cost and time.1},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {726–727},
numpages = {2},
keywords = {service layer, foglet, cloud computing foglet layer, MCC},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@proceedings{10.1145/2939940,
title = {RSES '16: Proceedings of the Workshop on Communications, Computation and Control for Resilient Smart Energy Systems},
year = {2016},
isbn = {9781450344180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Waterloo, Ontario, Canada}
}

@inproceedings{10.5555/1035053.1035090,
author = {Winschiers, Heike and Paterson, Barbara},
title = {Sustainable Software Development},
year = {2004},
publisher = {South African Institute for Computer Scientists and Information Technologists},
address = {ZAF},
abstract = {Information and Communication Technology (ICT) transfer to so-called developing countries has failed to fulfil its promises. In order to harvest the benefits of ICT, the potential for local software development must be enhanced. Considering the resource constraints, Namibia and other African countries should strive for sustainable software development. This, however, can only be achieved through a cultural appropriation of the software development process itself, meaning that methods, concepts and project goals need to be redefined within the local context. Here we use a usability evaluation case study to demonstrate how Namibian cultural variances should be considered in such a process. Once software modules have been evaluated locally, re-use and community appropriation should be promoted to foster sustainability.},
booktitle = {Proceedings of the 2004 Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT Research in Developing Countries},
pages = {274–278},
numpages = {5},
keywords = {cross-cultural design, cultural appropriation, design, usability testing, human factors, sustainable software},
location = {Stellenbosch, Western Cape, South Africa},
series = {SAICSIT '04}
}

@inproceedings{10.1145/3447555.3466571,
author = {Meisenbacher, Stefan and Schwenk, Karl and Galenzowski, Johannes and Waczowicz, Simon and Mikut, Ralf and Hagenmeyer, Veit},
title = {Smart Charging of Electric Vehicles with Cloud-Based Optimization and a Lightweight User Interface: A Real-World Application in the Energy Lab 2.0: Poster},
year = {2021},
isbn = {9781450383332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447555.3466571},
doi = {10.1145/3447555.3466571},
abstract = {Smart Charging (SC) of Electric Vehicles (EVs) integrates them into the power system to support grid stability by power management. Large-scale adoption of SC requires a high level of EV user acceptance. Therefore, it is imperative to make the underlying charging scheme tangible for the user. We propose a web app for the user to start, adjust and monitor the charging process via a User Interface (UI). We outline the integration of this web app into an Internet of Things (IoT) architecture to establish communication with the charging station. Two scenarios demonstrate the operation of the system. Future field studies on SC should involve the EV user due to individual preferences and responses to incentive schemes. Therefore, we propose the Smart Charging Wizard with a customizable UI and optimization module for future research and collaborative development.},
booktitle = {Proceedings of the Twelfth ACM International Conference on Future Energy Systems},
pages = {284–285},
numpages = {2},
keywords = {Smart Charging, Web Applications, Battery Aging, Electric Vehicles},
location = {Virtual Event, Italy},
series = {e-Energy '21}
}

@article{10.1145/3477009,
author = {Qiu, Keni and Jao, Nicholas and Zhou, Kunyu and Liu, Yongpan and Sampson, Jack and Kandemir, Mahmut Taylan and Narayanan, Vijaykrishnan},
title = {MaxTracker: Continuously Tracking the Maximum Computation Progress for Energy Harvesting ReRAM-Based CNN Accelerators},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3477009},
doi = {10.1145/3477009},
abstract = {There is an ongoing trend to increasingly offload inference tasks, such as CNNs, to edge devices in many IoT scenarios. As energy harvesting is an attractive IoT power source, recent ReRAM-based CNN accelerators have been designed for operation on harvested energy. When addressing the instability problems of harvested energy, prior optimization techniques often assume that the load is fixed, overlooking the close interactions among input power, computational load, and circuit efficiency, or adapt the dynamic load to match the just-in-time incoming power under a simple harvesting architecture with no intermediate energy storage.Targeting a more efficient harvesting architecture equipped with both energy storage and energy delivery modules, this paper is the first effort to target whole system, end-to-end efficiency for an energy harvesting ReRAM-based accelerator. First, we model the relationships among ReRAM load power, DC-DC converter efficiency, and power failure overhead. Then, a maximum computation progress tracking scheme (MaxTracker) is proposed to achieve a joint optimization of the whole system by tuning the load power of the ReRAM-based accelerator. Specifically, MaxTracker accommodates both continuous and intermittent computing schemes and provides dynamic ReRAM load according to harvesting scenarios.We evaluate MaxTracker over four input power scenarios, and the experimental results show average speedups of 38.4%/40.3% (up to 51.3%/84.4%), over a full activation scheme (with energy storage) and order-of-magnitude speedups over the recently proposed (energy storage-less) ResiRCA technique. Furthermore, we also explore MaxTracker in combination with the Capybara reconfigurable capacitor approach to offer more flexible tuners and thus further boost the system performance.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {sep},
articleno = {78},
numpages = {23},
keywords = {DC-DC efficiency, maximum computation progress, Energy harvesting, ReRAM crossbar, CNN, computing schemes}
}

@inproceedings{10.1109/E2SC.2014.14,
author = {Oden, Lena and Klenk, Benjamin and Fr\"{o}ning, Holger},
title = {Energy-Efficient Stencil Computations on Distributed GPUs Using Dynamic Parallelism and GPU-Controlled Communication},
year = {2014},
isbn = {9781479970360},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/E2SC.2014.14},
doi = {10.1109/E2SC.2014.14},
abstract = {GPUs are widely used in high performance computing, due to their high computational power and high performance per Watt. Still, one of the main bottlenecks of GPU-accelerated cluster computing is the data transfer between distributed GPUs. This not only affects performance, but also power consumption. The most common way to utilize a GPU cluster is a hybrid model, in which the GPU is used to accelerate the computation while the CPU is responsible for the communication. This approach always requires a dedicated CPU thread, which consumes additional CPU cycles and therefore increases the power consumption of the complete application.In recent work we have shown that the GPU is able to control the communication independently of the CPU. Still, there are several problems with GPU-controlled communication. The main problem is intra-GPU synchronization, since GPU blocks are non-preemptive. Therefore, the use of communication requests within a GPU can easily result in a deadlock. In this work we show how Dynamic Parallelism solves this problem. GPU-controlled communication in combination with Dynamic Parallelism allows keeping the control flow of multi-GPU applications on the GPU and bypassing the CPU completely. Although the performance of applications using GPU-controlled communication is still slightly worse than the performance of hybrid applications, we will show that performance per Watt increases by up to 10% while still using commodity hardware.},
booktitle = {Proceedings of the 2nd International Workshop on Energy Efficient Supercomputing},
pages = {31–40},
numpages = {10},
keywords = {dynamic parallelism, data transfer, communication, GPUs, infiniband, energy efficient},
location = {New Orleans, Louisiana},
series = {E2SC '14}
}

@inproceedings{10.1145/2950290.2983983,
author = {Robillard, Martin P.},
title = {Sustainable Software Design},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2983983},
doi = {10.1145/2950290.2983983},
abstract = {Although design plays a central role in software development, the information produced in this activity is often left to progressively evaporate as the result of software evolution, loss of artifacts, or the fading of related knowledge held by the development team. This paper introduces the concept of sustainability for software design, and calls for its integration into the existing catalog of design quality attributes. Applied to software design, sustainability conveys the idea that a particular set of design decisions and their rationale can be succinctly reflected in the host technology and/or described in documentation in a way that is checkable for conformance with the code and generally resistant to evaporation. The paper discusses the relation between sustainability and existing research areas in software engineering, and highlights future research challenges related to sustainable software design.},
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {920–923},
numpages = {4},
keywords = {Software Design, Software Evolution},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/3503161.3548319,
author = {Jaya, Iryanto and Li, Yusen and Cai, Wentong},
title = {Improving Scalability, Sustainability and Availability via Workload Distribution in Edge-Cloud Gaming},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548319},
doi = {10.1145/3503161.3548319},
abstract = {Recent uses of heterogeneous mobile and lightweight devices encourage computations to be abstracted remotely as black box systems. This same concept applies for cloud gaming in which computer games are located and run inside remote rendering servers (RSes). While cloud gaming enables lightweight devices with sufficient input capabilities and network connection to be able to play desktop games, latency and cost issue become significant hindrances in recent applications. In this paper, we came up with our edge-cloud gaming architecture which reduces the overall workload in RSes while increasing playerbase coverage by using edge RSes. Furthermore, we also proposed our allocation algorithm in order to assign incoming players to RSes. From our experiments, our proposed architecture has higher playerbase coverage while our allocation algorithm significantly reduces the cost in both single and batch player arrival pattern.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {2987–2995},
numpages = {9},
keywords = {workload splitting, cost minimization, workload sharing, cloud gaming},
location = {Lisboa, Portugal},
series = {MM '22}
}

@article{10.1145/3528223.3530070,
author = {Wang, Yujie and Chakravarthula, Praneeth and Sun, Qi and Chen, Baoquan},
title = {Joint Neural Phase Retrieval and Compression for Energy- and Computation-Efficient Holography on the Edge},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3528223.3530070},
doi = {10.1145/3528223.3530070},
abstract = {Recent deep learning approaches have shown remarkable promise to enable high fidelity holographic displays. However, lightweight wearable display devices cannot afford the computation demand and energy consumption for hologram generation due to the limited onboard compute capability and battery life. On the other hand, if the computation is conducted entirely remotely on a cloud server, transmitting lossless hologram data is not only challenging but also result in prohibitively high latency and storage.In this work, by distributing the computation and optimizing the transmission, we propose the first framework that jointly generates and compresses high-quality phase-only holograms. Specifically, our framework asymmetrically separates the hologram generation process into high-compute remote encoding (on the server), and low-compute decoding (on the edge) stages. Our encoding enables light weight latent space data, thus faster and efficient transmission to the edge device. With our framework, we observed a reduction of 76% computation and consequently 83% in energy cost on edge devices, compared to the existing hologram generation methods. Our framework is robust to transmission and decoding errors, and approach high image fidelity for as low as 2 bits-per-pixel, and further reduced average bit-rates and decoding time for holographic videos.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {110},
numpages = {16},
keywords = {computer generated holography, neural hologram generation, hologram compression}
}

@inproceedings{10.1145/3531056.3542767,
author = {Zhou, Minghui},
title = {Open Source Software Digital Sociology: Engineering Open Source Software Ecosystem for Impact and Sustainability},
year = {2022},
isbn = {9781450396639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531056.3542767},
doi = {10.1145/3531056.3542767},
abstract = {Open source Software (OSS) ecosystems have had a tremendous impact on computing and society, while their sustainability poses great challenges to both practitioners and researchers. We utilize vast collections of open data produced by distributed version control and social media to discover the mechanisms by which such ecosystems form and operate, which we call open source software sociology.},
booktitle = {Proceedings of the Federated Africa and Middle East Conference on Software Engineering},
pages = {95–96},
numpages = {2},
keywords = {software supply chain, group collaboration, Open source ecosystem, individual learning},
location = {Cairo-Kampala, Egypt},
series = {FAMECSE '22}
}

@inproceedings{10.1145/3577065.3577098,
author = {Li, Donghao and Zhang, Chao and Zhang, Linuo and Dong, Bin},
title = {Energy-Saving Computer Room Monitoring Method Based on Mixed Deployment of Video and CSI Monitoring},
year = {2023},
isbn = {9781450397797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577065.3577098},
doi = {10.1145/3577065.3577098},
abstract = {The security system is a vital part of the telecommunications room. At present, video monitoring is still the major monitoring method of the telecommunications room. The power consumption of the monitoring equipment and the resource consumption of video uploading to the cloud and continuous image recognition algorithms are high since the video monitoring system needs to run 24 hours a day. This paper proposes a hybrid deployment energy-saving computer room monitoring method, that is, under the background of the existing video monitoring system of the telecommunications room, without adding new equipment, design a two-layer structure energy-saving CSI location identification algorithm and mixed deployment with image recognition algorithms for telecom room monitoring. The method realizes energy saving, emission reduction and monitoring quality improvement without adding new equipment.},
booktitle = {Proceedings of the 2022 5th International Conference on Telecommunications and Communication Engineering},
pages = {181–185},
numpages = {5},
keywords = {Video monitoring, Telecommunications room monitoring, Energy saving, CSI},
location = {Chengdu, China},
series = {ICTCE '22}
}

@inproceedings{10.1145/2145694.2145757,
author = {Lin, Colin Yu and Wong, Ngai and So, Hayden Kwok-Hay},
title = {Operation Scheduling and Architecture Co-Synthesis for Energy-Efficient Dataflow Computations on FPGAs (Abstract Only)},
year = {2012},
isbn = {9781450311557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2145694.2145757},
doi = {10.1145/2145694.2145757},
abstract = {Compiling high-level user applications for execution on FPGAs often involves synthesizing dataflow graphs beyond the size of the available on-chip computational resources. One way to address this is by folding the execution of the given dataflow graphs onto an array of directly connected simple configurable processing elements (CPEs). Under this scenario, the performance and energy-efficiency of the resulting system depends not only on the mapping schedule of the compute operations on the CPEs, but also on the topology of the interconnect array that connects the CPEs. This paper presents a framework in which the operation scheduler and the underlying CPE interconnect network topology are co-optimized on a per-application basis for energy-efficient FPGA computation. Given the same application, more than 2.5x difference in energy-efficiency was achievable by the use of different common regular array topologies to connect the CPEs. Moreover, by using irregular application-specific interconnect topologies derived from a genetic algorithm, up to 50% improvement in energy-delay-product was achievable when compared to the use of even the best regular topology. The use of such framework is anticipated to serve as part of a rapid high-level FPGA application compiler since minimum hardware place-and-route is needed to generate the optimal schedule and topology.},
booktitle = {Proceedings of the ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
pages = {270},
numpages = {1},
keywords = {energy-efficient, architecture synthesis, fpga, dataflow computation, operation scheduling},
location = {Monterey, California, USA},
series = {FPGA '12}
}

@proceedings{10.1145/3524614,
title = {IWSiB '22: Proceedings of the 5th International Workshop on Software-Intensive Business: Towards Sustainable Software Business},
year = {2022},
isbn = {9781450393027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {There are many researchers and practitioners whose work is related to the field of software-intensive business. However, they are often not fully aware of each other's work as the research is scattered. For example, individual research contributions have emerged related to, for example, software engineering economics, digital ecosystems and software startups. The goal of the workshop on Software-intensive Business is to bring these different sub-fields together and strengthen their ties.},
location = {Pittsburgh, Pennsylvania}
}

@inproceedings{10.5555/1356802.1356912,
author = {Yu, Heng and Veeravalli, Bharadwaj and Ha, Yajun},
title = {Dynamic Scheduling of Imprecise-Computation Tasks in Maximizing QoS under Energy Constraints for Embedded Systems},
year = {2008},
isbn = {9781424419227},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
abstract = {In designing energy-aware CPU scheduling algorithms for real-time embedded systems, dynamic slack reclamation techniques significantly improve system Quality-of-Service (QoS) and energy efficiency. However, the limited schemes in this domain either demand high complexity or can only achieve limited QoS. In this paper, we present a novel low complexity runtime scheduling algorithm for the Imprecise Computation (IC) modeled tasks. The target is to maximize system QoS under energy constraints. Our proposed algorithm, named Gradient Curve Shifting (GCS), is able to decide the best allocation of slack cycles arising at runtime, with very low complexity. We study both linear and concave QoS functions associated with IC modelde tasks, on non-DVS and DVS processors. Furthermore, we apply the intra-task DVS technique to tasks and achieve as large as 18% more of the system QoS compared to the conventional "optimal" solution which is inter-task DVS based.},
booktitle = {Proceedings of the 2008 Asia and South Pacific Design Automation Conference},
pages = {452–455},
numpages = {4},
location = {Seoul, Korea},
series = {ASP-DAC '08}
}

@inproceedings{10.1145/3194747.3194753,
author = {Haupt, Carina and Schlauch, Tobias and Meinel, Michael},
title = {The Software Engineering Initiative of DLR: Overcome the Obstacles and Develop Sustainable Software},
year = {2018},
isbn = {9781450357487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194747.3194753},
doi = {10.1145/3194747.3194753},
abstract = {Software is a vital part of modern research. The competence to develop sustainable software becomes increasingly important for research organizations. The DLR - a large research organization in Germany - has set up a software engineering initiative to address typical obstacles in this regard such as missing long-term funding, lack of incentives, or missing knowledge about essential software development practices. In this paper, we describe the concept and activities of the initiative as well as discuss the impact of these activities on the identified obstacles.},
booktitle = {Proceedings of the International Workshop on Software Engineering for Science},
pages = {16–19},
numpages = {4},
keywords = {obstacles, maintenance, research software engineering, community},
location = {Gothenburg, Sweden},
series = {SE4Science '18}
}

@inproceedings{10.5555/2663779.2663782,
author = {Gu, Yan and March, Verdi and Lee, Bu Sung},
title = {GMoCA: Green Mobile Cloud Applications},
year = {2012},
isbn = {9781467318327},
publisher = {IEEE Press},
abstract = {Mobile cloud computing enables numerous associated mobile users to access the abundant cloud computing resources, thereby complements the resource constrain of mobile devices. A fundamental issue in the mobile application platform is to make deployment decision for individual tasks when the battery life of the mobile device is a major concern for the mobile user's experience. We propose a deployment scheme to offload expensive computational tasks from thin, mobile devices to powered, powerful devices on the cloud so that we could prolong battery life for mobile devices, meanwhile provide rich user experiences for such mobile applications. We envision that the scheme can be extended to other type of smart devices such as smart printers, smart TVs or sensors where offloading tasks is required to trade-off between performance and battery life.},
booktitle = {Proceedings of the First International Workshop on Green and Sustainable Software},
pages = {15–20},
numpages = {6},
keywords = {energy, cost function, cloud computing, mobile computing},
location = {Zurich, Switzerland},
series = {GREENS '12}
}

@inproceedings{10.1145/3325480.3325481,
author = {Sturdee, Miriam and Mann, Samuel and Carpendale, Sheelagh},
title = {Sketching Sustainability in Computing},
year = {2019},
isbn = {9781450359177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325480.3325481},
doi = {10.1145/3325480.3325481},
abstract = {We investigate engaging a computer science conference audience in sketching responses to the event as it occurs. In particular, we explore the response to inviting those present to engage in what is essentially an off-line, co-located, attendee-sourcing experience. Sketchnoting is a popular practice for documenting events, but these sketched records can be limited in scope at multi-track conferences, and paid professionals can be unaffordable at smaller events. Our challenges included: working with an audience with little or no experience of sketching or working with imagery; who were unaware of the possible benefits; and whose attendee engagement was variable - with individuals often working on laptops rather than actively listening during sessions. In order encourage engagement we hosted a pre-conference workshop, developed a conference-specific set of visual icons, and created prompt materials. This resulted in a remarkable visual record of the event, and also an increase in active listening and engagement.},
booktitle = {Proceedings of the 2019 Conference on Creativity and Cognition},
pages = {29–40},
numpages = {12},
keywords = {sketchnotes, sustainability, attendee-sourcing, graphic recording, visual facilitation},
location = {San Diego, CA, USA},
series = {C&amp;C '19}
}

@inproceedings{10.1145/2554688.2554733,
author = {Wang, Zhibin and Yang, Wenmin and Yu, Jin and Chai, Zhilei},
title = {Implementing FPGA-Based Energy-Efficient Dense Optical Flow Computation with High Portability in C (Abstract Only)},
year = {2014},
isbn = {9781450326711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554688.2554733},
doi = {10.1145/2554688.2554733},
abstract = {Optical flow computation is widely used in many video/image based applications such as motion detection, video compression etc. Dense optical flow field that provides more details of information is more useful in lots of applications. However, high-quality algorithms for dense optical flow computation are computationally expensive. For instance, on the ARM Cortex-A9 processor within ZYNQ, the popular linear variational method Combine-Brightness-Gradient (CBG), spends $26.68s per frame to compute optical flow when the image size is 640 x 480. It is difficult to be sped up especially when embedded systems with power constraints are considered. Poor portability is another factor to limit current implementations of optical flow computation to be used in more applications. In this paper, a high-performance, low-power FPGA-accelerated implementation of dense optical flow computation is presented. One high-quality dense optical flow method, the Combine-Brightness-Gradient model, is implemented. C code instead of VHDL/Verilog HDL is used to improve the productivity. Portability of the system is designed carefully for deploying it on different platforms conveniently. Experimental results show 12 fps and 0.38J per frame are achieved by this optical flow computing system when 640 x 480 image is used and optical flow for all pixels are computed. Furthermore, portability is demonstrated by implementing the optical flow algorithm on different heterogeneous platforms such as the ZYNQ-7000 SoC and the PC-FPGA platform with a Kintex-7 FPGA respectively.},
booktitle = {Proceedings of the 2014 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {255},
numpages = {1},
keywords = {fpgas, optical flow computation, portability, energy efficient, high-level-synthesis},
location = {Monterey, California, USA},
series = {FPGA '14}
}

@inproceedings{10.1145/3463274.3463346,
author = {Lammert, Dominic},
title = {The Connection between the Sustainability Impacts of Software Products and the Role of Software Engineers},
year = {2021},
isbn = {9781450390538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463274.3463346},
doi = {10.1145/3463274.3463346},
abstract = {Context: It is impossible to imagine our everyday and professional lives without software. Consequently, software products, especially socio-technical systems, have more or less obvious impacts on almost all areas of our society. For this purpose, a group of scientists worldwide has developed the Sustainability Awareness Framework (SusAF) which examines the impacts on five interrelated dimensions: social, individual, environmental, economic, and technical. According to this framework, we should design software to maintain or improve the Sustainability Impacts. Designing for sustainability is a major challenge that can profoundly change the field of activity – particular for Software Engineers. Objectives: The aim of the thesis work is to analyze the current role of Software Engineers and relate it to Sustainability Impacts of Software Products in order to contribute to this paradigm shift. This should provide a basis for follow-up works. The question in which direction exactly the Software Engineer should develop and how exactly this path can be followed is still owed by the scientific community. Perhaps universities will have to adapt the curriculum in the training of Software Engineers, politics could possibly initiate support programs in the field of sustainability for software companies, or maybe software sustainability certifications could emerge. In any case, Software Engineers must adapt to the times and acquire the necessary knowledge, the skills and the competencies. Results: The results of the dissertation are a better understanding of the needed paradigm shift of Software Engineers and complement the SusAF that to better support sustainability design. The extended SusAF is intended for both training and corporate use.},
booktitle = {Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering},
pages = {294–299},
numpages = {6},
keywords = {Sustainability Design, Software Engineering, Role understanding, SusAF, Sustainability},
location = {Trondheim, Norway},
series = {EASE '21}
}

@article{10.1145/1473195.1473241,
author = {Mann, Samuel and Smith, Lesley and Muller, Logan},
title = {Computing Education for Sustainability},
year = {2008},
issue_date = {December 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0097-8418},
url = {https://doi.org/10.1145/1473195.1473241},
doi = {10.1145/1473195.1473241},
abstract = {This paper presents policy on Computing Education for Sustainability for adoption by SIGCSE. The paper describes results from a survey of Computing Educators who attended ITiCSE 2008 where such a policy statement was mooted. This survey also provides a comparison of understandings of sustainability held by those computing educators against recognized benchmarks. From these findings and understandings an action plan to integrate Education for Sustainability into computing education is proposed.},
journal = {SIGCSE Bull.},
month = {nov},
pages = {183–193},
numpages = {11},
keywords = {practitioner, sustainability, education, teaching philosophy}
}

@article{10.1145/270439.270443,
author = {Koshelev, Misha and Starks, Scott},
title = {Energy from Space: A New Potential Application of Interval Computations},
year = {1997},
issue_date = {July 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {0163-5778},
url = {https://doi.org/10.1145/270439.270443},
doi = {10.1145/270439.270443},
abstract = {The sun is a practically limitless source of energy. In some areas, solar cells enable us to use this source. In many places on Earth, however, clouds prevent us from tapping into solar energy. To use this energy, researchers have proposed placing solar cells on a satellite and beaming the collected energy down to the Earth.The problem with this solution is that the resulting high-energy beam is highly dangerous. Instead of using a single beam, we propose to use several beams from different satellites; this configuration will enable us to beam the energy to practically any location on Earth without endangering other locations. Since errors can be extremely dangerous, we need verified computations (i.e., interval computations) to compute the parameters of the beams. Thus, interval computations are useful for transmitting energy from space.},
journal = {SIGNUM Newsl.},
month = {jul},
pages = {9–13},
numpages = {5}
}

@article{10.1145/1709424.1709459,
author = {Mann, Samuel and Muller, Logan and Davis, Janet and Roda, Claudia and Young, Alison},
title = {Computing and Sustainability: Evaluating Resources for Educators},
year = {2010},
issue_date = {December 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0097-8418},
url = {https://doi.org/10.1145/1709424.1709459},
doi = {10.1145/1709424.1709459},
abstract = {Computing has a significant impact on sustainable outcomes and computing education for sustainability has previously been identified as an important goal. This paper aims to address a barrier to the integration of sustainability into computing teaching -- that of a perceived paucity of resources. The "framework" (Computing Education for Sustainability, CE4S) is developed that could be used by educators to access resources for the integration of sustainability in the computing curriculum.},
journal = {SIGCSE Bull.},
month = {jan},
pages = {144–155},
numpages = {12},
keywords = {education computing, sustainability, teaching philosophy, practitioner}
}

@inproceedings{10.1145/3325917.3325936,
author = {Soini, Charles T. and Fellah, Sofiane and Abid, Muhammad Rizwan},
title = {Citrus Greening Infection Detection (CiGID) by Computer Vision and Deep Learning},
year = {2019},
isbn = {9781450366359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325917.3325936},
doi = {10.1145/3325917.3325936},
abstract = {The citrus greening infection detection algorithm is performed via computer vision techniques and deep learning for the purpose of extracting sub-images of fruit from a tree image and using a trained machine learning function to determine if the fruit shows signs of a citrus greening infection disease called Huanglongbing. We trained our deep learning inception model with 4000 iterations and achieved validation accuracy 93.3%. The computer vision fruit sub-image extraction resulted in at worst around 80% accuracy in tree images and was manually calibrated to detect a specific range of orange color values.},
booktitle = {Proceedings of the 2019 3rd International Conference on Information System and Data Mining},
pages = {21–26},
numpages = {6},
keywords = {Psyllids, Contouring, Inception, Huanglongbing, Candidatus Liberibacter, Greening},
location = {Houston, TX, USA},
series = {ICISDM 2019}
}

@inproceedings{10.1145/3061639.3062228,
author = {Ko, Jong Hwan and Mudassar, Burhan and Na, Taesik and Mukhopadhyay, Saibal},
title = {Design of an Energy-Efficient Accelerator for Training of Convolutional Neural Networks Using Frequency-Domain Computation},
year = {2017},
isbn = {9781450349277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3061639.3062228},
doi = {10.1145/3061639.3062228},
abstract = {Convolutional neural networks (CNNs) require high computation and memory demand for training. This paper presents the design of a frequency-domain accelerator for energy-efficient CNN training. With Fourier representations of parameters, we replace convolutions with simpler pointwise multiplications. To eliminate the Fourier transforms at every layer, we train the network entirely in the frequency domain using approximate frequency-domain nonlinear operations. We further reduce computation and memory requirements using sinc interpolation and Hermitian symmetry. The accelerator is designed and synthesized in 28nm CMOS, as well as prototyped in an FPGA. The simulation results show that the proposed accelerator significantly reduces training time and energy for a target recognition accuracy.},
booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},
articleno = {59},
numpages = {6},
keywords = {convolutional neural network (CNN), training, frequency domain},
location = {Austin, TX, USA},
series = {DAC '17}
}

@inproceedings{10.1145/120694.120770,
author = {Vinette, F.},
title = {Features of Symbolic Computation Exploited in the Calculation of Lower Energy Bounds of Cyclic Polyene Models},
year = {1991},
isbn = {0897914376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/120694.120770},
doi = {10.1145/120694.120770},
booktitle = {Proceedings of the 1991 International Symposium on Symbolic and Algebraic Computation},
pages = {458–459},
numpages = {2},
location = {Bonn, West Germany},
series = {ISSAC '91}
}

@inproceedings{10.1145/3447555.3466569,
author = {Dubara, Himanshu V. and Parihar, Mahesh and Ramamritham, Krithi},
title = {Smart Energy Meter Calibration: An Edge Computation Method: Poster},
year = {2021},
isbn = {9781450383332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447555.3466569},
doi = {10.1145/3447555.3466569},
abstract = {Smart meters are the backbone of smart grids. They provide real time electricity consumption data and and are widely used for measuring, monitoring and analyzing energy consumption. Sometimes, they enable users to perform corrective actions. But, to facilitate proper data analysis, it is imperative that data be accurate or have minimum error. This paper presents an edge deployed smart meter error correction algorithm that utilises Clustering (using K-Means algorithm) and Feed-Forward Artificial Neural Networks (ANN). An edge device, a Raspberry Pi Module, connects smart meters to the internet. The algorithm maps (possibly erroneous) readings of our in-house developed meters to readings of calibrated standard off-the-shelf (Schneider) meters. Usage of Clustering with ANN has helped substantially improve the accuracy of the readings from a previously used linear regression designed for the same purpose. An accuracy of 70-75% was achieved while using linear regression, whereas the proposed algorithm obtains accuracy in the range of 84.47-88%. The neural networks are also less complex, making them suitable for deployment in Raspberry Pi 3B based embedded hardware systems.},
booktitle = {Proceedings of the Twelfth ACM International Conference on Future Energy Systems},
pages = {280–281},
numpages = {2},
keywords = {Error Correction, Neural Networks, Regression, Calibration},
location = {Virtual Event, Italy},
series = {e-Energy '21}
}

@article{10.1145/3591466,
author = {Lu, Qianyun and Murmann, Boris},
title = {Enhancing the Energy Efficiency and Robustness of TinyML Computer Vision Using Coarsely-Quantized Log-Gradient Input Images},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1539-9087},
url = {https://doi.org/10.1145/3591466},
doi = {10.1145/3591466},
abstract = {This paper studies the merits of applying log-gradient input images to convolutional neural networks (CNNs) for tinyML computer vision (CV). We show that log gradients enable: (i) aggressive 1-bit quantization of first-layer inputs, (ii) potential CNN resource reductions, (iii) inherent insensitivity to illumination changes (1.7% accuracy loss across 2− 5⋅⋅⋅23 brightness variation vs. up to 10% for JPEG), and (iv) robustness to adversarial attacks (&gt;10% higher accuracy than JPEG-trained models). We establish these results using the PASCAL RAW image data set and through a combination of experiments using quantization threshold search, neural architecture search, and a fixed three-layer network. The latter reveal that training on log-gradient images leads to higher filter similarity, making the CNN more prunable. The combined benefits of aggressive first-layer quantization, CNN resource reductions, and operation without tight exposure control and image signal processing (ISP) are helpful for pushing tinyML CV toward its ultimate efficiency limits.},
note = {Just Accepted},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {apr},
keywords = {illumination invariance, filter similarity, quantization threshold search, neural network quantization, log gradients, image signal processing, sensor datasets, computer vision pipeline, Adversarial examples}
}

@inproceedings{10.1145/3195970.3196044,
author = {Bai, Kangjun and Li, Jialing and Hamedani, Kian and Yi, Yang},
title = {Enabling a New Era of Brain-Inspired Computing: Energy-Efficient Spiking Neural Network with Ring Topology},
year = {2018},
isbn = {9781450357005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195970.3196044},
doi = {10.1145/3195970.3196044},
abstract = {The reservoir computing, an emerging computing paradigm, has proven its benefit to multifarious applications. In this work, we successfully designed and fabricated an analog delayed feedback reservoir (DFR) chip. Measurement results demonstrate its rich dynamic behaviors and high energy efficiency. System performance, as well as the robustness, are evaluated. The application of video frame recognition is investigated using a hybrid neural network, which employs the multilayer perceptron (MLP) training model as the readout layer of our designed DFR system, and yields 98% classification accuracy. Compared to results of using the MLP training only, our hybrid training model exhibits much higher recognition rate and accuracy.},
booktitle = {Proceedings of the 55th Annual Design Automation Conference},
articleno = {166},
numpages = {6},
keywords = {delayed feedback reservoir, spiking neuromorphic computing, edge of chaos, video frame recognition},
location = {San Francisco, California},
series = {DAC '18}
}

@inproceedings{10.1145/2846661.2846675,
author = {Abadi, Aharon and Flynn, Lori and Gray, Jeff and Gordon, Aaron},
title = {Mobile Computing to Support Sustainability},
year = {2015},
isbn = {9781450339063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2846661.2846675},
doi = {10.1145/2846661.2846675},
abstract = {This report documents the Mobile Sustainability activity that was facilitated at the end of the Workshop on Mobile Development Lifecycle (MobileDeLi), in conjunction with SPLASH 2015. The workshop attendees were presented with several discussion questions and were charged with the task of listing the challenges in Mobile Sustainability. Participants were asked to outline a research agenda that could address the core challenges.},
booktitle = {Proceedings of the 3rd International Workshop on Mobile Development Lifecycle},
pages = {54–57},
numpages = {4},
keywords = {Mobile devices, App Development},
location = {Pittsburgh, PA, USA},
series = {MobileDeLi 2015}
}

@article{10.1145/3559163,
author = {Chien, Andrew A.},
title = {Computing's Grand Challenge for Sustainability},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {65},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/3559163},
doi = {10.1145/3559163},
journal = {Commun. ACM},
month = {sep},
pages = {5},
numpages = {1}
}

@inproceedings{10.5555/800166.805323,
author = {Glass, Norman R.},
title = {Use of a Computer Model to Determine Energy Requirements of a Predatory Fish, the Largemouth Black Bass (Micropterus Salmoides)},
year = {1968},
publisher = {Winter Simulation Conference},
abstract = {In some types of biological research the techniques of engineering and other applied sciences have figured prominently in many significant advances made during the last ten years. Such analytical methods as simulation studies, optimization techniques, dynamic programming, and others have opened whole new theoretical and mission-oriented capabilities in many areas of investigation. The analysis of energy flow in both individual animals and populations of animals has been one field of ecological research that has developed rapidly, and one which will continue to enlarge in scope in the future. However, modern numerical techniques are not solely responsible for advances in energetics analysis. Rather, progress has been due to the conceptual framework for study that has developed from principles and considerations underlying theory in many seemingly diverse disciplines. At first glance, such areas of endeavor as urban transit system design, land and resource management strategies, urban planning, and economic theory do not appear to be too closely related. However, all of these activities along with the study of energetics in ecological systems have in common the analysis and optimization of energy flow.},
booktitle = {Proceedings of the Second Conference on Applications of Simulations},
pages = {333–336},
numpages = {4},
location = {New York, New York, USA}
}

@inproceedings{10.5555/2337223.2337491,
author = {Serrano Zanetti, Marcelo},
title = {The Co-Evolution of Socio-Technical Structures in Sustainable Software Development: Lessons from the Open Source Software Communities},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {Software development depends on many factors, including technical, human and social aspects. Due to the complexity of this dependence, a unifying framework must be defined and for this purpose we adopt the complex networks methodology. We use a data-driven approach based on a large collection of open source software projects extracted from online project development platforms. The preliminary results presented in this article reveal that the network perspective yields key insights into the sustainability of software development.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {1587–1590},
numpages = {4},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@inproceedings{10.1145/2504776.2504802,
author = {Herrick, Dan R. and Tyndall, John B.},
title = {Sustainable Automated Software Deployment Practices},
year = {2013},
isbn = {9781450323185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2504776.2504802},
doi = {10.1145/2504776.2504802},
abstract = {Many organizations follow the same error-prone, time-consuming, and redundant procedures to install software manually, whether as part of a master image or on individual computers. Usually this involves visiting a system, executing some sort of interface, selecting a subset of modules or configuring certain options, and waiting for the installer to complete. There is another way: automated software deployment, which affords greater efficiency, consistency, and ultimately, service. This paper discusses the organization and detailed implementation of automating software installations and updates using silent and unattended methods, with various levels of administrative intervention, from help desk to systems administrator. We also describe different approaches to creating such an environment for both "mass" devices (e.g., public computer lab systems) and individual devices (e.g., faculty/staff desktop systems).Key concepts include leveraging management software and resources you may already have (i.e., the "zero budget" approach) versus efficiency gains from third-party resources, high-level administrative toolkits along with low-level control methods, and developing a workflow for automated and semi-automated software installations.},
booktitle = {Proceedings of the 41st Annual ACM SIGUCCS Conference on User Services},
pages = {189–196},
numpages = {8},
keywords = {software installation, software deployment, best practice, installation, updater, easi, software distribution, process, software packing, software, easi make, baseline, thin imaging},
location = {Chicago, Illinois, USA},
series = {SIGUCCS '13}
}

@inproceedings{10.5555/2819009.2819082,
author = {Becker, Christoph and Chitchyan, Ruzanna and Duboc, Leticia and Easterbrook, Steve and Penzenstadler, Birgit and Seyff, Norbert and Venters, Colin C.},
title = {Sustainability Design and Software: The Karlskrona Manifesto},
year = {2015},
publisher = {IEEE Press},
abstract = {Sustainability has emerged as a broad concern for society. Many engineering disciplines have been grappling with challenges in how we sustain technical, social and ecological systems. In the software engineering community, for example, maintainability has been a concern for a long time. But too often, these issues are treated in isolation from one another. Misperceptions among practitioners and research communities persist, rooted in a lack of coherent understanding of sustainability, and how it relates to software systems research and practice. This article presents a cross-disciplinary initiative to create a common ground and a point of reference for the global community of research and practice in software and sustainability, to be used for effectively communicating key issues, goals, values and principles of sustainability design for software-intensive systems. The centrepiece of this effort is the Karlskrona Manifesto for Sustainability Design, a vehicle for a much needed conversation about sustainability within and beyond the software community, and an articulation of the fundamental principles underpinning design choices that affect sustainability. We describe the motivation for developing this manifesto, including some considerations of the genre of the manifesto as well as the dynamics of its creation. We illustrate the collaborative reflective writing process and present the current edition of the manifesto itself. We assess immediate implications and applications of the articulated principles, compare these to current practice, and suggest future steps.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {467–476},
numpages = {10},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3583133.3596347,
author = {Almeida, Jos\'{e} and Lezama, Fernando and Soares, Jo\~{a}o and Macedo, Leonardo and Vale, Zita and Romero, Ruben},
title = {Metaheuristic Optimization for Transmission Network Expansion Planning: Testebed 2 of the Competition on Evolutionary Computation in the Energy Domain},
year = {2023},
isbn = {9798400701207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583133.3596347},
doi = {10.1145/3583133.3596347},
abstract = {The complexity of the transmission network expansion planning (TNEP) problem has been increasing due to the new constraints given by renewable generation uncertainty, new market rules and players, and the continuous demand growth with the introduction of electric vehicles and energy storage systems. The problem consists of finding the optimal number and location of new transmission lines to support the demand, which can be extremely hard to optimize. As such, in this paper, we focus on metaheuristic optimization to solve a TENP problem proposed in testbed 2 of the 2023 competition on evolutionary computation in the energy domain. The 87-bus north-northeast Brazilian transmission system is considered for the case study, and different DE metaheuristics are used for the optimization process. Results show that the HyDE algorithm presents the overall best performance when compared to other DE strategies. HyDE is able to achieve the overall lowest costs with a reduction of around 67% compared to L-SHADE.},
booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
pages = {1668–1675},
numpages = {8},
keywords = {differential evolution, metaheuristic, optimization, transmission network expansion planning},
location = {Lisbon, Portugal},
series = {GECCO '23 Companion}
}

@inproceedings{10.1145/2729094.2754850,
author = {Hamilton, Margaret},
title = {Learning and Teaching Computing Sustainability},
year = {2015},
isbn = {9781450334402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2729094.2754850},
doi = {10.1145/2729094.2754850},
abstract = {In this paper we present a new course designed around computing sustainability, and aimed at encouraging students to analyse and adapt to design more sustainable workplaces which reduce the overall carbon footprint into the future. We explain the curriculum for this course, and the concepts of green variables, green clouds, sustainable computing, the gathering of relevant crowdsourced information which can be integrated onto a green virtual platform.},
booktitle = {Proceedings of the 2015 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {338},
numpages = {1},
keywords = {sustainability, green computing., professionalism},
location = {Vilnius, Lithuania},
series = {ITiCSE '15}
}

@inproceedings{10.5555/2561828.2561870,
author = {Jones, Alex K. and Chen, Yiran and Collinge, William O. and Xu, Haifeng and Schaefer, Laura A. and Landis, Amy E. and Bilec, Melissa M.},
title = {Considering Fabrication in Sustainable Computing},
year = {2013},
isbn = {9781479910694},
publisher = {IEEE Press},
abstract = {The term green computing has become effectively synonymous with low-power/energy computing. However, for computing to be truly sustainable, all phases of the system life-cycle must be considered. In contrast to the considerable effort that has been applied to address the use-phase energy consumption issue---ranging from battery powered embedded systems to data center servers---there is limited awareness or attention to the considerable energy consumption and environmental impacts from semiconductor fabrication. Current research indicates that fabrication is responsible for a significant factor of the energy utilized by these systems throughout their life-cycle. The trends of technology scaling coupled with developing hybrid fabrication solutions for integration of emerging technologies, while beneficial for use-phase power consumption, exacerbate these increasing environmental impacts from fabrication. Thus, design for sustainability is a grand challenge that must be addressed over the next decade.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
pages = {206–210},
numpages = {5},
location = {San Jose, California},
series = {ICCAD '13}
}

@inproceedings{10.5555/3522802.3522854,
author = {DeLong, Suzanne and Tolk, Andreas},
title = {Sustainable Computing and Simulation: A Literature Survey},
year = {2022},
publisher = {IEEE Press},
abstract = {Smart technologies are everywhere and the creation of a smart world, from smart devices to smart cities is rapidly growing to potentially improve quality of life. Businesses, governments, and individual users of smart technology expect a level of service and access to data that is achieved through data and supercomputing centers. These centers potentially consume vast amounts of power and their continued growth may be unsustainable and contribute to greenhouse gasses. As smart technologies rely heavily on such computational capabilities their sustainability is pivotal for a smart future. This paper explores the literature to: identify the problems; categorize the challenges as well as possible solutions; explore how simulation and machine learning can improve computational sustainability; and consider the need to conduct trade-off analysis to determine when to apply simulation and machine learning benefits. A taxonomy for sustainable computing is presented for future research.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {81},
numpages = {12},
location = {Phoenix, Arizona},
series = {WSC '21}
}

@article{10.1145/3372315.3372317,
author = {Pal, Ranjan and Ahuja, Aditya and Lin, Sung-Han and Kumar, Abhishek and Golubchik, Leana and Jagadeesan, Nachikethas A.},
title = {On the Economic Sustainability of Cloud Sharing Systems Are Dynamic Single Resource Sharing Markets Stable?},
year = {2019},
issue_date = {March 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/3372315.3372317},
doi = {10.1145/3372315.3372317},
abstract = {The recent emergence of the small cloud (SC), both in concept and in practice, has been driven mainly by issues related to service cost and complexity of commercial cloud providers (e.g., Amazon) employing massive data centers. However, the resource inelasticity problem [29] faced by the SCs due to their relatively scarce resources might lead to a potential degradation of customer QoS and loss of revenue. A proposed solution to this problem recommends the sharing of resources between competing SCs to alleviate the resource inelasticity issues that might arise. Based on this idea, a recent e?ort ([18]) proposed SC-Share, a performance-driven static market model for competitive small cloud environments that results in an e?cient market equilibrium jointly optimizing customer QoS satisfaction and SC revenue generation. However, an important question with a non-obvious answer still remains to be answered, without which SC sharing markets may not be guaranteed to sustain in the long-run - is it still possible to achieve a stable market e?cient state when the supply of SC resources is dynamic in nature?. In this paper, we take a? rst step to addressing the problem of e?cient market design for single SC resource sharing in dynamic environments. We answer our previous question in the a?rmative through the use of Arrow and Hurwicz's disequilibrium process [9, 10] in economics, and the gradient play technique in game theory that allows us to iteratively converge upon e?cient and stable market equilibria.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {nov},
pages = {2–10},
numpages = {9}
}

@inproceedings{10.1145/3512576.3512621,
author = {Ruangvanich, Supparang and Piriyasurawong, Pallop},
title = {Investigating the Acceptance Model of Cloud Learning: MOOCs for Sustainability Usage in Higher Education Institutes},
year = {2022},
isbn = {9781450384971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512576.3512621},
doi = {10.1145/3512576.3512621},
booktitle = {Proceedings of the 2021 9th International Conference on Information Technology: IoT and Smart City},
pages = {248–255},
numpages = {8},
location = {Guangzhou, China},
series = {ICIT '21}
}

@inproceedings{10.5555/3291291.3291326,
author = {Badreddin, Omar},
title = {Powering Software Sustainability with Blockchain},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software sustainability is a systematic challenge that impacts broad segments of software systems. Software codebases must evolve overtime to address changing contexts and adapt to the flux in middlewares and platforms. In the process, it accumulates arbitrary complexities and its maintenance becomes progressively difficult.Current sustainability approaches focus on the symptoms and tend to be reactive in nature, and ignore the fundamental incentive structures that drive decision-making processes. Moreover, contemporary approaches are insensitive to the uniqueness of each software project context and operate on the assumption that sustainability measurements are universally applicable to the majority of software systems.This paper introduces a fundamentally novel peer-driven approach to managing software sustainability. The methodology ensures that software teams can define their own sustainability measures that adequately address the unique context of their project and its priorities. These measures are dynamically defined by the project peers to ensure their applicability as the project context evolves. Finally, the paper introduces Susereum, a blockchain platform that materializes the methodology and establishes novel incentive structures to systematically promote software sustainability throughout the project lifecycle.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {315–322},
numpages = {8},
keywords = {code smells, crowd computing, software sustainability, design smells, blockchain, distributed consensus, distributed sovereignty, maintainability, scientific software},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@inproceedings{10.1145/2304636.2304642,
author = {Weiss, Roland J. and Repetto, Daniele and Koziolek, Heiko},
title = {Perseverance in Sustainable Software Architecting},
year = {2012},
isbn = {9781450313490},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2304636.2304642},
doi = {10.1145/2304636.2304642},
abstract = {In the recent past, there has been an increased interest in better managing the evolution of existing software systems and improving the software engineering practices for this now common task. In this paper, we take a look at the efforts at ABB to advance in this area, with special emphasis on architectures of long-living systems. The review consists of detailing the introduced methods and tools, as well as sharing experiences from applying them. In addition, we present two current case studies from the industrial automation domain that will be used as additional test fields for the developed methods.},
booktitle = {Proceedings of the 2012 ACM SIGSOFT Symposium on Industry Day},
pages = {11–14},
numpages = {4},
keywords = {validation, long-lived software systems, sustainability},
location = {Bertinoro, Italy},
series = {Industry Day '12}
}

@inproceedings{10.1145/2648511.2655956,
author = {Chitchyan, Ruzanna and Noppen, Joost and Groher, Iris},
title = {Sustainability in Software Product Lines},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2655956},
doi = {10.1145/2648511.2655956},
abstract = {Sustainability encompasses a wide set of aims: ranging from energy efficient software products (environmental sustainability), reduction of software development and maintenance costs (economic sustainability), to employee wellbeing (social sustainability). This panel brings together researchers and practitioners to explore the role that sustainability will play in software product line engineering. The panel aims to explore how sustainability manifests itself in domain engineering, via study of, for instance, sustainability patterns in domain analysis, architectural decisions motivated by specific sustainability concerns, types of variability that results from sustainability considerations, as well as engineering of sustainability as a domain itself. This panel explores challenges in research and practice for Sustainability in Software Product Line Engineering.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {367},
numpages = {1},
keywords = {sustainability through product liens, product line, domain analysis, sustainability, sustainability of product lines},
location = {Florence, Italy},
series = {SPLC '14}
}

@article{10.1145/3466851,
author = {Wang, Yingfei},
title = {Computing and Sustainability: How Can Technology Lead Us to a Better Future?},
year = {2021},
issue_date = {Summer 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {1528-4972},
url = {https://doi.org/10.1145/3466851},
doi = {10.1145/3466851},
journal = {XRDS},
month = {jun},
pages = {7–8},
numpages = {2}
}

@inproceedings{10.1145/2528282.2528293,
author = {Batra, Nipun and Gulati, Manoj and Singh, Amarjeet and Srivastava, Mani B.},
title = {It's Different: Insights into Home Energy Consumption in India},
year = {2013},
isbn = {9781450324311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2528282.2528293},
doi = {10.1145/2528282.2528293},
abstract = {Residential buildings contribute significantly to the overall energy usage across the world. Real deployments, and collected data thereof, play a critical role in providing insights into home energy consumption and occupant behavior. Existing datasets from real residential deployments are all from the developed countries. Developing countries, such as India, present unique opportunities to evaluate the scalability of existing research in diverse settings. Building upon more than a year of experience in sensor network deployments, we undertake an extensive deployment in a three storey home in Delhi, spanning 73 days from May-August 2013, measuring electrical, water and ambient parameters. We used 33 sensors across the home, measuring these parameters, collecting a total of approx. 400 MB of data daily. We discuss the architectural implications on the deployment systems that can be used for monitoring and control in the context of developing countries. Addressing the unreliability of electrical grid and internet in such settings, we present Sense Local-store Upload architecture for robust data collection. While providing several unique aspects, our deployment further validates the common considerations from similar residential deployments, discussed previously in the literature. We also release our collected data- Indian data for Ambient Water and Electricity Sensing (iAWE), for public use.},
booktitle = {Proceedings of the 5th ACM Workshop on Embedded Systems For Energy-Efficient Buildings},
pages = {1–8},
numpages = {8},
keywords = {Buildings, Sensor Networks, Deployment, Smart Homes},
location = {Roma, Italy},
series = {BuildSys'13}
}

@article{10.1145/3001912,
author = {Mann, Samuel},
title = {Computing Education for Sustainability: What Gives Me Hope?},
year = {2016},
issue_date = {November-December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {6},
issn = {1072-5520},
url = {https://doi.org/10.1145/3001912},
doi = {10.1145/3001912},
journal = {Interactions},
month = {oct},
pages = {44–47},
numpages = {4}
}

@inproceedings{10.1145/3530019.3530025,
author = {Hampau, Raluca Maria and Kaptein, Maurits and van Emden, Robin and Rost, Thomas and Malavolta, Ivano},
title = {An Empirical Study on the Performance and Energy Consumption of AI Containerization Strategies for Computer-Vision Tasks on the Edge},
year = {2022},
isbn = {9781450396134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3530019.3530025},
doi = {10.1145/3530019.3530025},
abstract = {Context. The rise of use cases of AI catered towards the Edge, where devices have limited computation power and storage capabilities, motivates the need for better understating of how AI performs and consumes energy. Goal. The aim of this paper is to empirically assess the impact of three different AI containerization strategies on the energy consumption, execution time, CPU, and memory usage for computer-vision tasks on the Edge. Method. In this paper we conduct an experiment with the used containerization strategy as main factor, with three treatments: ONNX Runtime, WebAssembly, and Docker. The subjects of the experiment are four widely-used computer-vision algorithms. We then orchestrate a series of runs where we deploy the four subjects on different generations of Raspberry Pi devices, with different hardware capabilities. A total of 120 runs (per device) are recorded to gather data on energy, execution time, CPU, and memory. Results. We found a statistically significant difference between the three containerization strategies on all dependent variables. Specifically, WebAssembly proves to be a valuable alternative for devices with reduced disk space and computation power. Conclusions. For computer-vision tasks with limited disk space and RAM memory requirements, developers should prefer WebAssembly for deployment. The (non-dockerized) ONNX Runtime resulted to be the best choice in terms of energy consumption and execution time.},
booktitle = {Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering},
pages = {50–59},
numpages = {10},
location = {Gothenburg, Sweden},
series = {EASE '22}
}

@article{10.5555/1791129.1791131,
author = {Young, Alison},
title = {Computing and Sustainability: An ICT Project in the High Andes: Saturday Plenary Session},
year = {2010},
issue_date = {June 2010},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {25},
number = {6},
issn = {1937-4771},
abstract = {This address will describe an ICT research project that is context specific and achieved economic and social turnarounds where other ICT projects have failed. The message for computer science educators and professionals is that desired impact has less to do with science and technology and more to do with understanding context and culture. Evaluating implementation options to advance educational and social needs is applying intelligence to technology. Technology without context is a chasm.},
journal = {J. Comput. Sci. Coll.},
month = {jun},
pages = {6–7},
numpages = {2}
}

@inproceedings{10.1145/2468356.2468618,
author = {Guo, Yukang and Jones, Matt and Cowan, Benjamin and Beale, Russell},
title = {Take It Personally: Personal Accountability and Energy Consumption in Domestic Households},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468618},
doi = {10.1145/2468356.2468618},
abstract = {We explore the overlooked area of personal energy consumption in the context of a shared domestic household. We discuss the potential benefits of such an approach. We report the results of a lab study and field trial with four households using a personal energy monitoring system. We describe the results of the studies and discuss how such previously hidden information might raise awareness of individual energy consumption and the benefits and problems this entails.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {1467–1472},
numpages = {6},
keywords = {wearable computing., mobiles, energy consumption},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.1145/1734263.1734439,
author = {Cai, Yu},
title = {Integrating Sustainability into Undergraduate Computing Education},
year = {2010},
isbn = {9781450300063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1734263.1734439},
doi = {10.1145/1734263.1734439},
abstract = {In the past few years sustainability and green computing have received tremendous interest across the world. Computing plays a critical role in our society, thus it has a special responsibility for sustainability and green movement. In this paper, we advocate sustainability integration into undergraduate computing education. We present three sustainability integration strategies, our efforts to develop a green computing course and learning modules, and course evaluation. We believe that sustainability integration will help prepare our graduates with computing competencies, multi-disciplinary knowledge, and computational thinking to create a sustainable future.},
booktitle = {Proceedings of the 41st ACM Technical Symposium on Computer Science Education},
pages = {524–528},
numpages = {5},
keywords = {sustainability, green computing},
location = {Milwaukee, Wisconsin, USA},
series = {SIGCSE '10}
}

@inproceedings{10.5555/2820656.2820658,
author = {Lago, Patricia},
title = {Challenges and Opportunities for Sustainable Software},
year = {2015},
publisher = {IEEE Press},
abstract = {With the increasing role played by software in supporting our society, its sustainability and environmental impact have become major factors in the development and operation of software-intensive systems. Myths and beliefs hide the real truth behind Green IT: IT is energy-inefficient because software is developed to make it so -- intentionally or not. But how far are we from being able to control software energy-efficiency? What makes software greener? How can we transform measuring software energy consumption in a general practice? What architectural design decisions will result in more sustainable systems? How can we ensure that new-generation software will be both cloud-ready and environmental-friendly? and How can we make evident the economic and social impact of developing software with 'energy in mind'? These are a few of the challenges ahead for a more sustainable digital society. This talk will discuss them, hence drawing directions for exciting challenges, promising opportunities, and ultimately inspiring research.},
booktitle = {Proceedings of the Fifth International Workshop on Product LinE Approaches in Software Engineering},
pages = {1–2},
numpages = {2},
location = {Florence, Italy},
series = {PLEASE '15}
}

@inproceedings{10.1145/2000259.2000263,
author = {Koziolek, Heiko},
title = {Sustainability Evaluation of Software Architectures: A Systematic Review},
year = {2011},
isbn = {9781450307246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2000259.2000263},
doi = {10.1145/2000259.2000263},
abstract = {Long-living software systems are sustainable if they can be cost-efficiently maintained and evolved over their entire life-cycle. The quality of software architectures determines sustainability to a large extent. Scenario-based software architecture evaluation methods can support sustainability analysis, but they are still reluctantly used in practice. They are also not integrated with architecture-level metrics when evaluating implemented systems, which limits their capabilities. Existing literature reviews for architecture evaluation focus on scenario-based methods, but do not provide a critical reflection of the applicability of such methods for sustainability evaluation. Our goal is to measure the sustainability of a software architecture both during early design using scenarios and during evolution using scenarios and metrics, which is highly relevant in practice. We thus provide a systematic literature review assessing scenario-based methods for sustainability support and categorize more than 40 architecture-level metrics according to several design principles. Our review identifies a need for further empirical research, for the integration of existing methods, and for the more efficient use of formal architectural models.},
booktitle = {Proceedings of the Joint ACM SIGSOFT Conference -- QoSA and ACM SIGSOFT Symposium -- ISARCS on Quality of Software Architectures -- QoSA and Architecting Critical Systems -- ISARCS},
pages = {3–12},
numpages = {10},
keywords = {sustainability, software architecture, survey, architectural metric, evolution scenario},
location = {Boulder, Colorado, USA},
series = {QoSA-ISARCS '11}
}

@inproceedings{10.1145/2639189.2639228,
author = {Pargman, Daniel and Raghavan, Barath},
title = {Rethinking Sustainability in Computing: From Buzzword to Non-Negotiable Limits},
year = {2014},
isbn = {9781450325424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639189.2639228},
doi = {10.1145/2639189.2639228},
abstract = {Recent years have seen a flurry of work on sustainable computing and sustainable HCI, but it is unclear whether this body of work adheres to a meaningful definition of sustainability. In this paper, we review four interlocking frameworks that together provide a rigorous foundation for what constitutes sustainability. Each consecutive framework both builds upon and can loosely be seen as a refinement of the previous framework. More specifically, we leverage prominent ecological thinking from outside of computer science to inform what sustainability means in the context of computing. To this end, we re-evaluate some recent results from the field of sustainable HCI and offer thoughts on further research in the field.},
booktitle = {Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational},
pages = {638–647},
numpages = {10},
keywords = {ecological sustainability, sustainable development, collapse informatics, ecological footprint, limits to growth, sustainable HCI, sustainability, environmental sustainability, critical reflection, steady-state economy},
location = {Helsinki, Finland},
series = {NordiCHI '14}
}

@inproceedings{10.1145/3033701.3033757,
author = {de Oliveira, Renata Rodrigues and de Almeida Neris, V\^{a}nia Paula and J\'{u}nior, Newton A. Galindo},
title = {Perceptions of Sustainability Aspects in Computing},
year = {2016},
isbn = {9781450352352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3033701.3033757},
doi = {10.1145/3033701.3033757},
abstract = {The importance of sustainability and the need of research on how to effectively reach it in different knowledge areas have been widely spread out. In computer science however, although there are several groups interested in the theme, the discussions on sustainability are still incipient. In the Brazilian community, researchers from Human-Computer Interaction have put focus on these issues and formalized a research challenge emphasizing the need of investigation about sustainability in computing. Aiming to contribute in this direction, collecting and evaluating the perceptions of the Brazilian computer science community on the theme, this paper presents the results of a questionnaire answered by 128 students, professors and other professionals. The results suggest that the community understands that the topic is relevant to computer science; it should consider software and hardware together and an implicit conscience about the need of consider social, economic and environmental aspects when judging if a computer science solution is sustainable.},
booktitle = {Proceedings of the 15th Brazilian Symposium on Human Factors in Computing Systems},
articleno = {55},
numpages = {4},
keywords = {Brazilian Community, Sustainability, Perceptions, Computer Science},
location = {S\~{a}o Paulo, Brazil},
series = {IHC '16}
}

@inproceedings{10.1145/2157136.2157223,
author = {Ericson, Barbara and McKlin, Tom},
title = {Effective and Sustainable Computing Summer Camps},
year = {2012},
isbn = {9781450310987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2157136.2157223},
doi = {10.1145/2157136.2157223},
abstract = {universities. But, it is not enough to offer computing summer camps and hope that students like them. The camps should be effective by some measure, such as broadening participation by underrepresented groups and/or increasing learning. Summer camps should also be financially sustainable, so that institutions can continue to offer them regularly. The summer camps at Georgia Tech have become effective and financially sustainable. This paper presents the rationale for our camps, the evaluation results that demonstrate positive attitude changes and increases in learning, and the business model that makes them financially sustainable. It also reports on the evaluation results from seven other colleges and universities in Georgia that offered computing summer camps during the summer of 2011 with assistance from Georgia Tech.},
booktitle = {Proceedings of the 43rd ACM Technical Symposium on Computer Science Education},
pages = {289–294},
numpages = {6},
keywords = {gender and diversity issues, cell phone programming, summer camps, picocrickets, scratch, outreach, robots, app inventor, Alice},
location = {Raleigh, North Carolina, USA},
series = {SIGCSE '12}
}

@inproceedings{10.1145/3194793.3194794,
author = {Winters, Titus},
title = {Non-Atomic Refactoring and Software Sustainability},
year = {2018},
isbn = {9781450357548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194793.3194794},
doi = {10.1145/3194793.3194794},
abstract = {Sustainability is the ability of a project / codebase / organization to react to necessary changes over its expected lifespan. At a large enough scale, or with enough disconnect between dependencies, sustainability comes from application of both technical and non-technical approaches. On the technical side, I advocate for restraint among API providers on making arbitrary changes, and use of non-atomic refactoring techniques when more invasive changes are required; such techniques are employed in many Google projects, and in programming languages like Go and C++, to allow more flexible changes to language standards over time. On the non-technical side, I argue for a clear separation of responsibilities (providers need to do the bulk of the work for the update), as well as a growing need to document acceptable usage of an API, be it a library or programming language. In many languages, there are very few changes to an API that are provably safe without this idea: just because a user's code currently works does not mean that it is supported and can be expected to continue to work indefinitely under maintenance. Taken together, these two approaches form what I believe to be a minimum set of requirements when approaching software sustainability.},
booktitle = {Proceedings of the 2nd International Workshop on API Usage and Evolution},
pages = {2–5},
numpages = {4},
keywords = {libraries, software engineering, refactoring},
location = {Gothenburg, Sweden},
series = {WAPI '18}
}

@inproceedings{10.1145/1985793.1985964,
author = {Amsel, Nadine and Ibrahim, Zaid and Malik, Amir and Tomlinson, Bill},
title = {Toward Sustainable Software Engineering (NIER Track)},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985964},
doi = {10.1145/1985793.1985964},
abstract = {Current software engineering practices have significant effects on the environment. Examples include e-waste from computers made obsolete due to software upgrades, and changes in the power demands of new versions of software. Sustainable software engineering aims to create reliable, long-lasting software that meets the needs of users while reducing environmental impacts. We conducted three related research efforts to explore this area. First, we investigated the extent to which users thought about the environmental impact of their software usage. Second, we created a tool called GreenTracker, which measures the energy consumption of software in order to raise awareness about the environmental impact of software usage. Finally, we explored the indirect environmental effects of software in order to understand how software affects sustainability beyond its own power consumption. The relationship between environmental sustainability and software engineering is complex; understanding both direct and indirect effects is critical to helping humans live more sustainably.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {976–979},
numpages = {4},
keywords = {software, green it, sustainability, energy consumption},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.1145/2820990.2820992,
author = {Kulau, Ulf and Schildt, Sebastian and Rottmann, Stephan and Wolf, Lars},
title = {Paint It Black: Increase WSN Energy Efficiency with the Right Housing},
year = {2015},
isbn = {9781450338400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2820990.2820992},
doi = {10.1145/2820990.2820992},
abstract = {It is a well-known fact that Wireless Sensor Networks (WSNs) that are exposed to real environmental conditions suffer from harsh temperatures. Yet, the temperature does not only have negative impact as the energy efficiency of processing units benefits from higher temperatures. The minimal voltage for correct operation of CMOS circuits is bounded by the temperature. Thus, temperature-dependent undervolting schemes for WSN nodes have been proposed in the past to extend the network lifetime. However, not much thought has been given into directly influencing the most relevant factor: Temperature. In this work we look at the influence of various WSN housings onto the temperature profile of WSN nodes and quantify the energy saving potential of choosing the right housing.},
booktitle = {Proceedings of the 6th ACM Workshop on Real World Wireless Sensor Networks},
pages = {3–6},
numpages = {4},
keywords = {housing, wireless sensor network, environmental conditions, temperature effects, undervolting, energy efficiency},
location = {Seoul, South Korea},
series = {RealWSN '15}
}

@inproceedings{10.5555/2818754.2818847,
author = {Zhu, Haitao Steve and Lin, Chaoren and Liu, Yu David},
title = {A Programming Model for Sustainable Software},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {This paper presents a novel energy-aware and temperature-aware programming model with first-class support for sustainability. A program written in the new language, named Eco, may adaptively adjusts its own behaviors to stay on a given (energy or temperature) budget, avoiding both deficit that would lead to battery drain or CPU overheating, and surplus that could have been used to improve the quality of results. Sustainability management in Eco is captured as a form of supply and demand matching, and the language runtime consistently maintains the equilibrium between supply and demand. Among the efforts of energy-adaptive and temperature-adaptive systems, Eco is distinctive in its role in bridging the programmer and the underlying system, and in particular, bringing both programmer knowledge and application-specific traits into energy optimization. Through a number of intuitive programming abstractions, Eco reduces challenging issues in this domain --- such as workload characterization and decision making in adaptation --- to simple programming tasks, ultimately offering fine-grained, programmable, and declarative sustainability to energy-efficient computing. Eco is an minimal extension to Java, and has been implemented as an open-source compiler. We validate the usefulness of Eco by upgrading real-world Java applications with energy awareness and temperature awareness.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {767–777},
numpages = {11},
location = {Florence, Italy},
series = {ICSE '15}
}

@article{10.1145/1189276.1189292,
author = {Spinellis, D.},
title = {Review of "Sustainable Software Development: An Agile Perspective by Kevin Tate," Addison-Wesley Professional, 2005, $39.99, ISBN: 0321286081.: Review of "Sustainable Software Development: An Agile Perspective by Kevin Tate," Addison-Wesley Professional, 2005, $39.99, ISBN: 0321286081.},
year = {2006},
issue_date = {December-January 2006-2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {10},
issn = {1542-7730},
url = {https://doi.org/10.1145/1189276.1189292},
doi = {10.1145/1189276.1189292},
abstract = {Review of "Sustainable Software Development: An Agile Perspective by Kevin Tate," Addison-Wesley Professional, 2005, $39.99, ISBN: 0321286081.},
journal = {Queue},
month = {dec},
pages = {49},
numpages = {1}
}

@inproceedings{10.1145/3446382.3448607,
author = {Ramprasad, Brian and da Silva Veith, Alexandre and Gabel, Moshe and de Lara, Eyal},
title = {Sustainable Computing on the Edge: A System Dynamics Perspective},
year = {2021},
isbn = {9781450383233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3446382.3448607},
doi = {10.1145/3446382.3448607},
abstract = {This paper explores the CO2 footprint of IoT applications by using system dynamics modeling to estimate the CO2 emissions over time from a wireless video analytics application. We model the impact of the application design and the mobile infrastructure on the short and long term emissions produced by running the application on both cloud and edge computing infrastructures. Our analysis shows that the base station radio and the wide-area data network are major contributors of CO2 emissions. We find that CO2 emissions can be reduced by 50% by placing edge centers near the base stations, exploiting new features of the 5G mobile network, and scheduling data uploads judiciously. We also analyze the long term effects of application design choices and increased user base on carbon emissions.},
booktitle = {Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications},
pages = {64–70},
numpages = {7},
keywords = {mobile computing, sustainability, edge computing},
location = {Virtual, United Kingdom},
series = {HotMobile '21}
}

@article{10.1145/3057266,
author = {Perera, Charith and Qin, Yongrui and Estrella, Julio C. and Reiff-Marganiec, Stephan and Vasilakos, Athanasios V.},
title = {Fog Computing for Sustainable Smart Cities: A Survey},
year = {2017},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3057266},
doi = {10.1145/3057266},
abstract = {The Internet of Things (IoT) aims to connect billions of smart objects to the Internet, which can bring a promising future to smart cities. These objects are expected to generate large amounts of data and send the data to the cloud for further processing, especially for knowledge discovery, in order that appropriate actions can be taken. However, in reality sensing all possible data items captured by a smart object and then sending the complete captured data to the cloud is less useful. Further, such an approach would also lead to resource wastage (e.g., network, storage, etc.). The Fog (Edge) computing paradigm has been proposed to counterpart the weakness by pushing processes of knowledge discovery using data analytics to the edges. However, edge devices have limited computational capabilities. Due to inherited strengths and weaknesses, neither Cloud computing nor Fog computing paradigm addresses these challenges alone. Therefore, both paradigms need to work together in order to build a sustainable IoT infrastructure for smart cities. In this article, we review existing approaches that have been proposed to tackle the challenges in the Fog computing domain. Specifically, we describe several inspiring use case scenarios of Fog computing, identify ten key characteristics and common features of Fog computing, and compare more than 30 existing research efforts in this domain. Based on our review, we further identify several major functionalities that ideal Fog computing platforms should support and a number of open challenges toward implementing them, to shed light on future research directions on realizing Fog computing for building sustainable smart cities.},
journal = {ACM Comput. Surv.},
month = {jun},
articleno = {32},
numpages = {43},
keywords = {sustainability, Internet of things, fog computing, smart cities}
}

@inproceedings{10.5555/1030453.1030683,
author = {Brady, Thomas F.},
title = {Energy Production and Trading: Using Computer Simulation to Mitigate Risk in Electricity Generation/Consumption Collaboration Policies},
year = {2002},
isbn = {0780376153},
publisher = {Winter Simulation Conference},
abstract = {The electric utility industry has undergone fundamental change in the last decade. Foremost of these changes have been numerous deregulation attempts. Producers and large consumers have built business models based upon large volume transactions, which lead to smooth production and volume discounting. The risks associated with using these traditional business models in deregulated markets are many. This paper describes the development of a computer simulation environment that models a novel collaborative strategy proposed by a local electricity utility to mitigate highly varying load situations demanded by the largest steel-producing region in the United States. Through the use of this model, collaborative strategies for effective electricity generation and usage are developed and analyzed.},
booktitle = {Proceedings of the 34th Conference on Winter Simulation: Exploring New Frontiers},
pages = {1575–1577},
numpages = {3},
location = {San Diego, California},
series = {WSC '02}
}

@inproceedings{10.1145/3590837.3590855,
author = {Dora Pravina, C.T and Buradkar, Mrunalini Upendra and Jamal, Md Khalid and Tiwari, Ashish and Mamodiya, Udit and Goyal, Dinesh},
title = {A Sustainable and Secure Cloud Resource Provisioning System in Industrial Internet of Things (IIoT) Based on Image Encryption},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590855},
doi = {10.1145/3590837.3590855},
abstract = {An organization can be created through the Industrial Internet of Things (IIoT), which can transform an existing bound structure. The Industrial Internet of Things (IIoT) and its remote organization requirements for current sensors are very productive. The IIoT's introduced sensors monitor the conditions of contemporary machines and devices. Silicon Cloud demonstrated the advantages of modern distributed computing advancements for intelligent and planning applications. As a result, constant quality and security have emerged as the primary concerns in the IIoT. This presents several distinct and consistently increasing wagers on the advanced system. The research deals with the aim of cutting-edge handheld GPS devices. In a similar vein, recent region-based organizations make use of regional data. There is enough fragile data in the region data provided to these area-based expert communities to warrant overemphasis. As a result, experts are working on finding a solution for safe regional data. Most of the investigation frameworks that were suggested were designed to make them believe that the research objectives are fulfilled rather than precise headings of the client's region.},
booktitle = {Proceedings of the 4th International Conference on Information Management &amp; Machine Intelligence},
articleno = {18},
numpages = {5},
keywords = {Internet of Things (IoT), Information, Searching Methodology, Cloud Applications, Optimization},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@inproceedings{10.1109/ICSE-SEIS.2019.19,
author = {Lago, Patricia},
title = {Architecture Design Decision Maps for Software Sustainability},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIS.2019.19},
doi = {10.1109/ICSE-SEIS.2019.19},
abstract = {In software engineering, sustainability can be defined as the "capacity to endure" and to "preserve the function of a system over an extended period of time". These definitions mainly point towards technical sustainability over time. Sustainability, however, may entail a much broader scope including economic, social and environmental sustainability as well.In spite of the exciting hype around sustainability, we are very much lacking suitable instruments to design software-intensive systems that are sustainable and enable sustainability goals. To fill this gap, we advocate the treatment of sustainability as a software quality property and define a software sustainability assessment method that helps make sustainability-driven design decisions. The method essentially relies on the definition of so-called decision maps, i.e. views aimed at framing the architecture design concerns around the four sustainability dimensions mentioned above - technical, economic, social and environmental sustainability. This paper presents the notion of decision map. We use two illustrative examples extracted from industrial projects, to summarize our lessons learned and reflections.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Society},
pages = {61–64},
numpages = {4},
keywords = {architecture assessment, sustainability, architecture design decisions, decision map, software architecture},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIS '19}
}

@inproceedings{10.1145/2961111.2962590,
author = {Sedano, Todd and Ralph, Paul and P\'{e}raire, C\'{e}cile},
title = {Sustainable Software Development through Overlapping Pair Rotation},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962590},
doi = {10.1145/2961111.2962590},
abstract = {Context: Conventional wisdom says that team disruptions (like team churn) should be avoided. However, we have observed software development projects that succeed despite high disruption.Objective: The purpose of this paper is to understand how to develop software effectively, even in the face of team disruption.Method: We followed Constructivist Grounded Theory. The primary researcher conducted participant-observation of several projects at Pivotal (a software development company), and interviewed 21 software engineers, interaction designers, and product managers. The researcher iteratively sampled and analyzed the collected data until achieving theoretical saturation.Results: This paper introduces a descriptive theory of Sustainable Software Development. The theory encompasses principles, policies, and practices aiming at removing knowledge silos and improving code quality (including discoverability and readability), hence leading to development sustainability.Limitations: While the results are highly relevant to the observed projects at Pivotal, the outcomes may not be transferable to other software development organizations with different software development cultures.Conclusion: The theory refines and extends the understanding of Extreme Programming by adding a few principles, policies, and practices (like the unique Overlapping Pair Rotation practice) and aligning these principles, policies, and practices towards the business goal of sustainability.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {19},
numpages = {10},
keywords = {Sustainable software development, Code ownership, Grounded Theory, Extreme Programming},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@inproceedings{10.1145/3463274.3463347,
author = {Shamshiri, Hatef},
title = {Supporting Sustainability Design through Agile Software Development},
year = {2021},
isbn = {9781450390538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463274.3463347},
doi = {10.1145/3463274.3463347},
abstract = {Context: Sustainability has become an important topic for researchers and is gaining popularity among software development companies, but integrating it into their development processes is still lacking.&nbsp;Objectives: This paper aimed to discuss the purpose of doctoral research, the research questions, the steps to answer the research questions, and the research's current progress concerning sustainability in the software development life cycle.Results: I have presented the high-level plans for the doctoral research and outlined the first part of the results of phase 1. As part of this phase 1, I have conducted an extensive literature review to collect data about sustainability in companies' agile methods. I found only a few studies reporting sustainability in agile software development, and this finding proposes that either this field was not studied, or the results have not been widely published, indicating a gap in research.},
booktitle = {Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering},
pages = {300–304},
numpages = {5},
keywords = {Software, Method, Agile, companies, Sustainability},
location = {Trondheim, Norway},
series = {EASE '21}
}

@inproceedings{10.1145/2362536.2362539,
author = {de Lemos Meira, Silvio Romero},
title = {Sustainable Software Houses and Factories Are STARTUPS},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362539},
doi = {10.1145/2362536.2362539},
abstract = {The global, local and firm economies depend on software in an ever increasing way. Writing effective software on a day to day basis, for a long time (decades, maybe) depends upon agility (as a process and timing) to have, as consequences, reliability, scalability and security, in times of software and systems as services.The only way to achieve such tense and, in most cases, opposite goals, is to try and find business models (for software ops) that are continuously searching for a repeatable, scalable business models.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {3},
numpages = {1},
keywords = {scalable business models, startups, software},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@article{10.1145/2984071.2984073,
author = {Raghavan, Barath},
title = {New Directions in Sustainable Computing: The Benefit of Divergent Approaches and Divergent Goals},
year = {2016},
issue_date = {August 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {2},
issn = {0095-2737},
url = {https://doi.org/10.1145/2984071.2984073},
doi = {10.1145/2984071.2984073},
abstract = {In the past decade sustainable computing has emerged as a subject that touches many subfields of computing research. While even in its early years "sustainable computing" comprised a number of fundamentally different types of research, new efforts promise to widen its definition further still. Here I briefly describe some of the flavors of sustainable computing work and argue for further exploration of some of the new approaches that have recently emerged.},
journal = {SIGCAS Comput. Soc.},
month = {aug},
pages = {9–11},
numpages = {3},
keywords = {society, sustainable computing}
}

@inproceedings{10.1145/2493432.2493474,
author = {Knowles, Bran and Blair, Lynne and Hazas, Mike and Walker, Stuart},
title = {Exploring Sustainability Research in Computing: Where We Are and Where We Go Next},
year = {2013},
isbn = {9781450317702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2493432.2493474},
doi = {10.1145/2493432.2493474},
abstract = {This paper develops a holistic framework of questions which seem to motivate sustainability research in computing in order to enable new opportunities for critique. Analysis of systematically selected corpora of computing publications demonstrates that several of these question areas are well covered, while others are ripe for further exploration. It also provides insight into which of these questions tend to be addressed by different communities within sustainable computing. The framework itself reveals discursive similarities between other existing environmental discourses, enabling reflection and participation with the broader sustainability debate. It is argued that the current computing discourse on sustainability is reformist and premised in a Triple Bottom Line construction of sustainability. A radical, Quadruple Bottom Line alternative is explored as a new vista for computing research.},
booktitle = {Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {305–314},
numpages = {10},
keywords = {discourse, critical reflection, sustainability},
location = {Zurich, Switzerland},
series = {UbiComp '13}
}

@inproceedings{10.5555/968878.969044,
author = {Choi, Kihwan and Soma, Ramakrishna and Pedram, Massoud},
title = {Fine-Grained Dynamic Voltage and Frequency Scaling for Precise Energy and Performance Trade-Off Based on the Ratio of Off-Chip Access to On-Chip Computation Times},
year = {2004},
isbn = {0769520855},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper presents an intra-process dynamic voltage and frequency scaling (DVFS) technique targeted toward non real-time applications running on an embedded system platform. The key idea is to make use of runtime information about the external memory access statistics in order to perform CPU voltage and frequency scaling with the goal of minimizing the energy consumption while translucently controlling the performance penalty. The proposed DVFS technique relies on dynamically-constructed regression models that allow the CPU to calculate the expected workload and slack time for the next time slot, and thus, adjust its voltage and frequency in order to save energy while meeting soft timing constraints. This is in turn achieved by estimating and exploiting the ratio of the total off-chip access time to the total on-chip computation time. The proposed technique has been implemented on an XScale-based embedded system platform and actual energy savings have been calculated by current measurements in hardware. For memory-bound programs, a CPU energy saving of more than 70% with a performance degradation of 12% was achieved. For CPU-bound programs, 15-60% CPU energy saving was achieved at the cost of 5-20% performance penalty.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe - Volume 1},
pages = {10004},
series = {DATE '04}
}

@inproceedings{10.5555/2662693.2662702,
author = {Calero, Coral and Bertoa, Manuel F. and Moraga, Ma \'{A}ngeles},
title = {A Systematic Literature Review for Software Sustainability Measures},
year = {2013},
isbn = {9781467362672},
publisher = {IEEE Press},
abstract = {Nowadays, sustainability is a key factor that should be considered in the software quality models. It is increasingly important how environmentally friendly is a software product, both in its execution and during its development process. Therefore, we have proposed, in a previous work, a quality model (25010+S) an extension of the ISO/IEC 25010 standard by considering aspects of sustainability on its characteristics and sub-characteristics. However, in order to make the model useful, it is necessary to identify measures for each sub-characteristic and characteristic. For that reason, the objective of this paper is to carry out a Systematic Literature Review to discover the state-of-the art in software sustainability measures.},
booktitle = {Proceedings of the 2nd International Workshop on Green and Sustainable Software},
pages = {46–53},
numpages = {8},
keywords = {sustainability indicators, sustainability measures, quality model, sustainability models, systematic literature review},
location = {San Francisco, California},
series = {GREENS '13}
}

@inproceedings{10.1145/3284557.3284695,
author = {Francese, Dora and Buoninconti, Luca},
title = {Sustainable Design and Software Tools by Multimatrix Criteria},
year = {2018},
isbn = {9781450366281},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3284557.3284695},
doi = {10.1145/3284557.3284695},
abstract = {Architecture design has been for long time relying on graphic drawings and handmade calculations. The results of this procedure was surely an arts and craft product, which very often could not be reproduced or even built in an easy way. Lately, according to the new Computer Aided Systems, many problems - arisen from the impossibility of taking under control various factors - have been solved and a new world of representation, design and construction were born. In the CITTAM (a research centre of the University of Naples) a new methodology has been studied and developed by a team of experts in various disciplines. The methodology, applied to any scale of product, from a small component of a window, until a large urban area, takes into account indicators, parameters and performances of a great number of issues, aimed at assessing the level of sustainability of the product, employed in the construction. This Model, by shape of Multicriteria Matrix, is being processed firstly by means of a structure of Excel sheets, and is now been implementing into a Computer Software, which could help the designers ex-ante, ongoing and after the design procedure and the building construction, in order to allow them to take decisions regarding the choice of materials, shapes, volumes, location, orientation, etc. of the final product. The paper describes the Model and the potential of the innovative Software for assessing sustainability of products, by showing both the structure of the Matrix and the Information Technology. The results, provided by an example of use for a design procedure, demonstrate the usefulness of the tool. In conclusion this new methodology of design and production, by means of Multicriteria Information Tools can help to give again some arts and craft quality to building and architecture, at the same time allowing guarantee of sustainability.},
booktitle = {Proceedings of the 2nd International Symposium on Computer Science and Intelligent Control},
articleno = {29},
numpages = {6},
keywords = {Multicriteria matrix, Architectural design, Assessment, Software},
location = {Stockholm, Sweden},
series = {ISCSIC '18}
}

@article{10.1145/2714560,
author = {Lago, Patricia and Ko\c{c}ak, Sedef Akinli and Crnkovic, Ivica and Penzenstadler, Birgit},
title = {Framing Sustainability as a Property of Software Quality},
year = {2015},
issue_date = {October 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {58},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/2714560},
doi = {10.1145/2714560},
abstract = {This framework addresses the environmental dimension of software performance, as applied here by a paper mill and a car-sharing service.},
journal = {Commun. ACM},
month = {sep},
pages = {70–78},
numpages = {9}
}

@inproceedings{10.1145/2468356.2468773,
author = {Doerflinger, Joerg and Dearden, Andy and Gross, Tom},
title = {A Software Development Methodology for Sustainable ICTD Solutions},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468773},
doi = {10.1145/2468356.2468773},
abstract = {Information and Communication Technology continue to be increasingly used in social development and poverty alleviation projects, known as Information and Communication Technology for Development (ICTD) projects. However, most interventions either fail completely as a result of attempting to use inappropriate software development approaches and technology concepts in the different ICTD context or they only execute small scale prototypes without positive long-term social impact. We present a case study on how we combined and adapted, using an iterative action research refinement approach, established interaction design methods into a software development methodology supporting scalable long-term ICTD software projects: the Technical ICTD Methodology (TIM). Our case study is based on the experiences of a series of ICTD projects executed within a major software corporation over a period of more than five years.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {2371–2374},
numpages = {4},
keywords = {ictd, software development methodology},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.1145/3143434.3143438,
author = {Meding, Wilhelm},
title = {Sustainable Measurement Programs for Software Development Companies: What to Measure},
year = {2017},
isbn = {9781450348539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3143434.3143438},
doi = {10.1145/3143434.3143438},
abstract = {Software development companies have access to large amounts of software data, e.g. data that relate to the performance of their products (both during development and in field), data about finance, competitors. The software data is collected and analyzed; tables and graphs are developed showing status, progress, trends etc. This "post-process" of collected data, generates even more data. This situation creates, in one hand, a golden opportunity for these companies while raising at the same time a number of challenges. A golden opportunity, since the companies can analyze data to get a better understanding of e.g. the performance of their organizations and products and take fact based decisions. On the other hand, the large amount of data creates several challenges, e.g. how should the data be collected and stored, what makes measurement systems reliable [3], how the infrastructure should be set-up to support automation. Another challenge is how to identify those few important measures that provide the insight that is necessary for the organization to know that e.g. the product is being developed as specified; to know that there are no problems with the performance of the product when used by customers? In other words, given this plethora of data (e.g. more than 4 000 measurement systems), what should be measured?},
booktitle = {Proceedings of the 27th International Workshop on Software Measurement and 12th International Conference on Software Process and Product Measurement},
pages = {94–99},
numpages = {6},
keywords = {empirical study, metrics, case study, dashboards},
location = {Gothenburg, Sweden},
series = {IWSM Mensura '17}
}

@inproceedings{10.1145/1375657.1375666,
author = {Anand, Madhukar and Lee, Insup},
title = {Robust and Sustainable Schedulability Analysis of Embedded Software},
year = {2008},
isbn = {9781605581040},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1375657.1375666},
doi = {10.1145/1375657.1375666},
abstract = {For real-time systems, most of the analysis involves efficient or exact schedulability checking. While this is important, analysis is often based on the assumption that the task parameters such as execution requirements and inter-arrival times between jobs are known exactly. In most cases, however, only a worst-case estimate of these quantities is available at the time of analysis. It is therefore imperative that schedulability analysis hold for better parameter values (Sustainable Analysis). On the other hand, if the task or system parameters turn out to be worse off, then the analysis should tolerate some deterioration (Robust Analysis). Robust analysis is especially important, because the implication of task schedulability is often weakened in the presence of optimizations that are performed on its code, or dynamic system parameters.In this work, we define and address sustainability and robustness questions for analysis of embedded real-time software that is modeled by conditional real-time tasks. Specifically, we show that, while the analysis is sustainable for changes in the task such as lower job execution times and increased relative deadlines, it is not the case for code changes such as job splitting and reordering. We discuss the impact of these results in the context of common compiler optimizations, and then develop robust schedulability techniques for operations where the original analysis is not sustainable.},
booktitle = {Proceedings of the 2008 ACM SIGPLAN-SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems},
pages = {61–70},
numpages = {10},
keywords = {robust schedulability analysis, schedulability analysis, sustainable schedulability analysis},
location = {Tucson, AZ, USA},
series = {LCTES '08}
}

@inproceedings{10.1145/3344948.3344979,
author = {Volpato, Tiago and Allian, Ana and Nakagawa, Elisa Yumi},
title = {Has Social Sustainability Been Addressed in Software Architectures?},
year = {2019},
isbn = {9781450371421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344948.3344979},
doi = {10.1145/3344948.3344979},
abstract = {Research on sustainability in software engineering has gained importance as a result of the need to create better software and therefore avoid compromising future generations opportunities, whether in the social, economic, technical or environmental dimension. Social dimension encompasses the direct support of the software systems in any domain, as well as activities or processes that create benefits for social communities, such as health, education, and transportation. Although social aspects have been previously examined within the broader context of software engineering, the software systems design based on the notion of social sustainability is still poorly understood and practiced. This paper outline relevant points surrounding social sustainability as a concern in software architectures design. In particular, we discuss some issues in designing software systems that generate social values and have a positive impact on communities. We hope that this discussion will help broaden the concept of social sustainability in architectural design decisions and to bring awareness to the particular needs of software systems that have a direct impact on human well-being and contribute to sustainable development.},
booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
pages = {245–249},
numpages = {5},
keywords = {software architecture, social sustainability, sustainability},
location = {Paris, France},
series = {ECSA '19}
}

@inproceedings{10.1145/3266237.3266243,
author = {Costa, Joenio and Meirelles, Paulo and Chavez, Christina},
title = {On the Sustainability of Academic Software: The Case of Static Analysis Tools},
year = {2018},
isbn = {9781450365031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3266237.3266243},
doi = {10.1145/3266237.3266243},
abstract = {From 1991 to 2015, 60 papers published in the ASE and SCAM conferences introduced static analysis prototypes or tools as academic software developed to support research. In this study, we characterize such academic software concerning sustainability. We performed an exploratory study regarding publicization (whether the software is available from an explicitly given URL in a software publication), evolution stage (initial development, evolution, servicing, phase-out or close-down), and recognition (the way others mention the software in their papers). Thereby, we discussed the results under the umbrella of software sustainability. Results for the academic software for static analysis published at ASE and SCAM, show that 40% are not publicly available from the URL informed by the authors; 78% are in an initial development stage, discontinued, or closed-down; 23% has no mentions in relevant digital libraries besides the original software publication, but 30% received contributions to their source code. We observed that a large number of academic static analysis software has inadequate publicization, short life cycles and low recognition. A systematic analysis of publicization, software life cycle, and recognition of academic software is viable, and its results may be useful to support rapid decision-making on adopting academic software for use or even as a target for contribution. The results may also promote a more inclusive view of scientific reputation with respect to the academic software produced by researchers.},
booktitle = {Proceedings of the XXXII Brazilian Symposium on Software Engineering},
pages = {202–207},
numpages = {6},
keywords = {publicization of software, technical sustainability, software evolution, recognition of software, academic software},
location = {Sao Carlos, Brazil},
series = {SBES '18}
}

@article{10.1145/3573074.3573085,
author = {Moises de Souza, Ana Carolina},
title = {Social Sustainability Approaches for a Sustainable Software Product},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3573074.3573085},
doi = {10.1145/3573074.3573085},
abstract = {Sustainability is the use of existing resources without compromising them for future generations. Resources must be guaranteed in the environmental, economic, and social dimensions. Sustainable Software Engineering is an emerging research field aiming to minimize software development's negative impacts on society. Furthermore, software sustainability can be defined as a way of keeping something running at a certain level of quality in relation to these dimensions. From the social dimension perspective, it is necessary to confirm software's trade-offs, benefits, and impacts on society since it lacks empirical evidence of its achievements in software. In this research thesis, we will explore how the literature addresses the aspect of social sustainability during software development and understand how social sustainability approaches can be integrated into the context of agile software development. In the end, we expect to have a set of guidelines, activities, and practices that can be adopted by agile teams.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {38–43},
numpages = {6},
keywords = {experimentation, human factors, security, documentation, management, measurement, performance, design, algorithms}
}

@inproceedings{10.1145/3555228.3555236,
author = {Karita, Leila and Mour\~{a}o, Brunna Caroline and Machado, Ivan},
title = {Towards a Common Understanding of Sustainable Software Development},
year = {2022},
isbn = {9781450397353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555228.3555236},
doi = {10.1145/3555228.3555236},
abstract = {The underlying principles of Sustainable Software Engineering are a core set of competencies Software Engineers need for defining, building, and running sustainable software applications. However, despite its importance, recently published studies have shown that Software Engineers have not reached a common and clear understanding of Sustainable Software Development (SSD). Consequently, it might be challenging to understand the value of the principles behind sustainability and how Software Engineers should apply them in practice. Therefore, the first step is to promote a field characterization to mitigate such effects to bridge such a gap. This paper reports on qualitative data analysis to leverage the sustainability principles through the support of the Grounded Theory method. We conducted this study using unstructured data retrieved from a systematic mapping study on sustainable software engineering and a survey applied in the software industry. To achieve the principles, we considered five critical dimensions: economic, social, individual, environmental, and technical. The key results are: (i) technical, environmental, and social concerns are present in all software development life-cycle (SDLC) phases; (ii) software engineers should consider sustainability requirements in the early SDLC phases; (iii) there is a need for stakeholder engagement focused on sustainability; (iv) software quality requirements support the development of sustainable software; and (v) sustainable concerns could generate trade-offs in the project. The yielded results might trigger further discussions around the SSD’s underlying principles and concepts and serve as a basis for the research community to identify models, techniques, and tools to support SSD.},
booktitle = {Proceedings of the XXXVI Brazilian Symposium on Software Engineering},
pages = {269–278},
numpages = {10},
keywords = {Empirical Software Engineering, Sustainable Software Engineering, Grounded Theory},
location = {Virtual Event, Brazil},
series = {SBES '22}
}

@inproceedings{10.5555/2337223.2337337,
author = {Clesle, Frank-Dieter},
title = {Supporting Sustainability with Software - an Industrial Perspective (Keynote)},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {Supporting sustainability with software is often summed up in the expression Green IT and directly relates to the reduction of CO2 emissions and energy used by IT. The amount of CO2 used in the IT industry covers 2% of the overall CO2 emissions. Green by IT describes the influence of appropriate software to the remaining 98% of the industry. We estimate that the effect of our sustainability related software on our customers CO2 footprint could be 10.000 times higher than our own. The so called triple bottom line defines sustainability as covering economic, ecological, and social aspects and the dependencies between. Based on this definition of sustainability, software could not only focus on green house gas reduction. Other topics like: consumers protection, sustainable supply, reduction of emission (air, water, waste), recycling, human recourse management and intelligent energy usage must be as well focus areas supported by software. At last software industry should not only focus on delivering tools for life cycle assessment (LCA), we should use it and provide a LCA for our software self. The industrial question is how to increase short and long term profitability by holistically managing economic, social and environmental risks and opportunities supported by software.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {962},
numpages = {1},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@article{10.1145/2695533.2695554,
author = {Joseph, Siny and Namboodiri, Vinod and Dev, Vishnu C.},
title = {A MarketDriven Framework Towards Environmentally Sustainable Mobile Computing},
year = {2014},
issue_date = {December 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0163-5999},
url = {https://doi.org/10.1145/2695533.2695554},
doi = {10.1145/2695533.2695554},
abstract = {Amid the plethora of initiatives and research endeavors targeting the minimization of power and energy consumption of information and communication technologies (ICT), what has been largely missing is an effort to reduce the energy consumption and electronic waste generated by the rapidly growing segment of mobile computing and communication devices. One "green" approach to meet both the goals of minimizing life cycle energy consumption and reducing electronic waste generation is that of increased device lifespan. Increased device lifespans, however, are possible only if the underlying market forces support such a paradigm shift. This paper develops a market-driven framework for mobile phone devices that helps understand the reasons that affect a firm's decision to offer a green choice for consumers (where "green" is defined as devices with longer lifespan) and considers the feasibility, possible benefits, and challenges in increasing device lifespan.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {dec},
pages = {46–48},
numpages = {3}
}

@inproceedings{10.5555/1109180.1109219,
author = {Shyba, Lori M. and Parker, J. R.},
title = {The Pipeline Pinball Energy Thrill Ride Game: A Little Theatre in a Computer Game},
year = {2005},
isbn = {0975153323},
publisher = {Creativity &amp; Cognition Studios Press},
address = {Sydney, AUS},
abstract = {Our world is in a dilemma. We're hooked on hydrocarbons and unless we stop spinning the gears of fossil-fuel dependency we risk being held ransom by what that industry observers call a "logic-defying rally based on fear and speculation." (The National Post, August 2005) As human beings, we don't deserve to be victimized by fear factors ranging from Middle-East politics and terrorism to refinery shut downs and turbo-moneymaking bullishness. No one can fully predict the future but it's easy to see that the stakes are high. For the sake of the world economy and our own peace of mind as individuals, we need to pull out all the stops on alternative energy research and development to help spiral our way out of a vicious circle of fear and fossil fuel dependency. This is where "The Pipeline Pinball Energy Thrill Ride Game" comes into being. This lecture demonstration, meant to accompany a viewing of the game design video, intertextualizes the video's script with the "action story" of the computer pinball game's narrative along pathways of non-linear risks and plot surprises that make it a "little theatre in a serious game." "The Pipeline Pinball Energy Thrill Ride Game" game design is part of Lori Shyba "Spies in the Oilpatch" practice-based PhD dissertation at The University of Calgary, Canada, where the operative inquiry is, "How can computer-mediated interactive theatre activate us to better understand our world's natural energy resources?},
booktitle = {Proceedings of the Second Australasian Conference on Interactive Entertainment},
pages = {245},
numpages = {1},
location = {Sydney, Australia},
series = {IE '05}
}

@inproceedings{10.1145/3447555.3465324,
author = {Liu, Gaosheng and Wang, Lin},
title = {Self-Sustainable Cyber-Physical Systems with Collaborative Intermittent Computing},
year = {2021},
isbn = {9781450383332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447555.3465324},
doi = {10.1145/3447555.3465324},
abstract = {Cyber-physical systems have become a main technology driver for our intelligent society. However, almost all cyber-physical systems rely on battery-powered devices to function, which suffer from high maintenance cost for recharging/replacing the batteries and bring in negative environmental impacts due to the hazardous chemicals used in the batteries. To address this challenge, a new computing paradigm called intermittent computing (IC) was proposed which advocates a battery-free design where cyber-physical devices can be completely powered by energy scavenged from ambient sources such as sunlight, radio waves, and vibrations. Since its advent, many efforts have been made on addressing the challenges in IC, from the hardware to the software stack. In this vision paper, we make a brief summary of existing works on IC and discuss a more realistic setup where, instead of focusing on one IC node as done in most existing works, we propose to build a self-sustainable cyber-physical system through the collaboration of distributed IC devices---collaborative intermittent computing (CIC). We discuss the challenges in CIC and provide a vision for the future cyber-physical systems.},
booktitle = {Proceedings of the Twelfth ACM International Conference on Future Energy Systems},
pages = {316–321},
numpages = {6},
keywords = {cyber-physical systems, low-power sensing and computing, energy harvesting, Intermittent computing},
location = {Virtual Event, Italy},
series = {e-Energy '21}
}

@inbook{10.5555/3467967.C5641401,
title = {Appendix I: Sustainable Computing and Engineering Competence in China},
year = {2021},
isbn = {9781450390590},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Computing Curricula 2020: Paradigms for Global Computing Education}
}

@inproceedings{10.1145/120694.120764,
author = {Surguladze, Levan R. and Samuel, Mark A.},
title = {Algebraic Perturbative Calculations in High Energy Physics: Methods, Algorithms, Computer Programs and Physical Applications},
year = {1991},
isbn = {0897914376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/120694.120764},
doi = {10.1145/120694.120764},
booktitle = {Proceedings of the 1991 International Symposium on Symbolic and Algebraic Computation},
pages = {439–447},
numpages = {9},
location = {Bonn, West Germany},
series = {ISSAC '91}
}

@inproceedings{10.1109/ICSE-SEIS.2017.4,
author = {Renzel, Dominik and Koren, Istv\'{a}n and Klamma, Ralf and Jarke, Matthias},
title = {Preparing Research Projects for Sustainable Software Engineering in Society},
year = {2017},
isbn = {9781538626733},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIS.2017.4},
doi = {10.1109/ICSE-SEIS.2017.4},
abstract = {With the pervasive need for digitization in modern information society, publicly funded research projects increasingly focus on engineering digital approaches to manage societal processes. Such projects inherently face the challenge of establishing a sustainable software engineering culture. A major challenge thereby is that project consortia need to establish a distributed developer community that effectively and resource-efficiently aligns development efforts with the goals and needs of complex societal constellations beyond project lifetime. In this paper we extract empirical evidence from longitudinal studies in two large-scale research projects to outline typical challenges in such problem contexts and to develop an open source software engineering methodology for research projects, including supportive infrastructure and social instruments of community building and awareness. We thus contribute a comprehensive strategy preparing collaborative research projects for sustainable societal software engineering.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Society Track},
pages = {23–32},
numpages = {10},
location = {Buenos Aires, Argentina},
series = {ICSE-SEIS '17}
}

@inproceedings{10.1145/2601248.2601256,
author = {Penzenstadler, Birgit and Raturi, Ankita and Richardson, Debra and Calero, Coral and Femmer, Henning and Franch, Xavier},
title = {Systematic Mapping Study on Software Engineering for Sustainability (SE4S)},
year = {2014},
isbn = {9781450324762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2601248.2601256},
doi = {10.1145/2601248.2601256},
abstract = {Background/Context: The objective of achieving higher sustainability in our lifestyles by information and communication technology has lead to a plethora of research activities in related fields. Consequently, Software Engineering for Sustainability (SE4S) has developed as an active area of research. Objective/Aim: Though SE4S gained much attention over the past few years and has resulted in a number of contributions, there is only one rigorous survey of the field. We follow up on this systematic mapping study from 2012 with a more in-depth overview of the status of research, as most work has been conducted in the last 4 years. Method: The applied method is a systematic mapping study through which we investigate which contributions were made, which knowledge areas are most explored, and which research type facets have been used, to distill a common understanding of the state-of-the-art in SE4S. Results: We contribute an overview of current research topics and trends, and their distribution according to the research type facet and the application domains. Furthermore, we aggregate the topics into clusters and list proposed and used methods, frameworks, and tools. Conclusion: The research map shows that impact currently is limited to few knowledge areas and there is need for a future roadmap to fill the gaps.},
booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {14},
numpages = {14},
keywords = {sustainability, systematic mapping study, software engineering},
location = {London, England, United Kingdom},
series = {EASE '14}
}

@inproceedings{10.1145/3194078.3194083,
author = {Ponsard, Christophe and De Landtsheer, Renaud and Germeau, Fabian},
title = {Building Sustainable Software for Sustainable Systems: Case Study of a Shared Pick-up and Delivery Service},
year = {2018},
isbn = {9781450357326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194078.3194083},
doi = {10.1145/3194078.3194083},
abstract = {Sustainability has become a major concern of the 21st century. With the digital revolution, ICT is actually part of both the problem and the solution. Despite this, sustainability-related design decisions are often left implicit and result from a process involving synergies and trade-offs among many non-functional requirements, including some constraints related to the software development and operation itself. The purpose of this paper is to identify such decisions and analyse the process that resulted into them based on a real-world industrial case with strong sustainability goals: a shared pick-up and delivery service. We also show how available methods for green software engineering help in better shaping this process and highlight some interesting lessons learned from our experience.},
booktitle = {Proceedings of the 6th International Workshop on Green and Sustainable Software},
pages = {31–34},
numpages = {4},
keywords = {optimisation, sustainability, goal analysis, software architecture, caching},
location = {Gothenburg, Sweden},
series = {GREENS '18}
}

@inproceedings{10.1145/2479787.2479817,
author = {Traverso-Rib\'{o}n, Ignacio and Ru\'{\i}z-Rube, Iv\'{a}n and Dodero, Juan Manuel and Palomo-Duarte, Manuel},
title = {Open Data Framework for Sustainable Assessment in Software Forges},
year = {2013},
isbn = {9781450318501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2479787.2479817},
doi = {10.1145/2479787.2479817},
abstract = {In a project-based learning experience, the detailed monitoring of the activities in which team members participate can be useful to evaluate their work. Using learning-oriented assessment procedures, supervisors can assess the teamwork abilities with a formative purpose. Evaluation strategies such as self-assessment, peer assessment and co-assessment are often used to make evaluation formative and sustainable. Conducting an assessment strategy is not easy for team members, since they need before to have a reasonable understanding of the evaluation process and criteria. This paper describes a learning-oriented evaluation methodology and a open data framework that can be applied to collaborative software development project settings. An evaluation rubric and a series of indicators that provide evidences about the developed skills have been elaborated and applied in a small-scale project-based course on Web Engineering. Projects were managed and developed with the help of an open source software forge that contains a ticketing tool for planning and tracking of tasks, a version control repository to save the software deliverables, and using a wiki to host text deliverables. The experience provides evidences in favor of using the assessment method and open data framework to make teamwork evaluation more sustainable.},
booktitle = {Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics},
articleno = {20},
numpages = {8},
keywords = {software forges, assessment, project-based learning},
location = {Madrid, Spain},
series = {WIMS '13}
}

@inproceedings{10.1145/2445196.2445410,
author = {Beck, Robert E. and Joyce, Daniel T.},
title = {Sustainability Improves Student Learning (SISL) in Computing (Abstract Only)},
year = {2013},
isbn = {9781450318686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2445196.2445410},
doi = {10.1145/2445196.2445410},
abstract = {Sustainability has been defined variously as the perpetual maintenance of diverse and productive environments upon which all life depends (Renewable Natural Resources Foundation); the responsible use of resources over an indefinite period of time (National Association of Biology Teachers); or "meet[ing] the needs of the present without compromising the ability of future generations to meet their own needs. (World Commission on Environment and Development)" A sustainable future depends on a workforce of professionals knowledgeable about creating practices, processes, and infrastructure to optimize resource management, and on a community informed about the ethics and influence of human activity on the integrated environmental, economic and social aspects of sustainability. For these reasons we believe that STEM education, which includes computing, is key to developing the knowledge, the technology, the skills, the motivation and the policies needed for a sustainable future. SIGCSE is one of eleven professional societies involved in the Sustainability Improves Student Learning (SISL) project, which seeks to engage those who teach computing in an effort to include sustainability ideas throughout the computing curriculum. This poster presents the current status and future plans of the SISL project, highlighting where and how computing plays a significant role (with special thanks to the ITiCSE sustainability-related working groups for the where and how information).},
booktitle = {Proceeding of the 44th ACM Technical Symposium on Computer Science Education},
pages = {730},
numpages = {1},
keywords = {sustainability},
location = {Denver, Colorado, USA},
series = {SIGCSE '13}
}

@inproceedings{10.1145/3377812.3381402,
author = {Alami, Adam},
title = {The Sustainability of Quality in Free and Open Source Software},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3381402},
doi = {10.1145/3377812.3381402},
abstract = {We learned from the history of software that great software are the ones who manage to sustain their quality. Free and open source software (FOSS) has become a serious software supply channel. However, trust on FOSS products is still an issue. Quality is a trait that enhances trust. In my study, I investigate the following question: how do FOSS communities sustain their software quality? I argue that human and social factors contribute to the sustainability of quality in FOSS communities. Amongst these factors are: the motivation of participants, robust governance style for the software change process, and the exercise of good practices in the pull requests evaluation process.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {222–225},
numpages = {4},
keywords = {software sustainability, FOSS sustainability, software quality sustainability},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00073,
author = {Ayoola, Bimpe},
title = {Evaluation of Stakeholder Mapping and Personas for Sustainable Software Development},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00073},
doi = {10.1109/ICSE-Companion58688.2023.00073},
abstract = {Sustainable software development is a major challenge in the software engineering industry. Software practitioners lack practical guidance or tools for integrating social sustainability in software development processes. This study proposes stakeholder mapping and the use of sustainability personas as a framework to guide software practitioners in making decisions that support socially sustainable software development. We will evaluate the effectiveness in a randomized controlled experiment with 104 final-year undergraduate computer science students who would select features to be included in the development of a software application. We aim to show how these interventions helps to improve software practitioners' perspective of social sustainability in software development.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {270–272},
numpages = {3},
keywords = {stakeholder, personas, social sustainability, sustainability, stakeholder map, software development},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/2486046.2486060,
author = {Lami, Giuseppe and Fabbrini, Fabrizio and Fusani, Mario},
title = {A Methodology to Derive Sustainability Indicators for Software Development Projects},
year = {2013},
isbn = {9781450320627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2486046.2486060},
doi = {10.1145/2486046.2486060},
abstract = {The ever-increasing pervasiveness of Information and Communication Technologies (ICT) not only is determining radical changes in everyone’s life-style, in the social organizations, and in the economic dynamics, but it is causing relevant direct and indirect effects on the environment as well. One of the aspects not yet sufficiently addressed in literature is the sustainability of the software lifecycle. In this paper, we focus on the sustainability management of software development projects. In the practice, software development projects are managed by considering principally parameters as time, costs and quality of work products. We propose a methodological approach aimed at identifying sustainability indicators to be used in project management to set up sustainability objectives for a software development project, to control their achievement during the project itself and, possibly, to adopt corrective actions to maintain the project aligned with them. The availability of such sustainability indicators may contribute to reduce the carbon footprint of the activities performed in software development projects as well as to speed-up the development of a green culture in organizations developing software.},
booktitle = {Proceedings of the 2013 International Conference on Software and System Process},
pages = {70–77},
numpages = {8},
keywords = {Sustainability, Software Project Management, Goal-Question-Metrics},
location = {San Francisco, CA, USA},
series = {ICSSP 2013}
}

@inproceedings{10.1145/2480362.2480585,
author = {Penzenstadler, Birgit},
title = {Towards a Definition of Sustainability in and for Software Engineering},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480585},
doi = {10.1145/2480362.2480585},
abstract = {Sustainability is not supported by traditional software engineering methods. This lack of support leads to inefficient efforts to address sustainability or complete omission of this important concept. Defining and developing adequate support requires a commonly accepted definition of what sustainability means in and for software engineering.We contribute a description of the aspects of sustainability in software engineering.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {1183–1185},
numpages = {3},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@inproceedings{10.1145/3080556.3080562,
author = {Lundstr\"{o}m, Anton and Pargman, Daniel},
title = {Developing a Framework for Evaluating the Sustainability of Computing Projects},
year = {2017},
isbn = {9781450349505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3080556.3080562},
doi = {10.1145/3080556.3080562},
abstract = {Toyama [19] has proposed a "preliminary taxonomy" for classifying computing projects as a way of separating sustainable computing efforts from unsustainable ones. In this paper we explore the feasibility of Toyama's taxonomy. We begin by describing how we revised and developed his taxonomy to make it more practically useful and then conducted a pilot study where we used the revised version to evaluate four computing projects. The pilot study was then used as a foundation for further discussing and developing the revised taxonomy into yet another, third and final version which we have chosen to call the Sustainable Computing Evaluation Framework (SCEF). While our proposed framework (SCEF) is more practically useful than Toyama's "preliminary taxonomy", there are still challenges that need to be addressed and we end the paper by suggesting where future efforts could be focused.},
booktitle = {Proceedings of the 2017 Workshop on Computing Within Limits},
pages = {111–117},
numpages = {7},
keywords = {computing, taxonomy, framework, sustainability, sustainable computing},
location = {Santa Barbara, California, USA},
series = {LIMITS '17}
}

@article{10.1145/3453631,
author = {Mitchell, Caven Cade},
title = {Computing Enabled Me To…promote Sustainability and Help Underserved Communities},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {5},
issn = {0001-0782},
url = {https://doi.org/10.1145/3453631},
doi = {10.1145/3453631},
journal = {Commun. ACM},
month = {apr},
pages = {7},
numpages = {1}
}

@article{10.1145/3555129,
author = {Yin, Likang and Chakraborti, Mahasweta and Yan, Yibo and Schweik, Charles and Frey, Seth and Filkov, Vladimir},
title = {Open Source Software Sustainability: Combining Institutional Analysis and Socio-Technical Networks},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555129},
doi = {10.1145/3555129},
abstract = {Sustainable Open Source Software (OSS) forms much of the fabric of our digital society, especially successful and sustainable ones. But many OSS projects do not become sustainable, resulting in abandonment and even risks for the world's digital infrastructure. Prior work has looked at the reasons for this mainly from two very different perspectives. In software engineering, the focus has been on understanding success and sustainability from the socio-technical perspective: the OSS programmers' day-to-day activities and the artifacts they create. In institutional analysis, on the other hand, emphasis has been on institutional designs (e.g., policies, rules, and norms) that structure project governance. Even though each is necessary for a comprehensive understanding of OSS projects, the connection and interaction between the two approaches have been barely explored.In this paper, we make the first effort toward understanding OSS project sustainability using a dual-view analysis, by combining institutional analysis with socio-technical systems analysis. In particular, we (i) use linguistic approaches to extract institutional rules and norms from OSS contributors' communications to represent the evolution of their governance systems, and (ii) construct socio-technical networks based on longitudinal collaboration records to represent each project's organizational structure. We combined the two methods and applied them to a dataset of developer digital traces from 253 nascent OSS projects within the Apache Software Foundation (ASF) incubator. We find that the socio-technical and institutional features relate to each other, and provide complimentary views into the progress of the ASF's OSS projects. Refining these combined analyses can help provide a more precise understanding of the synchronization between the evolution of institutional governance and organizational structure.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {404},
numpages = {23},
keywords = {institutional design, OSS sustainability, socio-technical systems}
}

@article{10.1145/3597504,
author = {Anjum, Bushra},
title = {A Conversation with Sunita Chandrasekaran: Exploring Sustainable and Portable Software Solutions},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2023},
number = {May},
url = {https://doi.org/10.1145/3597504},
doi = {10.1145/3597504},
abstract = {Ubiquity's senior editor Dr. Bushra Anjum chats with Sunita Chandrasekaran, an associate professor with the Department of Computer and Information Sciences at the University of Delaware. Chandrasekaran discusses her goal, as a researcher as well as an educator, to prepare the next-generation workforce to tackle rich hardware features while exploring suitable software solutions. The discussion also addresses sustainable, maintainable, and portable solutions for legacy code that is traditionally unsuited for modern architectures.},
journal = {Ubiquity},
month = {may},
articleno = {2},
numpages = {4}
}

@inproceedings{10.1145/3320326.3320377,
author = {Babou, Cheikh Saliou Mbacke and Sane, Bernard Ousmane and Diane, Ibrahima and Niang, Ibrahima},
title = {Home Edge Computing Architecture for Smart and Sustainable Agriculture and Breeding},
year = {2019},
isbn = {9781450366458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320326.3320377},
doi = {10.1145/3320326.3320377},
abstract = {Challenges of today and tomorrow in developing countries to ensure sustainable food security for their populations require smart agriculture and breeding. This necessarily depends on water control, soil erosion, livestock management, and so on. At the same time, Internet of Things (IoT) represents the latest evolution of the Internet and can significantly improve the ability to collect, analyze and retrieve data that we can then transform into information, knowledge and finally knowing. In the context of ensuring smart and sustainable agriculture, the importance of IoT seems obvious. Note that, IoT has implications for bandwidth, latency and processing speeds, given the huge amount of data to collect. Edge computing and Systems are one of the emerging solutions to reduce latency and improve bandwidth utilization for real-time applications and services. Thus, to achieve these aims, we propose, in this paper, a new three-tier architecture (3-TIER) for smart agriculture. It is based on that of Home Edge Computing allowing us to achieve ultra-low latency. This architecture will also allow us to effectively solve the problems related to agriculture and livestock breeding, but also to be able to resolve considerably the conflicts between farmers and herders. This proposal will be followed by an experimental validation of HEC architecture using the EdgeCloudSim simulator.},
booktitle = {Proceedings of the 2nd International Conference on Networking, Information Systems &amp; Security},
articleno = {45},
numpages = {7},
keywords = {EdgeCloudSim, Home Edge Computing (HEC), Ultra-low Latency, Edge Computing Systems, Smart Agriculture, Internet of Things (IoT)},
location = {Rabat, Morocco},
series = {NISS19}
}

@inproceedings{10.1145/3019943.3019956,
author = {Kadar, Manuella and Restrepo, Emmanuelle Guti\'{e}rrez y and Ferreira, Fernando and Calado, Jorge and Artifice, Andreia and Sarraipa, Joao and Jardim-Goncalves, Ricardo},
title = {Affective Computing to Enhance Emotional Sustainability of Students in Dropout Prevention},
year = {2016},
isbn = {9781450347488},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3019943.3019956},
doi = {10.1145/3019943.3019956},
abstract = {In ACACIA project, through its Apoya module seeks to provide means and methods to enhance emotional sustainability as innovative approach to student's dropout prevention. Emotional state of the students at risk of dropout have to be assessed and innovative methods for counselling and curricula adaptation should be applied for getting out the student from the risk zone.The aim of this study is to propose an innovative solution to meliorate both emotional state and attention of students in risk of dropout. A scenario is presented in which eyetrackers and webcams are integrated in a platform in order to infer and manage students' emotional state in a smart classroom environment.},
booktitle = {Proceedings of the 7th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion},
pages = {85–91},
numpages = {7},
keywords = {sensors, emotional state detection, Affective computing, student counselling},
location = {Vila Real, Portugal},
series = {DSAI '16}
}

@inproceedings{10.1109/ICSE48619.2023.00169,
author = {McGuire, Sean and Schultz, Erin and Ayoola, Bimpe and Ralph, Paul},
title = {Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00169},
doi = {10.1109/ICSE48619.2023.00169},
abstract = {Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or "pillars"---environmental, social, economic, technical and individual. However; these pillars are theoretically underdeveloped and require refinement. Objectives: The objective of this paper is to generate a better theory of SSE. Method: First, a scoping review was conducted to understand the state of research on SSE and identify existing models thereof. Next, a meta-synthesis of qualitative research on SSE was conducted to critique and improve the existing models identified. Results: 961 potentially relevant articles were extracted from five article databases. These articles were de-duplicated and then screened independently by two screeners, leaving 243 articles to examine. Of these, 109 were non-empirical, the most common empirical method was systematic review, and no randomized controlled experiments were found. Most papers focus on ecological sustainability (158) and the sustainability of software products (148) rather than processes. A meta-synthesis of 36 qualitative studies produced several key propositions, most notably, that sustainability is stratified (has different meanings at different levels of abstraction) and multisystemic (emerges from interactions among multiple social, technical, and sociotechnical systems). Conclusion: The academic literature on SSE is surprisingly non-empirical. More empirical evaluations of specific sustainability interventions are needed. The sustainability of software development products and processes should be conceptualized as multisystemic and stratified, and assessed accordingly.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {1996–2008},
numpages = {13},
keywords = {scoping review, software engineering, meta-synthesis, sustainable development, sustainable software engineering},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@article{10.1145/3402127.3402135,
author = {Bainomugisha, Engineer and Hebig, Regina and Chaudron, Michel},
title = {Sustainable Capacity Building in Software Engineering Research in Africa: The Example of the BRIGHT Project},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3402127.3402135},
doi = {10.1145/3402127.3402135},
abstract = {The software industry is a key engine of economic growth in Africa, which calls for sustainable and innovative approaches to build capacities in software engineering research and education for the continent. This paper presents the BRIGHT project as an example for a collaboration that aims to build such capacity. The collaboration includes institutions in Sweden and Uganda. The goal of the collaboration is to train faculty in software en- gineering and to build a supporting research environment, which includes the creation of networks with the software engineering community at a global scale as well as connecting academia and the local software industry. So far, the project has resulted in 50 publications, a software engineering research centre, software engineering summer schools, and conferences.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jul},
pages = {18–20},
numpages = {3},
keywords = {value-based software engineering, software startups, software business models, software product management, software business, software platforms, software engineering economics, software ecosystems, api economy}
}

@inproceedings{10.1145/2207676.2208396,
author = {Foster, Derek and Lawson, Shaun and Wardman, Jamie and Blythe, Mark and Linehan, Conor},
title = {"Watts in It for Me?": Design Implications for Implementing Effective Energy Interventions in Organisations},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208396},
doi = {10.1145/2207676.2208396},
abstract = {The design of technological interventions to motivate behaviour-based reductions in end-user energy consumption has recently been identified as a priority for the HCI community. Previous interventions have produced promising results, but have typically focused on domestic energy consumption. By contrast, this paper focuses on the workplace context, which presents very different opportunities and challenges. For instance, financial consequences, which have proved successful as motivations in the domestic environment, are not present in the workplace in the context of employees. We describe the outcome of a sequence of workshops that focussed on understanding employee perceptions of energy use in the workplace, with the locus of activity on energy intervention design. Using a grounded theory analysis, we produced a framework of key themes detailing user perceptions and energy intervention design considerations. Our findings provide a framework of considerations for the design of successful workplace energy interventions.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2357–2366},
numpages = {10},
keywords = {energy, organisations, hci, sustainability, behaviour change},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3578245.3585331,
author = {Farahani, Reza and Kimovski, Dragi and Ristov, Sashko and Iosup, Alexandru and Prodan, Radu},
title = {Towards Sustainable Serverless Processing of Massive Graphs on the Computing Continuum},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3585331},
doi = {10.1145/3578245.3585331},
abstract = {With the ever-increasing volume of data and the demand to analyze and comprehend it, graph processing has become an essential approach for solving complex problems in various domains, like social networks, bioinformatics, and finance. Despite the potential benefits of current graph processing platforms, they often encounter difficulties supporting diverse workloads, models, and languages. Moreover, existing platforms suffer from limited portability and interoperability, resulting in redundant efforts and inefficient resource and energy utilization due to vendor and even platform lock-in. To bridge the aforementioned gaps, the Graph-Massivizer project, funded by the Horizon Europe research and innovation program, conducts research and develops a high-performance, scalable, and sustainable platform for information processing and reasoning based on the massive graph (MG) representation of extreme data. In this paper, we briefly introduce the Graph-Massivizer platform. We explore how the emerging serverless computing paradigm can be leveraged to devise a scalable graph analytics tool over a codesigned computing continuum infrastructure. Finally, we sketch seven crucial research questions in our design and outline three ongoing and future research directions for addressing them.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {221–226},
numpages = {6},
keywords = {computing continuum, graph processing, serverless computing, massive graph, sustainability},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@proceedings{10.1145/3314344,
title = {COMPASS '19: Proceedings of the 2nd ACM SIGCAS Conference on Computing and Sustainable Societies},
year = {2019},
isbn = {9781450367141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Accra, Ghana}
}

@inproceedings{10.1145/2996890.3007878,
author = {Carrega, A. and Repetto, M.},
title = {Exploiting Novel Software Development Paradigms to Increase the Sustainability of Data Centers},
year = {2016},
isbn = {9781450346160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996890.3007878},
doi = {10.1145/2996890.3007878},
abstract = {The application of effective energy management strategies in data centers is often hindered by the substantial conflict between the interests of cloud users and infrastructure owners. As a matter of fact, cloud users require that the service level they are paying for is tightly met, whereas data center owners try to cut down their operational expenses.In this paper, we propose a novel consolidation algorithm that exploits emerging software development paradigms. Our approach enables cloud users to indicate their willingness to apply energy saving mechanisms to some of their virtual resources, hence giving infrastructure managers the ability to apply more efficient workload consolidation and to switch their hardware to very low-power states. The result is an optimal trade-off between energy consumption and performance.},
booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
pages = {310–315},
numpages = {6},
keywords = {consolidation algorithms, energy efficiency, software development paradigms, green data centers},
location = {Shanghai, China},
series = {UCC '16}
}

@inproceedings{10.1145/3239235.3239240,
author = {Aljarallah, Sulaiman and Lock, Russell},
title = {An Exploratory Study of Software Sustainability Dimensions and Characteristics: End User Perspectives in the Kingdom of Saudi Arabia (KSA)},
year = {2018},
isbn = {9781450358231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239235.3239240},
doi = {10.1145/3239235.3239240},
abstract = {Background: Sustainability has become an important topic globally and the focus on ICT sustainability is increasing. However, issues exist, including vagueness and complexity of the concept itself, in addition to immaturity of the Software Engineering (SE) field. Aims: The study surveys respondents on software sustainability dimensions and characteristics from their perspectives, and seeks to derive rankings for their priority. Method: An exploratory study was conducted to quantitatively investigate Saudi Arabian (KSA) software user's perceptions with regard to the concept itself, the dimensions and characteristics of the software sustainability. Survey data was gathered from 906 respondents. Results: The results highlight key dimensions for sustainability and their priorities to users. The results also indicate that the characteristics perceived to be the most significant, were security, usability, reliability, maintainability, extensibility and portability, whereas respondents were relatively less concerned with computer ethics (e.g. privacy and trust), functionality, efficiency and reusability. A key finding was that females considered the environmental dimension to be more important than males. Conclusions: The dimensions and characteristics identified here can be used as a means of providing valuable feedback for the planning and implementation of future development of sustainable software.},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {14},
numpages = {10},
keywords = {sustainability dimensions, empirical study, software sustainability},
location = {Oulu, Finland},
series = {ESEM '18}
}

@inproceedings{10.1145/2507908.2507912,
author = {Marin, Radu-Corneliu and Dobre, Ciprian},
title = {Reaching for the Clouds: Contextually Enhancing Smartphones for Energy Efficiency},
year = {2013},
isbn = {9781450323727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2507908.2507912},
doi = {10.1145/2507908.2507912},
abstract = {Energy efficiency has gradually become a compulsory need in mobile computing as the processing requirements for smartphones have increased exponentially. Moreover, the current demand is stretching beyond the extents of modern battery technology. In this sense, we introduce a novel collaboration solution for mobile devices based on a contextual search entitled Hybrid Contextual Cloud for Ubiquitous Platforms comprising of Smartphones (HYCCUPS). HYCCUPS takes advantage of the pervasive nature of smartphones and of current wireless communication technologies as to offer offloading execution of mobile applications in an opportunistic on-the-fly hybrid computing cloud. We design an adaptive contextual search algorithm for schedulling mobile code execution in smartphone communities based on predicting the availability and mobility of devices in the near vicinity. We emulate the HYCCUPS framework based on real user traces and we prove that it improves battery health, maximizes power save, minimizes overall execution time of mobile applications and it preserves or even enhances user experience.},
booktitle = {Proceedings of the 2nd ACM Workshop on High Performance Mobile Opportunistic Systems},
pages = {31–38},
numpages = {8},
keywords = {ubiquitous computing, contextual search, predictability, energy awareness, mobile computing},
location = {Barcelona, Spain},
series = {HP-MOSys '13}
}

@proceedings{10.1145/3209811,
title = {COMPASS '18: Proceedings of the 1st ACM SIGCAS Conference on Computing and Sustainable Societies},
year = {2018},
isbn = {9781450358163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Menlo Park and San Jose, CA, USA}
}

@proceedings{10.1145/3460112,
title = {COMPASS '21: Proceedings of the 4th ACM SIGCAS Conference on Computing and Sustainable Societies},
year = {2021},
isbn = {9781450384537},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Australia}
}

@proceedings{10.1145/3378393,
title = {COMPASS '20: Proceedings of the 3rd ACM SIGCAS Conference on Computing and Sustainable Societies},
year = {2020},
isbn = {9781450371292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ecuador}
}

@inproceedings{10.5555/2429759.2430247,
author = {Widok, Andi H. and Jahr, Paul and Schiemann, Lars and Wohlgemuth, Volker},
title = {Integration of Social Criteria in a Simulation Software for a More Sustainable Production},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Regarding that there still is a lack of simulation systems addressing sustainability as a whole, this project attempts to highlight the resulting shortcomings and show ways to make sustainability more applicable and thus measurable by focusing on the integration of social criteria in an existing Environmental Management Information System (EMIS) that combines discrete event simulation (DES) and life cycle analysis (LCA) as well as material flow analysis (MFA). This contribution will summarize the underlying concepts for the development and utilization of this module of the software tool following the integration and furthermore describe the concrete problems and approaches at the example of modeling, as well as on different levels of the software and along the process of assessing the economical, ecological and social impact of products.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {373},
numpages = {2},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.1145/3538637.3539634,
author = {Rowley, Soroya and Porter, George and Stufft, Monica},
title = {Telling the Story of Climate, Sustainability, and Modern Computing to the General Public},
year = {2022},
isbn = {9781450393973},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3538637.3539634},
doi = {10.1145/3538637.3539634},
abstract = {As the SIGEnergy Workshop solicitation aptly notes, climate change is a risk to our entire planet and mitigating its effects is one of the most urgent challenges we face as a society. In the field of computer science, researchers and the industry have increasingly recognized climate change as an important problem that they will need to solve. The National Science Foundation (NSF)'s March 15, 2022 "Dear Colleague Letter: Design for Sustainability in Computing" [4] implores researchers to do more in this area. Major companies like Apple, Google, Meta, and Microsoft have made commitments to sustainability efforts [2, 7, 8, 12]. These are laudable but top down strategies. Increasingly developers and researchers have focused on integrating sustainability into the design and implementation of the systems they build. However, all too often, there remains a disconnect between those aspirations, the users of these systems, and the developers and researchers that day to day build and maintain these systems. How, therefore, might we better connect the aims with action?},
booktitle = {Proceedings of the Thirteenth ACM International Conference on Future Energy Systems},
pages = {590–593},
numpages = {4},
location = {Virtual Event},
series = {e-Energy '22}
}

@article{10.1145/1377016.1377019,
author = {Greiner, Lynn},
title = {The Truth about Tech Recycling: It's Green or It's Mean},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1091-3556},
url = {https://doi.org/10.1145/1377016.1377019},
doi = {10.1145/1377016.1377019},
abstract = {The awkward thing about getting new tech toys is the fact that there's usually an old tech toy left over, suddenly unloved and unwanted. Over time drawers are filled with old cell phones and MP3 players, piles of old computers linger in our closets, or the obsolete electronics end up in the trash.},
journal = {NetWorker},
month = {jun},
pages = {9–11},
numpages = {3}
}

@proceedings{10.1145/3588001,
title = {COMPASS '23: Proceedings of the 6th ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies},
year = {2023},
isbn = {9798400701498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cape Town, South Africa}
}

@proceedings{10.1145/3530190,
title = {COMPASS '22: Proceedings of the 5th ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies},
year = {2022},
isbn = {9781450393478},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@inproceedings{10.1145/3389673,
author = {Esposito, Christian and Pop, Florin and Choi, Chang},
title = {Session Details: Theme: Information Systems: SFECS - Sustainability of Fog/Edge Computing Systems Track},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3389673},
doi = {10.1145/3389673},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/3329391,
author = {Esposito, Christian and Pop, Florin and Choi, Chang},
title = {Session Details: Theme: Information Systems: SFECS - Sustainability of Fog/Edge Computing Systems Track},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3329391},
doi = {10.1145/3329391},
abstract = {Fog/Edge Computing paradigms are widely used in enterprises to address the emerging challenges of big data analysis, because of their underlying scalable, flexible and distributed data management schemes. The data centers in the Clouds are facing great challenges on the burden of the consequent increasing the amount of data to be man- aged and the additional requirements of location awareness and low latency at the edge of network necessary by smart cites and factories. These are the reasons why a centralized model cannot be an efficient solution for generated or required data by the IoT devices in those applications and there is the progressive shift towards fog nodes and smarted edge nodes mediating between the cloud and the IoT devices. The Fog/Edge computing paradigm is a decentralized model that transfers a part of low computing data analysis from the cloud to the intermediate (fog) nodes or the edges, performing only high computing tasks in the cloud. This new approach tries to minimize the three factors that negatively compromise the effective and efficient application of the Cloud computing to smart cities and factories, or similar application domains: the network bandwidth usage, decentralization of the data processing tasks and reduced response latency for clients (IoT devices). Fog/Edge computing is a hierarchical approach where the overall infrastructure is structured in multiple layers, each responsible of offering a good coordination and data management to the nodes at the lower layer. The lowest layer is usually composed of sensors and/or actuators that measure and/or control the environment or a given business process, implemented as mobile devices that are running a sensing/controlling application. In this case, combining Sustainable computing with Fog and Edge computing represents a new approach for increasing quality-of- service and efficiency of the system, creating the capability to present temporal and geo-coded information, and increasing innovation, and co-designing sustainable future large scale distributed systems. This new paradigm appears to offer a good approach in handling the scale factor of the data size, reducing the network bandwidth usage and the response latency of the system. In order to support specifically the Fog/Edge architectures, there is a need, for instance, of location-awareness and computation placement, replication and recovery. In many cases Edge resources would be required for both computation and data storage to address the time and locality constraints. There are multiple kinds of orchestration management solutions for virtualization in this type of architecture with different characteristics and drawbacks. This results in different restrictions for application definition, scalability, availability, load balancing and so on. Also, virtualization may be needed at multiple levels in a Fog/Edge architecture as it consists of the following levels of abstraction: at the sensing level we have the IoT devices/smart things, at the Edge level there are the gateways to a first collection and the data from the IoT devices and their preliminary processing, at the Fog level we have an additional data management layer, and at the Cloud level there is the compute/storage infrastructure with applications on top. Last, but not least, the energy efficiency is particularly important at the IoT and edge level since the devices may be equipped with a limited battery, possible difficult or impossible to be charged. So, optimizing the energy consumption is a must. To address several open research is- sues regarding sustainability of future Fog/Edge systems, this track aims at solicit contributions highlighting challenges, state-of-the-art, and solutions to a set of currently unresolved key questions including - but not limited to - performance, modeling, optimization, energy-efficiency, reliability, security, privacy and techno-economic aspects of Fog/Edge systems. Through addressing these concerns while understanding their impacts and limitations, technological advancements will be channeled toward more sustainable/efficient platforms for tomorrow's ever-connected systems.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/2905055.2905314,
author = {Saini, Dinesh Kumar and Prakash, Lakshmi Sunil and Gaur, Hemant},
title = {Software Architecture for Smart Card: ICT Solution for Healthcare Industry for Sustainable Development},
year = {2016},
isbn = {9781450339629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2905055.2905314},
doi = {10.1145/2905055.2905314},
abstract = {Health care is one of the largest industry in today's world, data and records generated in health care industry are very difficult to transmit. Security of health data is one major area of concern which health industry is facing today. Smart card is one possible solution which can solve this problem to some extent still this will have some issues. In this paper we propose the smart card solution for health industry. Smart card can help in keeping health records secure, ubiquitous, and user friendly. Migration of the health records will be easier and simpler using the smart card. Smart card can be a multi-purpose solution for patient, insurance company and government.},
booktitle = {Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {100},
numpages = {5},
keywords = {Health System, Information Communication Technology, Health Care, Sustainable Development},
location = {Udaipur, India},
series = {ICTCS '16}
}

@inproceedings{10.1145/3194554.3194602,
author = {Wang, Longfei and K\"{o}se, Sel\c{c}uk},
title = {Reliable On-Chip Voltage Regulation for Sustainable and Compact IoT and Heterogeneous Computing Systems},
year = {2018},
isbn = {9781450357241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194554.3194602},
doi = {10.1145/3194554.3194602},
abstract = {As an essential part of modern power delivery networks, on-chip voltage regulation consisting of multiple distributed voltage regulators provides the required power and voltage levels for localized load circuits. The harsh application environment of internet of things (IoT) and heterogeneous computing systems including, but not limited to, high temperature and large load current variations, can lead to significant and uneven performance degradations of on-chip voltage regulators due to aging. Investigating sustainable on-chip voltage regulation schemes considering the lifetime of different distributed voltage regulators becomes imperative. Furthermore, techniques to mitigate the aging induced voltage regulator degradations can consume the scarce on-chip area resource. In this work, a new reliable on-chip voltage regulation technique is explored to simultaneously mitigate the performance degradation and reduce the area cost of distributed on-chip voltage regulators to achieve sustainable and compact design and satisfy the needs of different IoT and heterogeneous computing systems considering the interactions among different regulators. A brief survey of reliable design challenges and potential solutions is also provided.},
booktitle = {Proceedings of the 2018 on Great Lakes Symposium on VLSI},
pages = {285–290},
numpages = {6},
keywords = {reliability, internet of things, on-chip voltage regulation, heterogeneous computing},
location = {Chicago, IL, USA},
series = {GLSVLSI '18}
}

@inproceedings{10.1145/2345396.2345491,
author = {Raju, C. K. and Mishra, Ashok and Bhadoria, P. B. S.},
title = {Synthesis of Sustainability and Secureness of Software in Public Applications Using Deductive-Nomological Model},
year = {2012},
isbn = {9781450311960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2345396.2345491},
doi = {10.1145/2345396.2345491},
abstract = {Sustainability and secureness of software gain prominence when the software application serves public needs. Sustainability of software is an important concept for the agency providing the service, and secureness of software is often a concern of the citizens whose information get processed. There do not exist sufficient theories which adequately explain sustainability and secureness of software which serves some public application. In this work, an attempt was made to synthesize and explain sustainability and secureness of software using a Hempelian deductive-nomological (D-N) model. The covering law for the D-N model capable of explaining software sustainability was derived from world commission's report on sustainable development, and the covering law for the model describing software secureness was derived from standards related to information security management. Using the premises of the D-N model, a software prototype was designed and developed that showed promise of enhancing software sustainability as well as software secureness. A monitoring software associated with a rural employment guarantee scheme was used as a sample case.},
booktitle = {Proceedings of the International Conference on Advances in Computing, Communications and Informatics},
pages = {579–588},
numpages = {10},
keywords = {software sustainability, software secureness, logic},
location = {Chennai, India},
series = {ICACCI '12}
}

@inproceedings{10.1007/978-3-642-25821-3_8,
author = {Zhang, Yanwei and Wang, Yefu and Wang, Xiaorui},
title = {GreenWare: Greening Cloud-Scale Data Centers to Maximize the Use of Renewable Energy},
year = {2011},
isbn = {9783642258206},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-25821-3_8},
doi = {10.1007/978-3-642-25821-3_8},
abstract = {To reduce the negative environmental implications (e.g., <em>CO</em> 2 emission and global warming) caused by the rapidly increasing energy consumption, many Internet service operators have started taking various initiatives to operate their cloud-scale data centers with renewable energy. Unfortunately, due to the intermittent nature of renewable energy sources such as wind turbines and solar panels, currently renewable energy is often more expensive than brown energy that is produced with conventional fossil-based fuel. As a result, utilizing renewable energy may impose a considerable pressure on the sometimes stringent operation budgets of Internet service operators. Therefore, two key questions faced by many cloud-service operators are 1) how to dynamically distribute service requests among data centers in different geographical locations, based on the local weather conditions, to maximize the use of renewable energy, and 2) how to do that within their allowed operation budgets.In this paper, we propose GreenWare, a novel middleware system that conducts dynamic request dispatching to maximize the percentage of renewable energy used to power a network of distributed data centers, subject to the desired cost budget of the Internet service operator. Our solution first explicitly models the intermittent generation of renewable energy, e.g., wind power and solar power, with respect to varying weather conditions in the geographical location of each data center. We then formulate the core objective of GreenWare as a constrained optimization problem and propose an efficient request dispatching algorithm based on linear-fractional programming (LFP). We evaluate GreenWare with real-world weather, electricity price, and workload traces. Our experimental results show that GreenWare can significantly increase the use of renewable energy in cloud-scale data centers without violating the desired cost budget, despite the intermittent supplies of renewable energy in different locations and time-varying electricity prices and workloads.},
booktitle = {Proceedings of the 12th ACM/IFIP/USENIX International Conference on Middleware},
pages = {143–164},
numpages = {22},
location = {Lisbon, Portugal},
series = {Middleware'11}
}

@inproceedings{10.1145/3401335.3401670,
author = {Eriksson, Elina and Rivera, Miriam B\"{o}rjesson and Hedin, Bj\"{o}rn and Pargman, Daniel and Hasselqvist, Hanna},
title = {Systems Thinking Exercises in Computing Education: Broadening the Scope of ICT and Sustainability},
year = {2020},
isbn = {9781450375955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3401335.3401670},
doi = {10.1145/3401335.3401670},
abstract = {Integrating sustainability in computing education entails broadening the scope of the education, but how can that be done while maintaining student engagement? Climate change and species extinction can appear far removed from data structures and algorithms to say the least. In our ongoing work of integrating sustainability in our Media Technology programme, we have addressed this gap by introducing systems thinking games and activities to broaden the scope, as well as by situating the issues addressed in the course in relation to their future profession. In this paper, we present our experiences of introducing and playing systems thinking games, how the systems thinking exercise sessions were conducted, outcomes of the sessions and finally some lessons learnt. Furthermore, we present and analyse changes we did to the exercises and that led to a richer material for discussions in the classroom.},
booktitle = {Proceedings of the 7th International Conference on ICT for Sustainability},
pages = {170–176},
numpages = {7},
keywords = {computing, education, games, Systems thinking},
location = {Bristol, United Kingdom},
series = {ICT4S2020}
}

@proceedings{10.1145/2034649,
title = {MAASC '11: Proceedings of the 1st Workshop on Middleware and Architectures for Autonomic and Sustainable Computing},
year = {2011},
isbn = {9781450308472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {You will find in these pages the Proceedings of the 1st Workshop on Middleware and Architectures for Autonomic and Sustainable Computing (MAASC'11), which was held in Paris, France, in collocation with the 11th International Conference on New Technologies of Distributed Systems (NOTERE'11). MAASC was a particularly lively event, with two exciting keynote presentations, and four papers presented.},
location = {Paris, France}
}

@inproceedings{10.5555/2429759.2429967,
author = {Widok, Andi H. and Schiemann, Lars and Jahr, Paul and Wohlgemuth, Volker},
title = {Achieving Sustainability through a Combination of LCA and DES Integrated in a Simulation Software for Production Processes},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {This paper outlines the application of a special Environmental Management Information System (EMIS) that combines discrete event simulation (DES) and life cycle analysis (LCA) in addition to material flow analysis as an integrated part of the simulation software. The motivation behind the combination of these different techniques is to close the gap between identifying only parts of the life cycle, namely production processes, when simulating such processes, while at the same time focusing more sharply on LCA allowing for the resolution of results by DES and the detailed view of what is or might be happening in the production phase of the cycle. This view focuses not only on economic optimization but also on material flow analysis with a possible integration of social criteria opening the door to sustainable production in reality in the future. The paper will highlight important development phases as well as current applications of the software.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {155},
numpages = {12},
location = {Berlin, Germany},
series = {WSC '12}
}

@proceedings{10.1145/3093338,
title = {PEARC '17: Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact},
year = {2017},
isbn = {9781450352727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {New Orleans, LA, USA}
}

@inproceedings{10.5555/2819009.2819244,
author = {Rubin, Julia and Botterweck, Goetz and Pleuss, Andreas and Weiss, David},
title = {5th International Workshop on Product Line Approaches in Software Engineering PLE for a Sustainable Society (PLEASE 2015)},
year = {2015},
publisher = {IEEE Press},
abstract = {This paper summarizes the motivation, objectives, and format of the 5th International Workshop on Product LinE Approaches in Software Engineering (PLEASE15). The main goal of the PLEASE workshop series is to encourage and promote the adoption of Software Product Line Engineering. This year's edition focuses on the link between software product line engineering (SPLE) and new challenges posed by emerging societal trends. Towards this end, we invited reports on (1) opportunities posed by societal challenges for SPLE research and practice and (2) concrete solutions exemplifying application of SPLE techniques to societal challenges.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {989–990},
numpages = {2},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/2048147.2048229,
author = {Mancl, Dennis and Fraser, Steven D. and Opdyke, Bill},
title = {Workshop: Beyond Green-Field Software Development: Reuse, Recycle, Refactor},
year = {2011},
isbn = {9781450309424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2048147.2048229},
doi = {10.1145/2048147.2048229},
abstract = {There are many languages, tools, and design methodologies in the software community that are aimed at the creation of new software. But a lot of valuable software is the product of evolution, reuse, and reengineering. Some software is too expensive to "throw away and start over." A skilled software team will have an arsenal of techniques at their disposal for adapting, evolving, and refactoring existing code and designs. Adapting legacy software is a kind of recycling. If extending a legacy system is done well, it can help deliver business value sooner at a lower cost.This workshop will explore some old and new techniques for building on existing code -- wrapper classes, design patterns, test-driven approaches, refactoring tools, and others. The workshop will also address management issues: what factors to consider in the decision to reengineer or to build anew. This workshop revisits a topic discussed in an OOPSLA 2003 workshop.},
booktitle = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion},
pages = {321–322},
numpages = {2},
keywords = {legacy code, reengineering, refactoring},
location = {Portland, Oregon, USA},
series = {OOPSLA '11}
}

@inproceedings{10.1145/1594233.1594271,
author = {Bash, Cullen E.},
title = {Sustainable IT Ecosystems and Data Centers},
year = {2009},
isbn = {9781605586847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1594233.1594271},
doi = {10.1145/1594233.1594271},
abstract = {A recent study found that IT contributes about 2% of global greenhouse gas emissions, in line with that of the aviation industry. Furthermore, it projected that that this share would double by the year 2020. Increasing environmental concern and regulatory action will soon force a paradigm shift in how IT solutions are designed and managed across their lifecycles. Data centers are a prominent and fast growing component of this impact.To address these concerns, we propose the development of a suite of technologies for a sustainable data center (SDC). The goal is to reduce the environmental footprint of a data center to such an extent that the services it offers are more environmentally friendly than conventional services offered within today's state-of-the-art facilities.Developing and demonstrating a SDC requires the multi-disciplinary collaboration of mechanical engineers, electrical engineers, computer scientists, and others. The compute infrastructure of the data center consists of thousands of servers hosting revenue-generating services, interconnected with each other and the outside world via networking equipment, and relying on storage devices for persistent data. The data center also has a power infrastructure that feeds electricity to all of the equipment, and a cooling infrastructure that removes heat from the equipment. The economic and environmental burden of the latter two infrastructures can often equal that of the compute infrastructure.All of these infrastructures, and many of their components, have traditionally been designed and managed independently, resulting in unnecessary redundancy and waste. For example, CRAC units are often provisioned in high availability (tier 4) data centers at twice the required capacity. This is to ensure sufficient backup cooling capacity in the event of failure. However, we have previously shown how to map the thermal zones of influence for each CRAC, and how to identify regions of the data center that naturally have high levels of cooling redundancy. Using such thermal zones, hardware can be provisioned to services based on availability and reliability requirements. For example, critical workloads can be placed within regions of the data center that are served by multiple thermal zones. The economic and environmental benefit of eliminating a redundant standby CRAC unit illustrates the type of advantage that can be garnered through integration of the compute and cooling infrastructures in the data center. Similarly integrating design and management of an entire data center, both within and across its compute, power, and cooling infrastructures, is crucial to improved operational efficiency and reduced environmental impact.We identify five principles for integrated design and management that cut across all three infrastructures, and indeed cut across the multiple disciplines that are needed to achieve this goal. This talk will describe each of these five principles and discuss how they can be employed to improve IT and data center sustainability.},
booktitle = {Proceedings of the 2009 ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {155–156},
numpages = {2},
keywords = {energy efficiency, sustainability, data centers},
location = {San Fancisco, CA, USA},
series = {ISLPED '09}
}

@inproceedings{10.1145/3472749.3474819,
author = {Guo, Philip},
title = {Ten Million Users and Ten Years Later: Python Tutor’s Design Guidelines for Building Scalable and Sustainable Research Software in Academia},
year = {2021},
isbn = {9781450386357},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472749.3474819},
doi = {10.1145/3472749.3474819},
abstract = {Research software is often built as prototypes that never get widespread usage and are left unmaintained after a few papers get published. To counteract this trend, we propose a method for building research software with scale and sustainability in mind so that it can organically grow a large userbase and enable longer-term research. To illustrate this method, we present the design and implementation of Python Tutor (pythontutor.com), a code visualization tool that is, to our knowledge, one of the most widely-used pieces of research software developed within a university lab. Over the past decade, it has been used by over ten million people in over 180 countries. It has also contributed to 55 publications from 35 research groups in 13 countries. We distilled lessons from working on Python Tutor into three sets of design guidelines: 1) user experience design for scale and sustainability, 2) software architecture design for long-term sustainability, and 3) designing a sustainable software development workflow within academia. These guidelines can enable a student to create long-lasting software that reaches many users and facilitates research from many independent groups.},
booktitle = {The 34th Annual ACM Symposium on User Interface Software and Technology},
pages = {1235–1251},
numpages = {17},
keywords = {Python Tutor, sustainability, code visualization, research software},
location = {Virtual Event, USA},
series = {UIST '21}
}

@inproceedings{10.1145/1631728.1631755,
author = {Stanley, Timothy Daryl and Colton, Don},
title = {Six Years of Sustainable IT Service Learning},
year = {2009},
isbn = {9781605587653},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1631728.1631755},
doi = {10.1145/1631728.1631755},
abstract = {This paper describes six years of experience in a bi-annual personal computer (PC) repair, service learning project for IT students. The location is a relatively remote community of professionals with many personal computers exposed to a humid salt air environment. The idea came from an informal survey at a local elementary school where half the students with a PC indicated that they were broken. At the end of each semester, for the last two labs of our PC hardware and operating systems class, we invited people from the community to bring in their PCs for service troubleshooting help and repair advice. This paper explains how issues of data integrity, security and liability were solved as well as the learning outcomes from these six years of service learning computer repair workshops.},
booktitle = {Proceedings of the 10th ACM Conference on SIG-Information Technology Education},
pages = {87–90},
numpages = {4},
keywords = {information technology education, service learning, pc hardware &amp; operating systems},
location = {Fairfax, Virginia, USA},
series = {SIGITE '09}
}

@inproceedings{10.1145/1654059.1654125,
author = {Eisenbach, M. and Zhou, C.-G. and Nicholson, D. M. and Brown, G. and Larkin, J. and Schulthess, T. C.},
title = {A Scalable Method for Ab Initio Computation of Free Energies in Nanoscale Systems},
year = {2009},
isbn = {9781605587448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1654059.1654125},
doi = {10.1145/1654059.1654125},
abstract = {Calculating the thermodynamics of nanoscale systems presents challenges in the simultaneous treatment of the electronic structure, which determines the interactions between atoms, and the statistical fluctuations that become ever more important at shorter length scales. Here we present a highly scalable method that combines ab initio electronic structure techniques, we use the Locally Self-Consitent Multiple Scattering (LSMS) technique, with the Wang-Landau (WL) algorithm to compute free energies and other thermodynamic properties of nanoscale systems. The combined WL-LSMS code is targeted to the study of nanomagnetic systems that have anywhere from about one hundred to a few thousand atoms. The code scales very well on the Cray XT5 system at ORNL, sustaining 1.03 Petaflop/s in double precision on 147,464 cores.},
booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},
articleno = {64},
numpages = {8},
location = {Portland, Oregon},
series = {SC '09}
}

@article{10.1145/2692208,
author = {JafariNaimi, Nassim and Meyers, Eric},
title = {Play It Seriously: Fostering Innovative Engagement with Sustainability},
year = {2015},
issue_date = {January + February 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
issn = {1072-5520},
url = {https://doi.org/10.1145/2692208},
doi = {10.1145/2692208},
abstract = {In this forum we highlight innovative thought, design, and research in the area of interaction design and sustainability, illustrating the diversity of approaches across HCI communities. --- Lisa Nathan and Samuel Mann, Editors},
journal = {Interactions},
month = {jan},
pages = {68–70},
numpages = {3}
}

@inproceedings{10.1145/2901739.2901763,
author = {Chowdhury, Shaiful Alam and Hindle, Abram},
title = {GreenOracle: Estimating Software Energy Consumption with Energy Measurement Corpora},
year = {2016},
isbn = {9781450341868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2901739.2901763},
doi = {10.1145/2901739.2901763},
abstract = {Software energy consumption is a relatively new concern for mobile application developers. Poor energy performance can harm adoption and sales of applications. Unfortunately for the developers, the measurement of software energy consumption is expensive in terms of hardware and difficult in terms of expertise. Many prior models of software energy consumption assume that developers can use hardware instrumentation and thus cannot evaluate software running within emulators or virtual machines. Some prior models require actual energy measurements from the previous versions of applications in order to model the energy consumption of later versions of the same application.In this paper, we take a big-data approach to software energy consumption and present a model that can estimate software energy consumption mostly within 10% error (in joules) and does not require the developer to train on energy measurements of their own applications. This model leverages a big-data approach whereby a collection of prior applications' energy measurements allows us to train, transmit, and apply the model to estimate any foreign application's energy consumption for a test run. Our model is based on the dynamic traces of system calls and CPU utilization.},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
pages = {49–60},
numpages = {12},
location = {Austin, Texas},
series = {MSR '16}
}

@inproceedings{10.1145/1851182.1851272,
author = {Aggarwal, Bhavish and Chitnis, Pushkar and Dey, Amit and Jain, Kamal and Navda, Vishnu and Padmanabhan, Venkata N. and Ramjee, Ramachandran and Schulman, Aaron and Spring, Neil},
title = {Stratus: Energy-Efficient Mobile Communication Using Cloud Support},
year = {2010},
isbn = {9781450302012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851182.1851272},
doi = {10.1145/1851182.1851272},
abstract = {Cellular radio communication is a significant contributor to battery energy drain on smartphones, in some cases inflating the energy cost by a factor of 5 or more compared to the energy cost of the base device. Stratus is a system to reduce this energy consumption by leveraging cloud resources to make data communication on smartphones more efficient. Using a cloud-based proxy, Stratus employs optimizations that adapt an application's incoming and outgoing traffic to better match the energy characteristics of the radio interface. The optimizations include (a) aggregation to bunch up sporadic transmissions, (b) asymmetric dictionary-based compression to reduce the number of bits transmitted over the air, and (c) opportunistic scheduling to avoid communication during periods of poor signal reception. These optimizations can be used individually, or in combination, subject to an application's delay tolerance. For example, using our Stratus prototype, the aggregation and compression optimizations together achieve up to 50% energy savings for web browsing, while the aggregation and scheduling optimizations together achieve up to 35% energy savings for a media streaming application.},
booktitle = {Proceedings of the ACM SIGCOMM 2010 Conference},
pages = {477–478},
numpages = {2},
keywords = {cloud proxy, energy, smartphone},
location = {New Delhi, India},
series = {SIGCOMM '10}
}

@inproceedings{10.1145/3149572.3149578,
author = {Marhraoui, Mohamed Amine and El Manouar, Abdellah},
title = {IT Innovation and Firm's Sustainable Performance: The Mediating Role of Organizational Agility},
year = {2017},
isbn = {9781450353373},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3149572.3149578},
doi = {10.1145/3149572.3149578},
abstract = {During the last ten years, the business environment has become complex and turbulent. Companies should thus innovate in order to gain competitive advantage. By proposing new IT innovations or adopting new ways to use existing IT innovations, firms are able to sense customers' needs and to design rapidly new products and services. In this article, an original framework is proposed. It links IT innovations and company's sustainable performance and highlights the intermediary role of firm's organizational agility. An inductive/deductive methodology was adopted by formulating general findings and a research question based on observations of both large corporate and SMEs in banking and telecommunications sectors.},
booktitle = {Proceedings of the 9th International Conference on Information Management and Engineering},
pages = {150–156},
numpages = {7},
keywords = {Environmental performance, IT innovation, Social performance, Organizational agility, Economic performance},
location = {Barcelona, Spain},
series = {ICIME 2017}
}

@inproceedings{10.1145/1358628.1358870,
author = {Kase, Sue E. and Zhang, Yang and Carroll, John M. and Rosson, Mary Beth},
title = {Sustainable Informal It Learning in Community-Based Nonprofits},
year = {2008},
isbn = {9781605580128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1358628.1358870},
doi = {10.1145/1358628.1358870},
abstract = {Nonprofit organizations (NPOs) play a substantial role in the economies of many countries, in the delivery of social services, and in many quasi-government functions. But NPOs face many resource challenges; for example, they depend on volunteer labor that is often under-trained and has high turnover resulting in limited knowledge acquisition and decreased sustainability. Ethnographic data from a three-year multi-organizational analysis reveals the occurrence of social and technical patterns during informal technology learning. Construction of a pattern schema grounded in organizational learning and activity theories will enable the development of lightweight interventions in establishing information technology sustainability, self-directed learning, and management processes in NPOs.},
booktitle = {CHI '08 Extended Abstracts on Human Factors in Computing Systems},
pages = {3435–3440},
numpages = {6},
keywords = {participatory design, informal learning, nonprofits},
location = {Florence, Italy},
series = {CHI EA '08}
}

@inproceedings{10.1145/3417113.3422999,
author = {Maia, Daniel and Couto, Marco and Saraiva, Jo\~{a}o and Pereira, Rui},
title = {E-Debitum: Managing Software Energy Debt},
year = {2021},
isbn = {9781450381284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417113.3422999},
doi = {10.1145/3417113.3422999},
abstract = {This paper extends previous work on the concept of a new software energy metric: Energy Debt. This metric is a reflection on the implied cost, in terms of energy consumption over time, of choosing an energy flawed software implementation over a more robust and efficient, yet time consuming, approach.This paper presents the implementation a SonarQube tool called E-Debitum which calculates the energy debt of Android applications throughout their versions. This plugin uses a robust, well defined, and extendable smell catalog based on current green software literature, with each smell defining the potential energy savings. To conclude, an experimental validation of E-Debitum was executed on 3 popular Android applications with various releases, showing how their energy debt fluctuated throughout releases.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {170–177},
numpages = {8},
keywords = {green software, energy debt, code analysis},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/2445196.2445372,
author = {Koh, Kyu Han and Repenning, Alexander and Nickerson, Hilarie and Endo, Yasko and Motter, Pate},
title = {Will It Stick? Exploring the Sustainability of Computational Thinking Education through Game Design},
year = {2013},
isbn = {9781450318686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2445196.2445372},
doi = {10.1145/2445196.2445372},
abstract = {A strategy exposing middle school students to computer science through game design appears to be a promising means to mitigate the computer science pipeline challenge. Particularly when short game design activities are integrated into already existing middle school courses, research suggests that game design is effective in broadening participation and motivating large numbers of students, along with large percentages of women and minorities. A study with over 10,000 students is exploring the sustainability of this approach and finding positive responses to inquiries such as these: Do teachers continue to use game design? Can they advance beyond extrinsic rewards such as research stipends? After building one game, do students advance, building more games or even STEM simulations?},
booktitle = {Proceeding of the 44th ACM Technical Symposium on Computer Science Education},
pages = {597–602},
numpages = {6},
keywords = {zone of proximal flow, simulation design, computational thinking, sustainability, game design},
location = {Denver, Colorado, USA},
series = {SIGCSE '13}
}

@inproceedings{10.1145/2148600.2148651,
author = {Knobloch, Michael and Minartz, Timo and Molka, Daniel and Krempel, Stephan and Ludwig, Thomas and Mohr, Bernd},
title = {Electronic Poster: Eeclust: Energy-Efficient Cluster Computing},
year = {2011},
isbn = {9781450310307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2148600.2148651},
doi = {10.1145/2148600.2148651},
abstract = {The eeClust project aims at reducing the energy consumption of applications on a HPC cluster by an integrated approach of analysis, efficient management of hardware power-states and monitoring of the clusters power consumption. The application is traced and the trace file is analyzed - manually with Vampir and automatically with Scalasca - to determine phases in the application with non-optimal hardware utilization. The source-code is then instrumented with API calls to control a daemon which switches hardware power-states at runtime. This daemon is aware of shared resources (e.g. the network interface) and only switches a resource to a lower power-state when all processes sharing that resource do not need it. The ParaStation Grid Monitor is used to monitor and visualize the power consumption and hardware usage of the cluster. This poster gives an overview of the project and presents the analysis, hardware management and monitoring aspects in more detail.},
booktitle = {Proceedings of the 2011 Companion on High Performance Computing Networking, Storage and Analysis Companion},
pages = {99–100},
numpages = {2},
keywords = {benchmark, analysis, power, monitoring, energy},
location = {Seattle, Washington, USA},
series = {SC '11 Companion}
}

@inproceedings{10.1109/ISLPED52811.2021.9502472,
author = {Marculescu, Diana},
title = {When Climate Meets Machine Learning: Edge to Cloud ML Energy Efficiency},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISLPED52811.2021.9502472},
doi = {10.1109/ISLPED52811.2021.9502472},
abstract = {A large portion of current cloud and edge workloads feature Machine Learning (ML) tasks, thereby requiring a deep understanding of their energy efficiency. While the holy grail for judging the quality of a ML model has largely been testing accuracy, and only recently its resource usage, neither of these metrics translate directly to energy efficiency, runtime, or mobile device battery lifetime. This work uncovers the need for building accurate, platform-specific power and latency models for ML and efficient hardware-aware ML design methodologies, thus allowing machine learners and hardware designers to identify not just the best accuracy ML model configuration, but also those that satisfy given hardware constraints.},
booktitle = {Proceedings of the ACM/IEEE International Symposium on Low Power Electronics and Design},
articleno = {37},
numpages = {1},
keywords = {model compression, neural architecture search, hardware-aware ML, quantization},
location = {Boston, Massachusetts},
series = {ISLPED '21}
}

@inproceedings{10.1145/1551609.1551610,
author = {Gentzsch, Wolfgang},
title = {Sustainable HPC Infrastructures - Supercomputers, Grids, and Clouds: The DEISA Experience},
year = {2009},
isbn = {9781605585871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1551609.1551610},
doi = {10.1145/1551609.1551610},
booktitle = {Proceedings of the 18th ACM International Symposium on High Performance Distributed Computing},
pages = {69–70},
numpages = {2},
keywords = {e-science, infrastructure sustainability, grid computing, cloud computing, high performance computing},
location = {Garching, Germany},
series = {HPDC '09}
}

@inproceedings{10.1145/2830629.2835222,
author = {Baig, Roger and Freitag, Felix and Moll, Agust\'{\i} and Navarro, Leandro and Pueyo, Roger and Roca, Ramon},
title = {From Sustainable Community Networks to Sustainable Community Clouds},
year = {2015},
isbn = {9781450334907},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2830629.2835222},
doi = {10.1145/2830629.2835222},
abstract = {The advent of community networks has shown that citizens can take action not only at the technical level to expand the Internet but also at the governance level. What started as isolated and uncoordinated efforts to, mainly, bring connectivity to undeserved areas (using hacked WiFi devices -- the so called Wireless communities) has evolved into self-organised groups offering effective tools to empower people to self-satisfy their telecommunication needs under sustainable alternative models to the dominant one in the global Internet. Inspired by the success of community networks we propose the community network cloud (community cloud) as an instrument to fight the threat posed by the concentration of vast amount of data in few multinational corporations (privacy, vendor lock-in, etc.) and to make the use of the community network infrastructure more efficient.},
booktitle = {Proceedings of the 2015 Annual Symposium on Computing for Development},
pages = {81–82},
numpages = {2},
keywords = {Community networks, community clouds, sustainability},
location = {London, United Kingdom},
series = {DEV '15}
}

@inproceedings{10.1145/3407023.3409226,
author = {Vidal, Jorge Maestre and Monge, Marco Antonio Sotelo},
title = {Denial of Sustainability on Military Tactical Clouds},
year = {2020},
isbn = {9781450388337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3407023.3409226},
doi = {10.1145/3407023.3409226},
abstract = {As the digitalization of the military conflicts increases, gaining decision superiority become the key to enhance the likelihood of success, which among others is enabled by bringing to the tactical edge emerging ICT paradigms like advanced data fusion, Artificial Intelligence, distributed computation or end-to-trust. Based on them, Tactical Clouds will allow the provisioning of C3 services for enhancing the development of the tactical pillars of modern join military operations, like Intelligence, Surveillance, Situational Awareness, or support to decision-making. But the adoption of new technological enablers bring novel and unexplored challenges that when no remediated, may jeopardize the operability of the digital tactical assets, being the cyber defence an essential cornerstone for their safeguarding. In these grounds, the main purpose of the conducted research is to review and analyze the denial of sustainability problem on tactical combat clouds; which entails a rara avis topic on the existing bibliography among other due to the novelty, secrecy and low level of technological maturity on their related digital enablers. The research presents and scoping action that developed the following secondary objectives: 1) to frame the denial of sustainability threats on the emerging Tactical Cloud paradigm; 2) to formalize the Tactical Denial of Sustainability (TDoS) concept; 3) to introduce the phasing, potential attack surfaces, terrains and impact of TDoS attacks; 4) to illustrate heterogeneous CONOPS that facilitate the understanding of TDoS; and 5) to raise and encourage the development of further research topics and actions.},
booktitle = {Proceedings of the 15th International Conference on Availability, Reliability and Security},
articleno = {104},
numpages = {9},
keywords = {situational awareness, cyber defence, military operations, tactical denial of sustainability, economical denial of sustainability},
location = {Virtual Event, Ireland},
series = {ARES '20}
}

@inproceedings{10.1109/CCGRID.2017.105,
author = {Imai, Shigeru and Patterson, Stacy and Varela, Carlos A.},
title = {Maximum Sustainable Throughput Prediction for Data Stream Processing over Public Clouds},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.105},
doi = {10.1109/CCGRID.2017.105},
abstract = {In cloud-based stream processing services, the maximum sustainable throughput (MST) is defined as the maximum throughput that a system composed of a fixed number of virtual machines (VMs) can ingest indefinitely. If the incoming data rate exceeds the system's MST, unprocessed data accumulates, eventually making the system inoperable. Thus, it is important for the service provider to keep the MST always larger than the incoming data rate by dynamically changing the number of VMs used by the system. In this paper, we identify a common data processing environment used by modern data stream processing systems, and we propose MST prediction models for this environment. We train the models using linear regression with samples obtained from a few VMs and predict MST for a larger number of VMs. To minimize the time and cost for model training, we statistically determine a set of training samples using Intel's Storm benchmarks with representative resource usage patterns. Using typical use-case benchmarks on Amazon's EC2 public cloud, our experiments show that, training with up to 8 VMs, we can predict MST for streaming applications with less than 4% average prediction error for 12 VMs, 9% for 16 VMs, and 32% for 24 VMs. Further, we evaluate our prediction models with simulation-based elastic VM scheduling on a realistic workload. These simulation results show that with 10% over-provisioning, our proposed models' cost efficiency is on par with the cost of an optimal scaling policy without incurring any service level agreement violations.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {504–513},
numpages = {10},
keywords = {performance prediction, resource management, auto-scaling, cloud computing},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@inproceedings{10.1145/3417113.3423001,
author = {Pathania, Priyavanshi and Mithani, Rajan Dilavar},
title = {Sustainability in Migrating Workloads to Public Clouds},
year = {2021},
isbn = {9781450381284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417113.3423001},
doi = {10.1145/3417113.3423001},
abstract = {In recent times, there has been a considerable increase in Cloud-Based applications and infrastructure. This has led to quicker innovations, agile businesses, availability of new services over the internet, improved collaboration, and better security. With the growth of new technologies like blockchain, quantum computing, mobility-focused applications, and edge computing, there has been an increased interest in adopting cloud services. In this paper, we highlight the different sustainability metrics and benefits while migrating workloads from the on-prem data center to the public clouds. Also, the clouds are elastic, scalable, cost-efficient, robust, and overall a better alternative to host the client applications and services. We present how the major Cloud Service Providers (CSPs) are continuously working on improving their infrastructure for a more energy efficient cloud. But with so many factors like the cost of cloud services, the location of the data center to name a few, it becomes quite a tedious task for the clients to select a cloud service provider when moving from their on-premise data center(s). Hence, we also briefly propose our solution that we are currently working on. The final goal is to have a cross-platform advisory that based on a wide-range of client-based inputs and a rich repository of current energy efficient clouds and their sustainability metrics, aims to provide them a detailed recommendation about their preferred cloud service provider. In case the client does not provide any such preference, the advisory should also recommend an ideal cloud service provider for their particular workload. This suggested action will be able to fulfill the client's constraints as well as provide them an energy efficient cloud along with a sustainability score. This score is indicative of how much improvement in the energy consumed and carbon footprint can be achieved through this migration to the suggested cloud.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {166–169},
numpages = {4},
keywords = {pre-migration cloud sustainability, energy efficient cloud, cloud computing, carbon footprint, cloud sustainability},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.5555/3408352.3408431,
author = {Magno, Michele and Wang, Xiaying and Eggimann, Manuel and Cavigelli, Lukas and Benini, Luca},
title = {InfiniWolf: Energy Efficient Smart Bracelet for Edge Computing with Dual Source Energy Harvesting},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {This work presents InfiniWolf, a novel multi-sensor smartwatch that can achieve self-sustainability exploiting thermal and solar energy harvesting, performing computationally high demanding tasks. The smartwatch embeds both a System-on-Chip (SoC) with an ARM Cortex-M processor and Bluetooth Low Energy (BLE) and Mr. Wolf, an open-hardware RISC-V based parallel ultra-low-power processor that boosts the processing capabilities on board by more than one order of magnitude, while also increasing energy efficiency. We demonstrate its functionality based on a sample application scenario performing stress detection with multi-layer artificial neural networks on a wearable multi-sensor bracelet. Experimental results show the benefits in terms of energy efficiency and latency of Mr. Wolf over an ARM Cortex-M4F micro-controllers and the possibility, under specific assumptions, to be self-sustainable using thermal and solar energy harvesting while performing up to 24 stress classifications per minute in indoor conditions.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {342–345},
numpages = {4},
keywords = {Energy Harvesting, Wearable devices, Biomedical Applications},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.1145/2554850.2554920,
author = {Field, Hayden and Anderson, Glen and Eder, Kerstin},
title = {EACOF: A Framework for Providing Energy Transparency to Enable Energy-Aware Software Development},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554920},
doi = {10.1145/2554850.2554920},
abstract = {Making energy consumption data accessible to software developers is an essential step towards energy efficient software engineering. The presence of various different, bespoke and incompatible, methods of instrumentation to obtain energy readings is currently limiting the widespread use of energy data in software development. This paper presents EACOF, a modular Energy-Aware Computing Framework that provides a layer of abstraction between sources of energy data and the applications that exploit them. EACOF replaces platform specific instrumentation through two APIs---one accepts input to the framework while the other provides access to application software. This allows developers to profile their code for energy consumption in an easy and portable manner using simple API calls. We outline the design of our framework and provide details of the API functionality. In a use case, where we investigate the impact of data bit width on the energy consumption of various sorting algorithms, we demonstrate that the data obtained using EACOF provides interesting, sometimes counter-intuitive, insights. All the code is available online under an open source license. http://github.com/eacof},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1194–1199},
numpages = {6},
keywords = {abstraction, eacof, energy profiling, energy-aware computing, energy transparency},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@article{10.1109/TCBB.2011.81,
author = {Zhao, Wenqi and Xu, Guoliang and Bajaj, Chandrajit L.},
title = {An Algebraic Spline Model of Molecular Surfaces for Energetic Computations},
year = {2011},
issue_date = {November 2011},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {8},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2011.81},
doi = {10.1109/TCBB.2011.81},
abstract = {In this paper, we describe a new method to generate a smooth algebraic spline (AS) approximation of the molecular surface (MS) based on an initial coarse triangulation derived from the atomic coordinate information of the biomolecule, resident in the Protein data bank (PDB). Our method first constructs a triangular prism scaffold covering the PDB structure, and then generates a piecewise polynomial F on the Bernstein-Bezier (BB) basis within the scaffold. An ASMS model of the molecular surface is extracted as the zero contours of F, which is nearly C^1 and has dual implicit and parametric representations. The dual representations allow us easily do the point sampling on the ASMS model and apply it to the accurate estimation of the integrals involved in the electrostatic solvation energy computations. Meanwhile comparing with the trivial piecewise linear surface model, fewer number of sampling points are needed for the ASMS, which effectively reduces the complexity of the energy estimation.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {nov},
pages = {1458–1467},
numpages = {10},
keywords = {Polynomial splines, Bernstein-Bezier basis, rate of convergence., prismatic scaffolds, solvation energetics, molecular surfaces, error bounds}
}

@inproceedings{10.1145/2627369.2627613,
author = {Venkataramani, Swagath and Ranjan, Ashish and Roy, Kaushik and Raghunathan, Anand},
title = {AxNN: Energy-Efficient Neuromorphic Systems Using Approximate Computing},
year = {2014},
isbn = {9781450329750},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2627369.2627613},
doi = {10.1145/2627369.2627613},
abstract = {Neuromorphic algorithms, which are comprised of highly complex, large-scale networks of artificial neurons, are increasingly used for a variety of recognition, classification, search and vision tasks. However, their computational and energy requirements can be quite high, and hence their energy-efficient implementation is of great interest.We propose a new approach to design energy-efficient hardware implementations of large-scale neural networks (NNs) using approximate computing. Our work is motivated by the observations that (i) NNs are used in applications where less-than-perfect results are acceptable, and often inevitable, and (ii) they are highly resilient to inexactness in many (but not all) of their constituent computations. We make two key contributions. First, we propose a method to transform any given NN into an Approximate Neural Network (AxNN). This is performed by (i) adapting the backpropagation technique, which is commonly used to train these networks, to quantify the impact of approximating each neuron to the overall network quality (e.g., classification accuracy), and (ii) selectively approximating those neurons that impact network quality the least. Further, we make the key observation that training is a naturally error-healing process that can be used to mitigate the impact of approximations to neurons. Therefore, we incrementally retrain the network with the approximations in-place, reclaiming a significant portion of the quality ceded by approximations. As a second contribution, we propose a programmable and quality-configurable neuromorphic processing engine (qcNPE), which utilizes arrays of specialized processing elements that execute neuron computations with dynamically configurable accuracies and can be used to execute AxNNs from diverse applications. We evaluated the proposed approach by constructing AXNNs for 6 recognition applications (ranging in complexity from 12-47,818 neurons and 160-3,155,968 connections) and executing them on two different platforms--qcNPE implementation containing 272 processing elements in 45nm technology and a commodity Intel Xeon server. Our results demonstrate 1.14X-1.92X energy benefits for virtually no loss (&lt; 0.5%) in output quality, and even higher improvements (upto 2.3X) when some loss (upto 7.5%) in output quality is acceptable.},
booktitle = {Proceedings of the 2014 International Symposium on Low Power Electronics and Design},
pages = {27–32},
numpages = {6},
keywords = {large-scale neural networks, neuromorphic systems, energy efficiency, approximate computing},
location = {La Jolla, California, USA},
series = {ISLPED '14}
}

@inproceedings{10.1145/504450.504460,
author = {Marzullo, Keith and Ogg, Michael and Ricciardi, Aleta and Amoroso, Alessandro and Calkins, F. Andrew and Rothfus, Eric},
title = {NILE: Wide-Area Computing for High Energy Physics},
year = {1996},
isbn = {9781450373395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/504450.504460},
doi = {10.1145/504450.504460},
abstract = {The CLEO project [2], centered at Cornell University, is a large-scale high energy physics project. The goals of the project arise from an esoteric question---why is there apparently so little antimatter in the universe?---and the computational problems that arise in trying to answer this question are quite challenging.To answer this question, the CESR storage ring at Cornell is used to generate a beam of electrons directed at an equally strong beam of positrons. These two beams meet inside a detector that is embedded in a magnetic field and is equipped with sensors. The collisions of electrons and positrons generate several secondary subatomic particles. Each collision is called an event and is sensed by detecting charged particles (via the ionization they produce in a drift chamber) and neutral particles (in the case of photons, via their deposition of energy in a crystal calorimeter), as well as by other specialized detector elements. Most events are ignored, but some are recorded in what is called raw data (typically 8Kbytes per event). Offline, a second program called pass2 computes, for each event, the physical properties of the particles, such as their momenta, masses, and charges. This compute-bound program produces a new set of records describing the events (now typically 20Kbytes per event). Finally, a third program reads these events, and produces a lossily-compressed version of only certain frequently-accessed fields, written in what is called roar format (typically 2Kbytes per event).The physicists analyze this data with programs that are, for the most part, embarrassingly parallel and I/O limited. Such programs typically compute a result based on a projection of a selection of a large number of events, where the result is insensitive to the order in which the events are processed. For example, a program may construct histograms, or compute statistics, or cull the raw data for physical inspection. The projection is either the complete pass2 record or (much more often) the smaller roar record, and the selection is done in an ad-hoc manner by the program itself.Other programs are run as well. For example, a Monte Carlo simulation of the experiment is also run (called monte carlo) in order to correct the data for detector acceptance and inefficiencies, as well as testing aspects of the model used to interpret the data. This program is compute bound. Another important example is called recompress. Roughly every two years, improvements in detector calibration and reconstruction algorithms make it worthwhile to recompute more accurate pass2 data (and hence, more accurate roar data) from all of the raw data. This program is compute-bound (it currently requires 24 200-MIP workstations running flat out for three months) and so must be carefully worked into the schedule so that it does not seriously impact the ongoing operations.Making this more concrete, the current experiment generates approximately 1 terabyte of event data a year. Only recent roar data can be kept on disk; all other data must reside on tape. The data processing demands consume approximately 12,000 SPECint92 cycles a year. Improvements in the performance of CESR and the sensitivity of the detector will cause both of these values to go up by a factor of ten in the next few years, which will correspondingly increase the storage and computational needs by a factor of ten.The CLEO project prides itself on being able to do big science on a tight budget, and so the programming environment that the CLEO project provides for researchers is innovative but somewhat primitive. Jobs that access the entire data set can take days to complete. To circumvent limited access to tape, the network, or compute resources close to the central disk, physicists often do preliminary selections and projections (called skims) to create private disk data sets of events for further local analysis. Limited resources usually exact a high human price for resource and job management and ironically, can sometimes lead to inefficiencies. Given the increase in data storage, data retrieval, and computational needs, it has become clear that the CLEO physicists require a better distributed environment in which to do their work.Hence, an NSF-funded National Challenge project was started with participants from both high energy physics, distributed computing, and data storage, in order to provide a better environment for the CLEO experiment. The goals of this project, called NILE [7], are:Finally, the CLEO necessity of building on a budget carries over to NILE. There are some more expensive resources, such as ATM switches and tape silos, that it will be necessary to use. However, as far as possible we are using commodity equipment, and free or inexpensive software whenever possible. For example, one of our principal development platforms is Pentium-based PCs, interconnected with 100 Mbps Ethernet, running Linux and the GNU suite of tools.},
booktitle = {Proceedings of the 7th Workshop on ACM SIGOPS European Workshop: Systems Support for Worldwide Applications},
pages = {49–54},
numpages = {6},
location = {Connemara, Ireland},
series = {EW 7}
}

@inproceedings{10.5555/2662693.2662700,
author = {Ferreira, Miguel A. and Hoekstra, Eric and Merkus, Bo and Visser, Bram and Visser, Joost},
title = {SEFLab: A Lab for Measuring Software Energy Footprints},
year = {2013},
isbn = {9781467362672},
publisher = {IEEE Press},
abstract = {Hardware dissipates energy because software tells it to. But attributing hardware energy usage to particular software functions is complicated due to distribution, resource sharing, and layering of software. To enable research on energy usage attribution, we have created the Software Energy Footprint Lab. We explain the experimental setup offered by the lab and the measurement and analysis methodology that it supports. We also describe some preliminary results aimed at deciphering hardware dissipation profiles for various types of servers under various forms of software stress. Finally, we provide an outlook of how energy footprint measurements can contribute to a body of knowledge on software-level energy optimization.},
booktitle = {Proceedings of the 2nd International Workshop on Green and Sustainable Software},
pages = {30–37},
numpages = {8},
keywords = {energy efficiency, green products, software engineering},
location = {San Francisco, California},
series = {GREENS '13}
}

@inproceedings{10.1145/2559206.2581358,
author = {Prost, Sebastian and Schrammel, Johann and Tscheligi, Manfred},
title = { 'Sometimes It's the Weather's Fault': Sustainable HCI &amp; Political Activism},
year = {2014},
isbn = {9781450324748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2559206.2581358},
doi = {10.1145/2559206.2581358},
abstract = {This paper presents empirical evidence that design for political activism that goes beyond the individual user is crucial for sustainable HCI. The analysis of a series of qualitative interviews conducted during a field trial evaluating a persuasive technology for transport behaviour resulted in 20 factors that influence such behaviour. Factors were ordered and grouped by the potential of a person to influence a factor individually. Concluding, four approaches for HCI, namely, entertainment, education, community support, and political activism are identified that can together address the full continuum of influence factors.},
booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
pages = {2005–2010},
numpages = {6},
keywords = {activism, sustainable hci, persuasion},
location = {Toronto, Ontario, Canada},
series = {CHI EA '14}
}

@inproceedings{10.1145/3018896.3018944,
author = {Rawas, Soha and Itani, Wassim and Zekri, Ahmed and Zaart, Ali El},
title = {ENAGS: Energy and Network-Aware Genetic Scheduling Algorithm on Cloud Data Centers},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3018944},
doi = {10.1145/3018896.3018944},
abstract = {Cloud computing plays a significant role in today's network computing by delivering virtualized resources as pay-as-you-go services over the Internet. However, the growing demand drastically increases the energy consumption of data centers, which has become a prominent problem. Hence, energy efficient solutions are required to minimize system power consumption and increase the availability of computational resources and obviously reduce the operational expenses. In this paper we present ENAGS (Energy and Network-Aware Genetic Scheduling algorithm) to minimize the energy consumption of servers and reduce the network traffic. The proposed algorithm takes into account communication dependencies among VMs and computational requirements of tasks to improve communication performance and minimize the energy consumption by maximizing the resource utilization. Our experimental results show that the proposed ENAGS algorithm can reduce data center energy consumption as well as network traffic by approximately 38% compared to other placement algorithms.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {49},
numpages = {7},
keywords = {energy efficiency, green computing, network-aware scheduling, genetic algorithms},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.5555/359640.359932,
author = {Courtney, James F. and Lyytinen, Kalle and Porra, Jaana and Paradice, David B.},
title = {The Role of IT in the Creation of Sustainable Communities (Panel Session)},
year = {2000},
publisher = {Association for Information Systems},
address = {USA},
booktitle = {Proceedings of the Twenty First International Conference on Information Systems},
pages = {717–719},
numpages = {3},
location = {Brisbane, Queensland, Australia},
series = {ICIS '00}
}

@inproceedings{10.5555/2819009.2819148,
author = {Chen, Feifei and Grundy, John and Schneider, Jean-Guy and Yang, Yun and He, Qiang},
title = {StressCloud: A Tool for Analysing Performance and Energy Consumption of Cloud Applications},
year = {2015},
publisher = {IEEE Press},
abstract = {Finding the best deployment configuration that maximises energy efficiency while guaranteeing system performance of cloud applications is an extremely challenging task. It requires the evaluation of system performance and energy consumption under a wide variety of realistic workloads and deployment configurations. This paper demonstrates StressCloud, an automatic performance and energy consumption analysis tool for cloud applications in real-world cloud environments. StressCloud supports 1) the modelling of realistic cloud application workloads, 2) the automatic generation and running of load tests, and 3) the profiling of system performance and energy consumption. A demonstration video can be accessed at: https://www.youtube.com/watch?v=0l4_a_CNtVQ},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {721–724},
numpages = {4},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/252493.252633,
author = {Chandrakasan, A. and Gutnik, V. and Xanthopoulos, T.},
title = {Data Driven Signal Processing: An Approach for Energy Efficient Computing},
year = {1996},
isbn = {0780335716},
publisher = {IEEE Press},
booktitle = {Proceedings of the 1996 International Symposium on Low Power Electronics and Design},
pages = {347–352},
numpages = {6},
location = {Monterey, California, USA},
series = {ISLPED '96}
}

@article{10.1145/3264659,
author = {Bai, Kangjun and Yi, Yang},
title = {DFR: An Energy-Efficient Analog Delay Feedback Reservoir Computing System for Brain-Inspired Computing},
year = {2018},
issue_date = {October 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3264659},
doi = {10.1145/3264659},
abstract = {Neuromorphic computing, which is built on a brain-inspired silicon chip, is uniquely applied to keep pace with the explosive escalation of algorithms and data density on machine learning. Reservoir computing, an emerging computing paradigm based on the recurrent neural network with proven benefits across multifaceted applications, offers an alternative training mechanism only at the readout stage. In this work, we successfully design and fabricate an energy-efficient analog delayed feedback reservoir (DFR) computing system, which is built upon a temporal encoding scheme, a nonlinear transfer function, and a dynamic delayed feedback loop. Measurement results demonstrate its high energy efficiency with rich dynamic behaviors, making the designed system a candidate for low power embedded applications. The system performance, as well as the robustness, are studied and analyzed through the Monte Carlo simulation. The chaotic time series prediction benchmark, NARMA10, is examined through the proposed DFR computing system, and exhibits a 36%−85% reduction on the error rate compared to state-of-the-art DFR computing system designs. To the best of our knowledge, our work represents the first analog integrated circuit (IC) implementation of the DFR computing system.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {dec},
articleno = {45},
numpages = {22},
keywords = {delayed feedback system, Reservoir computing, spiking neural network, brain-inspired computing, edge of chaos regime, analog integrated circuit design}
}

@inproceedings{10.1145/3061639.3062210,
author = {Imani, Mohsen and Peroni, Daniel and Rosing, Tajana},
title = {CFPU: Configurable Floating Point Multiplier for Energy-Efficient Computing},
year = {2017},
isbn = {9781450349277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3061639.3062210},
doi = {10.1145/3061639.3062210},
abstract = {Many applications, such as machine learning and data sensing are statistical in nature and can tolerate some level of inaccuracy in their computation. Approximate computation is a viable method to save energy and increase performance by trading energy for accuracy. There are a number of proposed approximate solutions, however, they are limited to a small range of applications because they cannot control the error rate of their output. In this paper, we propose a novel approximate floating point multiplier, called CFPU, which significantly reduces energy and improves performance of multiplication at the expense of accuracy. Our design approximately models multiplication by replacing the most costly step of the operation with a lower energy alternative. In order to tune the level of approximation, CFPU dynamically identifies the inputs which will produce the largest approximation error and processes them in precise CFPU mode. We showed that our CFPU can outperforms a standard FPU when at least 4% of multiplications are performed in approximate mode. In our tested applications this percentage of multiplications is substantially higher, leading to significant energy savings. Our experimental evaluation on AMD Southern Island GPU shows that replacing the proposed CFPU with traditional FPUs results in 77% energy savings and 3.5x energy-delay product improvement over eight general OpenCL applications while providing acceptable quality of service. In addition, for the same level of accuracy, the CFPU provides 2.4x energy-delay product improvement compared to state-of-the-art approximate multipliers.},
booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},
articleno = {76},
numpages = {6},
keywords = {Floating point unit, Energy efficiency, Approximate computing},
location = {Austin, TX, USA},
series = {DAC '17}
}

@inproceedings{10.1145/3524842.3528028,
author = {Kim, Jinyoung and Kim, Misoo and Lee, Eunseok},
title = {ECench: An Energy Bug Benchmark of Ethereum Client Software},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528028},
doi = {10.1145/3524842.3528028},
abstract = {With the introduction of smart contacts, Ethereum has become one of the most popular blockchain networks. In the wake of its popularity, an increasing number of Ethereum-based software have been developed. However, the carbon emissions resulting from these software has been pointed out as a global issue. It is necessary to reduce the energy consumed by these software to reduce carbon emissions. Recently, most studies have focused on smart contracts and proposed energy-efficient methods for the development of carbon friendly Ethereum networks. However, in addition to smart contracts, the energy used by client software in Ethereum networks should also be reviewed. This is because the client software performs all functions occurring in the Ethereum network, including smart contracts. Therefore, energy bugs that waste energy in Ethereum client software should be investigated and solved. The first task to enable this is to build an energy bug benchmark of Ethereum client software. This study introduces ECench, an energy bug benchmark of Ethereum client software. ECench includes 507 energy buggy commits from 7 series of client software that are officially operated in the Ethereum network. We carefully collected and manually reviewed them for cleaner commits. A key strength of our benchmark is that it provides eight energy wastage categories, which can serve as a cornerstone for researchers to identify energy waste codes. ECench can provide a valuable starting point for studies on energy reduction and carbon reduction in Ethereum.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {634–638},
numpages = {5},
keywords = {benchmark, software engineering, ethereum, energy consumption},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@inproceedings{10.1145/378239.378467,
author = {Sinha, Amit and Chandrakasan, Anantha P.},
title = {JouleTrack: A Web Based Tool for Software Energy Profiling},
year = {2001},
isbn = {1581132972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/378239.378467},
doi = {10.1145/378239.378467},
abstract = {A software energy estimation methodology is presented that avoids explicit characterization of instruction energy consumption and pre-dicts energy consumption to within 3% accuracy for a set of bench-mark programs evaluated on the StrongARM SA-1100 and Hitachi SH-4 microprocessors. The tool, JouleTrack, is available as an online resource and has various estimation levels. It also isolates the switch-ing and leakage components of the energy consumption.},
booktitle = {Proceedings of the 38th Annual Design Automation Conference},
pages = {220–225},
numpages = {6},
keywords = {software energy, instruction energy, leakage estimation},
location = {Las Vegas, Nevada, USA},
series = {DAC '01}
}

@inproceedings{10.1145/3127479.3128604,
author = {Pacheco, D. Lopez and Jacquemart, Q. and Segalini, A. and Rifai, M. and Dione, M. and Urvoy-Keller, G.},
title = {SEaMLESS: A SErvice Migration CLoud Architecture for Energy Saving and Memory ReleaSing Capabilities},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127479.3128604},
doi = {10.1145/3127479.3128604},
abstract = {Idle virtual machines (VMs) are a waste of resources in data centers. We introduce SEaMLESS, which transforms a fully-Hedged idle VM into a lightweight and resourceless Virtual Network Function (VNF). Idle VMs can then be saved to disk and release their memory. Simultaneously, the VNF provides service availability. Upon user activity, the appropriate VM is restored, without introducing any interruption for service users. Tens of VNFs can be contained within the same memory space required for one single VM, thereby facilitating ample resources savings when scaled up to a data center.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {645},
numpages = {1},
keywords = {server consolidation, gateway process, NFV, SDN, migration},
location = {Santa Clara, California},
series = {SoCC '17}
}

@inproceedings{10.1145/3331052.3332473,
author = {Kaur, Kuljeet and Garg, Sahil and Kaddoum, Georges and Ahmed, Syed Hassan and Jayakody, Dushantha Nalin K.},
title = {En-OsCo: Energy-Aware Osmotic Computing Framework Using Hyper-Heuristics},
year = {2019},
isbn = {9781450368056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331052.3332473},
doi = {10.1145/3331052.3332473},
abstract = {The proliferation of the Internet of Things (IoT) has paved the way for many cloud based applications such as smart grid, healthcare, traffic management, finance, etc. In this vein, the need of transferring large data-streams to remote data centers is a key concern for modern Cloud-based IoT paradigms. This disrupts the remote Cloud Computing model, moving applications, data and computing resources to the logical extremes of the network. Thus, to handle streaming data in IoT environments, an efficient IoT-based computing model that can dynamically handle the interplay between Cloud and Edge data centers is required. In this direction, a recent paradigm, popularly known as Osmotic Computing, has emerged to ensure the acceptable performance of widely dispersed services. However, the burden of data-offloading across multiple data centers usually leads to a consequent increase in their energy consumption which in-turn will affect the overall Quality of Service (QoS) of the IoT-based applications. Keeping focus on all these issues, a consolidated decision making framework for Osmotic Computing, i.e., En-OsCo, is designed to ensure the energy-aware dynamic management of resources. The proposed framework incorporates four significant contributions: i) Resource monitoring of Edge data centers using Extended Kalman Filter, ii) Optimal dispatch of incoming services to the Edge/Cloud setup using Hyper-heuristics, iii) Minimizing the energy consumption of underlying data centers and reducing the service latency, and iv) Reducing the search space of Hyper-heuristics by keeping track of previously made decisions using Universal Streaming Monitoring. Further, in order to validate the efficacy of the proposed En-OsCo framework, ContainerCloudSim has been used in combination of HyFlex on PlanetLab datasets. The obtained results validate the purpose of the proposed scheme in minimizing the overall energy consumption of the computing setup while considerably reducing the latency.},
booktitle = {Proceedings of the ACM MobiHoc Workshop on Pervasive Systems in the IoT Era},
pages = {19–24},
numpages = {6},
keywords = {Cloud Computing, Energy Minimization, Hyper-heuristics, Latency Minimization, Edge Computing, and Osmotic Computing, Extended Kalman Filter},
location = {Catania, Italy},
series = {PERSIST-IoT '19}
}

@inproceedings{10.1145/3142992.3142996,
author = {Moukarzel, Michael and Hicks, Matthew},
title = {Reap What You Store: Side-Channel Resilient Computing Through Energy Harvesting},
year = {2017},
isbn = {9781450354776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3142992.3142996},
doi = {10.1145/3142992.3142996},
abstract = {A hidden dimension of software and hardware security is secret-revealing information disseminated through side channels. Even the most secure systems tend to reveal their secrets through secret-dependent computation. Secret-dependent computation is detectable by monitoring a system's time, power, outputs, and electromagnetic signature. Common defenses to side channel emanations include adding noise to the channel or making algorithmic changes to eliminate specific side channels. Unfortunately, existing solutions are either, not automatic, not comprehensive, and/or not practical.We propose an isolation-based approach for eliminating power and timing side-channels that is automatic, comprehensive, and practical. Our approach eliminates side channels by leveraging energy harvesting techniques to isolate trusted computation from the rest of the system. Software has the ability to request a fixed-power and fixed-time quantum of isolated computation. By discretizing power and time, our approach controls the granularity of side channel leakage; the only burden on programmers is to ensure that all secret-dependent execution differences converge within a single power/time quantum.We design and implement three approaches to power/time-based quantization and isolation: a wholly-digital version, a hybrid version that uses capacitors for time tracking, and a full-custom version. A key insight we leverage is that capacitors act as resource efficient, workload and environment independent time trackers. We explore the trade-offs of the three designs and look at the challenges ahead.},
booktitle = {Proceedings of the Fifth ACM International Workshop on Energy Harvesting and Energy-Neutral Sensing Systems},
pages = {21–26},
numpages = {6},
location = {Delft, Netherlands},
series = {ENSsys'17}
}

@inproceedings{10.1145/1594233.1594292,
author = {Dhiman, Gaurav and Marchetti, Giacomo and Rosing, Tajana},
title = {VGreen: A System for Energy Efficient Computing in Virtualized Environments},
year = {2009},
isbn = {9781605586847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1594233.1594292},
doi = {10.1145/1594233.1594292},
abstract = {In this paper, we present vGreen, a multi-tiered software system for energy efficient computing in virtualized environments. It comprises of novel hierarchical metrics that capture power and performance characteristics of virtual and physical machines, and policies, which use it for energy efficient virtual machine scheduling across the whole deployment. We show through real life implementation on a state of the art testbed of server machines that vGreen can improve both performance and system level energy savings by 20% and 15% across benchmarks with varying characteristics.},
booktitle = {Proceedings of the 2009 ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {243–248},
numpages = {6},
keywords = {virtualization, migration, workload characterization, energy},
location = {San Fancisco, CA, USA},
series = {ISLPED '09}
}

@inproceedings{10.1145/3229631.3239370,
author = {Cristal, Adrian and Unsal, Osman S. and Martorell, Xavier and Carpenter, Paul and De La Cruz, Raul and Bautista, Leonardo and Jimenez, Daniel and Alvarez, Carlos and Salami, Behzad and Madonar, Sergi and Peric\`{a}s, Miquel and Trancoso, Pedro and vor dem Berge, Micha and Billung-Meyer, Gunnar and Krupop, Stefan and Christmann, Wolfgang and Klawonn, Frank and Mihklafi, Amani and Becker, Tobias and Gaydadjiev, Georgi and Salomonsson, Hans and Dubhashi, Devdatt and Port, Oron and Hadar, Elad and Etsion, Yoav and Fetzer, Christof and Hagemeyer, Jens and Jungeblut, Thorsten and Kucza, Nils and Kaiser, Martin and Porrmann, Mario and Pasin, Marcelo and Schiavoni, Valerio and Rocha, Isabelly and G\"{o}ttel, Christian and Felber, Pascal},
title = {LEGaTO: First Steps towards Energy-Efficient Toolset for Heterogeneous Computing},
year = {2018},
isbn = {9781450364942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229631.3239370},
doi = {10.1145/3229631.3239370},
abstract = {LEGaTO is a three-year EU H2020 project which started in December 2017. The LEGaTO project will leverage task-based programming models to provide a software ecosystem for Made-in-Europe heterogeneous hardware composed of CPUs, GPUs, FPGAs and dataflow engines. The aim is to attain one order of magnitude energy savings from the edge to the converged cloud/HPC.},
booktitle = {Proceedings of the 18th International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation},
pages = {210–217},
numpages = {8},
location = {Pythagorion, Greece},
series = {SAMOS '18}
}

@inproceedings{10.5555/2616606.2616852,
author = {Torrellas, Josep},
title = {Extreme-Scale Computer Architecture: Energy Efficiency from the Ground Up},
year = {2014},
isbn = {9783981537024},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {As we move to integration levels of 1,000-core processor chips, it is clear that energy and power consumption are the most formidable obstacles. To construct such a chip, we need to rethink the whole compute stack from the ground up for energy efficiency --- and attain Extreme-Scale Computing. First of all, we want to operate at low voltage, since this is the point of maximum energy efficiency. Unfortunately, in such an environment, we have to tackle substantial process variation. Hence, it is important to design efficient voltage regulation, so that each region of the chip can operate at the most efficient voltage and frequency point. At the architecture level, we require simple cores organized in a hierarchy of clusters. Moreover, we also need techniques to reduce the leakage of on-chip memories and to lower the voltage guardbands of logic. Finally, data movement should be minimized, through both hardware and software techniques. With a systematic approach that cuts across multiple layers of the computing stack, we can deliver the required energy efficiencies.},
booktitle = {Proceedings of the Conference on Design, Automation &amp; Test in Europe},
articleno = {200},
numpages = {5},
location = {Dresden, Germany},
series = {DATE '14}
}

@inproceedings{10.5555/3408352.3408391,
author = {Salami, B. and Parasyris, K. and Cristal, A. and Unsal, O. and Martorell, X. and Carpenter, P. and De La Cruz, R. and Bautista, L. and Jimenez, D. and Alvarez, C. and Nabavi, S. and Madonar, S. and Peric\`{a}s, M. and Trancoso, P. and Abduljabbar, M. and Chen, J. and Soomro, P. N. and Manivannan, M and Berge, M. and Krupop, S. and Klawonn, F. and Mekhlafi, Al and May, S. and Becker, T. and Gaydadjiev, G. and Salomonsson, H. and Dubhashi, D. and Port, O. and Etsion, Y. and Do, Le Quoc and Fetzer, Christof and Kaiser, M. and Kucza, N. and Hagemeyer, J. and Griessl, R. and Tigges, L. and Mika, K. and H\"{u}ffmeier, A. and Pasin, M. and Schiavoni, V. and Rocha, I. and G\"{o}ttel, C. and Felber, P.},
title = {LEGaTO: Low-Energy, Secure, and Resilient Toolset for Heterogeneous Computing},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {The LEGaTO project leverages task-based programming models to provide a software ecosystem for Made in-Europe heterogeneous hardware composed of CPUs, GPUs, FPGAs and dataflow engines. The aim is to attain one order of magnitude energy savings from the edge to the converged cloud/HPC, balanced with the security and resilience challenges. LEGaTO is an ongoing three-year EU H2020 project started in December 2017.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {169–174},
numpages = {6},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.1109/ISCA45697.2020.00030,
author = {Zhao, Shulin and Zhang, Haibo and Bhuyan, Sandeepa and Mishra, Cyan Subhra and Ying, Ziyu and Kandemir, Mahmut T. and Sivasubramaniam, Anand and Das, Chita R.},
title = {D\'{e}j\`{a} View: Spatio-Temporal Compute Reuse for Energy-Efficient 360° VR Video Streaming},
year = {2020},
isbn = {9781728146614},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA45697.2020.00030},
doi = {10.1109/ISCA45697.2020.00030},
abstract = {The emergence of virtual reality (VR) and augmented reality (AR) has revolutionized our lives by enabling a 360° artificial sensory stimulation across diverse domains, including, but not limited to, sports, media, healthcare, and gaming. Unlike the conventional planar video processing, where memory access is the main bottleneck, in 360° VR videos the compute is the primary bottleneck and contributes to more than 50% energy consumption in battery-operated VR headsets. Thus, improving the computational efficiency of the video processing pipeline in a VR is critical. While prior efforts have attempted to address this problem through acceleration using a GPU or FPGA, none of them has analyzed the 360° VR pipeline to examine if there is any scope to optimize the computation with known techniques such as memoization.Thus, in this paper, we analyze the VR computation pipeline and observe that there is significant scope to skip computations by leveraging the temporal and spatial locality in head orientation and eye correlations, respectively, resulting in computation reduction and energy efficiency. The proposed D\'{e}j\`{a} View design takes advantage of temporal reuse by memoizing head orientation and spatial reuse by establishing a relationship between left and right eye projection, and can be implemented either on a GPU or an FPGA. We propose both software modifications for existing compute pipeline and microarchitectural additions for further enhancement. We evaluate our design by implementing the software enhancements on an NVIDIA Jetson TX2 GPU board and our microarchitectural additions on a Xilinx Zynq-7000 FPGA model using five video workloads. Experimental results show that D\'{e}j\`{a} View can provide 34% computation reduction and 17% energy saving, compared to the state-of-the-art design.},
booktitle = {Proceedings of the ACM/IEEE 47th Annual International Symposium on Computer Architecture},
pages = {241–253},
numpages = {13},
keywords = {virtual reality, IoT, 360° video processing, edge computing},
location = {Virtual Event},
series = {ISCA '20}
}

@inproceedings{10.5555/2492708.2492996,
author = {Fettweis, Gerhard and Nagel, Wolfgang and Lehner, Wolfgang},
title = {Pathways to Servers of the Future: Highly Adaptive Energy Efficient Computing (HAEC)},
year = {2012},
isbn = {9783981080186},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {The Special Session on "Pathways to Servers of the Future" outlines a new research program set up at Technische Universit\"{a}t Dresden addressing the increasing energy demand of global internet usage and the resulting ecological impact of it. The program pursues a novel holistic approach that considers hardware as well as software adaptivity to significantly increase energy efficiency, while suitably addressing application demands. The session presents the research challenges and industry perspective.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {1161–1166},
numpages = {6},
keywords = {server, interconnects, computing, adaptivity, data center, software architecture, wireless, energy efficienc, optical},
location = {Dresden, Germany},
series = {DATE '12}
}

@inproceedings{10.5555/2388996.2389067,
author = {Kaushik, Rini T. and Nahrstedt, Klara},
title = {T: A Data-Centric Cooling Energy Costs Reduction Approach for Big Data Analytics Cloud},
year = {2012},
isbn = {9781467308045},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
abstract = {Explosion in Big Data has led to a surge in extremely large-scale Big Data analytics platforms, resulting in burgeoning energy costs. Big Data compute model mandates strong data-locality for computational performance, and moves computations to data. State-of-the-art cooling energy management techniques rely on thermal-aware computational job placement/migration and are inherently data-placement-agnostic in nature. T* takes a novel, data-centric approach to reduce cooling energy costs and to ensure thermal-reliability of the servers. T* is cognizant of the uneven thermal-profile and differences in thermal-reliability-driven load thresholds of the servers, and the differences in the computational jobs arrival rate, size, and evolution life spans of the Big Data placed in the cluster. Based on this knowledge, and coupled with its predictive file models and insights, T* does proactive, thermal-aware file placement, which implicitly results in thermal-aware job placement in the Big Data analytics compute model. Evaluation results with one-month long real-world Big Data analytics production traces from Yahoo! show up to 42% reduction in the cooling energy costs with T* courtesy of its lower and more uniform thermal-profile and 9x better performance than the state-of-the-art data-agnostic cooling techniques.},
booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
articleno = {52},
numpages = {11},
location = {Salt Lake City, Utah},
series = {SC '12}
}

@inproceedings{10.1145/2451605.2451610,
author = {Wilke, Claas and G\"{o}tz, Sebastian and Richly, Sebastian},
title = {JouleUnit: A Generic Framework for Software Energy Profiling and Testing},
year = {2013},
isbn = {9781450318662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2451605.2451610},
doi = {10.1145/2451605.2451610},
abstract = {Energy consumption has become an important characteristic of nowadays information and communication technology (ICT) applications, especially for mobile devices, whose uptime is limited by the available battery capacity. Hence, ICT applications are optimized to provide the best possible user satisfaction for the least possible energy budget. An inevitable prerequisite for such optimizations is the ability to analyze software's energy consumption. In consequence, many energy profiling frameworks have been developed. The problem we address in this paper is that profiling frameworks are device- and application-specific and, hence, cannot be reused. We analyze the key requirements of energy profiling frameworks and propose a generic framework reusable for different devices and applications, designed according to these requirements. We evaluate the presented framework using two case studies showing the reusability in two significantly different scenarios.},
booktitle = {Proceedings of the 2013 Workshop on Green in/by Software Engineering},
pages = {9–14},
numpages = {6},
keywords = {nao robot, android, profiling, energy testing},
location = {Fukuoka, Japan},
series = {GIBSE '13}
}

@article{10.1145/2160803.2160872,
author = {Stefanek, Anton and Hayden, Richard A. and Bradley, Jeremy T.},
title = {Fluid Computation of the Performance: Energy Tradeoff in Large Scale Markov Models},
year = {2011},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {0163-5999},
url = {https://doi.org/10.1145/2160803.2160872},
doi = {10.1145/2160803.2160872},
abstract = {Recent fluid analysis techniques allow fast and effcient calculation of complex reward metrics and passage time probabilities in systems with very large state space. We demonstrate how to incorporate these to look at the trade-off between service level agreement (SLA) satisfaction and complex reward optimisation. We show how the uid analysis naturally leads to a constrained global optimisation problem with embedded differential equations. We illustrate this problem on an abstract model of a virtualised execution environment that accurately captures resource allocations.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {dec},
pages = {104–106},
numpages = {3}
}

@inproceedings{10.1145/3316781.3317785,
author = {Imani, Mohsen and Morris, Justin and Messerly, John and Shu, Helen and Deng, Yaobang and Rosing, Tajana},
title = {BRIC: Locality-Based Encoding for Energy-Efficient Brain-Inspired Hyperdimensional Computing},
year = {2019},
isbn = {9781450367257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316781.3317785},
doi = {10.1145/3316781.3317785},
abstract = {Brain-inspired Hyperdimensional (HD) computing is a new computing paradigm emulating the neuron's activity in high-dimensional space. The first step in HD computing is to map each data point into high-dimensional space (e.g., 10,000), which requires the computation of thousands of operations for each element of data in the original domain. Encoding alone takes about 80% of the execution time of training. In this paper, we propose BRIC, a fully binary Brain-Inspired Classifier based on HD computing for energy-efficient and high-accuracy classification. BRIC introduces a novel encoding module based on random projection with a predictable memory access pattern which can efficiently be implemented in hardware. BRIC is the first HD-based approach which provides data projection with a 1:1 ratio to the original data and enables all training/inference computation to be performed using binary hypervectors. To further improve BRIC efficiency, we develop an online dimension reduction approach which removes insignificant hypervector dimensions during training. Additionally, we designed a fully pipelined FPGA implementation which accelerates BRIC in both training and inference phases. Our evaluation of BRIC a wide range of classification applications show that BRIC can achieve 64.1\texttimes{} and 9.8\texttimes{} (43.8\texttimes{} and 6.1\texttimes{}) energy efficiency and speed up as compared to baseline HD computing during training (inference) while providing the same classification accuracy.},
booktitle = {Proceedings of the 56th Annual Design Automation Conference 2019},
articleno = {52},
numpages = {6},
keywords = {Machine learning, Energy efficiency, Hyperdimensional computing, Brain-inspired computing},
location = {Las Vegas, NV, USA},
series = {DAC '19}
}

@inproceedings{10.1145/3203217.3205339,
author = {Cristal, Adrian and Unsal, Osman S. and Martorell, Xavier and Carpenter, Paul and De La Cruz, Raul and Bautista, Leonardo and Jimenez, Daniel and Alvarez, Carlos and Salami, Behzad and Madonar, Sergi and Peric\`{a}s, Miquel and Trancoso, Pedro and vor dem Berge, Micha and Billung-Meyer, Gunnar and Krupop, Stefan and Christmann, Wolfgang and Klawonn, Frank and Mihklafi, Amani and Becker, Tobias and Gaydadjiev, Georgi and Salomonsson, Hans and Dubhashi, Devdatt and Port, Oron and Etsion, Yoav and Nowack, Vesna and Fetzer, Christof and Hagemeyer, Jens and Jungeblut, Thorsten and Kucza, Nils and Kaiser, Martin and Porrmann, Mario and Pasin, Marcelo and Schiavoni, Valerio and Rocha, Isabelly and G\"{o}ttel, Christian and Felber, Pascal},
title = {LEGaTO: Towards Energy-Efficient, Secure, Fault-Tolerant Toolset for Heterogeneous Computing},
year = {2018},
isbn = {9781450357616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3203217.3205339},
doi = {10.1145/3203217.3205339},
abstract = {LEGaTO is a three-year EU H2020 project which started in December 2017. The LEGaTO project will leverage task-based programming models to provide a software ecosystem for Made-in-Europe heterogeneous hardware composed of CPUs, GPUs, FPGAs and dataflow engines. The aim is to attain one order of magnitude energy savings from the edge to the converged cloud/HPC.},
booktitle = {Proceedings of the 15th ACM International Conference on Computing Frontiers},
pages = {276–278},
numpages = {3},
location = {Ischia, Italy},
series = {CF '18}
}

@inproceedings{10.1145/2597917.2597948,
author = {Ge, Rong and Feng, Xizhou and Burtscher, Martin and Zong, Ziliang},
title = {PEACH: A Model for Performance and Energy Aware Cooperative Hybrid Computing},
year = {2014},
isbn = {9781450328708},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597917.2597948},
doi = {10.1145/2597917.2597948},
abstract = {Accelerator-based heterogeneous systems become increasingly important to high performance computing because of their potentials to deliver high performance and energy efficiency. To fully realize this potential, parallel software must utilize both host processors and accelerators' computing power and power-aware capabilities. We develop PEACH, a model for Performance and Energy Aware Cooperative Hybrid computing. PEACH explores judicious workload distribution between hosts and accelerators and intelligent energy-aware scheduling for further performance and energy efficiency gains on heterogenous systems. With a few system- and application-dependent parameters, PEACH accurately captures the performance and energy impact of workload distribution and energy-aware scheduling.},
booktitle = {Proceedings of the 11th ACM Conference on Computing Frontiers},
articleno = {24},
numpages = {2},
keywords = {heterogeneous computing, energy-efficient computing, performance and energy modeling},
location = {Cagliari, Italy},
series = {CF '14}
}

@inproceedings{10.1145/3370748.3406553,
author = {Zamani, Hadi and Tripathy, Devashree and Bhuyan, Laxmi and Chen, Zizhong},
title = {SAOU: Safe Adaptive Overclocking and Undervolting for Energy-Efficient GPU Computing},
year = {2020},
isbn = {9781450370530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3370748.3406553},
doi = {10.1145/3370748.3406553},
abstract = {The current trend of ever-increasing performance in scientific applications comes with tremendous growth in energy consumption. In this paper, we present a framework for GPU applications, which reduces energy consumption in GPUs through Safe Overclocking and Undervolting (SAOU) without sacrificing performance. The idea is to increase the frequency beyond the safe frequency fsa f eMax and undervolt below Vsa f eMin to get maximum energy saving. Since such overclocking and undervolting may give rise to faults, we employ an enhanced checkpoint-recovery technique to cover the possible errors. Empirically, we explore different errors and derive a fault model that can set the undervolting and overclocking level for maximum energy saving. We target cuBLAS Matrix Multiplication (cuBLAS-MM) kernel for error correction using the checkpoint and recovery (CR) technique as an example of scientific applications. In case of cuBLAS, SAOU achieves up to 22% energy reduction through undervolting and overclocking without sacrificing the performance.},
booktitle = {Proceedings of the ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {205–210},
numpages = {6},
keywords = {overclocking, checkpoint-recovery, undervolting, energy efficiency},
location = {Boston, Massachusetts},
series = {ISLPED '20}
}

@article{10.1145/3417708,
author = {Jafri, Syed M. A. H. and Hassan, Hasan and Hemani, Ahmed and Mutlu, Onur},
title = {Refresh Triggered Computation: Improving the Energy Efficiency of Convolutional Neural Network Accelerators},
year = {2021},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1544-3566},
url = {https://doi.org/10.1145/3417708},
doi = {10.1145/3417708},
abstract = {To employ a Convolutional Neural Network (CNN) in an energy-constrained embedded system, it is critical for the CNN implementation to be highly energy efficient. Many recent studies propose CNN accelerator architectures with custom computation units that try to improve the energy efficiency and performance of CNNs by minimizing data transfers from DRAM-based main memory. However, in these architectures, DRAM is still responsible for half of the overall energy consumption of the system, on average. A key factor of the high energy consumption of DRAM is the refresh overhead, which is estimated to consume 40% of the total DRAM energy.In this article, we propose a new mechanism, Refresh Triggered Computation (RTC), that exploits the memory access patterns of CNN applications to reduce the number of refresh operations. RTC uses two major techniques to mitigate the refresh overhead. First, Refresh Triggered Transfer (RTT) is based on our new observation that a CNN application accesses a large portion of the DRAM in a predictable and recurring manner. Thus, the read/write accesses of the application inherently refresh the DRAM, and therefore a significant fraction of refresh operations can be skipped. Second, Partial Array Auto-Refresh (PAAR) eliminates the refresh operations to DRAM regions that do not store any data.We propose three RTC designs (min-RTC, mid-RTC, and full-RTC), each of which requires a different level of aggressiveness in terms of customization to the DRAM subsystem. All of our designs have small overhead. Even the most aggressive RTC design (i.e., full-RTC) imposes an area overhead of only 0.18% in a 16 Gb DRAM chip and can have less overhead for denser chips. Our experimental evaluation on six well-known CNNs shows that RTC reduces average DRAM energy consumption by 24.4% and 61.3% for the least aggressive and the most aggressive RTC implementations, respectively. Besides CNNs, we also evaluate our RTC mechanism on three workloads from other domains. We show that RTC saves 31.9% and 16.9% DRAM energy for Face Recognition and Bayesian Confidence Propagation Neural Network (BCPNN), respectively. We believe RTC can be applied to other applications whose memory access patterns remain predictable for a sufficiently long time.},
journal = {ACM Trans. Archit. Code Optim.},
month = {dec},
articleno = {2},
numpages = {29},
keywords = {DRAM, convolution neural networks, DRAM refresh overhead}
}

@inproceedings{10.1145/3369740.3369772,
author = {Limbasiya, Trupil and Das, Debasis},
title = {SearchCom: Vehicular Cloud-Based Secure and Energy-Efficient Communication and Searching System for Smart Transportation},
year = {2020},
isbn = {9781450377515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369740.3369772},
doi = {10.1145/3369740.3369772},
abstract = {The cutting-edge technologies have improved the journey of vehicle users on the road using different vehicular-based structures (vehicular ad-hoc networks (VANETs), vehicular cloud computing (VCC), and Internet of Vehicles (IoV)). Vehicles generally transmit different road-side data (e.g., traffic, details of nearby vehicles, emergency/environment, location, etc.) from/to another end in a public environment. Hence, three key challenges on data are as follows; (1) secure and effective data storage in the vehicular cloud (VC) (2) efficient data extraction from the VC and (3) reliable data transmission between two entities. Some general methods are to search/store data from/in the cloud, but these techniques are only for data storage and extraction. Next, various communication schemes are proposed for VANETs, VCC, and IoV, but they need high computational resources, and these schemes are vulnerable to multiple security attacks. We find that there is no system, which provides all these data operations (storage, searching, and communication) for vehicle users. In this paper, we propose a dependable system (named as SearchCom) for vehicle applicants to overcome above-mentioned challenges and provide operational facility. The SearchCom is analyzed to verify its security strengths against various security attacks and its performance results in execution time, memory requirement, communication overhead, searching, and energy consumption.},
booktitle = {Proceedings of the 21st International Conference on Distributed Computing and Networking},
articleno = {9},
numpages = {10},
keywords = {Communication, Data, Search, Security, Storage},
location = {Kolkata, India},
series = {ICDCN '20}
}

@inproceedings{10.5555/3539845.3540190,
author = {Shim, Jun S. and Han, Bogyeong and Kim, Yeseong and Kim, Jihong},
title = {DeepPM: Transformer-Based Power and Performance Prediction for Energy-Aware Software},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Many system-level management and optimization techniques need accurate estimates of power consumption and performance. Earlier research has proposed many high-level/source-level estimation modeling works, particularly for basic blocks. However, most of them still need to execute the target software at least once on a fine-grained simulator or real hardware to extract required features. This paper proposes a performance/power prediction framework, called Deep Power Meter (DeepPM), which estimates them accurately only using the compiled binary. Inspired by the deep learning techniques in natural language processing, we convert the program instructions in the form of vectors and predict the average power and performance of basic blocks based on a transformer model. In addition, unlike existing works based on a Long Short-Term Memory (LSTM) model structure, which only works for basic blocks with a small number of instructions, DeepPM provides highly accurate results for long basic blocks, which takes the majority of the execution time for actual application runs. In our evaluation conducted with SPEC2006 benchmark suite, we show that DeepPM can provide accurate prediction for performance and power consumption with 10.2% and 12.3% error, respectively. DeepPM also outperforms the LSTM-based model by up to 67.2% and 34.9% error for performance and power, respectively.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {1491–1496},
numpages = {6},
keywords = {power and performance modeling, transformer, system resource prediction},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3307650.3322248,
author = {Feng, Yu and Zhu, Yuhao},
title = {PES: Proactive Event Scheduling for Responsive and Energy-Efficient Mobile Web Computing},
year = {2019},
isbn = {9781450366694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307650.3322248},
doi = {10.1145/3307650.3322248},
abstract = {Web applications are gradually shifting toward resource-constrained mobile devices. As a result, the Web runtime system must simultaneously address two challenges: responsiveness and energy-efficiency. Conventional Web runtime systems fall short due to their reactive nature: they react to a user event only after it is triggered. The reactive strategy leads to local optimizations that schedule event executions one at a time, missing global optimization opportunities.This paper proposes Proactive Event Scheduling (PES). The key idea of PES is to proactively anticipate future events and thereby globally coordinate scheduling decisions across events. Specifically, PES predicts events that are likely to happen in the near future using a combination of statistical inference and application code analysis. PES then speculatively executes future events ahead of time in a way that satisfies the QoS constraints of all the events while minimizing the global energy consumption. Fundamentally, PES unlocks more optimization opportunities by enlarging the scheduling window, which enables coordination across both outstanding events and predicted events. Hardware measurements show that PES reduces the QoS violation and energy consumption by 61.2% and 26.5%, respectively, over the Android's default Interactive CPU governor. It also reduces the QoS violation and energy consumption by 63.1% and 17.9%, respectively, compared to EBS, a state-of-the-art reactive scheduler.},
booktitle = {Proceedings of the 46th International Symposium on Computer Architecture},
pages = {66–78},
numpages = {13},
location = {Phoenix, Arizona},
series = {ISCA '19}
}

@inproceedings{10.1145/3195970.3196069,
author = {Akhlaghi, Vahideh and Gao, Sicun and Gupta, Rajesh K.},
title = {LEMAX: Learning-Based Energy Consumption Minimization in Approximate Computing with Quality Guarantee},
year = {2018},
isbn = {9781450357005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195970.3196069},
doi = {10.1145/3195970.3196069},
abstract = {Approximate computing aims to trade accuracy for energy efficiency. Various approximate methods have been proposed in the literature that demonstrate the effectiveness of relaxing accuracy requirements in a specific unit. This provides a basis for exploring simultaneous use of multiple approximate units to improve efficiency under guarantees on quality of results. In this paper, we explore the effect of combining multiple approximate units on the energy consumption and identify the best setting that minimizes energy consumption under a quality constraint. Our approach also enables changes in unit configurations throughout the program. To do this effectively, we need a method to examine the combined impact of multiple approximate units on the output quality, and configure individual units accordingly. To solve this problem, we propose LEMAX that uses gradient descent approach to identify the best configuration of the individual approximate units for a given program. We evaluate the efficacy of LEMAX in minimizing the energy consumption of several machine learning applications with varying size (i.e., number of operations) under different quality constraints. Our evaluation shows that the configuration provided by LEMAX for a system with multiple approximate units improves the energy consumption by on average, 97.7%, 83.12%, and 73.95% for quality loss of 5%, 2% and 0.5%, respectively, compared to configurations obtained for a system with a single approximate resource.},
booktitle = {Proceedings of the 55th Annual Design Automation Conference},
articleno = {161},
numpages = {6},
keywords = {design automation, machine learning, approximate computing},
location = {San Francisco, California},
series = {DAC '18}
}

@article{10.1145/3223047,
author = {Parveen, Farhana and Angizi, Shaahin and Fan, Deliang},
title = {IMFlexCom: Energy Efficient In-Memory Flexible Computing Using Dual-Mode SOT-MRAM},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1550-4832},
url = {https://doi.org/10.1145/3223047},
doi = {10.1145/3223047},
abstract = {In this article, we propose an <u>I</u>n-<u>M</u>emory <u>Flex</u>ible <u>Com</u>puting platform (IMFlexCom) using a novel Spin Orbit Torque Magnetic Random Access Memory (SOT-MRAM) array architecture, which could work in dual mode: memory mode and computing mode. Such intrinsic in-memory logic (AND/OR/XOR) could be used to process data within memory to greatly reduce power-hungry and long distance massive data communication in conventional Von Neumann computing systems. A comprehensive reliability analysis is performed, which confirms ∼90mV and ∼10mV (worst-case) sense margin for memory and in-memory logic operation in variations on resistance-area product and tunnel magnetoresistance. We further show that sense margin for in-memory logic computation can be significantly increased by increasing the oxide thickness. Furthermore, we employ bulk bitwise vector operation and data encryption engine as case studies to investigate the performance of our proposed design. IMFlexCom shows ∼35\texttimes{} energy saving and ∼18\texttimes{} speedup for bulk bitwise in-memory vector AND/OR operation compared to DRAM-based in-memory logic. Again, IMFlexCom can achieve 77.27% and 85.4% lower energy consumption compared to CMOS-ASIC- and CMOL-based Advanced Encryption Standard (AES) implementations, respectively. It offers almost similar energy consumption as recent DW-AES implementation with 66.7% less area overhead.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = {oct},
articleno = {35},
numpages = {18},
keywords = {memory architecture, giant spin Hall effect, SOT-MRAM, magnetic tunnel junction, In-memory computing}
}

@inproceedings{10.1145/3339186.3339210,
author = {Bourassa, Norman and Johnson, Walker and Broughton, Jeff and Carter, Deirdre McShane and Joy, Sadie and Vitti, Raphael and Seto, Peter},
title = {Operational Data Analytics: Optimizing the National Energy Research Scientific Computing Center Cooling Systems},
year = {2019},
isbn = {9781450371964},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339186.3339210},
doi = {10.1145/3339186.3339210},
abstract = {In 2017/2018, the Energy Efficient HPC Working Group (EE HPC WG) Dashboard Team conducted an analysis that assessed the current use of information dashboards for operational facility management in major supercomputing centers around the globe, resulting in the formalization of a process now referred to as Operational Data Analytics (ODA). Subsequent to surveys of multiple HPC facilities, the EE HPC WG determined that case studies were needed to help HPC facilities evaluate the value of implementing ODA practices. This paper provides a summary of the successful use of an ODA approach being used by the National Energy Research Scientific Computing Center (NERSC) at Lawrence Berkeley National Laboratory (Berkeley Lab) in meeting organizational energy efficiency performance goals for the NERSC HPC cooling systems.},
booktitle = {Workshop Proceedings of the 48th International Conference on Parallel Processing},
articleno = {5},
numpages = {7},
keywords = {time series data, building controls, energy efficiency, Green HPC, data centers, high-performance computing, iTUE, building management systems, data collection, PUE, operations, data analytics},
location = {Kyoto, Japan},
series = {ICPP Workshops '19}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00089,
author = {Sun, Zhensu and Du, Xiaoning and Song, Fu and Wang, Shangwen and Ni, Mingze and Li, Li},
title = {Don't Complete It! Preventing Unhelpful Code Completion for Productive and Sustainable Neural Code Completion Systems},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00089},
doi = {10.1109/ICSE-Companion58688.2023.00089},
abstract = {Currently, large pre-trained language models are widely applied in neural code completion systems. Though large code models significantly outperform their smaller counterparts, around 70% of displayed code completions from Copilot are not accepted by developers. Being reviewed but not accepted, their help to developer productivity is considerably limited. Even worse, considering the high cost of the large code models, it is a huge waste of computing resources and energy. To fill this significant gap, we propose an early-rejection mechanism to turn down low-return prompts by foretelling the code completion qualities without sending them to the code completion system. Furthermore, we propose a lightweight Transformer-based estimator to demonstrate the feasibility of the mechanism. The experimental results show that the proposed estimator helps save 23.3% of computational cost measured in floating-point operations for the code completion systems, and 80.2% of rejected prompts lead to unhelpful completion.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {324–325},
numpages = {2},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3470496.3527397,
author = {Lee, Sangwon and Kwon, Miryeong and Park, Gyuyoung and Jung, Myoungsoo},
title = {LightPC: Hardware and Software Co-Design for Energy-Efficient Full System Persistence},
year = {2022},
isbn = {9781450386104},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3470496.3527397},
doi = {10.1145/3470496.3527397},
abstract = {We propose LightPC, a lightweight persistence-centric platform to make the system robust against power loss. LightPC consists of hardware and software subsystems, each being referred to as open-channel PMEM (OC-PMEM) and persistence-centric OS (PecOS). OC-PMEM removes physical and logical boundaries in drawing a line between volatile and nonvolatile data structures by unshackling new memory media from conventional PMEM complex. PecOS provides a single execution persistence cut to quickly convert the execution states to persistent information in cases of a power failure, which can eliminate persistent control overhead. We prototype LightPC's computing complex and OC-PMEM using our custom system board. PecOS is implemented based on Linux 4.19 and Berkeley bootloader on the hardware prototype. Our evaluation results show that OC-PMEM can make user-level performance comparable with a DRAM-only non-persistent system, while consuming 73% lower power and 69% less energy. LightPC also shortens the execution time of diverse HPC, SPEC, and In-memory DB workloads, compared to traditional persistent systems by 4.3X, on average.},
booktitle = {Proceedings of the 49th Annual International Symposium on Computer Architecture},
pages = {289–305},
numpages = {17},
location = {New York, New York},
series = {ISCA '22}
}

@inproceedings{10.5555/2735522.2735546,
author = {Aggarwal, Karan and Zhang, Chenlei and Campbell, Joshua Charles and Hindle, Abram and Stroulia, Eleni},
title = {The Power of System Call Traces: Predicting the Software Energy Consumption Impact of Changes},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Battery is a critical resource for smartphones. Software developers as the builders and maintainers of applications, are responsible for updating and deploying energy efficient applications to end users. Unfortunately, the impact of software change on energy consumption is still unclear. Estimation based on software metrics has proved difficult. As energy consumption profiling requires special infrastructure, developers have difficulty assessing the impact of their actions on energy consumption. System calls are the interface between applications and the OS kernel and provide insight into how software utilizes hardware and software resources. As profiling system calls requires no specialized infrastructure, unlike energy consumption, it is much easier for the developers to track changes to system calls. Thus we relate software change to energy consumption by tracing the changes in an application's pattern of system call invocations. We find that significant changes to system call profiles often induce significant changes in energy consumption.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {219–233},
numpages = {15},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1109/NANOARCH.2011.5941506,
author = {Wang, Xinmu and Narasimhan, Seetharam and Paul, Somnath and Bhunia, Swarup},
title = {NEMTronics: Symbiotic Integration of Nanoelectronic and Nanomechanical Devices for Energy-Efficient Adaptive Computing},
year = {2011},
isbn = {9781457709937},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/NANOARCH.2011.5941506},
doi = {10.1109/NANOARCH.2011.5941506},
abstract = {Heterogeneity, programmability and parallelism are expected to be the key drivers for future nanoelectronics systems. The proposed work builds on these key drivers to achieve an energy-efficient, adaptive, and reliable computing framework. The primary intellectual merit of this effort lies in the heterogeneous integration of two fundamentally different state variables - charge-based electronics and electromechanical. We exploit the complementary capabilities of the two layers - high-performance operation of nanoscale FET and ultralow-power and harsh environment operation of NEMS - to merge the benefit of both. The layers are used in a symbiotic manner where each addresses the limitations of the other. The leakage/programmability issues in FET layer are addressed by exploiting the near-zero leakage and low ON-resistance of NEMS switches. The reliability and drivability issues of NEMS layer are addressed by FETs. The innovative memory based computing architecture exploits the density advantage of nanoscale memory to reduce the programmable interconnect overhead of traditional reconfigurable computing. It enables realizing custom computing functions in a core-based architecture to improve energy efficiency through hardware acceleration. The fundamental questions on the effectiveness of nanomechanical computing and the physics of its interaction with charge-based nanoelectronics are investigated.},
booktitle = {Proceedings of the 2011 IEEE/ACM International Symposium on Nanoscale Architectures},
pages = {210–217},
numpages = {8},
series = {NANOARCH '11}
}

@inproceedings{10.1145/2530544.2530551,
author = {Nelson, Andrew and Molnos, Anca and Nejad, Ashkan Beyranvand and Mirzoyan, Davit and Cotofana, Sorin and Goossens, Kees},
title = {Embedded Computer Architecture Laboratory: A Hands-on Experience Programming Embedded Systems with Resource and Energy Constraints},
year = {2012},
isbn = {9781450317658},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2530544.2530551},
doi = {10.1145/2530544.2530551},
abstract = {Embedded systems are complex, requiring multi-disciplinary skills for their design. Developing appropriate educational curricula is a non trivial problem. Embedded system design requires both theoretical and practical understanding. It is common in embedded system education to provide practical laboratory sessions to put into practice what is learnt from lectures and textbooks.In this paper, we present our embedded systems laboratory that is given as part of the Embedded Computer Architecture (ECA) module at Delft University of Technology. Our laboratory provides practical, hands-on experience of programming a multiprocessor embedded system, that is prototyped on an FPGA. We provide details of the hardware platform and software APIs that are provided to the students, along with the laboratory assignment that was given to the ECA students in the 2011-2012 academic year. We present example results that were submitted by groups taking part in the laboratory, and describe the lessons we learned from our own practical experience of giving the laboratory.},
booktitle = {Proceedings of the Workshop on Embedded and Cyber-Physical Systems Education},
articleno = {7},
numpages = {8},
keywords = {multiprocessor system on chip, embedded system design, education},
location = {Tampere, Finland},
series = {WESE '12}
}

@inproceedings{10.1145/2847263.2847325,
author = {Qian, Wenchao and Babecki, Christopher and Karam, Robert and Bhunia, Swarup},
title = {ENFIRE: An Energy-Efficient Fine-Grained Spatio-Temporal Reconfigurable Computing Fabric (Abstact Only)},
year = {2016},
isbn = {9781450338561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2847263.2847325},
doi = {10.1145/2847263.2847325},
abstract = {Field Programmable Gate Arrays (FPGAs) are well-established as fine-grained hardware reconfigurable computing platforms. However, FPGA energy usage is dominated by programmable interconnects, which have poor scalability across different technology generations. In this work, we propose ENFIRE, a novel, energy-efficient, fine-grained, spatio-temporal, memory-based reconfigurable computing framework that provides the flexibility of bit-level information processing, which is not available in conventional coarse-grain reconfigurable architectures (CGRAs). A dense two-dimensional memory array is the main computing element in the proposed framework, which stores not only the data to be processed, but also the functional behavior of a mapped application in the form of lookup tables (LUTs) of various input/output sizes. Spatially distributed configurable computing elements (CEs) communicate with each other based on data dependencies using a mesh network, while execution inside each CE occurs in a temporal manner. A custom software framework has also been co-developed which enables application mapping to a set of CEs. By finding the right balance between spatial and temporal computing, it can achieve a highly energy-efficient mapping, significantly reducing the programmable interconnect overhead when compared with FPGA. Simulation results show an improvement of 7.6X in overall energy, 1.6X in energy efficiency, 1.1X in leakage energy, and 5.3X in Unified Energy-Efficiency, a metric that considers energy and area together, compared with comparable FPGA implementations for a set of random logic benchmarks.},
booktitle = {Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {275},
numpages = {1},
keywords = {energy-efficiency, fine-grain reconfigurable hardware, fpga, spatio-temporal computing, memory based computing},
location = {Monterey, California, USA},
series = {FPGA '16}
}

@inproceedings{10.1145/3307772.3330176,
author = {Herzog, Benedict and H\"{o}nig, Timo and Schr\"{o}der-Preikschat, Wolfgang and Plauth, Max and K\"{o}hler, Sven and Polze, Andreas},
title = {Bridging the Gap: Energy-Efficient Execution of Software Workloads on Heterogeneous Hardware Components},
year = {2019},
isbn = {9781450366717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307772.3330176},
doi = {10.1145/3307772.3330176},
abstract = {The recent restructuring of the electricity grid (i.e., smart grid) introduces a number of challenges for today's large-scale computing systems. To operate reliable and efficient, computing systems must adhere not only to technical limits (i.e., thermal constraints) but they must also reduce operating costs, for example, by increasing their energy efficiency. Efforts to improve the energy efficiency, however, are often hampered by inflexible software components that hardly adapt to underlying hardware characteristics. In this paper, we propose an approach to bridge the gap between inflexible software and heterogeneous hardware architectures. Our proposal introduces adaptive software components that dynamically adapt to heterogeneous processing units (i.e., accelerators) during runtime to improve the energy efficiency of computing systems.},
booktitle = {Proceedings of the Tenth ACM International Conference on Future Energy Systems},
pages = {428–430},
numpages = {3},
location = {Phoenix, AZ, USA},
series = {e-Energy '19}
}

@article{10.1145/3281300,
author = {Balsamo, Domenico and Fletcher, Benjamin J. and Weddell, Alex S. and Karatziolas, Giorgos and Al-Hashimi, Bashir M. and Merrett, Geoff V.},
title = {Momentum: Power-Neutral Performance Scaling with Intrinsic MPPT for Energy Harvesting Computing Systems},
year = {2019},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {6},
issn = {1539-9087},
url = {https://doi.org/10.1145/3281300},
doi = {10.1145/3281300},
abstract = {Recent research has looked to supplement or even replace the batteries in embedded computing systems with energy harvesting, where energy is derived from the device’s environment. However, such supplies are generally unpredictable and highly variable, and hence systems typically incorporate large external energy buffers (e.g., supercapacitors) to sustain computation; however, these pose environmental issues and increase system size and cost. This article proposes Momentum, a general power-neutral methodology, with intrinsic system-wide maximum power point tracking, that can be applied to a wide range of different computing systems, where the system dynamically scales its performance (and hence power consumption) to optimize computational progress depending on the power availability. Momentum enables the system to operate around an efficient operating voltage, maximizing forward application execution, without adding any external tracking or control units. This methodology combines at runtime (1) a hierarchical control strategy that utilizes available power management controls (such as dynamic voltage and frequency scaling, and core hot-plugging) to achieve efficient power-neutral operation; (2) a software-based maximum power point tracking scheme (unlike existing approaches, this does not require any additional hardware), which adapts the system power consumption so that it can work at the optimal operating voltage, considering the efficiency of the entire system rather than just the energy harvester; and (3) experimental validation on two different scales of computing system: a low power microcontroller (operating from the already-present 4.7μF decoupling capacitance) and a multi-processor system-on-chip (operating from 15.4mF added capacitance). Experimental results from both a controlled supply and energy harvesting source show that Momentum operates correctly on both platforms and exhibits improvements in forward application execution of up to 11% when compared to existing power-neutral approaches and 46% compared to existing static approaches.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {jan},
articleno = {93},
numpages = {25},
keywords = {power neutrality, embedded computing systems, Energy harvesting, performance adaptation, maximum power point tracking, transient computing}
}

@inproceedings{10.1109/ICSE-C.2017.18,
author = {Di Nucci, Dario and Palomba, Fabio and Prota, Antonio and Panichella, Annibale and Zaidman, Andy and De Lucia, Andrea},
title = {PETrA: A Software-Based Tool for Estimating the Energy Profile of Android Applications},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.18},
doi = {10.1109/ICSE-C.2017.18},
abstract = {Energy efficiency is a vital characteristic of any mobile application, and indeed is becoming an important factor for user satisfaction. For this reason, in recent years several approaches and tools for measuring the energy consumption of mobile devices have been proposed. Hardware-based solutions are highly precise, but at the same time they require costly hardware toolkits. Model-based techniques require a possibly difficult calibration of the parameters needed to correctly create a model on a specific hardware device. Finally, software-based solutions are easier to use, but they are possibly less precise than hardware-based solution. In this demo, we present PETrA, a novel software-based tool for measuring the energy consumption of Android apps. With respect to other tools, PETrA is compatible with all the smartphones with Android 5.0 or higher, not requiring any device specific energy profile. We also provide evidence that our tool is able to perform similarly to hardware-based solutions.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {3–6},
numpages = {4},
keywords = {energy consumption, estimation, mobile apps},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1145/3489517.3530398,
author = {Zhang, He and Jiang, Linjun and Wu, Jianxin and Chen, Tingran and Liu, Junzhan and Kang, Wang and Zhao, Weisheng},
title = {CP-SRAM: Charge-Pulsation SRAM Marco for Ultra-High Energy-Efficiency Computing-in-Memory},
year = {2022},
isbn = {9781450391429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489517.3530398},
doi = {10.1145/3489517.3530398},
abstract = {SRAM-based computing-in-memory (SRAM-CIM) provides fast speed and good scalability with advanced process technology. However, the energy efficiency of the state-of-the-art current-domain SRAM-CIM bit-cell structure is limited and the peripheral circuitry (e.g., DAC/ADC) for high-precision is expensive. This paper proposes a charge-pulsation SRAM (CP-SRAM) structure to achieve ultra-high energy-efficiency thanks to its charge-domain mechanism. Furthermore, our proposed CP-SRAM CIM supports configurable precision (2/4/6-bit). The CP-SRAM CIM macro was designed in 180nm (with silicon verification) and 40nm (simulation) nodes. The simulation results in 40nm show that our macro can achieve energy efficiency of ~2950Tops/W at 2-bit precision, ~576.4 Tops/W at 4-bit precision and ~111.7 Tops/W at 6-bit precision, respectively.},
booktitle = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
pages = {109–114},
numpages = {6},
keywords = {computing-in-memory, charge-pulsation, SRAM, configurable precision},
location = {San Francisco, California},
series = {DAC '22}
}

@inproceedings{10.1145/3489517.3530399,
author = {Xu, Liukai and Liu, Songyuan and Li, Zhi and Wang, Dengfeng and Chen, Yiming and Sun, Yanan and Li, Xueqing and He, Weifeng and Xu, Shi},
title = {CREAM: Computing in ReRAM-Assisted Energy and Area-Efficient SRAM for Neural Network Acceleration},
year = {2022},
isbn = {9781450391429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489517.3530399},
doi = {10.1145/3489517.3530399},
abstract = {Computing-in-memory has been widely explored to accelerate DNN. However, most existing CIM cannot store all NN weights due to limited SRAM capacity for edge AI devices, inducing a large amount off-chip DRAM access. In this paper, a new computing in ReRAM-assisted energy and area-efficient SRAM (CREAM) is proposed for implementing large-scale NNs while eliminating off-chip DRAM access. The weights of DNN are all stored in the high-dense on-chip ReRAM devices and restored to the proposed nvSRAM-CIM cells with array-level parallelism. A data-aware weight-mapping method is also proposed to enhance the CIM performance while fully exploiting the hardware utilization. Experiment results show that the proposed CREAM scheme enhances the storage density by up to 7.94x compared to the traditional SRAM arrays. The energy-efficiency of proposed CREAM is also enhanced by 2.14x and 1.99x, compared to the traditional SRAM-CIM with off-chip DRAM access and ReRAM-CIM circuits, respectively.},
booktitle = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
pages = {115–120},
numpages = {6},
keywords = {compute-in-memory, neural network, ReRAM-assisted SRAM, high density},
location = {San Francisco, California},
series = {DAC '22}
}

@inproceedings{10.1145/3060403.3060470,
author = {Ehsan, Md Amimul and Zhou, Zhen and Yi, Yang},
title = {Neuromorphic 3D Integrated Circuit: A Hybrid, Reliable and Energy Efficient Approach for Next Generation Computing},
year = {2017},
isbn = {9781450349727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3060403.3060470},
doi = {10.1145/3060403.3060470},
abstract = {In this paper, we proposed to use 3D integration technology to create a neuromorphic hardware system that is compatible with current technology, provides high system speed, high density, massively parallel processing, low power consumption, and small footprint. The Through Silicon Vias (TSVs) used in the 3D neuromorphic structure provide high density integration and energy efficient links for transferring information through multiple neuron layers. This work details how a 3D neuromorphic system is benefited from the redundant TSV with substantial design-area reduction. We discussed the yield and reliability issues and explained the impact in neuromorphic 3D system design. A spiking neuron model is developed for the proposed 3D system. Furthermore, a new methodology have been proposed by introducing oxide around the bump that could significantly enhance the TSV capacitance in 3D Neuromorphic Computing (NC) system.},
booktitle = {Proceedings of the on Great Lakes Symposium on VLSI 2017},
pages = {221–226},
numpages = {6},
keywords = {tsv, reliability, yield, spiking neuron, 3d integration, neuromorphic computing},
location = {Banff, Alberta, Canada},
series = {GLSVLSI '17}
}

@inproceedings{10.1145/2789168.2789174,
author = {Ding, Aaron Yi and Liu, Yanhe and Tarkoma, Sasu and Flinck, Hannu and Crowcroft, Jon},
title = {Demo: An Open-Source Software Defined Platform for Collaborative and Energy-Aware WiFi Offloading},
year = {2015},
isbn = {9781450336192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2789168.2789174},
doi = {10.1145/2789168.2789174},
abstract = {This demonstration presents a novel software defined platform for achieving collaborative and energy-aware WiFi offloading. The platform consists of an extensible central controller, programmable offloading agents, and offloading extensions on mobile devices. Driven by our extensive measurements of energy consumption on smartphones, we propose an effective energy-aware offloading algorithm and integrate it to our platform. By enabling collaboration between wireless networks and mobile users, our solution can make optimal offloading decisions that improve offloading efficiency for network operators and achieve energy saving for mobile users. To enhance deployability, we have released our platform under open-source licenses on GitHub.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Computing and Networking},
pages = {182–184},
numpages = {3},
keywords = {mobile data offloading, software-defined networking},
location = {Paris, France},
series = {MobiCom '15}
}

@inproceedings{10.1145/1641944.1641952,
author = {Itani, Wassim and Kayssi, Ayman and Chehab, Ali},
title = {PETRA: A Secure and Energy-Efficient Software Update Protocol for Severely-Constrained Network Devices},
year = {2009},
isbn = {9781605586199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1641944.1641952},
doi = {10.1145/1641944.1641952},
abstract = {In this paper we propose PETRA; an energy-efficient and secure software update protocol for severely-constrained network devices. PETRA ensures the authenticity and end-to-end integrity of software update components delivered from trusted content distribution networks. The protocol operates by employing a set of energy-efficient data structures and cryptographic constructs to efficiently detect any form of man-in-the-middle modification attacks on the update packets. This methodology contributes to a sizeable decrease in network traffic and as a result huge energy savings. This makes PETRA a very suitable security protocol for limited-resource battery-operated devices such as low-end mobile phones, wireless sensors, and even Radio Frequency Identification Devices (RFIDs) tags. Moreover, PETRA realizes an incremental security verification mechanism that allows the dynamic eager loading of received software components. This mechanism prevents any form of service disruption or operation downtime during the code upgrade process. A prototype PETRA implementation is tested on a grid of simulated micaz sensor nodes running the TinyOS operating system. A platform-independent performance analysis and an experimental simulation show that PETRA can achieve up to 30% average reduction in network-wide energy consumption.},
booktitle = {Proceedings of the 5th ACM Symposium on QoS and Security for Wireless and Mobile Networks},
pages = {37–43},
numpages = {7},
keywords = {wsn security, energy-efficient code updates, secure software updates},
location = {Tenerife, Canary Islands, Spain},
series = {Q2SWinet '09}
}

@inproceedings{10.1145/1185373.1185383,
author = {Lufei, Hanping and Shi, Weisong},
title = {E-QoS: Energy-Aware QoS for Application Sessions across Multiple Protocol Domains in Mobile Computing},
year = {2006},
isbn = {1595935371},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1185373.1185383},
doi = {10.1145/1185373.1185383},
abstract = {In this paper we propose a novel energy-aware QoS model, e-QoS, for application sessions that might across multiple protocol domains. The model provides the QoS guarantee by dynamically selecting and adapting application protocols. To the best of our knowledge, our model is the first attempt to address QoS adaptation at the application session level by proposing a new QoS metric called session lifetime. To show the effectiveness of the proposed scheme, we have implemented a case study: instant messenger applications between two PocketPCs. Experiment shows that the session lifetime has been successfully extended to the value negotiated by two PocketPCs with very diverse battery capacities.},
booktitle = {Proceedings of the 3rd International Conference on Quality of Service in Heterogeneous Wired/Wireless Networks},
pages = {7–es},
keywords = {protocol adaptation, energy-aware, quality of service, application sessions, multiple application domains, session lifetime, protocol domain},
location = {Waterloo, Ontario, Canada},
series = {QShine '06}
}

@inproceedings{10.1145/3560905.3568561,
author = {Bakar, Abu and Goel, Rishabh and de Winkel, Jasper and Huang, Jason and Ahmed, Saad and Islam, Bashima and Pawe\l{}czak, Przemys\l{}aw and Y\i{}ld\i{}r\i{}m, Kas\i{}m Sinan and Hester, Josiah},
title = {Protean: An Energy-Efficient and Heterogeneous Platform for Adaptive and Hardware-Accelerated Battery-Free Computing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568561},
doi = {10.1145/3560905.3568561},
abstract = {Battery-free and intermittently powered devices offer long lifetimes and enable deployment in new applications and environments. Unfortunately, developing sophisticated inference-capable applications is still challenging due to the lack of platform support for more advanced (32-bit) microprocessors and specialized accelerators---which can execute data-intensive machine learning tasks, but add complexity across the stack when dealing with intermittent power. We present Protean to bridge the platform gap for inference-capable battery-free sensors. Designed for runtime scalability, meeting the dynamic range of energy harvesters with matching heterogeneous processing elements like neural network accelerators. We develop a modular "plug-and-play" hardware platform, SuperSensor, with a reconfigurable energy storage circuit that powers a 32-bit ARM-based microcontroller with a convolutional neural network accelerator. An adaptive task-based runtime system, Chameleon, provides intermittency-proof execution of machine learning tasks across heterogeneous processing elements. The runtime automatically scales and dispatches these tasks based on incoming energy, current state, and programmer annotations. A code generator, Metamorph, automates conversion of ML models to intermittent safe execution across heterogeneous compute elements. We evaluate Protean with audio and image workloads and demonstrate up to 666x improvement in inference energy efficiency by enabling usage of modern computational elements within intermittent computing. Further, Protean provides up to 166% higher throughput compared to non-adaptive baselines.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {207–221},
numpages = {15},
keywords = {protean, intermittent computing, energy harvesting platform},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@article{10.1145/1716383.1716385,
title = {A Conversation with Steve Furber: The Designer of the ARM Chip Shares Lessons on Energy-Efficient Computing.},
year = {2010},
issue_date = {February 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/1716383.1716385},
doi = {10.1145/1716383.1716385},
abstract = {If you were looking for lessons on energy-efficient computing, one person you would want to speak with would be Steve Furber, principal designer of the highly successful ARM (Acorn RISC Machine) processor. Currently running in billions of cellphones around the world, the ARM is a prime example of a chip that is simple, low power, and low cost. Furber led development of the ARM in the 1980s while at Acorn, the British PC company also known for the BBC Microcomputer, which Furber played a major role in developing.},
journal = {Queue},
month = {feb},
pages = {1–8},
numpages = {8}
}

@inproceedings{10.1145/3324884.3415294,
author = {Xu, Jia and Liu, Xiao and Li, Xuejun and Zhang, Lei and Yang, Yun},
title = {EXPRESS: An Energy-Efficient and Secure Framework for Mobile Edge Computing and Blockchain Based Smart Systems},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3415294},
doi = {10.1145/3324884.3415294},
abstract = {As most smart systems such as smart logistic and smart manufacturing are delay sensitive, the current mainstream cloud computing based system architecture is facing the critical issue of high latency over the Internet. Meanwhile, as huge amount of data is generated by smart devices with limited battery and computing power, the increasing demand for energy-efficient machine learning and secure data communication at the network edge has become a hurdle to the success of smart systems. To address these challenges with using smart UAV (Unmanned Aerial Vehicle) delivery system as an example, we propose EXPRESS, a novel energy-efficient and secure framework based on mobile edge computing and blockchain technologies. We focus on computation and data (resource) management which are two of the most prominent components in this framework. The effectiveness of the EXPRESS framework is demonstrated through the implementation of a real-world UAV delivery system. As an open-source framework, EXPRESS can help researchers implement their own prototypes and test their computation and data management strategies in different smart systems. The demo video can be found at https://youtu.be/r3U1iU8tSmk.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1283–1286},
numpages = {4},
keywords = {data management, blockchain, mobile edge computing, smart system framework, computation management},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/2393347.2393405,
author = {Bhojan, Anand and Chong, Lee Kee and Chang, Ee-Chien and Chan, Mun Choon and Akkihebbal, Ananda L. and Ooi, Wei Tsang},
title = {El-Pincel: A Painter Cloud Service for Greener Web Pages},
year = {2012},
isbn = {9781450310895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393347.2393405},
doi = {10.1145/2393347.2393405},
abstract = {Due to their thin size, vivid colors, high contrast and power efficiency, OLED (Organic Light-Emitting Diode) display and its variants such as AMOLED (Active Matrix OLED) displays are increasingly replacing traditional LCD (Liquid Crystal Display) screens in smart phones. However, the power efficiency of OLED screens greatly depends on the luminance and colors of the displayed contents on the screen. Web browsing is one of the most widely used applications in mobile devices. In this paper, we present our cloud service, which intelligently re-paints the web pages in real-time with power efficient colors and HVS (Human Visual System) based tone mapping techniques, without adversely affecting the identity (brand color) of the web pages as well as the user's browsing experience. El-pincel helps to save up to 60% of OLED energy with color combinations that ensure good legibility and pleasing affective response to human eyes.},
booktitle = {Proceedings of the 20th ACM International Conference on Multimedia},
pages = {399–408},
numpages = {10},
keywords = {OLED display, color transformation, low power, tone mapping, browsing, color harmony, cloud service},
location = {Nara, Japan},
series = {MM '12}
}

@inproceedings{10.1145/1878335.1878366,
author = {Felthousen, Mat},
title = {Reduce Costs by Reducing Power: Navigating the Conflict between Administering Computers and Being 'Green'},
year = {2010},
isbn = {9781450300032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878335.1878366},
doi = {10.1145/1878335.1878366},
abstract = {Managers of public computing facilities are challenged with how to keep computers updated while also minimizing downtime. That is often solved by letting computers update automatically overnight while facilities are closed, or having staff on hand to apply updates manually. The latter usually involves increased payroll budgets.Leaving the machines on overnight and automating updates reduces payroll costs, but brings other challenges. There are significant potential savings in energy costs by reducing the amount of time that a computer is left on, in terms of electricity and cooling. There are less easily quantifiable savings resulting from reduced wear and tear on computer components. However, if computers are off, they cannot be remotely administered or updated. Simply setting all of the machines to turn on automatically at a set hour for updates is inefficient.At the University of Rochester we have created a distributed system with existing classroom audio-visual control systems that functions in a "Wake on LAN" (WOL) capacity. A command can be sent via the network to individual (or all) PCs and Macintoshes to power up on demand, meaning that we now can administer the machines remotely, even after they have been turned off. If the computers in facilities lapse into a reduced power state when not being used, the result will be a reduction of 75% or more in electricity usage for the computing facilities. If this approach were adopted University-wide, the savings could be more than $300,000 annually.},
booktitle = {Proceedings of the 38th  Annual ACM SIGUCCS Fall Conference: Navigation and Discovery},
pages = {113–120},
numpages = {8},
keywords = {power reduction, wake on lan, public computing labs},
location = {Norfolk, Virginia, USA},
series = {SIGUCCS '10}
}

@inproceedings{10.1145/2598394.2605695,
author = {Tantar, Alexandru-Adrian and Tantar, Emilia},
title = {A Survey on Sustainability in ICT: A Computing Perspective},
year = {2014},
isbn = {9781450328814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2598394.2605695},
doi = {10.1145/2598394.2605695},
abstract = {The rise of the data centers industry, together with the emergence of large cloud computing that require large quantities of resources to be maintained, brought the need of providing a sustainable development process. Through this paper we aim to provide an introductory insight on the status and tools available to tackle this perspective within the evolutionary and genetic algorithms community. Existing advancements are also emphasized and perspectives outlined.},
booktitle = {Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation},
pages = {1213–1220},
numpages = {8},
keywords = {sustainable ict, energy efficiency, evolutionary computation},
location = {Vancouver, BC, Canada},
series = {GECCO Comp '14}
}

@inproceedings{10.5555/2755753.2757176,
author = {Venkatesan, Rangharajan and Venkataramani, Swagath and Fong, Xuanyao and Roy, Kaushik and Raghunathan, Anand},
title = {Spintastic: &lt;u&gt;spin&lt;/U&gt;-Based S&lt;u&gt;t&lt;/U&gt;och&lt;u&gt;astic&lt;/U&gt; Logic for Energy-Efficient Computing},
year = {2015},
isbn = {9783981537048},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Spintronics is one of the leading technologies under consideration for the post-CMOS era. While spintronic memories have demonstrated great promise due to their density, non-volatility and low leakage, efforts to realize spintronic logic have been much less fruitful. Recent studies project the performance and energy efficiency of spintronic logic to be considerably inferior to CMOS. In this work, we explore Stochastic Computing (SC) as a new direction for the realization of energy-efficient logic using spintronic devices. We establish the synergy between stochastic computing and spintronics by demonstrating that (i) the peripheral circuits required for SC to convert to/from stochastic domains, which incur significant energy overheads in CMOS, can be efficiently realized by exploiting the characteristics of spintronic devices, and (ii) the low logic complexity and fine-grained parallelism in SC circuits can be leveraged to alleviate the shortcomings of spintronic logic. We propose Spintastic, a new design approach in which all the components of stochastic circuits --- stochastic number generators, stochastic arithmetic units, and stochastic-to-binary converters --- are realized using spintronic devices. Our experiments on a range of benchmarks from different application domains demonstrate that Spintastic achieves 2.8X improvement in energy over CMOS stochastic implementations and 1.9X over a CMOS binary baseline.},
booktitle = {Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition},
pages = {1575–1578},
numpages = {4},
location = {Grenoble, France},
series = {DATE '15}
}

@article{10.1145/2207222.2207227,
author = {Abbasi, Zahra and Varsamopoulos, Georgios and Gupta, Sandeep K. S.},
title = {TACOMA: Server and Workload Management in Internet Data Centers Considering Cooling-Computing Power Trade-off and Energy Proportionality},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {1544-3566},
url = {https://doi.org/10.1145/2207222.2207227},
doi = {10.1145/2207222.2207227},
abstract = {A two-tier Internet data center management scheme, TACOMA, with thermal-aware server provisioning (TASP) in one tier, and thermal-aware workload distribution (TAWD) in the other is proposed. TASP and TAWD coordinate to maximize the energy savings by leveraging the workload dynamics, at coarse and fine time scale, respectively. TACOMA is aware of the QoS constraints, the energy proportionality of servers, and the potential trade-off between cooling and computing power. The obtained energy savings are a combination of suspending idle servers, using servers at their peak efficiency, and avoiding heat recirculation.},
journal = {ACM Trans. Archit. Code Optim.},
month = {jun},
articleno = {11},
numpages = {37},
keywords = {energy-proportional systems, Data center, thermal aware server provisioning, and cooling computing power trade-off, energy saving, thermal aware workload distribution}
}

@inproceedings{10.1145/1999995.2000037,
author = {Bhojan, Anand and Akhihebbal, Ananda L. and Chan, Mun Choon},
title = {Demo: El-Pincel - a Painter Cloud Service for Greener Web Pages},
year = {2011},
isbn = {9781450306430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1999995.2000037},
doi = {10.1145/1999995.2000037},
abstract = {Due to their thin size, vivid colors, high contrast and power efficiency, OLED and its variants such as AMOLED screens are increasingly replacing traditional LCD screens in mobile phones (eg. Google Nexus One, Samsung Galaxy S phones). However, the power efficiency of OLED screens greatly depends on the luminance and colors of the displayed contents on the screen. Web browsing is one of the most widely used applications in mobile devices. We demonstrate our cloud service, which intelligently re-paints the web pages in real-time with power efficient colors and tone mapping techniques without adversely affecting the user experience in reading the page and the identity of the page. Transformation of images, flash contents and videos in client itself will incur significant computational and energy overhead. El-pincel is designed as a cloud service to avoid any additional overhead to the mobile device.},
booktitle = {Proceedings of the 9th International Conference on Mobile Systems, Applications, and Services},
pages = {365–366},
numpages = {2},
keywords = {oled display, tone mapping, human visual system, power management, color wheel},
location = {Bethesda, Maryland, USA},
series = {MobiSys '11}
}

@article{10.1145/3415199,
author = {Rifat, Mohammad Rashidujjaman and Toriq, Toha and Ahmed, Syed Ishtiaque},
title = {Religion and Sustainability: Lessons of Sustainable Computing from Islamic Religious Communities},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {CSCW2},
url = {https://doi.org/10.1145/3415199},
doi = {10.1145/3415199},
abstract = {While persuasion has often been considered an important design tool for achieving sustainable behavior, a growing scholarship is criticizing it for its narrow focus on individuals and an overarching economic worldview. This criticism is often based on the limitations of economic-rationales that many persuasive design efforts hold and cannot fully capture the values of people who reside outside the modern scientific world - especially where values originate from and are shaped by religiosity and spirituality. We join this discourse and argue that such a narrow view of persuasion sidelines the theological roots. Based on our six-month long ethnography with the Islamic communities in a Bangladeshi city, Kushtia, we describe how 'motivation' and 'habit' are built there - two of the basic components of persuasion. Drawing from a rich body of literature on the sociology of religions and theology, we highlight how Islamic values are closely tied to the idea of persuasion and reflect a vision of sustainable living. We further discuss how such a deeper understanding of religious values can help design for sustainable living and broaden the scope of CSCW literature in the various domains.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {128},
numpages = {32},
keywords = {islam, environment, habits, religion, persuasion, sustainability, rhetoric, design, faith}
}

@article{10.1145/3339399,
author = {Gomes, Carla and Dietterich, Thomas and Barrett, Christopher and Conrad, Jon and Dilkina, Bistra and Ermon, Stefano and Fang, Fei and Farnsworth, Andrew and Fern, Alan and Fern, Xiaoli and Fink, Daniel and Fisher, Douglas and Flecker, Alexander and Freund, Daniel and Fuller, Angela and Gregoire, John and Hopcroft, John and Kelling, Steve and Kolter, Zico and Powell, Warren and Sintov, Nicole and Selker, John and Selman, Bart and Sheldon, Daniel and Shmoys, David and Tambe, Milind and Wong, Weng-Keen and Wood, Christopher and Wu, Xiaojian and Xue, Yexiang and Yadav, Amulya and Yakubu, Abdul-Aziz and Zeeman, Mary Lou},
title = {Computational Sustainability: Computing for a Better World and a Sustainable Future},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {62},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/3339399},
doi = {10.1145/3339399},
abstract = {Computer and information scientists join forces with other fields to help solve societal and environmental challenges facing humanity, in pursuit of a sustainable future.},
journal = {Commun. ACM},
month = {aug},
pages = {56–65},
numpages = {10}
}

@inproceedings{10.5555/2819009.2819094,
author = {Sawyer, Pete and Sutcliffe, Alistair and Rayson, Paul and Bull, Chris},
title = {Dementia and Social Sustainability: Challenges for Software Engineering},
year = {2015},
publisher = {IEEE Press},
abstract = {Dementia is a serious threat to social sustainability. As life expectancy increases, more people are developing dementia. At the same time, demographic change is reducing the economically active part of the population. Care of people with dementia imposes great emotional and financial strain on sufferers, their families and society at large. In response, significant research resources are being focused on dementia. One research thread is focused on using computer technology to monitor people in at-risk groups to improve rates of early diagnosis. In this paper we provide an overview of dementia monitoring research and identify a set of scientific challenges for the engineering of dementia-monitoring software, with implications for other mental health self-management systems.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {527–530},
numpages = {4},
keywords = {social sustainability, software engineering, dementia},
location = {Florence, Italy},
series = {ICSE '15}
}

@article{10.5555/1127389.1127396,
author = {Kurkovsky, Anatoly},
title = {Educational Aspects of Sustainable Development Analysis: Computational Models and Software},
year = {2006},
issue_date = {April 2006},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {21},
number = {4},
issn = {1937-4771},
abstract = {Sustainable development is one of the most important aspects of successful growing and prosperity of the world community. The United Nations established a special Decade for Education for Sustainable Development (2005-2014) to encourage educational institutions participates in this processes. In this paper we discuss and propose a course on Sustainable Development Analysis at the undergraduate level offered at a small private university. In our course we concentrate on computational aspects of sustainable development using simulation models and appropriate software packages. According to the goals of the course, we present case studies and encourage students to conduct small independent research projects. Within the student's research projects certain air pollution concentrations are calculated using US Environmental Protection Agency software. These calculations with some extended information are considered as elements of sustainable development analysis at a regional level.},
journal = {J. Comput. Sci. Coll.},
month = {apr},
pages = {24–31},
numpages = {8},
keywords = {sustainable development, software, simulation, education}
}

@inproceedings{10.1145/3594441.3594449,
author = {Ram\'{\i}rez-Montoya, Mar\'{\i}a Soledad and Buenestado-Fern\'{a}ndez, Mariana and Ibarra-Vazquez, Gerardo},
title = {Unlocking Sustainable Development Goals through Computational Thinking: A Search to Inform Computers Education from Citizen Science Dataset},
year = {2023},
isbn = {9798400700613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594441.3594449},
doi = {10.1145/3594441.3594449},
abstract = {Linking sustainable development with computational thinking promotes high-impact problem solving, integrating fundamental concepts of computer programming. This study analyzed the relationship between computational thinking and the Sustainable Development Goals (SDGs) using text mining and data visualization techniques. A text mining method was employed to analyze computational thinking and its sub-competencies (decomposition, pattern recognition, abstraction and algorithm) appearances in the OSDG Community dataset, consisting of 32,120 text fragments labeled with the associated SDG. Results revealed that computational thinking and its subcompetencies: decomposition, pattern recognition, abstraction, and algorithm, were frequently linked to SDGs 4 (quality education), SDG 5 (gender equality), SDG 6 (clean water and sanitation), and SDG 11 (sustainable cities and communities). The findings demonstrate the potential of computational thinking to provide innovative solutions to global problems and support the achievement of the SDGs. The study can be of value to stakeholders in the social, governmental, academic and business sectors interested in sustainable development and educational innovation in the application of computational thinking.},
booktitle = {Proceedings of the 2023 8th International Conference on Information and Education Innovations},
pages = {41–47},
numpages = {7},
keywords = {Educational innovation, Text mining, Computational thinking, Data visualization},
location = {Manchester, United Kingdom},
series = {ICIEI '23}
}

@inproceedings{10.1145/3017680.3022346,
author = {Derbinsky, Nate and Suresh, Durga},
title = {Sustainable Methods for Impactful Service Learning in Computer Science (Abstract Only)},
year = {2017},
isbn = {9781450346986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3017680.3022346},
doi = {10.1145/3017680.3022346},
abstract = {Service learning offers students of computer science an experiential opportunity to hone not only their technical skills of design and programming, but also the soft skills of teamwork, communication, and social/ethical behavior. With hard work and effective mentoring from faculty, the output of student work can also benefit community partners, assuming there is proper infrastructure in place to provide long-term project management and technical support. This Birds of a Feather session provides a discussion platform to share lessons learned and best practices related to establishing a sustainable service-learning program within an undergraduate computer-science curriculum, with a particular focus on balancing benefits to students and community partners with organizational overhead.},
booktitle = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
pages = {723},
numpages = {1},
keywords = {experiential learning, service learning, curriculum},
location = {Seattle, Washington, USA},
series = {SIGCSE '17}
}

@inproceedings{10.1145/3482632.3484075,
author = {Wang, Shiwen and He, Yunjie and Wei, Yiwei},
title = {Design of Sustainable Intelligent Food Information System through Computer Dynamic System Model},
year = {2021},
isbn = {9781450390255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3482632.3484075},
doi = {10.1145/3482632.3484075},
booktitle = {2021 4th International Conference on Information Systems and Computer Aided Education},
pages = {1958–1963},
numpages = {6},
location = {Dalian, China},
series = {ICISCAE 2021}
}

@inproceedings{10.1145/3328778.3372580,
author = {Stange, Melissa C. and Stange, Rachel M.},
title = {Integrate Global Sustainability Virtual Exchange Into Teaching Computer Science Concepts},
year = {2020},
isbn = {9781450367936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328778.3372580},
doi = {10.1145/3328778.3372580},
abstract = {The increasing globalization of technology has changed the face of computer science. In addition to core technology skills, modern computer scientist must possess cross-cultural communication skills, team management skills, the ability to perform on geographically distributed teams, and an understanding of the big picture in addition to technical ability. Lord Fairfax Community College (LFCC) used a virtual exchange as a teaching tool for introductory computer science concepts. Nineteen students participated in the Global Solutions Sustainability Challenge, a project supported by the Stevens Initiative, which is sponsored by the U.S. Department of State and administered by the Aspen Institute. The project aims to find a sustainable solution to an issue within the hospitality and tourism industry, while providing students an opportunity to learn about a different culture. Over 10 week students learned about the seven big concepts of computer science, marketing, business plans, team work, public speaking, research, leadership, graphic design, application development, and much more. The poster describes the virtual student exchange concept, highlights the experiences and key elements that global virtual exchange offers students without travel expenses.},
booktitle = {Proceedings of the 51st ACM Technical Symposium on Computer Science Education},
pages = {1286},
numpages = {1},
keywords = {computer science, community colleges, virtual exchanges, interdisciplinary, intercultural communication},
location = {Portland, OR, USA},
series = {SIGCSE '20}
}

@inproceedings{10.1145/2484762.2484817,
author = {Taylor, James and Nekrutenko, Anton and Coraor, Nate and Blood, Philip D. and Ropelewski, Alex and Zhang, Zhihui and Palencia, Josephine and Sanielevici, Sergiu and Yanovich, Jared and Budden, Robert},
title = {A Sustainable National Gateway for Biological Computation},
year = {2013},
isbn = {9781450321709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2484762.2484817},
doi = {10.1145/2484762.2484817},
abstract = {We have developed and continue to support the Galaxy genomic analysis system [1]. Our main public Galaxy analysis website (Galaxy Main) currently supports close to 30,000 users performing hundreds of thousands of analysis jobs every month. Many academic and commercial institutions around the world operate private Galaxy instances. Our efforts so far have been focused on the development of software that enables any biological researcher to perform complex computational analyses by hiding technical complexities associated with management of underlying programs and high-performance compute infrastructure [2]. As a direct consequence of our initial success we have reached a point where we can no longer sustain the exponential growth of analysis load and associated biological data storage on our public servers. Here we discuss our ongoing efforts and future plans for establishing a sustainable national gateway for the analysis of biological data.},
booktitle = {Proceedings of the Conference on Extreme Science and Engineering Discovery Environment: Gateway to Discovery},
articleno = {32},
numpages = {3},
keywords = {de novo assembly, shared memory, computational gateway, genomics, data storage, NGS, data-intensive computing, high-performance computing, data transfer},
location = {San Diego, California, USA},
series = {XSEDE '13}
}

@inproceedings{10.1145/2538862.2544251,
author = {Inclezan, Daniela},
title = {Preparing Computer Science Students for a Sustainable Future (Abstract Only)},
year = {2014},
isbn = {9781450326056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2538862.2544251},
doi = {10.1145/2538862.2544251},
abstract = {Computer science students graduating in the next decade will face the big energy and environmental challenges of the 21st century. According to current trends, an increasing number of them will be employed in "green jobs" and will contribute to promoting biodiversity, minimizing the consumption of energy and materials, or restoring environmental quality. It is our job to prepare them for the task ahead. While the vast majority of textbooks and materials used in different areas of CS are oblivious to these problems, many resources can be found at the boundaries with other disciplines (e.g., environmental science, architecture, agriculture, etc.). Moreover, new computer applications are created every day for the analysis of current environmental problems and the evaluation of their possible solutions, but these applications are normally not mentioned in CS classes. This is a lost opportunity for engaging our students in the real world challenges we are facing today. Environmental problems can be addressed in the CS classroom in a way that does not impede the learning of the technical content, but rather increases students' ability to think critically about complex systems. This BoF intends to brainstorm innovative resources, examples, activities, and assignments that can be incorporated into the CS classes, in order to raise students' awareness to current ecological problems and, at the same time, illustrate the role computer scientists can play in solving them. For this BoF session, a laptop is optional.},
booktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},
pages = {731},
numpages = {1},
keywords = {ecological literacy, systemic thinking, critical thinking, ethical responsibility, sustainability},
location = {Atlanta, Georgia, USA},
series = {SIGCSE '14}
}

@inproceedings{10.5555/2338790.2338794,
author = {Kurkovsky, Anatoly},
title = {An Approach to Formalize the Dynamics of Complex Computer Systems for Subsequent Simulation and Sustainability Analysis},
year = {2012},
isbn = {9781618397874},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Globalization creates many challenges for the society, as well as for various technologies including computer systems. On the basis of the international higher education sustainable development initiative we considered sustainability of computer systems in universities as a response to globalization. Sustainability analysis requires an improved understanding of potential bottlenecks of the system dynamics. We identified computer systems of higher education as Multifunction Complex Computer Systems (MCCS) and proposed a formalization of their dynamics within a hierarchy of models. At the low level of the hierarchy we propose using propositional logic in order to formalize the system dynamics. At the top level of the hierarchy we propose creating an MCCS simulation model in order to conduct the sustainability analysis.},
booktitle = {Proceedings of the 2012 Symposium on Emerging Applications of M&amp;S in Industry and Academia Symposium},
articleno = {4},
numpages = {7},
keywords = {model development, simulation tools, applications, sustainability, higher education},
location = {Orlando, Florida},
series = {EAIA '12}
}

@article{10.5555/2667432.2667464,
author = {Abernethy, Ken and Treu, Kevin},
title = {Integrating Sustainability across the Computer Science Curriculum},
year = {2014},
issue_date = {December 2014},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {30},
number = {2},
issn = {1937-4771},
abstract = {Issues of sustainability have received considerable attention on college campuses over the last decade. However, actions taken in support of sustainability generally take the form of changing the practices of campus institutions and individuals (instituting a recycling program, for example). This paper describes experiences with incorporating sustainability topics into the computer science curriculum, at both the introductory and upper-levels. The results support the hypothesis that leveraging what the university does best -- teaching and learning -- can be an effective way to make students aware of these important issues, and possibly to motivate modified behavior. Moreover, computer science is an ideal discipline in which to embed sustainability lessons.},
journal = {J. Comput. Sci. Coll.},
month = {dec},
pages = {220–228},
numpages = {9},
keywords = {curriculum, sustainability, computer science, teaching, information technology}
}

@proceedings{10.1145/3604930,
title = {HotCarbon '23: Proceedings of the 2nd Workshop on Sustainable Computer Systems},
year = {2023},
isbn = {9798400702426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Hot Carbon focuses on understanding and addressing the negative environmental impacts of computing's success and computing's proliferation. The objective of the workshop is to foster insights and discussions as well as a growing community that focuses on sustainability of computer systems. We expect this includes innovative approaches to how we build, deploy, operate, and retire our creations, but perhaps even more. For example, software-driven hardware obsolescence that increases E-waste and embodied carbon suggests we must challenge computing's endemic upgrade and throwaway practices, and mindset.},
location = {Boston, MA, USA}
}

@article{10.1145/3265901,
author = {Eriksson, Elina},
title = {What is the Role of a Computer Scientist in Shaping a Sustainable Future?},
year = {2018},
issue_date = {Fall 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {1528-4972},
url = {https://doi.org/10.1145/3265901},
doi = {10.1145/3265901},
abstract = {It is becoming increasingly difficult to ignore the warnings of a disrupted climate system, from melting ice caps to species extinction. But the problems are so far removed, and so large, we often wonder what does this have to do with our work as computer scientists?},
journal = {XRDS},
month = {oct},
pages = {48–51},
numpages = {4}
}

@article{10.1145/3139290,
author = {Fokaefs, Marios and Barna, Cornel and Litoiu, Marin},
title = {From DevOps to BizOps: Economic Sustainability for Scalable Cloud Applications},
year = {2017},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {1556-4665},
url = {https://doi.org/10.1145/3139290},
doi = {10.1145/3139290},
abstract = {Virtualization of resources in cloud computing has enabled developers to commission and recommission resources at will and on demand. This virtualization is a coin with two sides. On one hand, the flexibility in managing virtual resources has enabled developers to efficiently manage their costs; they can easily remove unnecessary resources or add resources temporarily when the demand increases. On the other hand, the volatility of such environment and the velocity with which changes can occur may have a greater impact on the economic position of a stakeholder and the business balance of the overall ecosystem. In this work, we recognise the business ecosystem of cloud computing as an economy of scale and explore the effect of this fact on decisions concerning scaling the infrastructure of web applications to account for fluctuations in demand. The goal is to reveal and formalize opportunities for economically optimal scaling that takes into account not only the cost of infrastructure but also the revenue from service delivery and eventually the profit of the service provider. The end product is a scaling mechanism that makes decisions based on both performance and economic criteria and takes adaptive actions to optimize both performance and profitability for the system.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {nov},
articleno = {25},
numpages = {29},
keywords = {software engineering economics, DevOps, Cloud computing, self-adaptive systems}
}

@inproceedings{10.1109/MICRO.2014.43,
author = {Mckeown, Michael and Balkind, Jonathan and Wentzlaff, David},
title = {Execution Drafting: Energy Efficiency Through Computation Deduplication},
year = {2014},
isbn = {9781479969982},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MICRO.2014.43},
doi = {10.1109/MICRO.2014.43},
abstract = {Computation is increasingly moving to the data enter. Thus, the energy used by CPUs in the data centeris gaining importance. The centralization of computation in the data center has also led to much commonality between the applications running there. For example, there are many instances of similar or identical versions of the Apache web server running in a large data center. Many of these applications, such as bulk image resizing or video Transco ding, favor increasing throughput over single stream performance. In this work, we propose Execution Drafting, an architectural technique for executing identical instructions from different programs or threads on the same multithreaded core, such that they flow down the pipe consecutively, or draft. Drafting reduces switching and removes the need to fetch and decode drafted instructions, thereby saving energy. Drafting can also reduce the energy of the execution and commit stages of a pipeline when drafted instructions have similar operands, such as when loading constants. We demonstrate Execution Drafting saving energy when executing the same application with different data, as well as different programs operating on different data, as is the case for different versions of the same program. We evaluate hardware techniques to identify when to draft and analyze the hardware overheads of Execution Drafting implemented in an Open SPARC T1 core. We show that Execution Drafting can result in substantial performance per energy gains (up to 20%) in a data center without decreasing throughput or dramatically increasing latency.},
booktitle = {Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {432–444},
numpages = {13},
keywords = {Microarchitecture, Data Center Computing, Cloud Computing, Multithreading, Energy Efficiency, Energy Efficient Computing, Computation Deduplication},
location = {Cambridge, United Kingdom},
series = {MICRO-47}
}

@inproceedings{10.1145/1736020.1736044,
author = {Venkatesh, Ganesh and Sampson, Jack and Goulding, Nathan and Garcia, Saturnino and Bryksin, Vladyslav and Lugo-Martinez, Jose and Swanson, Steven and Taylor, Michael Bedford},
title = {Conservation Cores: Reducing the Energy of Mature Computations},
year = {2010},
isbn = {9781605588391},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1736020.1736044},
doi = {10.1145/1736020.1736044},
abstract = {Growing transistor counts, limited power budgets, and the breakdown of voltage scaling are currently conspiring to create a utilization wall that limits the fraction of a chip that can run at full speed at one time. In this regime, specialized, energy-efficient processors can increase parallelism by reducing the per-computation power requirements and allowing more computations to execute under the same power budget. To pursue this goal, this paper introduces conservation cores. Conservation cores, or c-cores, are specialized processors that focus on reducing energy and energy-delay instead of increasing performance. This focus on energy makes c-cores an excellent match for many applications that would be poor candidates for hardware acceleration (e.g., irregular integer codes). We present a toolchain for automatically synthesizing c-cores from application source code and demonstrate that they can significantly reduce energy and energy-delay for a wide range of applications. The c-cores support patching, a form of targeted reconfigurability, that allows them to adapt to new versions of the software they target. Our results show that conservation cores can reduce energy consumption by up to 16.0x for functions and by up to 2.1x for whole applications, while patching can extend the useful lifetime of individual c-cores to match that of conventional processors.},
booktitle = {Proceedings of the Fifteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {205–218},
numpages = {14},
keywords = {utilization wall, heterogeneous many-core, conservation core, patching},
location = {Pittsburgh, Pennsylvania, USA},
series = {ASPLOS XV}
}

@inproceedings{10.1145/1944862.1944886,
author = {Du Bois, Kristof and Schaeps, Tim and Polfliet, Stijn and Ryckbosch, Frederick and Eeckhout, Lieven},
title = {SWEEP: Evaluating Computer System Energy Efficiency Using Synthetic Workloads},
year = {2011},
isbn = {9781450302418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1944862.1944886},
doi = {10.1145/1944862.1944886},
abstract = {Energy efficiency is a key design concern in contemporary processor and system design, in the embedded domain as well as in the enterprise domain. The focus on energy efficiency has led to a number of power benchmarking methods recently. For example, EEMBC released EnergyBench and SPEC released SPECpower to quantify a system's energy efficiency; also academics have proposed power benchmarks, such as JouleSort. A major limitation for each of these proposals is that they are tied to a specific benchmark, and hence, they provide limited insight with respect to why one system may be more energy-efficient than another.This paper proposes SWEEP, Synthetic Workloads for Energy Efficiency and Performance evaluation, a framework for generating synthetic workloads with specific behavioral characteristics. We employ SWEEP to generate a wide range of synthetic workloads while varying the instruction mix, ILP, memory access patterns, and I/O-intensiveness; and we use SWEEP to evaluate the energy efficiency of commercial computer systems across the workload space and learn about how the energy efficiency of a computer system is tied to its workload's characteristics.This paper also presents the Energy-Delay Diagram (EDD), a novel method for visualizing energy efficiency. The EDD clearly illustrates the energy versus performance trade-off, and provides more intuitive insight than the traditionally used EDP and ED2P metrics.},
booktitle = {Proceedings of the 6th International Conference on High Performance and Embedded Architectures and Compilers},
pages = {159–166},
numpages = {8},
keywords = {workload characterization, energy-efficiency, generation},
location = {Heraklion, Greece},
series = {HiPEAC '11}
}

@inproceedings{10.1145/313451.313482,
author = {Havinga, Paul J. M. and Smit, Gerard J. M.},
title = {Octopus: Embracing the Energy Efficiency of Handheld Multimedia Computers},
year = {1999},
isbn = {1581131429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/313451.313482},
doi = {10.1145/313451.313482},
booktitle = {Proceedings of the 5th Annual ACM/IEEE International Conference on Mobile Computing and Networking},
pages = {77–87},
numpages = {11},
keywords = {handheld computers, multimedia, quality of service, switching fabric, energy efficiency},
location = {Seattle, Washington, USA},
series = {MobiCom '99}
}

@article{10.1145/3407228,
author = {Comber, Rob and Bardzell, Shaowen and Bardzell, Jeffrey and Hazas, Mike and Muller, Michael},
title = {Announcing a New CHI Subcommittee: Critical and Sustainable Computing},
year = {2020},
issue_date = {July - August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {1072-5520},
url = {https://doi.org/10.1145/3407228},
doi = {10.1145/3407228},
journal = {Interactions},
month = {jul},
pages = {101–103},
numpages = {3}
}

@article{10.1145/3492903,
author = {Chien, Andrew A.},
title = {Good, Better, Best: How Sustainable Should Computing Be?},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3492903},
doi = {10.1145/3492903},
journal = {Commun. ACM},
month = {nov},
pages = {6–7},
numpages = {2}
}

@article{10.1145/203356.203359,
author = {Dedrick, J. L. and Goodman, S. E. and Kraemer, K. L.},
title = {Little Engines That Could: Computing in Small Energetic Countries},
year = {1995},
issue_date = {May 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {5},
issn = {0001-0782},
url = {https://doi.org/10.1145/203356.203359},
doi = {10.1145/203356.203359},
abstract = {How do very small countries, here defined as having fewer than 10 million people, find places for themselves in the information technologies (IT) arena? Does success require accommodation in the global IT regime that often seems dominated by the U.S. and Japan? Do the little countries scurry around, like birds among the lions and other predators looking for scraps? Are they relegated to second tier “appropriate technologies,” or do they operate in the mainstream?},
journal = {Commun. ACM},
month = {may},
pages = {21–26},
numpages = {6}
}

@inproceedings{10.5555/3539845.3540026,
author = {Byrne, Anthony and Pang, Yanni and Zou, Allen and Nadgowda, Shripad and Coskun, Ayse K.},
title = {MicroFaaS: Energy-Efficient Serverless on Bare-Metal Single-Board Computers},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Serverless function-as-a-service (FaaS) platforms offer a radically-new paradigm for cloud software development, yet the hardware infrastructure underlying these platforms is based on a decades-old design pattern. The rise of FaaS presents an opportunity to reimagine cloud infrastructure to be more energy-efficient, cost-effective, reliable, and secure. In this paper, we show how replacing handfuls of x86-based rack servers with hundreds of ARM-based single-board computers could lead to a virtualization-free, energy-proportional cloud that achieves this vision. We call our systematically-designed implementation MicroFaaS, and we conduct a thorough evaluation and cost analysis comparing MicroFaaS to a throughput-matched FaaS platform implemented in the style of conventional virtualization-based cloud systems. Our results show a 5.6x increase in energy efficiency and 34.2% decrease in total cost of ownership compared to our baseline.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {754–759},
numpages = {6},
keywords = {serverless infrastructure, function-asa-service, energy-proportional computing, bare metal, single-board computers},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.5555/1379249.1379269,
author = {Lister, Raymond},
title = {After the Gold Rush: Toward Sustainable Scholarship in Computing},
year = {2008},
isbn = {9781920682590},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {In just thirty years, we have gone from punched cards to Second Life. But, as the American National Science Foundation (NSF) recently noted, "undergraduate computing education today often looks much as it did several decades ago" (NSF, 2006). Consequently, today's "Nintendo Generation" have voted with their feet. We bore them. The contrast between the changes wrought via computer research over the last 30 years, and the failure of computing education to adapt to those changes, is because computing academics lead a double life. In our research lives we see ourselves as part of a community that reaches beyond our own university. We read literature, we attend conferences, we publish, and the cycle repeats, with community members building upon each other's work. But in our teaching lives we rarely discuss teaching beyond our own university, we are not guided by any teaching literature; instead we simply follow our instincts.Academics in computing, or in any other discipline, can approach their teaching as research into how novices become experts. Several recent multi-institutional research collaborations have studied the development of novice programmers. This paper describes some of the results from those collaborations.The separation of our teaching and research lives diminishes not just our teaching but also our research. The modern practice of stripping away all 'distractions' to maximize research output is like the practice of stripping away rainforest to grow beef -- both practices appear to work, for a little while, but not indefinitely. Twenty-first century academia needs to bring teaching and research together, to form a scholarship of computing that is an integrated, sustainable, ecological whole.},
booktitle = {Proceedings of the Tenth Conference on Australasian Computing Education - Volume 78},
pages = {3–17},
numpages = {15},
keywords = {scholarship of teaching and learning, action research, discipline-based education research},
location = {Wollongong, NSW, Australia},
series = {ACE '08}
}

@inproceedings{10.1145/2517899.2517900,
author = {Masinde, Muthoni},
title = {Survivability to Sustainability of Biodiversity: What Do ICTs and Indigenous Knowledge Have to Do with It?},
year = {2013},
isbn = {9781450319072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517899.2517900},
doi = {10.1145/2517899.2517900},
abstract = {Literature is awash with the term 'sustainability'; sustainable development, sustainable education, sustainable eco-system, sustainable this, sustainable that but, it all boil down "the balance among nature (ecology), people (community of social networks) and the economy which transcends one generation". Sustainability is driven by the thirst to improve quality of life through sustained economic growth; however, with the world's population growing exponentially, and an equal measure of world's resource decline, maintaining this has become a mountainous task. This has led to the 'survival-for-the-fittest' kind of scenario where many people are left pushing so hard to survive; for them, sustainability has slowly given way to survivability. Sustainable use of biodiversity is one area where African has lagged behind. Rampant biodiversity degradation and the inability to cope with the resultant changes are some of the reasons why the Continent tops the list of climate change vulnerability victims. As researchers develop solutions to ensure Africa's survivability amidst these changes, they must avoid "transferring of Northern designs to Southern realities". No one knows Africa's biodiversity more that the local people themselves; they are host to rich indigenous knowledge on biodiversity degradation and mitigation practices; they have observed and experienced the changes over the years. However, this knowledge is facing threats from various circles and on its own, it may not deliver Africa's survivability tool. Information and telecommunications technology (ICT) provides the missing puzzle; integrating this with the indigenous knowledge (IK) is a sure way of improving survivability. In this paper, the design of such an integrated system for tracking biodiversity degradation is described and the link between the system and survivability demonstrated.},
booktitle = {Proceedings of the Sixth International Conference on Information and Communications Technologies and Development: Notes - Volume 2},
pages = {80–83},
numpages = {4},
keywords = {traditional knowledge, biodiversity degradation, sustainability, indigenous knowledge, Africa, survivability},
location = {Cape Town, South Africa},
series = {ICTD '13}
}

@article{10.1145/1647300.1658422,
author = {Fedorova, Alexandra and Saez, Juan Carlos and Shelepov, Daniel and Prieto, Manuel},
title = {Maximizing Power Efficiency with Asymmetric Multicore Systems: Asymmetric Multicore Systems Promise to Use a Lot Less Energy than Conventional Symmetric Processors. How Can We Develop Software That Makes the Most out of This Potential?},
year = {2009},
issue_date = {November 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {10},
issn = {1542-7730},
url = {https://doi.org/10.1145/1647300.1658422},
doi = {10.1145/1647300.1658422},
abstract = {In computing systems, a CPU is usually one of the largest consumers of energy. For this reason, reducing CPU power consumption has been a hot topic in the past few years in both the academic community and the industry. In the quest to create more power-efficient CPUs, several researchers have proposed an asymmetric multicore architecture that promises to save a significant amount of power while delivering similar performance to conventional symmetric multicore processors.},
journal = {Queue},
month = {nov},
pages = {30–45},
numpages = {16}
}

@inproceedings{10.5555/2663779.2663784,
author = {Gr\"{u}ter, Cyrill and Gysel, Peter and Krebs, Matthias and Meier, Christoph},
title = {EoD Designer: A Computation Tool for Energy Optimization of Data Centers},
year = {2012},
isbn = {9781467318327},
publisher = {IEEE Press},
abstract = {Total energy consumption in a data center is the sum of various components. We consider six main subsystems: Voltage transformer, uninterruptable power supply, IT equipment, computer room air handler, chiller and cooling tower. In this project a mathematical model for all six components was derived. Based on this model, a software tool was developed. It allows to simulate different variants of a data center and to minimize the total energy consumption by optimizing equipment and operating parameters. Thus potential energy savings can be evaluated. Finally the resulting reduction of operation expenses can directly be derived from the energy savings.},
booktitle = {Proceedings of the First International Workshop on Green and Sustainable Software},
pages = {28–34},
numpages = {7},
keywords = {data center, greening by software, energy efficiency, power modeling},
location = {Zurich, Switzerland},
series = {GREENS '12}
}

@inproceedings{10.1145/3183377.3183382,
author = {Penzenstadler, Birgit and Betz, Stefanie and Venters, Colin C. and Chitchyan, Ruzanna and Porras, Jari and Seyff, Norbert and Duboc, Leticia and Becker, Christoph},
title = {Everything is INTERRELATED: Teaching Software Engineering for Sustainability},
year = {2018},
isbn = {9781450356602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183377.3183382},
doi = {10.1145/3183377.3183382},
abstract = {Sustainability has become an important concern across many disciplines, and software systems play an increasingly central role in addressing it. However, teaching students from software engineering and related disciplines to effectively act in this space requires interdisciplinary courses that combines the concept of sustainability with software engineering practice and principles. Yet, presently little guidance exist on which subjects and materials to cover in such courses and how, combined with a lack of reusable learning objects. This paper describes a summer school course on Software Engineering for Sustainability (SE4S). We provide a blueprint for this course, in the hope that it can help the community develop a shared approach and methods to teaching SE4S. Practical lessons learned from delivery of this course are also reported here, and could help iterate over the course materials, structure, and guidance for future improvements. The course blueprint, availability of used materials and report of the study results make this course viable for replication and further improvement.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {153–162},
numpages = {10},
keywords = {sustainability design, sustainability, software engineering, pedagogy, sustainability education},
location = {Gothenburg, Sweden},
series = {ICSE-SEET '18}
}

@inproceedings{10.1145/1165573.1165674,
author = {Chen, Feng and Jiang, Song and Zhang, Xiaodong},
title = {SmartSaver: Turning Flash Drive into a Disk Energy Saver for Mobile Computers},
year = {2006},
isbn = {1595934626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1165573.1165674},
doi = {10.1145/1165573.1165674},
abstract = {In a mobile computer the hard disk consumes a considerable amount of energy. Existing dynamic power management policies usually take conservative approaches to save disk energy, and disk energy consumption remains a serious issue. Meanwhile, the flash drive is becoming a must-have portable storage device for almost every laptop user on travel. In this paper, we propose to make another highly desired use of the flash drive --- saving disk energy. This is achieved by using the flash drive as a standby buffer for caching and prefetching disk data. Our design significantly extends disk idle times with careful and deliberate consideration of the particular characteristics of the flash drive. Trace-driven simulations show that up to 41% of disk energy can be saved with a relatively small amount of data written to the flash drive.},
booktitle = {Proceedings of the 2006 International Symposium on Low Power Electronics and Design},
pages = {412–417},
numpages = {6},
keywords = {hard disk, flash drive, energy saving, mobile computer},
location = {Tegernsee, Bavaria, Germany},
series = {ISLPED '06}
}

@inproceedings{10.1145/3318216.3363302,
author = {Liu, Liangkai and Chen, Jiamin and Brocanelli, Marco and Shi, Weisong},
title = {E2M: An Energy-Efficient Middleware for Computer Vision Applications on Autonomous Mobile Robots},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363302},
doi = {10.1145/3318216.3363302},
abstract = {Autonomous mobile robots (AMRs) have been widely utilized in industry to execute various on-board computer-vision applications including autonomous guidance, security patrol, object detection, and face recognition. Most of the applications executed by an AMR involve the analysis of camera images through trained machine learning models. Many research studies on machine learning focus either on performance without considering energy efficiency or on techniques such as pruning and compression to make the model more energy-efficient. However, most previous work do not study the root causes of energy inefficiency for the execution of those applications on AMRs. The computing stack on an AMR accounts for 33% of the total energy consumption and can thus highly impact the battery life of the robot. Because recharging an AMR may disrupt the application execution, it is important to efficiently utilize the available energy for maximized battery life.In this paper, we first analyze the breakdown of power dissipation for the execution of computer-vision applications on AMRs and discover three main root causes of energy inefficiency: uncoordinated access to sensor data, performance-oriented model inference execution, and uncoordinated execution of concurrent jobs. In order to fix these three inefficiencies, we propose E2M, an energy-efficient middleware software stack for autonomous mobile robots. First, E2M regulates the access of different processes to sensor data, e.g., camera frames, so that the amount of data actually captured by concurrently executing jobs can be minimized. Second, based on a predefined per-process performance metric (e.g., safety, accuracy) and desired target, E2M manipulates the process execution period to find the best energy-performance trade off. Third, E2M coordinates the execution of the concurrent processes to maximize the total contiguous sleep time of the computing hardware for maximized energy savings. We have implemented a prototype of E2M on HydraOne, a real-world AMR. Our experimental results show that, compared to several baselines, E2M leads to 24% energy savings for the computing platform, which translates into an extra 11.5% of battery time and 14 extra minutes of robot runtime, with a performance degradation lower than 7.9% for safety and 1.84% for accuracy.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {59–73},
numpages = {15},
keywords = {energy efficiency, deep learning, autonomous mobile robots},
location = {Arlington, Virginia},
series = {SEC '19}
}

@inproceedings{10.1145/2938559.2948825,
author = {Ko, Jaejun and Lee, Jongwon and Choi, Young-June},
title = {Poster: A Novel Computation Offloading Technique for Reducing Energy Consumption of Smart Watch},
year = {2016},
isbn = {9781450344166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2938559.2948825},
doi = {10.1145/2938559.2948825},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion},
pages = {46},
numpages = {1},
keywords = {computation offloading, smartphone, cloud server, smart watch},
location = {Singapore, Singapore},
series = {MobiSys '16 Companion}
}

@inproceedings{10.1109/SE4Science.2019.00015,
author = {Badreddin, Omar and Hamou-Lhadj, Wahab and Chauhan, Swapnil},
title = {Susereum: Towards a Reward Structure for Sustainable Scientific Research Software},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SE4Science.2019.00015},
doi = {10.1109/SE4Science.2019.00015},
abstract = {Research software has opened up new pathways of discovery in many and diverse disciplines. This research software is developed under unique budgetary and schedule constraints. Its development is driven by knowledge discovery goals often without documented requirements. As a result, the software code quality is impacted which often hinders its sustainability beyond the immediate research goals. More importantly, the prevalent reward structures favor contributions in terms of research articles and systematically undervalues research codes contributions. As a result, researchers and funding agencies do not allocate appropriate efforts or resources to the development, sustenance, and dissemination of research codebases. This paper presents Susereum, a Blockchain based platform that aims at achieving two goals. First, restructuring prevalent incentives by awarding permanent immutable credit to research code authors similar to the credit awarded to the authors of scientific articles. Second, distributing sovereignty by empowering peers through a consensus process to define code sustainability and impact metrics.},
booktitle = {Proceedings of the 14th International Workshop on Software Engineering for Science},
pages = {51–54},
numpages = {4},
keywords = {software sustainability, blockchain, susereum, consensus algorithm, distributed sovereignty, research codes},
location = {Montreal, Quebec, Canada},
series = {SE4Science '19}
}

@inproceedings{10.1145/2468356.2468744,
author = {Mancini, Clara},
title = {Animal-Computer Interaction (ACI): Changing Perspective on HCI, Participation and Sustainability},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468744},
doi = {10.1145/2468356.2468744},
abstract = {In the spirit of this year's conference theme 'changing perspectives', this paper invites the CHI community to glance at interaction design through the lense of Animal-Computer Interaction (ACI). In particular, I argue that such a perspective could have at least three benefits: strengthening HCI as a discipline; broadening participation in Interaction Design; and supporting CHI's commitment to sustainability. I make the case that, far from being a niche research area, ACI is directly relevant to and even encompasses HCI. Thus ACI research firmly belongs at CHI.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {2227–2236},
numpages = {10},
keywords = {multispecies communities and ecologies, systemic design, designing-with, human and nonhuman animal computer interactions},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.5555/2819009.2819090,
author = {Pathak, Animesh and Issarny, Val\'{e}rie and Holston, James},
title = {AppCivist: A Service-Oriented Software Platform for Socially Sustainable Activism},
year = {2015},
publisher = {IEEE Press},
abstract = {The increased adoption of mobile devices and social networking is drastically changing the way people monitor and share knowledge about their environment. Here, information and communication technologies (ICT) offer significant new ways to support social activism in cities by providing residents with new digital tools to articulate projects and mobilize activities. However, the development of ICT for activism is still in its infancy, with activists using basic tools stitched together in an ad hoc manner for their needs. Still, Internet-based technologies and related software architectures feature various enablers for civic action beyond base social networking. To that end, this paper discusses the vision and initial details of AppCivist, a platform that builds on cross-domain research among social scientists and computer scientists to revisit service-oriented architecture and relevant services to further social activism. We discuss the ICT challenges inherent in this project and present our recent work to address them.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {515–518},
numpages = {4},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/2559206.2559214,
author = {Read, Janet C. and Hourcade, Juan Pablo and Markopoulos, Panos and Iversen, Ole Sejer},
title = {Child Computer Interaction SIG: Towards Sustainable Thinking and Being},
year = {2014},
isbn = {9781450324748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2559206.2559214},
doi = {10.1145/2559206.2559214},
abstract = {The discipline of Child Computer Interaction (CCI) has been steadily growing and it is now firmly established as a community in its own right, having the annual IDC (Interaction and Design for Children) conference and its own journal and also enjoying its role as a highly recognisable and vibrant contributor to the ACM CHI conference. Having recently been given status as an IFIP (International Federation for Information Processing) TC13 working group, the community now needs to make plans around its academic themes and its coherence as a developing academic community. The CCI SIG at CHI aims to use a mixture of facilitated creative thinking and a world caf\'{e} approach to bring the community together to tackle these two key challenges. The CCI SIG will be the natural meeting place for members of this community at CHI and will disseminate its discussion to the CCI and CHI communities through the production of visual and interactive materials at the CHI conference.},
booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
pages = {1135–1138},
numpages = {4},
keywords = {child computer interaction, research themes, research networks, community building},
location = {Toronto, Ontario, Canada},
series = {CHI EA '14}
}

@inproceedings{10.1145/3233391.3233527,
author = {Lundell, Bj\"{o}rn and Gamalielsson, Jonas},
title = {Sustainable Digitalisation through Different Dimensions of Openness: How Can Lock-in, Interoperability, and Long-Term Maintenance of IT Systems Be Addressed?},
year = {2018},
isbn = {9781450359368},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233391.3233527},
doi = {10.1145/3233391.3233527},
abstract = {Lock-in, interoperability, and long-term maintenance are three fundamental challenges that need to be addressed by any organisation involved in development, use and procurement of IT systems. This paper clarifies fundamental concepts and key dimensions of openness and provides examples of work-practices and recommendations for achieving sustainable digitalisation through addressing the fundamental challenges. Specifically, there are three main contributions. First, the concepts open standard, open source software, and open content are clarified and elaborated. Second, the associated three dimensions standard, software, and content are elaborated through examples of how different combinations along the dimensions can enable and inhibit sustainable digitalisation when IT-systems are developed and procured. Third, work-practices used by public sector organisations in specific projects for development and procurement of IT-systems are elaborated with the view to discuss how the three fundamental challenges are being addressed and provide guidance for how organisations can achieve a sustainable digitalisation.},
booktitle = {Proceedings of the 14th International Symposium on Open Collaboration},
articleno = {3},
numpages = {10},
keywords = {interoperability, open content, long-term maintenance, open standard, lock-in, IT systems, open source},
location = {Paris, France},
series = {OpenSym '18}
}

@inproceedings{10.1145/3202667.3202680,
author = {Ho, Jeffrey C. F.},
title = {Computer as Partner: A Critique Perspective of Interaction Design for Social Sustainability},
year = {2018},
isbn = {9781450365086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3202667.3202680},
doi = {10.1145/3202667.3202680},
abstract = {Sustainable human-computer interaction (HCI) is emerging as a major theme in the HCI community. Sustainability refers to fulfilling the long-term spiritual, environmental, and social requirements of humans. The previous discussions on sustainable HCI, specifically on the spiritual and social needs, were limited. Digital artifacts are essential parts of human life. A design critique perspective that considers computers as partners of users are proposed based on the human-computer integration concept. Three cases are reviewed in this paper to illustrate the critique perspective. Opportunities and implications are also discussed.},
booktitle = {Proceedings of the Sixth International Symposium of Chinese CHI},
pages = {95–99},
numpages = {5},
keywords = {Human--Computer Integration, Sustainability, Design Critique, Social Sustainability, Sustainable HCI, Computer as Partner},
location = {Montreal, QC, Canada},
series = {ChineseCHI '18}
}

@inproceedings{10.1145/2839509.2850496,
author = {Johnson, David E.},
title = {Computer Science Summer Camps: Making Summer Programs Fun and Sustainable (Abstract Only)},
year = {2016},
isbn = {9781450336857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2839509.2850496},
doi = {10.1145/2839509.2850496},
abstract = {Higher education has the opportunity (and often the mandate) to provide STEM outreach to their communities. Summer camp programs are one mechanism for providing quality CS learning experiences to a wide audience. This BOF will provide a platform for discussing strategies to make summer camps fun and sustainable. What are camp topics have been successful? How is funding obtained and sustained? Nationally, technology camps run the gamut from small, one-week programs to large camps that serve hundreds. The proposer will share his experience developing the University of Utah GREAT camps (www.cs.utah.edu/~dejohnso/GREAT), which have over 700 students attend one-week camps and hopes the BOF will attract others with their own experiences.},
booktitle = {Proceedings of the 47th ACM Technical Symposium on Computing Science Education},
pages = {708},
numpages = {1},
keywords = {summer camps, outreach},
location = {Memphis, Tennessee, USA},
series = {SIGCSE '16}
}

@inproceedings{10.1145/1520340.1520355,
author = {Kobayashi, Hiroki and Ueoka, Ryoko and Hirose, Michitaka},
title = {Human Computer Biosphere Interaction: Towards a Sustainable Society},
year = {2009},
isbn = {9781605582474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1520340.1520355},
doi = {10.1145/1520340.1520355},
abstract = {This paper presents the author's vision of Human Computer Biosphere Interaction (HCBI): Towards a Sustainable Society. HCBI extends the subject of HCI from countable people, objects, pets, and plants to an auditory biosphere that is uncountable, complex, and non-linguistic. By realizing HCBI, soundmarks in a forest can help us feel as one with nature, beyond the physical distance. The goal of HCBI is to realize the benefits of belonging to nature without causing environmental destruction. This paper presents the concept overview, related work, the method and developed interfaces.},
booktitle = {CHI '09 Extended Abstracts on Human Factors in Computing Systems},
pages = {2509–2518},
numpages = {10},
keywords = {sustainability, HCBI (human computer biosphere interaction), nature interface, sustainable interaction design, soundscape visualization, nature conservation, smart fashion},
location = {Boston, MA, USA},
series = {CHI EA '09}
}

@inproceedings{10.1145/3025453.3025542,
author = {Raghavan, Barath and Pargman, Daniel},
title = {Means and Ends in Human-Computer Interaction: Sustainability through Disintermediation},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025542},
doi = {10.1145/3025453.3025542},
abstract = {There has been an increased interest in broader contexts from ecology and economics within the HCI community in recent years. These developments suggest that the HCI community should engage with and respond to concerns that are external to computing yet profoundly impact human society. In this paper we observe that taking these broader contexts into account yields a fundamentally different way to think about sustainable interaction design, one in which the designer's focus must be on a) ecological limits, b) creating designs and artifacts that do not further a cornucopian paradigm, and c) fundamental human needs.It can be hard to be responsive to these contexts in practical HCI work. To address this, we propose that the design rubric of disintermediation can serve as a unifying approach for work that aims to meet the ecological and economic challenges outlined in the literature. After discussing the potential use and impact of disintermedation, we perform an analysis using this design rubric to several key application areas.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {786–796},
numpages = {11},
keywords = {sustainable computing, sustainable hci, disintermediation, complexity, sustainability},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/2897829.2897834,
author = {Park, Soojin and Park, Young B.},
title = {ITE Arbitrator: A Reference Architecture Framework for Sustainable IT Ecosystems},
year = {2016},
isbn = {9781450341721},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897829.2897834},
doi = {10.1145/2897829.2897834},
abstract = {As new IT systems and devices pervade all aspects of human routines, several new paradigms have recognized groups of IT systems as forming an ecosystem. As a result, the term "IT ecosystem" has been coined. Each individual system participating in an IT ecosystem has, to a varying degree, autonomy. The ultimate goal of participating systems is to satisfy the global goal of the entire IT ecosystem in which they are participating. In order to maintain autonomy and controllability over an IT ecosystem through environmental changes, orchestration strategies must be invented and implemented. In this paper, we propose a reference orchestration architecture framework, which we call ITE Arbitrator, to support IT ecosystems in accomplishing the goals of individual participant systems while simultaneously achieving system-wide goals. ITE Arbitrator provides a mechanism to decide on an adaptation strategy with an optimal configuration of available systems to satisfy local constraints while achieving its global goal. We use the detailed simulation example of an unmanned forest management IT ecosystem to show how the proposed framework orchestrates inter-system interaction against environmental changes and sustains stable service.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering for Systems-of-Systems},
pages = {25–31},
numpages = {7},
keywords = {system of systems, IT ecosystems, self-adaptive systems, orchestration},
location = {Austin, Texas},
series = {SESoS '16}
}

@inproceedings{10.1145/1936254.1936288,
author = {Ojala, T. and Valkama, V. and Kukka, H. and Heikkinen, T. and Lind\'{e}n, T. and Jurmu, M. and Kruger, F. and Hosio, S.},
title = {UBI-Hotspots: Sustainable Ecosystem Infrastructure for Real World Urban Computing Research and Business},
year = {2010},
isbn = {9781450300476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1936254.1936288},
doi = {10.1145/1936254.1936288},
abstract = {We report a novel deployment of so-called UBI-hotspots in a city center to establish an ecosystem infrastructure for conducting diverse urban computing research and business in authentic urban setting. We focus on the value network of the hotspots where the commercial use of the hotspots generates revenue for covering their operational expenses. The value network has been validated by a 12-month long operation, during which the hotspots and their services have been available to the general public on 24/7 basis.},
booktitle = {Proceedings of the International Conference on Management of Emergent Digital EcoSystems},
pages = {196–202},
numpages = {7},
keywords = {large public display, ubiquitous computing, value network},
location = {Bangkok, Thailand},
series = {MEDES '10}
}

@inproceedings{10.1145/3195970.3196092,
author = {Angizi, Shaahin and He, Zhezhi and Fan, Deliang},
title = {PIMA-Logic: A Novel Processing-in-Memory Architecture for Highly Flexible and Energy-Efficient Logic Computation},
year = {2018},
isbn = {9781450357005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195970.3196092},
doi = {10.1145/3195970.3196092},
abstract = {In this paper, we propose PIMA-Logic, as a novel <u>P</u>rocessing-<u>i</u>n-<u>M</u>emory <u>A</u>rchitecture for highly flexible and efficient <u>Logic</u> computation. Insteadof integrating complex logic units in cost-sensitive memory, PIMA-Logic exploits a hardware-friendly approach to implement Boolean logic functions between operands either located in the same row or the same column within entire memory arrays. Furthermore, it can efficiently process more complex logic functions between multiple operands to further reduce the latency and power-hungry data movement. The proposed architecture is developed based on Spin Orbit Torque Magnetic Random Access Memory (SOT-MRAM) array and it can simultaneously work as a non-volatile memory and a reconfigurable in-memory logic. The device-to-architecture co-simulation results show that PIMA-Logic can achieve up to 56% and 31.6% improvements with respect to overall energy and delay on combinational logic benchmarks compared to recent Pinatubo architecture. We further implement an in-memory data encryption engine based on PIMA-Logic as a case study. With AES application, it shows 77.2% and 21% lower energy consumption compared to CMOS-ASIC and recent RIMPA implementation, respectively.},
booktitle = {Proceedings of the 55th Annual Design Automation Conference},
articleno = {162},
numpages = {6},
location = {San Francisco, California},
series = {DAC '18}
}

@inproceedings{10.1145/3185089.3185107,
author = {Fhang, Mensely Cheah Siow and Tong, Wong Wai},
title = {Why a Good Process Fail? Experience in Building a Sustainable and Effective Process for Software Development},
year = {2018},
isbn = {9781450354141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185089.3185107},
doi = {10.1145/3185089.3185107},
abstract = {Considering a process as important as a software product is the first step towards establishing a robust and sustainable process for software development. Understanding the Non-Functional (characteristics) aspects of a process, capturing the properties and constraints under which a process must operate, and applying the knowledge and principle of implementing Non-Functional requirement in software development creates a process that is functional and sustainable. This paper examines how to effectively incorporate elements and standards for modelling product quality and adapting it for improving a process quality framework, which is practical for use by projects. The authors explore suggested models and case studies that contribute to forming a process that is widely acceptable by users and process stakeholders. This paper is extending and coupling a Characteristic-based Process Engineering Model and the approach of FMEA, synthesizing both the approaches towards establishing and institutionalizing processes for software development.},
booktitle = {Proceedings of the 2018 7th International Conference on Software and Computer Applications},
pages = {40–45},
numpages = {6},
keywords = {Characteristic-based, Non Functional Requirement, FMEA, Process Engineering},
location = {Kuantan, Malaysia},
series = {ICSCA '18}
}

@inproceedings{10.1145/2030031.2030036,
author = {Kirwan, Christopher Grant},
title = {Urban Media: A Design Process for the Development of Sustainable Applications for Ubiquitous Computing for Livable Cities},
year = {2011},
isbn = {9781450309318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2030031.2030036},
doi = {10.1145/2030031.2030036},
abstract = {Urban centers worldwide are now facing major challenges in almost every arena; population, health and public safety, environment, information access, housing, employment, security, banking, government and global economic competition. To effectively overcome these hurdles cities need to incorporate a broader design approach to understand, plan and shape new facets of urban growth and in the process, redefine the urban experience. As part of this effort, cities today are looking at new technologies to be incorporated into the urban fabric at different levels of intervention. Ubiquitous computing has the potential to be a key factor in these technologies and can be applied to reflect the nature of being human and the urban condition - on an individual level as well as recording the evolution of our society and the communities we live in.},
booktitle = {Proceedings of the 2011 ACM Symposium on The Role of Design in UbiComp Research &amp; Practice},
pages = {7–10},
numpages = {4},
keywords = {urban media, streaming media, media channels, urban growth, sensors, mobile media, interactive design, sms, urban interface, social media, location based media, urban branding systems, multimedia, interface design, data visualization, smart growth, ubiquitous technology, crowd sensing, community development, branding, interactive media, urban planning, kiosks, monitoring systems, smart cities, sustainable development},
location = {Beijing, China},
series = {RDURP '11}
}

@inproceedings{10.1145/2030031.2030033,
author = {Kirwan, Christopher Grant},
title = {Urban Media: A Design Process for the Development of Sustainable Applications for Ubiquitous Computing for Livable Cities},
year = {2011},
isbn = {9781450309318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2030031.2030033},
doi = {10.1145/2030031.2030033},
abstract = {Urban centers worldwide are now facing major challenges in almost every arena; population, health and public safety, environment, information access, housing, employment, security, banking, government and global economic competition. To effectively overcome these hurdles cities need to incorporate a broader design approach to understand, plan and shape new facets of urban growth and in the process, redefine the urban experience. As part of this effort, cities today are looking at new technologies to be incorporated into the urban fabric at different levels of intervention. Ubiquitous computing has the potential to be a key factor in these technologies and can be applied to reflect the nature of being human and the urban condition - on an individual level as well as recording the evolution of our society and the communities we live in.},
booktitle = {Proceedings of the 2011 ACM Symposium on The Role of Design in UbiComp Research &amp; Practice},
pages = {1–2},
numpages = {2},
keywords = {sensors, urban branding systems, interface design, urban growth, community development, crowd sensing, ubiquitous technology, social media, streaming media, multimedia, interactive media, branding, smart growth, sms, mobile media, monitoring systems, interactive design, urban planning, smart cities, kiosks, urban interface, location based media, urban media, data visualization, media channels, sustainable development},
location = {Beijing, China},
series = {RDURP '11}
}

@inproceedings{10.1145/1352592.1352600,
author = {Joukov, Nikolai and Sipek, Josef},
title = {GreenFS: Making Enterprise Computers Greener by Protecting Them Better},
year = {2008},
isbn = {9781605580135},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1352592.1352600},
doi = {10.1145/1352592.1352600},
abstract = {Hard disks contain data - frequently an irreplaceable asset of high monetary and non-monetary value. At the same time, hard disks are mechanical devices that consume power, are noisy, and fragile when their platters are rotating.In this paper we demonstrate that hard disks cause different kinds of problems for different types of computer systems and demystify several common misconceptions. We show that solutions developed to date are incapable of solving the power consumption, noise, and data reliability problems without sacrificing hard disk life-time, data reliability, or user convenience. We considered data reliability, recovery, performance, user convenience, and hard disk-caused problems together at the enterprise scale. We have designed GreenFS: a fan-out stackable file system that offers all-time all-data run-time data protection, improves performance under typical user workloads, and allows hard disks to be kept off most of the time. As a result, GreenFS improves enterprise data protection, minimizes disk drive-related power consumption and noise and increases the chances of disk drive survivability in case of unexpected external impacts.},
booktitle = {Proceedings of the 3rd ACM SIGOPS/EuroSys European Conference on Computer Systems 2008},
pages = {69–80},
numpages = {12},
keywords = {continuous data protection, power efficiency, backup},
location = {Glasgow, Scotland UK},
series = {Eurosys '08}
}

@article{10.1145/2506164.2506172,
author = {Taifi, Moussa},
title = {Banking on Decoupling: Budget-Driven Sustainability for HPC Applications on Auction-Based Clouds},
year = {2013},
issue_date = {July 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0163-5980},
url = {https://doi.org/10.1145/2506164.2506172},
doi = {10.1145/2506164.2506172},
abstract = {Cloud providers are auctioning their excess capacity using dynamically priced virtual instances. These spot instances provide significant savings compared to on-demand or fixed price instances. The users willing to use these resources are asked to provide a maximum bid price per hour, and the cloud provider runs the instances as long as the market price is below the user's bid price. By using such resources, the users are exposed explicitly to failures, and need to adapt their applications to provide some level of fault tolerance. In this paper, we expose the effect of bidding in the case of virtual HPC clusters composed of spot instances. We describe the interesting effect of uniform versus non-uniform bidding in terms of both the failure rate and the failure model. We propose an initial attempt to deal with the problem of predicting the runtime of a parallel application under various bidding strategies and various system parameters. We describe the relationship between bidding strategies and programming models, and we build a preliminary optimization model that uses real price traces from Amazon Web Services as inputs, as well as instrumented values related to the processing and network capacities of cluster instances on the EC2 services. Our results show preliminary insights into the relationship between non-uniform bidding and application scaling strategies.},
journal = {SIGOPS Oper. Syst. Rev.},
month = {jul},
pages = {41–50},
numpages = {10},
keywords = {spot instances, cloud virtual clusters, cost-aware optimization models, decoupling parallel programming models, auction-based cloud computing, cloud-based fault tolerance}
}

@inproceedings{10.1145/3470496.3527408,
author = {Gupta, Udit and Elgamal, Mariam and Hills, Gage and Wei, Gu-Yeon and Lee, Hsien-Hsin S. and Brooks, David and Wu, Carole-Jean},
title = {ACT: Designing Sustainable Computer Systems with an Architectural Carbon Modeling Tool},
year = {2022},
isbn = {9781450386104},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3470496.3527408},
doi = {10.1145/3470496.3527408},
abstract = {Given the performance and efficiency optimizations realized by the computer systems and architecture community over the last decades, the dominating source of computing's carbon footprint is shifting from operational emissions to embodied emissions. These embodied emissions owe to hardware manufacturing and infrastructure-related activities. Despite the rising embodied emissions, there is a distinct lack of architectural modeling tools to quantify and optimize the end-to-end carbon footprint of computing. This work proposes ACT, an architectural carbon footprint modeling framework, to enable carbon characterization and sustainability-driven early design space exploration. Using ACT we demonstrate optimizing hardware for carbon yields distinct solutions compared to optimizing for performance and efficiency. We construct use cases, based on the three tenets of sustainable design---Reduce, Reuse, Recycle---to highlight future methods that enable strong performance and efficiency scaling in an environmentally sustainable manner.},
booktitle = {Proceedings of the 49th Annual International Symposium on Computer Architecture},
pages = {784–799},
numpages = {16},
keywords = {sustainable computing, energy, manufacturing, computer architecture, mobile},
location = {New York, New York},
series = {ISCA '22}
}

@article{10.5555/3015063.3015079,
author = {Brock, J Dean and Bruce, Rebecca},
title = {Power Labs: Teaching Sustainability in a Computer Organizaton Class},
year = {2016},
issue_date = {December 2016},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {32},
number = {2},
issn = {1937-4771},
abstract = {With our ever-increasing reliance on information technology, sustainable computing has become a hot topic everywhere, with the possible exception of undergraduate CS education. We are working to change this by providing laboratory exercises that expose undergraduate students to the principles of power management without the complication and cost of specialized equipment.},
journal = {J. Comput. Sci. Coll.},
month = {dec},
pages = {104–110},
numpages = {7}
}

@inproceedings{10.1145/3450549.3464412,
author = {Jushchyshyn, Nick and Parks, Sandra},
title = {Virtual Production for Remote Teaching Modalities: Adapting Sustainable Remote Teaching and Learning Environments by Leveraging Real-Time Computer Graphics},
year = {2021},
isbn = {9781450383639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450549.3464412},
doi = {10.1145/3450549.3464412},
abstract = {Approaches for leveraging real-time graphics, virtual production technologies to bring the visual richness, diversity and fidelity of bespoke teaching venues into the realm of teleconference-based, distanced learning. A variety of readily accessible tools and implementations are presented that dramatically enhance the experience of teaching and learning through common teleconferencing platforms.},
booktitle = {ACM SIGGRAPH 2021 Educators Forum},
articleno = {1},
numpages = {2},
keywords = {Virtual Production, Education, Curricular Development},
location = {Virtual Event, USA},
series = {SIGGRAPH '21}
}

@inproceedings{10.1145/1841853.1841868,
author = {Weibert, Anne and Wulf, Volker},
title = {"All of a Sudden We Had This Dialogue...": Intercultural Computer Clubs' Contribution to Sustainable Integration},
year = {2010},
isbn = {9781450301084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1841853.1841868},
doi = {10.1145/1841853.1841868},
abstract = {A sustainable integration of migrants is an important societal task, touching numerous parts of everyday life. Developed as a socio-technical concept, intercultural computer clubs following the 'come_IN' approach are apt to provide a major contribution here. The aim is twofold: via collaboration in computer-based project work in the clubs, its participants a) establish and strengthen relationships in the intercultural neighborhood they now live in, and b) acquire computer skills that may broaden and ease their access to the job market as well as help them to keep up a remote relationship with their respective home countries. A qualitative evaluation study reveals the chances and limitations of this concept.},
booktitle = {Proceedings of the 3rd International Conference on Intercultural Collaboration},
pages = {93–102},
numpages = {10},
keywords = {integration, computer club, intercultural collaboration},
location = {Copenhagen, Denmark},
series = {ICIC '10}
}

