@article{https://doi.org/10.1002/spe.3078,
author = {Das, Jaydeep and Ghosh, Shreya and Mukherjee, Anwesha and Ghosh, Soumya K. and Buyya, Rajkumar},
title = {RESCUE: Enabling green healthcare services using integrated IoT-edge-fog-cloud computing environments},
journal = {Software: Practice and Experience},
volume = {52},
number = {7},
pages = {1615-1642},
keywords = {cloud computing, edge computing, geospatial query processing, green computing, healthcare service, internet of things, spatio-temporal data},
doi = {https://doi.org/10.1002/spe.3078},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3078},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.3078},
abstract = {Abstract Internet of Things (IoT) has a pivotal role in developing intelligent and computational solutions to facilitate varied real-life applications. To execute high-end computations and data analytics, IoT and cloud-based solutions play the most significant role. However, frequent communication with long distant cloud servers is not a delay-aware and energy-efficient solution while providing time-critical applications such as healthcare. This article explores the possibilities and opportunities of integrating cloud technology with fog and edge-based computing to provide healthcare services to users in exigency. Here, we propose an end-to-end framework named RESCUE (enabling green healthcare services using integrated iot-edge-fog-cloud computing environments), consisting efficient spatio-temporal data analytics module for efficient information sharing, spatio-temporal data analysis to predict the path for users to reach the destination (healthcare center or relief camps) with minimum delay in the time of exigency (say, natural disaster). This module analyzes the collected information through crowd-sourcing and assists the user by extracting optimal path postdisaster when many regions are nonreachable. Our work is different from the existing literature in varied aspects: it analyses the context and semantics by augmenting real-time volunteered geographical information (VGI) and refines it. Furthermore, the novel path prediction module incorporates such VGI instances and predicts routes in emergencies avoiding all possible risks. Also, the design of development of a latency-aware, power-aware data-driven analytics system helps to resolve any spatio-temporal query more efficiently compared to the existing works for any time-critical application. The experimental and simulation results outperform the baselines in terms of accuracy, delay, and power consumption.},
year = {2022}
}

@inbook{doi:https://doi.org/10.1002/9781118305393.ch3,
author = {Steigerwald, Bob and Agrawal, Abhishek},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781118305393},
title = {Green Software},
booktitle = {Harnessing Green It},
chapter = {3},
pages = {39-62},
doi = {https://doi.org/10.1002/9781118305393.ch3},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118305393.ch3},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118305393.ch3},
year = {2012},
keywords = {Software energy efficiency, Computational efficiency, Data efficiency, Context awareness, Idle efficiency, C-state, P-state, Timer resolution},
abstract = {Summary This chapter examines software methodologies, designs, and software development tools that can be used to improve the energy efficiency of application software and extend mobile platform battery life. During software development, computational efficiency, data efficiency, context-aware methods, and idle efficiency can all contribute to creating applications that conserve energy. To help developers evaluate software, we also describe measurement methodologies and tools that will help developers obtain the necessary feedback to improve their applications.}
}@article{https://doi.org/10.1002/ett.2967,
author = {Chen, Chao and Bao, Weidong and Zhu, Xiaomin and Ji, Haoran and Xiao, Wenhua and Wu, Jianhong},
title = {AGILE: A terminal energy efficient scheduling method in mobile cloud computing},
journal = {Transactions on Emerging Telecommunications Technologies},
volume = {26},
number = {12},
pages = {1323-1336},
doi = {https://doi.org/10.1002/ett.2967},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.2967},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ett.2967},
abstract = {Abstract With the development of mobile telecommunication technology, mobile phones have become a necessary tool in daily life and provided us many conveniences. Meanwhile, the huge number of cell phones constitute a potential high performance data processing system, called mobile cloud computing, to strengthen capacity for individual devices. Many researchers have studied about the architectures and scheduling algorithms of mobile cloud computing. However, little work has been performed about how to schedule mobile application tasks in data centers to extend battery life for mobile terminals. To address this issue, we investigate agent models, mobile energy consumption models and data transmission models under different connection environments. Based on which, we propose a novel terminal energy efficient scheduling method (AGILE for short). AGILE compares energy consumption in cloud execution and mobile execution according to the actual wireless environment, then makes energy-efficient decisions. Extensive experiments are conducted to evaluate the performance of the AGILE under different wireless channels, and the performance impact on different parameters are studied. The experimental results indicate that the proposed method can save mobile devices' energy effectively. Copyright © 2015 John Wiley \& Sons, Ltd.},
year = {2015}
}
@article{https://doi.org/10.1049/iet-com.2016.0046,
author = {Alhumaima, Raad S. and Al-Raweshidy, Hamed S.},
title = {Evaluating the energy efficiency of software defined-based cloud radio access networks},
journal = {IET Communications},
volume = {10},
number = {8},
pages = {987-994},
keywords = {software radio, energy conservation, radio access networks, energy efficiency evaluation, software defined-based cloud radio access networks, communications network, power consumption, PC, SDC-RAN, parameterised PM, linear power model, componentised PM},
doi = {https://doi.org/10.1049/iet-com.2016.0046},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-com.2016.0046},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1049/iet-com.2016.0046},
abstract = {Densifying the communications network and integrating innovative technologies leads to increased power consumption (PC), along with increased signalling and degraded scalability. The latter can be mitigated by using software defined networks, while cloud radio access network (C-RAN) reduces the PC. Since evaluating and improving the PC is an important key success factor for the upcoming fifth generations, a reliable power model (PM) is required. This study proposes a componentised, linear and parameterised PM, and explores the individual components relevant for PC analysis, particularly for software defined C-RAN (SDC-RAN) architecture. The model quantifies the energy efficiency (EE) by capturing the PC of individual components, and measures the amount of PC in the network. Cooling and total PC of C-RAN and SDC-RAN for different parameters such as varying numbers of antennas and different system's bandwidth share has also been considered. The results show that SDC-RAN increases the total PC by about 20\% compared with C-RAN. Additionally, the study shows the results of modelling the participating core network's control plane unit's PC along with establishing the accuracy of the components and the parameterised models.},
year = {2016}
}
@article{https://doi.org/10.1002/cpe.3941,
author = {Zhao, Haihui and Qi, Yaoguang and Du, Hongwei and Wang, Ningning and Zhang, Guofu and Liu, Wenbao and Lu, Hailong},
title = {Running state of the high energy consuming equipment and energy saving countermeasure for chinese petroleum industry in cloud computing},
journal = {Concurrency and Computation: Practice and Experience},
volume = {29},
number = {14},
pages = {e3941},
keywords = {high energy consuming equipment, petroleum industry, cloud computing, running state, obsolete equipment, energy saving countermeasure},
doi = {https://doi.org/10.1002/cpe.3941},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3941},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3941},
note = {e3941 cpe.3941},
abstract = {Summary The energy consumption of the high energy consuming petroleum equipment in oil field possesses a high proportion in the total energy consumption of oil industry, so these equipment act as an important role in oil field energy saving. This paper analyzes the energy consumption constitutions in different production process. It is based on the study focusing on the running state and energy saving countermeasure of the high energy consuming mechanical equipment. The research is organized by the Chinese Academy of Engineering. The high energy consumption cause is studied by investigating and analyzing the running state of the principle energy consuming equipment in oil field and the design and manufacture level of the key large equipment in cloud computing. This thesis provides concurrent data processing model for shortening the production cycle and the fuzzy weighting subspace clustering algorithm to implement the equipment comparability, applying the big data on the running status statistics and applying cloud computation analysis on the corresponding energy saving countermeasure. The proposed approach is providing the method of eliminating equipment and the advice of the research directions in order to address the energy saving counter measure issues. The findings of this paper can be referenced as the energy saving counter measure in the petroleum industry. Copyright © 2016 John Wiley \& Sons, Ltd.},
year = {2017}
}
@article{https://doi.org/10.1002/dac.5359,
author = {Malla, Parvaz Ahmad and Sheikh, Sophiya},
title = {Analysis of QoS aware energy-efficient resource provisioning techniques in cloud computing},
journal = {International Journal of Communication Systems},
volume = {36},
number = {1},
pages = {e5359},
keywords = {energy efficiency, load balancing, resource allocation, scheduling, virtual machine optimization},
doi = {https://doi.org/10.1002/dac.5359},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.5359},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/dac.5359},
abstract = {Summary By incorporating on-demand resources, software and data for collaborative services through the Internet, the conventional Information Technology enterprise has been transformed by cloud computing. Based on the pay-per-use approach, Infrastructure, platform or Software resources and servers located across data centres are among the several types of resources offered to consumers in cloud computing. Data centres handle these resources. These resources are constantly provisioned to users based on their availability, demand, and quality requirements. Cloud computing systems are known as one of the largest utilisers of energy resources all over the world. Also, power consumption has become a crucial aspect as most cloud computing systems work on traditional nonrenewable resources of energy. In order to make data centres environment-friendly, there is a need for optimal approaches to reduce energy consumption and their hazardous effects on the environment. To analyse different available strategies for building and maintaining an energy-efficient cloud is the main objective of this paper. The paper will comprehensively review several energy-efficient resource provisioning methods and provide a graphical comparative study of Quality of Service (QoS) Metrics in cloud computing. Moreover, the present study identifies the areas of study that need to be further improved to increase the energy efficiency of cloud computing systems.},
year = {2023}
}
@article{https://doi.org/10.1002/cpe.3295,
author = {Kansal, Nidhi Jain and Chana, Inderveer},
title = {Artificial bee colony based energy-aware resource utilization technique for cloud computing},
journal = {Concurrency and Computation: Practice and Experience},
volume = {27},
number = {5},
pages = {1207-1225},
keywords = {resource utilization, server consolidation, virtualization, energy efficiency, artificial bee colony},
doi = {https://doi.org/10.1002/cpe.3295},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3295},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3295},
abstract = {SummaryCloud computing is a form of distributed computing, which promises to deliver reliable services through next-generation data centers that are built on virtualized compute and storage technologies. It is becoming truly ubiquitous and with cloud infrastructures becoming essential components for providing Internet services, there is an increase in energy-hungry data centers deployed by cloud providers. As cloud providers often rely on large data centers to offer the resources required by the users, the energy consumed by cloud infrastructures has become a key environmental and economical concern. Much energy is wasted in these data centers because of under-utilized resources hence contributing to global warming. To conserve energy, these under-utilized resources need to be efficiently utilized and to achieve this, jobs need to be allocated to the cloud resources in such a way so that the resources are used efficiently and there is a gain in performance and energy efficiency. In this paper, a model for energy-aware resource utilization technique has been proposed to efficiently manage cloud resources and enhance their utilization. It further helps in reducing the energy consumption of clouds by using server consolidation through virtualization without degrading the performance of users’ applications. An artificial bee colony based energy-aware resource utilization technique corresponding to the model has been designed to allocate jobs to the resources in a cloud environment. The performance of the proposed algorithm has been evaluated with the existing algorithms through the CloudSim toolkit. The experimental results demonstrate that the proposed technique outperforms the existing techniques by minimizing energy consumption and execution time of applications submitted to the cloud. Copyright © 2014 John Wiley \& Sons, Ltd.},
year = {2015}
}
@article{https://doi.org/10.1002/2050-7038.12094,
author = {Allahvirdizadeh, Yousef and Moghaddam, Mohsen Parsa and Shayanfar, Heidarali},
title = {A survey on cloud computing in energy management of the smart grids},
journal = {International Transactions on Electrical Energy Systems},
volume = {29},
number = {10},
pages = {e12094},
keywords = {cloud computing, demand response, demand side management, energy hub, energy management, smart grid},
doi = {https://doi.org/10.1002/2050-7038.12094},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2050-7038.12094},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/2050-7038.12094},
note = {e12094 ITEES-18-1106.R1},
abstract = {Summary Smart grid mitigates the environmental concerns associated with the global warming and climate shifting and reduces the dependence of the power generation on conventional fossil fuels. This is done by energy efficiency improvement and renewable energy sources exploitation at large scales in the form of centralized systems as well as small-scale systems in the form of microgrids and nanogrids. However, smart grid technology brings new challenges to the big data management of the new power system construction. Additionally, due to the large-scale intermittent distributed renewable resources contribution and stochastic electric vehicles integration, the current energy management systems must undergo some improvements to handle the smart grid requirements. Cloud computing, as an intermittent based on-demand computing model, serves an emerging solution to the aforementioned challenges. As a result, this paper presents a survey study on the smart grid and state of art energy management methods and the necessitation of the cloud computing incorporation in smart grid energy management. Then, the application of the cloud computing in energy management, demand side management programs, building energy management systems, energy hubs, and power dispatching systems have been discussed and associated models are addressed.},
year = {2019}
}
@article{https://doi.org/10.1002/er.6141,
author = {Hashmi, Shahwaiz Ahmed and Ali, Chaudhry Fahad and Zafar, Saima},
title = {Internet of things and cloud computing-based energy management system for demand side management in smart grid},
journal = {International Journal of Energy Research},
volume = {45},
number = {1},
pages = {1007-1022},
keywords = {demand side management, energy management system, internet of things, load profile, power consumption, smart grid},
doi = {https://doi.org/10.1002/er.6141},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/er.6141},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/er.6141},
abstract = {Summary A smart grid is an electricity network, which deals with electronic power conditioning and control of production, transmission, and distribution of electrical power by employing digital communication technologies to monitor and manage local changes in electricity usage. In the traditional power grid, energy consumers remain oblivious to their power consumption patterns, resulting in wasted energy as well as money. This issue is severely pronounced in the developing countries where there is a huge gap between demand and supply, resulting in frequent power outages and load-shedding. For electrical energy savings, the smart grid employs demand side management (DSM), which refers to adaptation in consumer's demand for energy through various approaches such as financial incentives and awareness. The DSM in future smart grid must exploit automated energy management systems (EMS) built upon the state-of-the-art technologies such as the internet of things (IoT) and cloud and/or fog computing. In this paper, we present the architecture framework, design, and implementation of an IoT and cloud computing-based EMS, which generates load profile of consumer to be accessed remotely by utility company or by the consumer. The consumers' load profiles enable utility companies to regulate and disseminate their incentives and incite the consumers to adapt their energy consumption. Our designed EMS is implemented on a Project Circuit Board (PCB) to be easily installed at the consumer premises where it performs the following tasks: (a) monitors energy consumption of electrical appliances by means of our designed current and voltage sensors, (b) uploads sensed data to Google Firebase cloud over many-to-many IoT communication protocol Message Queuing Telemetry Transport (MQTT) where consumer's load profile is generated, which can be accessed via a web portal. These load profiles serve as input for implementing the various DSM approaches. Our results demonstrate generated load profiles of consumer load in terms of current, voltage, energy, and power accessible via a web portal.},
year = {2021}
}
@article{https://doi.org/10.1002/smr.1849,
author = {Pahl, Claus and Jamshidi, Pooyan and Weyns, Danny},
title = {Cloud architecture continuity: Change models and change rules for sustainable cloud software architectures},
journal = {Journal of Software: Evolution and Process},
volume = {29},
number = {2},
pages = {e1849},
keywords = {adaptation, change, change models, cloud systems, evolution, software architecture},
doi = {https://doi.org/10.1002/smr.1849},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.1849},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/smr.1849},
note = {e1849 smr.1849},
abstract = {Abstract Cloud systems provide elastic execution environments of resources that link application and infrastructure/platform components, which are both exposed to uncertainties and change. Change appears in 2 forms: the evolution of architectural components under changing requirements and the adaptation of the infrastructure running applications. Cloud architecture continuity refers to the ability of a cloud system to change its architecture and maintain the validity of the goals that determine the architecture. Goal validity implies the satisfaction of goals in adapting or evolving systems. Architecture continuity aids technical sustainability, that is, the longevity of information, systems, and infrastructure and their adequate evolution with changing conditions. In a cloud setting that requires both steady alignment with technological evolution and availability, architecture continuity directly impacts economic sustainability. We investigate change models and change rules for managing change to support cloud architecture continuity. These models and rules define transformations of architectures to maintain system goals: Evolution is about unanticipated change of structural aspects of architectures, and adaptation is about anticipated change of architecture configurations. Both are driven by quality and cost, and both represent multidimensional decision problems under uncertainty. We have applied the models and rules for adaptation and evolution in research and industry consultancy projects.},
year = {2017}
}
@article{https://doi.org/10.1002/spe.3010,
author = {Zolfaghari, Rahmat and Sahafi, Amir and Rahmani, Amir Masoud and Rezaei, Reza},
title = {An energy-aware virtual machines consolidation method for cloud computing: Simulation and verification},
journal = {Software: Practice and Experience},
volume = {52},
number = {1},
pages = {194-235},
keywords = {cloud computing systems (CCSs), data center, energy consumption, formal verification, virtual machines consolidation (VMC)},
doi = {https://doi.org/10.1002/spe.3010},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3010},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.3010},
abstract = {Abstract Cloud systems have become an essential part of our daily lives owing to various Internet-based services. Consequently, their energy utilization has also become a necessary concern in cloud computing systems increasingly. Live migration, including several virtual machines (VMs) packed on in minimal physical machines (PMs) as virtual machines consolidation (VMC) technique, is an approach to optimize power consumption. In this article, we have proposed an energy-aware method for the VMC problem, which is called energy-aware virtual machines consolidation (EVMC), to optimize the energy consumption regarding the quality of service guarantee, which comprises: (1) the support vector machine classification method based on the utilization rate of all resource of PMs that is used for PM detection in terms of the amount' load; (2) the modified minimization of migration approach which is used for VM selection; (3) the modified particle swarm optimization which is implemented for VM placement. Also, the evaluation of the functional requirements of the method is presented by the formal method and the non-functional requirements by simulation. Finally, in contrast to the standard greedy algorithms such as modified best fit decreasing, the EVMC decreases the active PMs and migration of VMs, respectively, 30\%, 50\% on average. Also, it is more efficient for the energy 30\% on average, resources and the balance degree 15\% on average in the cloud.},
year = {2022}
}
@article{https://doi.org/10.1002/dac.3914,
author = {Vankadara, Saritha and Dasari, Nagaraju},
title = {Energy-aware dynamic task offloading and collective task execution in mobile cloud computing},
journal = {International Journal of Communication Systems},
volume = {33},
number = {13},
pages = {e3914},
keywords = {cloud computing, energy, mobile computing, network management, offloading},
doi = {https://doi.org/10.1002/dac.3914},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.3914},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/dac.3914},
note = {e3914 IJCS-18-0605.R1},
abstract = {Summary There is a good opportunity for enlightening the services of the mobile devices by introducing computational offloading using cloud technology. Offloading is a process for managing the complexity of the mobile environment by migrating computational load to the cloud. The mobile devices oblige the quick response for the offloading requests; it is dependent on network connectivity. The cloud services take long set-up time irrespective of network connectivity. In this paper, new system architecture for the dynamic task offloading in the mobile cloud environment is proposed. The architecture includes the offloading algorithm that concentrates on energy consumption of the tasks both in the local and remote environment. The proposed algorithm formulates a collective task execution model for minimizing the energy consumption. The architecture concentrates on the network model by considering the task completion time in three different network scenarios. The experimental results show the efficiency of the suggested architecture in reducing the energy consumption and completion time of the tasks.},
year = {2020}
}
@article{https://doi.org/10.1002/cpe.6579,
author = {Xu, Yanfei and Abnoosian, Karlo},
title = {A new metaheuristic-based method for solving the virtual machines migration problem in the green cloud computing},
journal = {Concurrency and Computation: Practice and Experience},
volume = {34},
number = {3},
pages = {e6579},
keywords = {cloud computing, genetic algorithm, green, metaheuristic, particle swarm optimization, virtual machine migration},
doi = {https://doi.org/10.1002/cpe.6579},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6579},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.6579},
abstract = {Summary Cloud computing (CC) provides dynamic hiring of server abilities as scalable virtualized services to end-users. However, data center hosting wastes massive amounts of energy resulting in high operational costs and carbon footprints. Also, virtualization is one of CC's main features, and physical resources are delivered by virtual machine (VM). Therefore, in the present article, a new method is provided to improve the VM energy consumption and execution time in the VM migration problem using a hybrid optimization algorithm. Since this issue is one of the famous NP-hard problems, a method is proposed in this article works based on genetic algorithm (GA) and particle swarm optimization (PSO) algorithm. The hybrid algorithm uses a GA to dominate PSO algorithms' constraints, such as weak convergence and stymie in global optima. The CloudSim simulator is employed to show the efficiency of the method compared to others. Using this method will keep the proficiency and power performance of the data centers at the same level. The results showed that energy consumption in the proposed method is better than the other three methods and has been improved by an average of 23.19\%. Also, the results showed that execution time is better than the other three methods and has been improved by an average of 29.01\%.},
year = {2022}
}
@article{https://doi.org/10.1002/dac.4225,
author = {Sharma, Bhisham and Mittal, Payal and Obaidat, Mohammad S.},
title = {Power-saving policies for annual energy cost savings in green computing},
journal = {International Journal of Communication Systems},
volume = {33},
number = {4},
pages = {e4225},
keywords = {carbon emissions, eco-friendly, energy consumption, green computing, power-saving policies, recycling devices},
doi = {https://doi.org/10.1002/dac.4225},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.4225},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/dac.4225},
note = {e4225 IJCS-19-0818.R1},
abstract = {Summary The concept of green computing is a step toward advanced information technology-related data computations. There is an urgent need to develop sustainable mobile telecommunication networks subscribed by Telecommunication Regulatory Authority of India (TRAI). This paper aims at deploying major recommendations and directions in computing systems directed by regulating authorities. Green computing–based power-saving policies include virtualization technique, power-saving method, and recycling technique-type solution components that we tried to embed in existing systems. The energy-efficient green computing reserves the reliability and power of information-driven technology. This research paper provides a comprehensive approach toward applying green mechanism by spotting the difference between energy consumption of current academic scenario and after embedding power-saving policies of green computing. Moreover, an account has been maintained about the amount of energy preservation. The extraordinary energy- and cost-saving features of green computing make environment sustainable and lively for future generations.},
year = {2020}
}
@article{https://doi.org/10.1002/pamm.201610407,
author = {Diethelm, Kai},
title = {Tools for assessing and optimizing the energy requirements of high performance scientific computing software},
journal = {PAMM},
volume = {16},
number = {1},
pages = {837-838},
doi = {https://doi.org/10.1002/pamm.201610407},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pamm.201610407},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/pamm.201610407},
abstract = {Abstract Score-P is a measurement infrastructure originally designed for the analysis and optimization of the performance of HPC codes. Recent extensions of Score-P and its associated tools now also allow the investigation of energy-related properties and support the user in the implementation of corresponding improvements. Since it would be counterproductive to completely ignore performance issues in this connection, the focus should not be laid exclusively on energy. We therefore aim to optimize software with respect to an objective function that takes into account energy and run time. (© 2016 Wiley-VCH Verlag GmbH \& Co. KGaA, Weinheim)},
year = {2016}
}
@article{https://doi.org/10.1002/ett.4643,
author = {Thirunavukkarasu, Mani and Shanmugapriya, Prakasam},
title = {Improving mobile cloud computing service efficiency using energy competent and federated learning process},
journal = {Transactions on Emerging Telecommunications Technologies},
volume = {n/a},
number = {n/a},
pages = {e4643},
doi = {https://doi.org/10.1002/ett.4643},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.4643},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ett.4643},
abstract = {Abstract Mobile cloud computing (MCC) helps to make effective communication that is used to transmit various information like voice, data, and video. The MCC environments support different real-time applications, including gaming and virtual reality implications. During the data transmission, energy conservation is one of the major issues for retaining the application span incorporating distributed and personalized computing and resource sharing. Ability-sustained energy competent method (ASECM) is introduced to overcome these issues and manage energy efficiency. The ASECM approach analyzes the session span and energy requirements for managing the applications' energy factor. In addition, the federated learning and computation offloading process is incorporated to retain the energy factor for ensuring reliable services. The effective utilization of the offloading process is used to meet the application deadline and energy-sufficient operations, preventing failures. In the recommendation process, cloud service availability with energy management constraints is considered for reducing energy expenditures. This process is nonrecurrent as the user/application requirements rely on diverse resources over different energy management techniques. The performance is measured using energy efficacy, utilization, application span, and failures.}
}
@article{https://doi.org/10.1002/cpe.3085,
author = {Khan, Khaled M. and Malluhi, Qutaibah},
title = {Role of contextual properties in enterprise service migration to cloud computing},
journal = {Concurrency and Computation: Practice and Experience},
volume = {25},
number = {18},
pages = {2455-2470},
keywords = {cloud computing, enterprise service migration, contextual properties, architectural properties, software architecture},
doi = {https://doi.org/10.1002/cpe.3085},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3085},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3085},
abstract = {SUMMARY This paper attempts to identify the role of contextual properties of enterprise systems architecture in relation to service migration to cloud computing. In a cloud-based service architecture, the shift of ownership, scope, and control over architectural elements from consumers to cloud providers has a profound impact on ways cloud consumers design and manage their systems architecture. In this perspective, we introduce the concepts of architectural scope, ownership, and control as the contextual properties of systems architecture. The paper explores ways in which these properties can be mapped into a quantifiable framework that could be used to measure the degree of changes of contextual properties due to service migration to cloud computing. We seek here to address the service migration problems from a different perspective, namely, focusing on the contextual properties of architectural elements. Copyright © 2013 John Wiley \& Sons, Ltd.},
year = {2013}
}
@article{https://doi.org/10.1002/cpe.3081,
author = {Pedersen, Jens Myrup and Tahir Riaz, M. and Dubalski, Bozydar and Ledzinski, Damian and Júnior, Joaquim Celestino and Patel, Ahmed},
title = {Using latency as a QoS indicator for global cloud computing services},
journal = {Concurrency and Computation: Practice and Experience},
volume = {25},
number = {18},
pages = {2488-2500},
keywords = {cloud computing, ICT infrastructure, QoS, service level agreements},
doi = {https://doi.org/10.1002/cpe.3081},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3081},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3081},
abstract = {ABSTRACT Many globally distributed cloud computing (CC) applications and services running over the Internet, between globally dispersed clients and servers, will require certain levels of QoS in order to deliver and give a sufficiently smooth user experience. This would be essential for real-time streaming multimedia applications such as online gaming and watching movies on a pay as you use basis hosted in a CC environment. However, guaranteeing or even predicting QoS in global and diverse networks that are supporting complex hosting of application services is a very challenging issue that needs a stepwise refinement approach to be solved as the technology of CC matures. In this paper, we investigate if latency in terms of simple ping measurements can be used as an indicator for other QoS parameters such as jitter and throughput. The experiments were carried out on a global scale, between servers placed in universities in Denmark, Poland, Brazil, and Malaysia. The results show the correlation between latency and throughput, and between latency and jitter, even though the results are not completely consistent. As a side result, we were able to monitor the changes in QoS parameters during a number of 24-hour periods. This is also a first step toward defining QoS parameters to be included in service level agreements for CC at the global scale in the foreseeable future. Concurrency and Computation: Practice and Experience, 2013.© 2013 Wiley Periodicals, Inc.},
year = {2013}
}
@article{https://doi.org/10.1002/dac.5111,
author = {Mishra, Pooja and Kumar, Neetesh and Godfrey, W. Wilfred},
title = {An evolutionary computing-based energy-efficient solution for IoT-enabled software-defined sensor network architecture},
journal = {International Journal of Communication Systems},
volume = {35},
number = {8},
pages = {e5111},
keywords = {balanced clustering (BC), heterogeneous sensors, hybrid grey wolf optimization (HGWO), optimization, residual energy, software-defined sensor networking (SDSN)},
doi = {https://doi.org/10.1002/dac.5111},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.5111},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/dac.5111},
abstract = {Summary Software-defined networking (SDN) has emerged as an evolving technique in wireless sensor networks (WSNs). SDN enables WSNs with programmable control to manage network functions dynamically and efficiently. In Internet of Things (IoT) applications, smart sensors suffer from the low battery issue, generally deployed in harsh network environments where regular recharge is not feasible. Moreover, integrating SDN with IoT-enabled sensor network puts forward several challenges, for example, control nodes' selection, load balancing, and energy cost optimization while aggregating the collected data, focusing on heterogeneous traffic data. Thus, an energy-efficient data collection technique via definite sensing control in two-level IoT-enabled software-defined heterogeneous WSN (2SD-HWSN) is formulated as an optimization problem, with transmission distance from smart sensors, residual energy of sensors, and load based on node density. The proposed algorithm is divided into two: set-up and transmission phases. In the set-up phase, the control server (CS) elects the best-suited control nodes (CNs) and sets up a schedule for coordinating data transmission. Further, normal nodes join appropriate CNs based on distance and residual energy. This way, CNs form clusters and route sensed data during the transmission phase. Therefore, an alternative nature-inspired algorithm, that is, grey wolf optimization (GWO), is hybridized with particle swarm optimization using a low-level co-evolutionary technique to improve its overall performance. This hybrid variant of GWO, known as HGWO-BC, offers balanced clustering (BC) via novel fitness function design. An exhaustive simulation study is performed in different scenarios considering homogeneous and heterogeneous sensors. Comparative results show that the HGWO-BC outperforms state-of-the-arts concerning network lifetime, instability period, residual energy, throughput, and computational efforts.},
year = {2022}
}
@article{https://doi.org/10.1002/cpe.6588,
author = {Yi, Shanwen and Li, Xiaole and Wang, Hua and Qin, Yao and Yan, Jiaxin},
title = {Energy-aware disaster backup among cloud datacenters using multiobjective reinforcement learning in software defined network},
journal = {Concurrency and Computation: Practice and Experience},
volume = {34},
number = {3},
pages = {e6588},
keywords = {Chebyshev scalarization function, energy-aware disaster backup, software defined network, the number of intermediate forwarding devices, transmission completion time, two-level multiobjective reinforcement learning},
doi = {https://doi.org/10.1002/cpe.6588},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6588},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.6588},
abstract = {Summary The transmission process of disaster backup with long distance and massive data causes huge energy consumption. Reducing the number of occupied intermediate forwarding devices and shortening the transmission completion time are two key factors for energy saving. Not jointly considering them, previous work can hardly realize optimal energy-aware transmission only by single objective optimization. For the first time, we leverage multiobjective reinforcement learning to simultaneously minimize the number of occupied intermediate forwarding devices and the transmission completion time in software defined network. We propose two-level reinforcement learning, consisting of search and selection operation. In the internal reinforcement learning, we aim to reduce hop number, improve node sharing degree, and give priority to the links with larger residual capacity. Then in the external level, we aim to reduce the total number of occupied devices and increase the total backup flow. We leverage Chebyshev scalarization function based on pseudo-random proportional rule to simplify weight selection, and enforce exploration to avoid falling into local optimum. We design the vector of rewards for different objectives, and update Pareto approximate set by multiple state steps to approach the optimal solution. Our strategy solves the weight selection problem successfully and achieves lower energy consumption.},
year = {2022}
}

