@article{XIE2020916,
title = {Energy management for multiple real-time workflows on cyber–physical cloud systems},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {916-931},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.05.033},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1731066X},
author = {Guoqi Xie and Gang Zeng and Junqiang Jiang and Chunnian Fan and Renfa Li and Keqin Li},
keywords = {Cyber–physical cloud systems (CPCS), Deadline miss ratio (DMR), Global energy saving (GES), Multiple workflows, Real-time constraint},
abstract = {Cyber–physical cloud systems (CPCS) are extensions of cyber–physical systems (CPS) that expand the cyber-part and distribute it on-device and in-cloud. CPCS are considered large-scale heterogeneous distributed cloud computing systems that support execution of multiple workflows. This study aims to reduce the energy consumption of multiple real-time workflows on CPCS and it contains two objectives: (1) maximizing the number of workflows that are completed within their deadlines; (2) minimizing the energy consumption of the workflows that are completed within their deadlines. The former is solved by proposing a deadline-driven processor merging for multiple workflows (DPMMW) algorithm, whereas the latter is solved by proposing a global energy saving for multiple workflows (GESMW) algorithm to minimize the total energy consumption. Experimental results validate that the combined DPMMW&GESMW algorithm can reduce deadline miss ratio (DMR) and save as much as possible energy over existing methods.}
}
@article{SHEN201582,
title = {Stochastic modeling of dynamic right-sizing for energy-efficiency in cloud data centers},
journal = {Future Generation Computer Systems},
volume = {48},
pages = {82-95},
year = {2015},
note = {Special Section: Business and Industry Specific Cloud},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2014.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X14001824},
author = {Dian Shen and Junzhou Luo and Fang Dong and Xiang Fei and Wei Wang and Guoqing Jin and Weidong Li},
keywords = {Cloud computing, Data center, Virtualization, Energy-efficiency, Queueing theory},
abstract = {Large data centers are usually built to support increasing computational and data storage demand of growing global business and industry, which consume an enormous amount of energy, at a huge cost to both business and the environment. However, much of that energy is wasted to maintain excess service capacity during periods of low load. In this paper, we investigate the problem of “right-sizing” data center for energy-efficiency through virtualization which allows consolidation of workloads into smaller number of servers while dynamically powering off the idle ones. In view of the dynamic nature of data centers, we propose a stochastic model based on Queueing theory to capture the main characteristics. Solving this model, we notice that there exists a tradeoff between the energy consumption and performance. We hereby develop a BFGS based algorithm to optimize the tradeoff by searching for the optimal system parameter values for the data center operators to “right-size” the data centers. We implement our Stochastic Right-sizing Model (SRM) and deploy it in the real-world cloud data center. Experiments with two real-world workload traces show that SRM can significantly reduce the energy consumption while maintaining high performance.}
}
@article{BERMEJO2016878,
title = {Cloud Resource Management to Improve Energy Efficiency Based on Local Nodes Optimizations},
journal = {Procedia Computer Science},
volume = {83},
pages = {878-885},
year = {2016},
note = {The 7th International Conference on Ambient Systems, Networks and Technologies (ANT 2016) / The 6th International Conference on Sustainable Energy Information Technology (SEIT-2016) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.04.179},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916302125},
author = {Belen Bermejo and Carlos Guerrero and Isaac Lera and Carlos Juiz},
keywords = {Cloud computing, Resource allocation, Virtualization, Energy efficiency},
abstract = {The energy consumption of Cloud Computing systems is one of the current concerns of systems architects. In order to reduce the energy consumption, they have provided techniques which go through the design of locations for data centres, together with techniques for the proper management of resources, taking into account the energy consumption of the system. This paper presents a resource allocation technique that maximizes the system efficiency. This technique is based on taking decisions at two levels: physical machine level and overall system level. Each of the levels ensure its own proper performance. To test that the technique complies with the initial hypothesis, simulations through the CloudSim tool have been developed. Also, we compared the results with a resource allocation technique based on a full knowledge of the system. As a result, we obtained a better solution time with the proposed technique that the other technique. Moreover, we obtained a lesser use of intra cluster network and a more energetically efficient cloud system.}
}
@article{MAKARATZIS2018715,
title = {Energy modeling in cloud simulation frameworks},
journal = {Future Generation Computer Systems},
volume = {79},
pages = {715-725},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.06.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17303229},
author = {Antonios T. Makaratzis and Konstantinos M. Giannoutakis and Dimitrios Tzovaras},
keywords = {Cloud computing, Cloud simulators, Modeling, Energy consumption, Data center},
abstract = {There is a quite intensive research for Cloud simulators in the recent years, mainly due to the fact that the need for powerful computational resources has led organizations to use cloud resources instead of acquiring and maintaining private servers. In order to test and optimize the strategies that are being used on cloud resources, cloud simulators have been developed since the simulation cost is substantially smaller than experimenting on real cloud environments. Several cloud simulation frameworks have been proposed during the last years, focusing on various components of the cloud resources. In this paper, a survey on cloud simulators is conducted, in order to examine the different models that have been used for the hardware components that constitute a cloud data center. Focus is given on the energy models that have been proposed for the prediction of the energy consumption of data center components, such as CPU, memory, storage and network, while experiments are performed in order to compare the different power models used by the simulation frameworks. The following cloud simulation frameworks are considered: CloudSched, CloudSim, DCSim, GDCSim, GreenCloud and iCanCloud.}
}
@article{SHAW2015241,
title = {Use of proactive and reactive hotspot detection technique to reduce the number of virtual machine migration and energy consumption in cloud data center},
journal = {Computers & Electrical Engineering},
volume = {47},
pages = {241-254},
year = {2015},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2015.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0045790615002748},
author = {Subhadra Bose Shaw and Anil Kumar Singh},
keywords = {Cloud computing, Energy efficiency, Hotspot mitigation, Load prediction, VM consolidation, VM migration},
abstract = {The increasing demand of cloud computing motivates the researchers to make cloud environment more efficient for its users and more profitable for the providers. Though virtualization technology helps to increase the resource utilization, still the operational cost of cloud gradually increases mainly due to the consumption of large amount of electrical energy. So to reduce the energy consumption virtual machines (VM) are dynamically consolidated to lesser number of physical machines (PMs) by live VM migration technique. But this may cause SLA violation and the provider is penalized. So to maintain an energy-performance trade-off, the number of VM migration should be minimized. VM migration primarily takes place in two cases: for hotspot mitigation and to switch off the underutilized nodes by migrating all its VMs. If a host is found to be overloaded then instead of immediately migrating some of its VMs we can check whether the migration is really required or not. For this we have proposed a load prediction algorithm to decide whether the migration will be performed or not. After the decision has been taken the algorithm finds a suitable destination host where the VM will be shifted. For this we have proposed a novel approach to decide whether a particular host is suitable as destination depending on its probable future load. We have simulated our algorithms in CloudSim using real world workload traces and compared them with the existing benchmark algorithms. Results show that the proposed methods significantly reduce the number of VM migration and subsequent energy consumption while maintaining the SLA.}
}
@article{DUTTON20191126,
title = {Moore vs. Murphy: Tradeoffs between complexity and reliability in distributed energy system scheduling using software-as-a-service},
journal = {Applied Energy},
volume = {238},
pages = {1126-1137},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.01.067},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919300650},
author = {Spencer Dutton and Chris Marnay and Wei Feng and Matthew Robinson and Andrea Mammoli},
keywords = {Distributed energy resources, Control optimization, Software-as-a-service, HVAC complexity, microgrids},
abstract = {Software-based optimization of building control strategies, including scheduling, has the potential to improve the performance of existing complex heating, ventilation, and air conditioning (HVAC), storage, and other systems—especially if temporally variable energy production, such as solar thermal or photovoltaics, is included. If reductions in energy bills can be achieved using optimized control strategies that take advantage of cost-saving opportunities, such as time-of-use pricing, the additional bill savings can cover further efficiency investment costs. As computer processing becomes cheaper over time (Moore’s Law), opportunities to perform complex control optimization become more abundant, and these can be performed remotely as software-as-a-service (SaaS). However, by “perfecting” our control strategies, we run an increased risk that when something unexpected happens (Murphy’s Law), the consequences of failure are greater. This study used simulation to explore the potential benefits of HVAC schedule optimization, delivery, and implementation using a SaaS paradigm, at various levels of complexity. Implementing optimal schedules in a model of an efficient building’s HVAC system, the study predicts energy cost savings of up to 10% compared to the naïve reference control strategy. Optimizing more system control variables increases the potential energy cost savings; however, these savings could be compromised by failures in communication inherent in delivering schedules via SaaS. The additional cost of energy resulting from the risk of increased demand charges generally increased with increased communication failure to a much larger extent than the risk of increased energy use charges. This work suggests that moderate improvements in performance, achieved at low cost by simple means, may be more effective than highly optimized schemes, which are more susceptible to failure due to their dependence on complex interactions between systems.}
}
@article{MASOOD20191481,
title = {Energy Efficient Software Defined Networking Algorithm for Wireless Sensor Networks},
journal = {Transportation Research Procedia},
volume = {40},
pages = {1481-1488},
year = {2019},
note = {TRANSCOM 2019 13th International Scientific Conference on Sustainable, Modern and Safe Transport},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2019.07.205},
url = {https://www.sciencedirect.com/science/article/pii/S2352146519303758},
author = {Mohsin Masood and Mohamed Mostafa Fouad and Saleh Seyedzadeh and Ivan Glesk},
keywords = {Software defined networks, energy efficient routing, wireless sensor networks, optimization techniques, adaptive dolphin echolocation algorithm},
abstract = {The real-time properties and operational constraints of Wireless Sensor Networks (WSNs) have emerged the need for designing energy efficient routing protocols. Recently, software defined network based WSN (SDN-WSN) emerging technology has offered a significant development by untying control logic plane from the low power sensor nodes. This centralized programmable control still suffers from several configuration challenges in distributed sensors environment. Meta-heuristic based SDN approaches had been proposed for the efficient path selection in WSN but they still suffer from both, exploration and exploitation problems. Therefore, this paper addresses these shortcomings by proposing a meta-heuristic based dolphin echolocation algorithm (DEA) for optimizing route selection in WSNs. Objective function of the DEA algorithm is to consider the residual energy of the nodes for selecting energy efficient routes. The proposed algorithm performance is compared with several meta-heuristic algorithms in terms of energy-consumption, and network throughput parameters.}
}
@article{ASSEFA2019127,
title = {A survey of energy efficiency in SDN: Software-based methods and optimization models},
journal = {Journal of Network and Computer Applications},
volume = {137},
pages = {127-143},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519301134},
author = {Beakal Gizachew Assefa and Öznur Özkasap},
keywords = {Software Defined Networking, SDN, Energy efficiency, Traffic aware, End system aware, Rule placement},
abstract = {Software Defined Networking (SDN) paradigm has the benefits of programmable network elements by separating the control and the forwarding planes, efficiency through optimized routing and flexibility in network management. As the energy costs contribute largely to the overall costs in networks, energy efficiency has become a significant design requirement for modern networking mechanisms. However, designing energy efficient solutions is non-trivial since they need to tackle the trade-off between energy efficiency and network performance. In this article, we address the energy efficiency capabilities that can be utilized in the emerging SDN. We provide a comprehensive and novel classification of software-based energy efficient solutions into subcategories of traffic aware, end system aware and rule placement. We propose general optimization models for each subcategory, and present the objective function, the parameters and constraints to be considered in each model. Detailed information on the characteristics of state-of-the-art methods, their advantages, drawbacks are provided. Hardware-based solutions used to enhance the efficiency of switches are also described. Furthermore, we discuss the open issues and future research directions in the area of energy efficiency in SDN.}
}
@article{CASTRO20161,
title = {A joint CPU-RAM energy efficient and SLA-compliant approach for cloud data centers},
journal = {Computer Networks},
volume = {94},
pages = {1-13},
year = {2016},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2015.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S1389128615004752},
author = {Pedro H.P. Castro and Vívian L. Barreto and Sand Luz Corrêa and Lisandro Zambenedetti Granville and Kleber Vieira Cardoso},
keywords = {Cloud computing, Energy efficiency, Resource management, Virtualization, Dynamic consolidation},
abstract = {Cloud computing is a new paradigm that offers computing resources in a virtualized way with unprecedented levels of flexibility, reliability, and scalability. The benefits of cloud computing, however, come at a high cost in terms of energy consumption, mainly because of one of the cloud’s core enablers, the data center. There are a number of proposals that seek to enhance the energy efficiency of data centers. Still, most of them focus on the energy consumed by CPU and ignore other important hardware components, e.g., RAM. In this paper, we show the considerable impact that RAM can have on the total energy consumption, particularly in servers with large amounts of this memory. We then propose two new approaches for dynamic consolidation of virtual machines in cloud data centers that take into account both CPU and RAM usage. We have implemented and evaluated our proposals in the CloudSim simulator using real-world traces and compared the results with other state-of-the-art solutions. By adopting a wider view of the system, our proposals can reduce not only energy consumption but also service level agreement (SLA) violations, thus providing a better service at a lower cost.}
}
@article{CARLI201620,
title = {A packing problem approach to energy-aware load distribution in Clouds},
journal = {Sustainable Computing: Informatics and Systems},
volume = {9},
pages = {20-32},
year = {2016},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2015.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2210537915000220},
author = {Thomas Carli and Stéphane Henriot and Johanne Cohen and Joanna Tomasik},
keywords = {Service virtualization, Cloud computing, Energy consumption minimization, Packing problems, Problem approximability, Approximation algorithm},
abstract = {The Cloud Computing paradigm consists in providing customers with virtual services of the quality which meets customers’ requirements. The efficiency of infrastructure exploitation may be expressed by the electrical energy consumption of computing centers, amongst others. We propose to model the energy consumption of private Clouds by a variant of the Bin Packing problem which we analyze next from a theoretical point of view. We advance on-line and off-line approximation algorithms to solve our problem to balance the load either on-the-fly or at the planning stage. In addition to the computation of the approximation factors of these two algorithms, we evaluate their performance experimentally. The quality of the results is encouraging, which makes a packing approach a serious candidate to model energy-aware load balancing in Cloud Computing.}
}
@article{SOHRABI20152794,
title = {The Effects of Hotspot Detection and Virtual Machine Migration Policies on Energy Consumption and Service Levels in the Cloud},
journal = {Procedia Computer Science},
volume = {51},
pages = {2794-2798},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.436},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915012442},
author = {S. Sohrabi and I. Moser},
keywords = {Cloud, Scheduling, IaaS, Virtual Machine Migration, Hotspot Detection, CloudSim},
abstract = {Managing Cloud resources efficiently necessitates effective policies that assign applications to hardware in a way that they require the least resources possible. Applications are first assigned to virtual machines which are subsequently placed on the most appropriate server host. If a server becomes overloaded, some of its virtual machines are reassigned. This process requires a hotspot detection mechanism in combination with techniques that select the virtual machine(s) to migrate. In this work we introduce two new virtual machine selection policies, Median Migration Time and Maximum Utilisation, and show that they outperform existing approaches on the criteria of minimising energy consumption, service level agreement violations and the number of migrations when combined with different hotspot detection mechanisms. We show that parametrising the the hotspot detection policies correctly has a significant influence on the workload balance of the system.}
}
@article{HOLWERDA201613,
title = {Surface energy exchange in a tropical montane cloud forest environment: Flux partitioning, and seasonal and land cover-related variations},
journal = {Agricultural and Forest Meteorology},
volume = {228-229},
pages = {13-28},
year = {2016},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2016.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0168192316303082},
author = {F. Holwerda and M.S. Alvarado-Barrientos and T.M. González-Martínez},
keywords = {Shaded coffee, Sugarcane, Transpiration, Bowen ratio, Tropical deforestation, Phenology},
abstract = {Relationships between seasonal climate, land cover and surface energy exchange in tropical montane cloud forest environments are poorly understood. The goal of this study was to investigate the seasonality of flux partitioning in lower montane cloud forest (LMCF), shaded coffee (CO) and sugarcane (SU) in central Veracruz, Mexico, as well as to evaluate the changes in surface energy exchange associated with the conversion of LMCF to CO or SU. Sensible (H) and latent heat (λE) fluxes were measured during the late dry and wet seasons using eddy covariance (CO and SU) and sap flow (LMCF) methods. Other measurements included: meteorological parameters, radiation balance, soil heat flux, soil moisture and vegetation characteristics. During the wet-season month of July, average midday Bowen ratios (βs) for sunny conditions were lowest and least variable among land covers: 0.4±0.2 (SE) in LMCF, 0.5±0.1 in SU and 0.7±0.1 in CO. In contrast, during the late dry-season months of March and April, βs were higher (i.e. higher H and lower λE) and more variable. The highest values of β were observed in LMCF, reflecting effects of partial leaf-shedding by dominant deciduous species (2.4±0.8, March) and increased stomatal control (1.4±0.3, April). There was also evidence of stomatal limitation of λE in CO and SU, having βs of up to 1.0±0.1 in April and March, respectively. As compared to LMCF, the average midday available energy (Ae) for sunny conditions was very similar in CO (−3±7%) and 15±8% lower in SU. Although not all results were statistically significant, they suggest that for the wet season conversion of LMCF to shaded coffee or sugarcane led to a decrease of 15±14% or 15±17% in midday λE under sunny conditions, respectively, whereas corresponding values of H increased by 37±38% or remained about the same (−4±40%). In contrast, for the late dry season, conversion of LMCF to shaded coffee or sugarcane appears to have resulted in higher λE and lower H, with changes of, respectively, +79 (±32)%/–45 (±16)% (CO) or +39 (±32)%/–43 (±16)% (SU) for a partially leafless LMCF in March, and +17 (±16)%/–11 (±16)% (CO) for a fully-leafed LMCF in April. In order to more accurately quantify the changes in surface energy fluxes associated with LMCF conversion, future work should focus on reducing the errors in the flux estimates. Nevertheless, for sunny days during the wet season, potential changes in the moisture and heat content of the local atmosphere due to the conversion of LMCF to CO or SU seem to have been in the same direction as those induced by increased greenhouse gases (drying and warming), whereas for the late dry season the effects appear to have been opposite (moistening and cooling).}
}
@article{NGUYEN2015132,
title = {Prediction-based energy policy for mobile virtual desktop infrastructure in a cloud environment},
journal = {Information Sciences},
volume = {319},
pages = {132-151},
year = {2015},
note = {Energy Efficient Data, Services and Memory Management in Big Data Information Systems},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S002002551500122X},
author = {Tien-Dung Nguyen and Pham Phuoc Hung and Tran Hoang Dai and Nguyen Huu Quoc and Cong-Thinh Huynh and Eui-Nam Huh},
keywords = {Energy policy, VM state management, mVDI, Remote desktop service},
abstract = {Using cloud services from mobile devices has become a growing trend because of its mobility and convenience. However, mobile devices join and leave cloud services more frequently than traditional computers, which causes energy inefficiency in a cloud data center. Waste, in the form of energy and cooling requirements, particularly occurs when a mobile device disconnects from a service, but the cloud servers, known as virtual machines (VMs), continue running. The VMs should transition to lower-power states instead remaining active. However, transition to a lower-power state causes a service delay when users reconnect to the service because VMs in a lower-power state are not ready to serve. Therefore, an efficient energy policy must not only maximize energy savings but also minimize service delays. In this paper, we propose two approaches to energy efficiency: an Instant Energy Policy (IEP) that can quickly find an appropriate low-power state based on a predicted disconnection time and a Prediction-based Energy Policy (PrEP) that determines when to transition VMs to a low-power state and when to return them to the active state based on each users activity history. IEP predicts the unknown disconnection time using the multisize sliding windows workload estimation technique, which supports a non-stationary environment. This method can quickly obtain an energy policy, but it is limited when disconnection time fluctuates widely. PrEP presents an improved approach to achieve an optimal global result with respect to both energy consumption and service delay. Through simulations with a real-world dataset collected by the MIT Human Dynamics Lab, we show that PrEP provides approximately 20% power saving over the benchmark policies while guaranteeing minimal service delay.}
}
@article{LI2019266,
title = {Editorial: Green computing in Wireless Sensor Networks},
journal = {Computer Networks},
volume = {150},
pages = {266-268},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618312052},
author = {Feng Li and Shibo He and Jun Luo and Mohan Gurusamy and Junshan Zhang}
}
@article{WU2016593,
title = {Cloud-based decision framework for waste-to-energy plant site selection – A case study from China},
journal = {Waste Management},
volume = {48},
pages = {593-603},
year = {2016},
issn = {0956-053X},
doi = {https://doi.org/10.1016/j.wasman.2015.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S0956053X15302142},
author = {Yunna Wu and Kaifeng Chen and Bingxin Zeng and Meng Yang and Shuai Geng},
keywords = {WtE plant site selection, Cloud model, 2-order additive fuzzy measures, CCI},
abstract = {Waste-to-energy (WtE) plant site selection is crucially important during the whole life cycle. Currently, the scholars launch some research in the WtE plant site selection. However, there are still two great problems in the present methods. Firstly, the uncertainty of information is not fully described. Secondly, the correlation among criteria lacks rationality, which is mainly manifested in two aspects: one is ignoring the correlation, and the other is measuring unreasonably. Firstly cloud model is introduced to describe the fuzziness and randomness of the information fully and precisely. Secondly, the 2-order additive fuzzy measures based on the Mobius transform and correlation coefficient matrix is introduced for fuzzy measure scientifically and reasonably. Thirdly, Cloud Choquet integral (CCI) operator is constructed to evaluate the alternatives. Finally, a case from China proves the effectiveness.}
}
@article{LAMRANI2019132,
title = {Energy and environmental analysis of an indirect hybrid solar dryer of wood using TRNSYS software},
journal = {Solar Energy},
volume = {183},
pages = {132-145},
year = {2019},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2019.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X19302312},
author = {Bilal Lamrani and Ahmed Khouya and Abdeslam Draoui},
keywords = {Hybrid solar dryer, Dynamic simulation, Compound parabolic concentrator, Energetic performance, Environmental analysis, TRNSYS},
abstract = {The aim of this work is to develop a numerical model for investigating the performance of an indirect hybrid solar dryer of wood using TRNSYS software. A solar compound parabolic concentrator (CPC) is used to produce thermal energy and the hourly dynamic simulations are conducted under Moroccan meteorological data. A comparative study between our numerical results and experimental results shows a good agreement and the Mean Relative Error (MRE) and the Root Mean Squared Error (RMSE) are 3.9% and 0.024 kg/kg, respectively. The energetic performance of the solar dryer components is investigated and the effect of some design and operation parameters on drying kinetic is presented. An environmental analysis is performed by focusing on the amount of carbon dioxide (CO2) emissions due to the combustion at the auxiliary heater system. Results show that the integration of the solar collector into the dryer system leads to reduce the energy consumption by the auxiliary heater system and to avoid annually about 34% of CO2 emissions.}
}
@article{ADDAI2016302,
title = {Experimental investigations of the minimum ignition energy and the minimum ignition temperature of inert and combustible dust cloud mixtures},
journal = {Journal of Hazardous Materials},
volume = {307},
pages = {302-311},
year = {2016},
issn = {0304-3894},
doi = {https://doi.org/10.1016/j.jhazmat.2016.01.018},
url = {https://www.sciencedirect.com/science/article/pii/S0304389416300188},
author = {Emmanuel Kwasi Addai and Dieter Gabel and Ulrich Krause},
keywords = {Minimum ignition energy, Minimum ignition temperature, Dust explosion, Ignition sensitivity, Inert materials},
abstract = {The risks associated with dust explosions still exist in industries that either process or handle combustible dust. This explosion risk could be prevented or mitigated by applying the principle of inherent safety (moderation). This is achieved by adding an inert material to a highly combustible material in order to decrease the ignition sensitivity of the combustible dust. The presented paper deals with the experimental investigation of the influence of adding an inert dust on the minimum ignition energy and the minimum ignition temperature of the combustible/inert dust mixtures. The experimental investigation was done in two laboratory scale equipment: the Hartmann apparatus and the Godbert-Greenwald furnace for the minimum ignition energy and the minimum ignition temperature test respectively. This was achieved by mixing various amounts of three inert materials (magnesium oxide, ammonium sulphate and sand) and six combustible dusts (brown coal, lycopodium, toner, niacin, corn starch and high density polyethylene). Generally, increasing the inert materials concentration increases the minimum ignition energy as well as the minimum ignition temperatures until a threshold is reached where no ignition was obtained. The permissible range for the inert mixture to minimize the ignition risk lies between 60 to 80%.}
}
@article{XU2017370,
title = {Energy Condition Perception and Big Data Analysis for Industrial Cloud Robotics},
journal = {Procedia CIRP},
volume = {61},
pages = {370-375},
year = {2017},
note = {The 24th CIRP Conference on Life Cycle Engineering},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2016.11.164},
url = {https://www.sciencedirect.com/science/article/pii/S2212827116313245},
author = {Wei Xu and Quan Liu and Wenjun Xu and Zude Zhou and Duc Truong Pham and Ping Lou and Qingsong Ai and Xiaomei Zhang and Jiwei Hu},
keywords = {Industrial cloud robotics, energy-efficient manufacturing, distributed perception, big data analysis},
abstract = {Industrial cloud robotics (ICRs), which is proposed to integrate the distributed industrial robots (IRs) resources to provide ICRs services at any place, has been attracted great attention due to the characteristics of convenient access, cheaper computing cost, more convenient network resources, etc. Meanwhile, in manufacturing industry, the energy-efficient issue, which means minimize the amount of energy resources to achieve a given output level in manufacturing process, is also gradually paid great attention by academia, industry and government. Currently, ICRs plays a crucial role in production. The implementation of energy-efficient manufacturing for ICRs will significantly decrease the energy consumption on the premise of normal production process, and also have remarkable effect on energy-saving and emission-reduction in manufacturing industry. In this context, the energy condition perception and big data analysis of ICRs are the essential procedure to achieve the aforementioned goals. A novel system architecture which mainly focuses on distributed energy condition perception and big data analysis for ICRs is built. Based on the perceptive data of ICRs related to energy consumption, a big data analysis model combined with the manufacturing status of ICRs is proposed, and the relationship between the big data and the analysis model is presented. Through the data analysis model, we can analyze the energy consumption fluctuation characteristic of ICRs operating state, count the energy consumption of the product related to different production phases, predict the health status of ICRs, as well as the trend of energy consumption associated with their operations. A case study is implemented to demonstrate the effectiveness of the proposed system and approaches.}
}
@article{YANG201778,
title = {Energy-Aware Provisioning in Optical Cloud Networks},
journal = {Computer Networks},
volume = {118},
pages = {78-95},
year = {2017},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2017.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S1389128617300762},
author = {Song Yang and Philipp Wieder and Ramin Yahyapour and Xiaoming Fu},
keywords = {Energy-efficiency, Routing, Cloud computing, Datacenters, IP-over-WDM optical networks},
abstract = {Cloud computing has recently emerged as a dominant Internet service computing model due to its “pay-as-you-go” and “elastic service” features. Cloud computing systems are usually composed of distributed datacenters, which leverage virtualization technology to provide a scalable and reliable service. Optical networks are recognized as promising next-generation core networks for connecting these distributed datacenters due to their characteristics such as high bandwidth provisioning, low latency, low bit error rate, etc. However, concern about the ever-increasing energy consumption of cloud computing systems together with core networks has been raised due to high electricity bills as well as environmental pollution. In this paper, we study the Energy-aware Provisioning in Optical Cloud Networks (EPOCN) problem for both dynamic and static cases. When traffic requests arrive in an online fashion, we propose a polynomial-time energy-aware routing algorithm to solve the dynamic EPOCN problem. Simulations show that our energy-aware routing algorithm brings more energy savings in comparison to a shortest path-based routing algorithm and a traffic grooming algorithm. On the other hand, we show that the EPOCN problem in the static case (the traffic matrix is known in advance) is NP-hard. We further divide this problem into (1) the Energy-Aware Routing (EAR) problem in optical networks and (2) the Energy-efficient Server and Switch Allocation (ESSA) problem in datacenter networks. Considering these two (sub)problems are still NP-hard, we present an exact Integer Linear Program (ILP) and a heuristic to solve each problem. We also conduct simulations to compare the proposed ILPs and heuristics in terms of energy consumption and running time.}
}
@article{BAKER201796,
title = {An energy-aware service composition algorithm for multiple cloud-based IoT applications},
journal = {Journal of Network and Computer Applications},
volume = {89},
pages = {96-108},
year = {2017},
note = {Emerging Services for Internet of Things (IoT)},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2017.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S1084804517301108},
author = {Thar Baker and Muhammad Asim and Hissam Tawfik and Bandar Aldawsari and Rajkumar Buyya},
keywords = {IoT, Multi-cloud, Service composition, Energy efficiency},
abstract = {There has been a shift in research towards the convergence of the Internet-of-Things (IoT) and cloud computing paradigms motivated by the need for IoT applications to leverage the unique characteristics of the cloud. IoT acts as an enabler to interconnect intelligent and self-configurable nodes “things” to establish an efficient and dynamic platform for communication and collaboration. IoT is becoming a major source of big data, contributing huge amounts of streamed information from a large number of interconnected nodes, which have to be stored, processed, and presented in an efficient, and easily interpretable form. Cloud computing can enable IoT to have the privilege of a virtual resources utilization infrastructure, which integrates storage devices, visualization platforms, resource monitoring, analytical tools, and client delivery. Given the number of things connected and the amount of data generated, a key challenge is the energy efficient composition and interoperability of heterogeneous things integrated with cloud resources and scattered across the globe, in order to create an on-demand energy efficient cloud based IoT application. In many cases, when a single service is not enough to complete the business requirement; a composition of web services is carried out. These composed web services are expected to collaborate towards a common goal with large amount of data exchange and various other operations. Massive data sets have to be exchanged between several geographically distributed and scattered services. The movement of mass data between services influences the whole application process in terms of energy consumption. One way to significantly reduce this massive data exchange is to use fewer services for a composition, which need to be created to complete a business requirement. Integrating fewer services can result in a reduction in data interchange, which in return helps in reducing the energy consumption and carbon footprint. This paper develops a novel multi-cloud IoT service composition algorithm called (E2C2) that aims at creating an energy-aware composition plan by searching for and integrating the least possible number of IoT services, in order to fulfil user requirements. A formal user requirements translation and transformation modelling and analysis is adopted for the proposed algorithm. The algorithm was evaluated against four established service composition algorithms in multiple cloud environments (All clouds, Base cloud, Smart cloud, and COM2), with the results demonstrating the superior performance of our approach.}
}
@article{SCHIFF2021e514,
title = {Estimating Proton Stopping Power Ratio of a Novel Iodinated Rectal Hydrogel Spacer Using Dual Energy Computed Tomography},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {111},
number = {3, Supplement },
pages = {e514-e515},
year = {2021},
note = {2021 Proceedings of the ASTRO 63rd Annual Meeting},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2021.07.1409},
url = {https://www.sciencedirect.com/science/article/pii/S0360301621022793},
author = {J.P. Schiff and T. Zhao and R.J. Brenneman and Y. Hao and H.A. Gay and B.C. Baumann and J.M. Michalski},
abstract = {Purpose/Objective(s)
A novel iodinated rectal hydrogel spacer (I-RS) has been developed to make the gel radiopaque on CT compared to the standard rectal hydrogel spacers (S-RS). As the iodine in I-RS strongly absorbs kV photons, the accuracy of currently employed CT calibration built into a single energy CT (SECT) becomes inaccurate to determine the proton stopping power ratio (PSR) of the injected gel. Direct measurements of PSR mediated by I-RS with proton beams has been reported; however, those measurements were conducted under ideal conditions without fully accounting for density heterogeneity mediated by air bubbles co-injected with the gel during placement. This study used dual-energy CT (DECT) to estimate I-RS PSR in patients undergoing CT simulation for prostate cancer (PCa) radiotherapy (RT).
Materials/Methods
Sequential scans at 90 and 140 kVp were acquired for 7 intact PCa (I-RS n = 5, S-RS n = 2) on a Philips Brilliance scanner. PSR was reconstructed following the method proposed by Torikoshi and improved by Yang, and compared to similar measurements when I-RS was replaced with S-RS. A pre-calculated table correlating effective atomic number with all possible Hounsfield Unit (HU) combinations from two sequential scans was implemented to accelerate reconstruction. PSRs were compared between DECT and SECT, and between I-RS and S-RS.
Results
In gel, HU measurements were heterogeneous (range −372 - +358). The mean PSR on reconstruction when using DECT was 0.966 (0.940-0.980) for I-RS. Replacement of I-RS with S-RS HU density resulted in a mean PSR of 0.937 (0.926-0.941) by DECT. PSR for I-RS on SECT was 1.107, and 1.014 for S-RS. The estimated difference between PSR in I-RS and S-RS on DECT vs. SECT were 14% and 8%, respectively.
Conclusion
These data demonstrate that the use of I-RS in proton RT treatment planning could overestimate proton range due to underestimating PSR when CT simulation is performed using standard SECT. Notably, PSR absolute value reported here is different compared to previously reported in vitro data under ideal conditions and may be related to differences in gel heterogeneity in vivo. Heterogeneity is highlighted by the wide range of gel HU measurements. Direct measurements of PSR will be obtained in a planned future experiment. These data suggest that PSR overestimation due to I-RS should be considered when planning PCa treatment using proton therapy for patients who get I-RS to reduce treatment toxicity.}
}
@article{DING201562,
title = {Energy efficient scheduling of virtual machines in cloud with deadline constraint},
journal = {Future Generation Computer Systems},
volume = {50},
pages = {62-74},
year = {2015},
note = {Quality of Service in Grid and Cloud 2015},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2015.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X15000369},
author = {Youwei Ding and Xiaolin Qin and Liang Liu and Taochun Wang},
keywords = {Energy efficiency, Virtual machine scheduling, Dynamic voltage and frequency scaling, Cloud computing},
abstract = {Cloud computing is a scale-based computing model, and requires more physical machines and consumes an extremely large amount of electricity, which will reduce the profit of the service providers and harm the environment. Virtualization is widely used in cloud computing nowadays. However, existing energy efficient scheduling methods of virtual machines (VMs) in cloud cannot work well if the physical machines (PMs) are heterogeneous and their total power is considered, and typically do not use the energy saving technologies of hardware, such as dynamic voltage and frequency scaling (DVFS). This paper proposes an energy efficient scheduling algorithm, EEVS, of VMs in cloud considering the deadline constraint, and EEVS can support DVFS well. A novel conclusion is conducted that there exists optimal frequency for a PM to process certain VM, based on which the notion of optimal performance–power ratio is defined to weight the homogeneous PMs. The PM with higher optimal performance–power ratio will be assigned to VMs first to save energy. The process of EEVS is divided into some equivalent schedule periods, in each of which VMs are allocated to proper PMs and each active core operates on the optimal frequency. After each period, the cloud should be reconfigured to consolidate the computation resources to further reduce the energy consumption. The deadline constraint should be satisfied during the scheduling. The simulation results show that our proposed scheduling algorithm achieves over 20% reduction of energy and 8% increase of processing capacity in the best cases.}
}
@article{SOUMELIDIS2018361,
title = {Cloud Aided Implementation of Energy Optimal Look-ahead Speed Control},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {9},
pages = {361-366},
year = {2018},
note = {15th IFAC Symposium on Control in Transportation Systems CTS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.07.059},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318307821},
author = {Alexandros Soumelidis and Péter Gáspár and Ádám Kisari and Ádám Bakos and Balázs Németh and András Mihály and Zoltán Hankovszki},
keywords = {Automotive control, Optimal control, Look-ahead, ADAS, Cloud},
abstract = {The aim of the paper is to present the development, implementation and testing of a novel look-ahead cruise control system. The method strives to decrease fuel consumption while maintaining travel time limitations. In the development phase the control algorithm has been evaluated and fine tuned using state of the art software- and hardware in the loop simulations. The real-world implementation and tests were conducted on Hungarian highways with a Volvo FH13 truck. The test results confirmed the simulations and proved that a reduction in fuel consumption can be achieved this way.}
}
@article{WANG2017117,
title = {An energy-efficient system on a programmable chip platform for cloud applications},
journal = {Journal of Systems Architecture},
volume = {76},
pages = {117-132},
year = {2017},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2016.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S1383762116302247},
author = {Xu Wang and Yongxin Zhu and Yajun Ha and Meikang Qiu and Tian Huang and Xueming Si and Jiangxing Wu},
keywords = {Cloud computing, ECG classification, FPGA, Performance analysis, Reconfigurable architectures, Web server},
abstract = {Traditional cloud service providers build large data-centers with a huge number of connected commodity computers to meet the ever-growing demand on performance. However, the growth potential of these data-centers is limited by their corresponding energy consumption and thermal issues. Energy efficiency becomes a key issue of building large-scale cloud computing centers. To solve this issue, we propose a standalone SOPC (System on a Programmable Chip) based platform for cloud applications. We improve the energy efficiency for cloud computing platforms with two techniques. First, we propose a massive-sessions optimized TCP/IP hardware stack using a macro-pipeline architecture. It enables the hardware acceleration of pipelining execution of network packet offloading and application level data processing. This achieves higher energy efficiency while maintaining peak performance. Second, we propose a online dynamic scheduling strategy. It can reconfigure or shut down FPGA nodes according to workload variance to reduce the runtime energy consumption in a standalone SOPC based reconfigurable cluster system. Two case studies including a webserver application and a cloud based ECG (electrocardiogram) classification application are developed to validate the effectiveness of the proposed platform. Evaluation results show that our SOPC based cloud computing platform can achieve up to 418X improvement in terms of energy efficiency over commercial cloud systems.}
}
@article{KECSKEMETI2015188,
title = {DISSECT-CF: A simulator to foster energy-aware scheduling in infrastructure clouds},
journal = {Simulation Modelling Practice and Theory},
volume = {58},
pages = {188-218},
year = {2015},
note = {Special issue on Cloud Simulation},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2015.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X15000842},
author = {Gabor Kecskemeti},
keywords = {Cloud computing, Infrastructure as a Service, Energy-awareness, Resource management, Simulation},
abstract = {Infrastructure as a Service (IaaS) systems offer on demand virtual infrastructures so reliably and flexibly that users expect a high service level. Therefore, even with regards to internal IaaS behaviour, production clouds only adopt novel ideas that are proven not to hinder established service levels. To analyse their expected behaviour, new ideas are often evaluated with simulators in production IaaS system-like scenarios. For instance, new research could enable collaboration amongst several layers of schedulers or could consider new optimisation objectives such as energy consumption. Unfortunately, current cloud simulators are hard to employ and they often have performance issues when several layers of schedulers interact in them. To target these issues, a new IaaS simulation framework (called DISSECT-CF) was designed. The new simulator’s foundation has the following goals: easy extensibility, support energy evaluation of IaaSs and to enable fast evaluation of many scheduling and IaaS internal behaviour related scenarios. In response to the requirements of such scenarios, the new simulator introduces concepts such as: a unified model for resource sharing and a new energy metering framework with hierarchical and indirect metering options. Then, the comparison of several simulated situations to real-life IaaS behaviour is used to validate the simulator’s functionality. Finally, a performance comparison is presented between DISSECT-CF and some currently available simulators.}
}
@article{CARSTENSEN2016560,
title = {Condition Monitoring and Cloud-based Energy Analysis for Autonomous Mobile Manipulation - Smart Factory Concept with LUHbots},
journal = {Procedia Technology},
volume = {26},
pages = {560-569},
year = {2016},
note = {3rd International Conference on System-Integrated Intelligence: New Challenges for Product and Production Engineering},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2016.08.070},
url = {https://www.sciencedirect.com/science/article/pii/S2212017316304170},
author = {Jan Carstensen and Torben Carstensen and Malte Pabst and Fabian Schulz and Jan Friederichs and Simon Aden and Daniel Kaczor and Jens Kotlarski and Tobias Ortmaier},
keywords = {Mobile Robotics, Condition Monitoring, Cloud-based Energy Analysis, Logistic Handling},
abstract = {In this paper, a smart factory concept for autonomous mobile robots is presented. The main purpose is to increase productivity of the transport in machine-floor. It is based on advanced methods for failure handling and prevention, leading to increased robustness, less downtime and less effort in maintenance [1], [2]. Therefore, condition data and states of the robot are collected by Robot Operation System (ROS) and transferred to a factory hub (server). The collected data, e.g. voltages, currents, set points, velocities and accelerations are used to identify important system parameters, e.g. moving masses and friction parameters to enable the proposed smart factory concept. Further aim is to let the factory hub control a group of mobile robots using a self-organizing algorithm for different tasks. Due to the increasing customization of products causing smaller lot sizes [3], manufacturers of mobile robotic production systems have developed a diversity of flexible robots [4], [5], [6], [7], [8]. Mobile robots inside the production line allow for collecting and evaluation of system-inherent data e.g. handling and transportation time, wheel friction, workpieces mass, center of gravity and energy consumption during trajectory execution. In general, mobile robots are electrically driven. Hence, an estimation of the battery state is essential in order to automatically plan charging cycles and to organize and optimize the cooperation behavior of a group of mobile robots. In this proposed approach, mobile robots are equipped with a measurement system and connected via Bluetooth to a factory hub, providing monitoring, analyzing and planning tools. The battery states of all robots are considered in the process planning. The robots are based on the KUKA youBot, equipped with a soft gripper and a RealSense camera. A condition monitoring system measures the energy consumption of all components and transfers the information to the factory hub. The state of charge limits the number of executable operations. Therefore, in a first step the power consumption of all individual consumers is captured, e.g. EC-Maxxon base motors, PC, gripper, camera and five-axis arm. Experimental results show, that the youBot requires 46 W in standstill plus the drive power depending on the movement. Here, the results for mobile manipulation in industrial scenarios during preparation for the RoboCup@Work 2016 will be presented. The transfer of raw measurement data to the hub is shown, as well as the proposed algorithms allowing for range prediction and optimized set point generation. The concept provides excellent capability in data collection, analysis of existing production and production planning.}
}
@article{VELAYUDHANKUMAR2016191,
title = {Heterogeneity and thermal aware adaptive heuristics for energy efficient consolidation of virtual machines in infrastructure clouds},
journal = {Journal of Computer and System Sciences},
volume = {82},
number = {2},
pages = {191-212},
year = {2016},
issn = {0022-0000},
doi = {https://doi.org/10.1016/j.jcss.2015.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S002200001500080X},
author = {Mohan Raj {Velayudhan Kumar} and Shriram Raghunathan},
keywords = {IaaS Cloud, Data center energy efficiency, Processor SLEEP states, Processor SLEEP state transition latency},
abstract = {Holistic datacenter energy minimization operation should consider interactions between computing and cooling source specific usage patterns. Decisions like workload type, server configuration, load, utilization etc., contributes to power consumption and influences datacenter's thermal profile and impacts the energy required to control temperature within operational thresholds. In this paper, we present an adaptive virtual machine placement and consolidation approach to improve energy efficiency of a cloud datacenter; accounting for server heterogeneity, server processor low-power SLEEP state, state transition latency and integrated thermal controls to maintain datacenter within operational temperature. Our proposed heuristic approach reduces energy consumption with acceptable level of performance.}
}
@article{SUBBIAH2015151,
title = {Energy Efficient Big Data Infrastructure Management in Geo-Federated Cloud Data Centers},
journal = {Procedia Computer Science},
volume = {58},
pages = {151-157},
year = {2015},
note = {Second International Symposium on Computer Vision and the Internet (VisionNet’15)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.043},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915021547},
author = {Sankari Subbiah and Perumal Varalakshmi and R. Prarthana and C. Renuka Devi},
keywords = {Big Data, QoS, CCH ;Data analytics, HIRGLAA},
abstract = {The hot-tempered development of hassle on big data processing make obligatory an intense load on computation, storage and networking in data centres. We suggested an approach of data centre node clustering for an efficient data placement and data retrieval which is unlike the routine in centralised architecture. The main objective for the proposed system is the shortcomings present in the conventional centralised server which is mainly the assumption that a single head is in the connectivity range of all other nodes. We proposed Hit Rate Geographical Locations Analysis Algorithm (HIRGLAA) for the dynamic election of cluster head based on the periodic hit rate analysis performance. We suggested candidate cluster heads containing redundant routing information to ensure data storage backup. Thus the proposed system assures Quality of Services (QoS) such as increased reliability, robustness, an energy efficient remote access and its efficiency can be validated by extensive simulation based studies.}
}
@article{GARWOOD20171805,
title = {Geometry Extraction for High Resolution Building Energy Modelling Applications from Point Cloud Data: A Case Study of a Factory Facility},
journal = {Energy Procedia},
volume = {142},
pages = {1805-1810},
year = {2017},
note = {Proceedings of the 9th International Conference on Applied Energy},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2017.12.567},
url = {https://www.sciencedirect.com/science/article/pii/S1876610217363233},
author = {Tom Lloyd Garwood and Ben Richard Hughes and Dominic O’Connor and John K Calautit and Michael R Oates and Thomas Hodgson},
keywords = {Building Energy Modelling, Point Cloud, Manufacturing, Industrial Energy Demand, Thermal Simulation},
abstract = {The industrial sector accounts for 17% of end-use energy in the UK, and 54% globally. Therefore, there is substantial scope for simulating and assessing potential energy retrofit options for industrial buildings. Building Energy Modelling (BEM) applied to industrial buildings poses a complex but important opportunity for reducing global energy demand, due to years of renovation and expansion. Large and complex industrial buildings make modelling existing geometry for BEM difficult and time consuming. This paper presents a potential solution for quickly capturing and processing as-built geometry of a factory to be utilized in BEM. Laser scans were captured from the interior of an industrial facility to produce a Point Cloud. The existing capabilities of a Point Cloud processing software were assessed to identify the potential development opportunities to automate the conversion of Point Clouds to building geometry for BEM applications. In conclusion, scope exists for increasing the speed of 3D geometry creation of an existing industrial building for application in BEM and subsequent thermal simulation.}
}
@article{JOY2015740,
title = {Energy Aware SLA with Classification of Jobs for Cloud Environment},
journal = {Procedia Computer Science},
volume = {70},
pages = {740-747},
year = {2015},
note = {Proceedings of the 4th International Conference on Eco-friendly Computing and Communication Systems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.10.112},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915032767},
author = {Nimisha Joy and K. Chandrasekaran and  {Binu A.}},
keywords = {Cloud computing, Service Level Agreement, Energy Aware SLA, Cloud federation},
abstract = {The accelerated growth of the cloud eco-system is leading to the progress of new services, innovative ideas for the service replen- ishing and the newest interaction models both among the cloud providers and the customers which take advantage of the cloud resources. SLAs are one of the factors which allow for different interactions by keeping the objectives over privacy,QoS attributes and security constraints driving towards QoP attributes, the description of actions is needed in order to deliver the services ac- cording to the QoS attributes as expected by the customers. Energy aware SLAs extends the existing SLA agreements in order to include energy and carbon aware parameters. In this paper we propose an approach in order to relax certain jobs in a standardized way to obtain high energy consumption without disturbing the efficiency and availability of the system especially during the peak load times. The results for the above proposal are being discussed in this paper and were able to find that it is energy efficient.}
}
@article{SHARMA2019221,
title = {Comparison of environmental assessment methodology in hybrid energy system simulation software},
journal = {Procedia CIRP},
volume = {80},
pages = {221-227},
year = {2019},
note = {26th CIRP Conference on Life Cycle Engineering (LCE) Purdue University, West Lafayette, IN, USA May 7-9, 2019},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2019.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212827119300095},
author = {Hemant Sharma and Élise Monnier and Guillaume Mandil and Peggy Zwolinski and Stéphane Colasson},
keywords = {hybrid energy system, environmental assessment, life cycle assessment (LCA)},
abstract = {The advent of renewable energy systems has led to an increase in decentralised energy systems. Consequently, the last 10 years have seen development of specialised software such as HOMER, iHOGA, EnergyPro, RETScreen and TRNSYS to analyse these systems. This study compares these software in detail especially in terms of the environmental assessment. It is concluded that these software do not adequately include environmental analysis since only 1 out of 5 software considers more than one life cycle stage, neglecting other upstream/downstream emissions. Furthermore, the emphasis is on emissions such as NOx and SO2 that are usually associated with fossil fuel utilization. As the energy systems are becoming increasingly complex, especially with storage technologies such as hydrogen and batteries, emissions ‘shift’ away from the operating stage. Moreover, it becomes essential to look further than global warming potential and take into account other impacts such as depletion of critical materials, acidification, eco-toxicity, etc. Hence, it becomes essential to take into account entire life cycle stages and provide comprehensive environmental impacts along with the already available techno-economic capabilities to the designers and decision-makers. Finally, this study provides recommendations on the methodology to include environmental analysis in the investigated software.}
}
@article{KUMAR2020754,
title = {Energy Management for Cyber-Physical Cloud Systems},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {754-756},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.072},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19313998},
author = {Neeraj Kumar and Athanasios V. Vasilakos and Kim-Kwang Raymond Choo and Laurence T. Yang}
}
@article{LI20121121,
title = {Extension and optimization of the FIND algorithm: Computing Green’s and less-than Green’s functions},
journal = {Journal of Computational Physics},
volume = {231},
number = {4},
pages = {1121-1139},
year = {2012},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2011.05.027},
url = {https://www.sciencedirect.com/science/article/pii/S002199911100338X},
author = {S. Li and E. Darve},
keywords = {Nested dissection, Green’s function, NEGF, Nanotransistor, Gaussian elimination, Sparse matrix, Inverse matrix, Recursive Green’s function method},
abstract = {The FIND algorithm is a fast algorithm designed to calculate certain entries of the inverse of a sparse matrix. Such calculation is critical in many applications, e.g., quantum transport in nano-devices. We extended the algorithm to other matrix inverse related calculations. Those are required for example to calculate the less-than Green’s function and the current density through the device. For a 2D device discretized as an Nx×Ny mesh, the best known algorithms have a running time of O(Nx3Ny), whereas FIND only requires O(Nx2Ny). Even though this complexity has been reduced by an order of magnitude, the matrix inverse calculation is still the most time consuming part in the simulation of transport problems. We could not reduce the order of complexity, but we were able to significantly reduce the constant factor involved in the computation cost. By exploiting the sparsity and symmetry, the size of the problem beyond which FIND is faster than other methods typically decreases from a 130×130 2D mesh down to a 40×40 mesh. These improvements make the optimized FIND algorithm even more competitive for real-life applications.}
}
@article{HUANG2012340,
title = {Computing transcription factor distribution profiles from green fluorescent protein reporter data},
journal = {Chemical Engineering Science},
volume = {68},
number = {1},
pages = {340-354},
year = {2012},
issn = {0009-2509},
doi = {https://doi.org/10.1016/j.ces.2011.09.044},
url = {https://www.sciencedirect.com/science/article/pii/S0009250911006853},
author = {Zuyi Huang and Yunfei Chu and Juergen Hahn},
keywords = {Signal transduction pathway, Inverse problem, Cellular biology and engineering, Imaging, Mathematical modeling, Parameter identification},
abstract = {Signal transduction pathways play a key role in many cellular functions as well as intercellular communication. However, elucidating the exact mechanisms involved in signal transduction pathways is non-trivial due to limited measurement capabilities for observing intracellular signals and stochasticity inherent in signaling pathways. This work will address part of these challenges by quantifying the distribution of important components in signaling pathways, e.g., transcription factors, from data. Specifically, this work presents a technique that computes the time-varying distribution of transcription factor concentrations inside cells from fluorescent images of green fluorescent protein (GFP) reporter systems. The presented approach consists of an algorithm for identifying individual fluorescent cells from fluorescent images, and an algorithm to compute the distribution of transcription factor profiles from the fluorescence intensity distribution by solving an inverse problem. The technique is applied to experimental data to derive the NF-κB concentration distribution from fluorescent images of a NF-κB GFP reporter system. The presented image analysis method is able to correctly identify individual fluorescent cells from fluorescent images, which are characterized by low contrast and a significant noise level. The derived heterogeneity in the NF-κB distribution not only matches available qualitative experimental data but can also be used for parameter estimation of mathematical models that describe the stochasticity inherent in TNF-α–NF-κB signaling.}
}
@article{HOLWERDA20131,
title = {The water and energy exchange of a shaded coffee plantation in the lower montane cloud forest zone of central Veracruz, Mexico},
journal = {Agricultural and Forest Meteorology},
volume = {173},
pages = {1-13},
year = {2013},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2012.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S016819231300004X},
author = {F. Holwerda and L.A. Bruijnzeel and V.L. Barradas and J. Cervantes},
keywords = {Land use change, Hydrometeorology, Transpiration, Rainfall interception, Cloud forest, Coffee cultivation},
abstract = {The water and energy fluxes of a shaded coffee plantation in the lower montane cloud forest (LMCF) zone of central Veracruz, Mexico, were measured over a two-year period (September 2006–August 2008) using the eddy covariance method. Complementary measurements of throughfall and stemflow were made to study rainfall interception. The sum of the observed sensible (H) and latent (λE) heat fluxes was almost 95% of the net radiation (Rn) minus the canopy heat storage fluxes, indicating very good energy balance closure. The mean annual evapotranspiration was 1066mm, and 95% of the corresponding FAO Penman-Monteith reference evapotranspiration (ET0) of 1117mm yr−1. Interception loss was 8% of annual rainfall (1386mm). Both the eddy covariance, and the throughfall and stemflow measurements showed average wet-canopy evaporation rate to be very low (0.05mmh−1) compared to the corresponding rainfall rate (3.06mmh−1). As a result, and despite the low canopy storage capacity of the coffee plantation (Cm, 0.50mm), interception was dominated by post-event evaporation of intercepted water rather than by within-event evaporation. Comparing the results for the coffee plantation with interception data from mature and secondary LMCFs in the study area suggests that the conversion of LMCF to shade-coffee may lead to a decrease in interception loss of 8−18% of incident rainfall. This decrease is caused by a three- to seven-fold decrease in Cm, probably due to the lower leaf area and smaller epiphyte biomass of the coffee plantation. The mean annual dry-canopy evaporation was 992mm, and 89% of ET0. Comparing the eddy covariance-based estimate of dry-canopy evaporation for the coffee plantation with sapflow-based estimates of transpiration for the LMCFs did not show any clear differences.}
}
@article{KOUTSANDRIA2016202,
title = {Can everybody be happy in the cloud? Delay, profit and energy-efficient scheduling for cloud services},
journal = {Journal of Parallel and Distributed Computing},
volume = {96},
pages = {202-217},
year = {2016},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2016.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0743731516300491},
author = {Georgia Koutsandria and Emmanouil Skevakis and Amir A. Sayegh and Polychronis Koutsakis},
keywords = {Cloud computing, Cloud services, Scheduling algorithms, Profit, Delay, Energy efficiency},
abstract = {The rapid development of Cloud Computing provides consumers and service providers with a wide range of opportunities and challenges. Considering the substantial infrastructure investments being made by cloud providers, the reduction of operating expenses (OPEX) while maximizing the profit of the provided services is of great importance. One way to achieve this is by maximizing the efficiency of resource utilization. However, profit maximization does not necessarily coincide with the improvement of a user’s Quality of Service (QoS); users generating higher profit for the provider may be scheduled first, causing high delays to low-paying users. Further, the contradictory nature of users’ and providers’ needs also extends to the energy consumption problem, as the minimization of service delays could cause cloud resources to be constantly “on”, leading to high energy consumption, high costs for providers and undue environmental impact. The objective of our work is to analyze this multi-dimensional trade-off. We first investigate the problem of efficient resource allocation strategies for time-varying traffic, and propose a new algorithm, MinDelay, which aims at achieving the minimum service delay while taking into account provider’s profit. Then, we propose E-MinDelay, an energy-efficient approach for CPU-intensive tasks in cloud systems. Furthermore, we propose an improved version of the Energy Conscious Task Consolidation (ECTC) algorithm, which combines task consolidation and migration techniques with E-MinDelay. Our results demonstrate that energy consumption and service delays corresponding to profit loss can be simultaneously decreased using an efficient scheduling algorithm.}
}
@article{SHRIMALI2020860,
title = {Multi-objective optimization oriented policy for performance and energy efficient resource allocation in Cloud environment},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {32},
number = {7},
pages = {860-869},
year = {2020},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2017.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1319157817302264},
author = {Bela Shrimali and Hiren Patel},
keywords = {Power efficiency, Optimization, Resource allocation, Resource utilization, Cloud},
abstract = {Cloud computing is a hybrid paradigm which makes use of utility computing, high performance cluster computing and grid computing and it offers various benefits such as flexibility, expandability, little or almost no capital investment, disaster recovery, moveable work space and much more. However, due to constantly increasing number of data centers worldwide, the issue of energy consumption by these data centers has attracted attention of researchers. Resource allocation and resource utilization are the major criterion in which the problem of energy efficiency can be addressed. In this research, we aim to provide energy-efficient resource allocation using Multi-Objective Optimization (MOO) method. Further, We propose MOO-based virtual machine (VM) allocation policy and implement it in CloudSim environment. The results are compared with existing policies. The results depict that MOO-based policy leads to saving in energy due to efficient resource allocation, without compromising performance of data center operations.}
}
@article{QUARATI2016403,
title = {Delivering cloud services with QoS requirements: Business opportunities, architectural solutions and energy-saving aspects},
journal = {Future Generation Computer Systems},
volume = {55},
pages = {403-427},
year = {2016},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2015.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X15000539},
author = {Alfonso Quarati and Andrea Clematis and Daniele D’Agostino},
keywords = {Cloud computing, Economics, IT architecture},
abstract = {The flexible and pay-as-you-go computing capabilities offered by Cloud infrastructures are nowadays very attractive, and widely adopted by many organizations and enterprises. In particular this is true for those having periodical or variable tasks to execute, and, choose to not or cannot afford the expenses of buying and managing computing facilities or software packages, that should remain underutilized for most of the time. For their ability to couple the scalability offered by public service providers, with the wider Quality of Service (QoS) provisions and ad-hoc customizations provided by private Clouds, Hybrid Clouds (HC) seem a particularly appealing solution for customers requiring something more than the mere availability of the service. The paper firstly introduces a Cloud brokering system leveraging on a promising architectural approach, based on the use of a gateway toolkit. This approach provides noticeably advantages, both to customers and to Cloud Brokers (CB), for its ability to hide all the intricacies related to the management of powerful, but often complex and heterogeneous infrastructures like the Cloud. Moreover such approach, through customized interfaces, facilitates customers in accessing Cloud resources thus easing the tailored deployment and execution of their applications and workflows. The major contribution of this work is given by the analysis of a set of brokering strategies for Hybrid Clouds, implemented by a brokering algorithm, aimed at the execution of various applications subject to different user requirements and computational conditions. With the objective of firstly maximize both user satisfaction and CB’s revenues the algorithm also pursues profit increases through the reduction of energy costs by adopting energy saving mechanisms. A simulation model is used to evaluate performance, and the results show that differences among strategies depend on type and size of system loads and that the use of turn on and off techniques greatly improves energy savings at low and medium load rates thus indirectly increasing CB revenues without diminishing customers’ satisfaction.}
}
@article{RAPPAPORT2017609,
title = {Cloud energy storage for grid scale applications in the UK},
journal = {Energy Policy},
volume = {109},
pages = {609-622},
year = {2017},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2017.07.044},
url = {https://www.sciencedirect.com/science/article/pii/S0301421517304743},
author = {Ron D. Rappaport and John Miles},
keywords = {Aggregated storage, Ancillary markets, Domestic batteries, Smart-grid, Virtual power plants},
abstract = {In this paper, the UK's electricity market and battery technologies were researched to determine the economics of aggregating domestic batteries for grid-scale services. A feasibility study was conducted under three scenarios in order to estimate the value of Advanced Lead-Acid (ALA) and Lithium-Ion (LI) batteries for domestic households in the UK. A profit optimization model was built using historical market data, and technical parameters of the batteries. An aggregated system of 5000 batteries was simulated and used to compare and stack value streams of seven different grid-scale services in the UK, including energy arbitrage, reserve and frequency regulation services. The results showed that using a battery system for domestic services is currently not economically viable, however grid-scale provision of dynamic frequency response and fast reserve services yield sufficient annual revenue to compensate for these losses. The annual profit margin per household obtained was £ 532/692 for ALA and LI batteries respectively, allowing a shared margin of £ 230–300 after accounting for household costs. The promotion of an aggregated storage system is hindered by current regulatory barriers in the UK, such as a double payment structure for storage operators, lack of subsidy and lack of separate definition for storage devices.}
}
@article{SHI201690,
title = {An energy-efficient scheduling scheme for time-constrained tasks in local mobile clouds},
journal = {Pervasive and Mobile Computing},
volume = {27},
pages = {90-105},
year = {2016},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2015.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S1574119215001431},
author = {Ting Shi and Mei Yang and Xiang Li and Qing Lei and Yingtao Jiang},
keywords = {Mobile cloud computing, Ad-hoc network, Offloading, Task scheduling},
abstract = {Mobile Cloud Computing (MCC) enables mobile devices to use resource providers other than mobile devices themselves to host the execution of mobile applications. Various mobile cloud architectures and scheduling algorithms have been studied recently. However, how to utilize MCC to enable mobile devices to run complex real-time applications while keeping high energy efficiency remains a challenge. In this paper, firstly, we introduce the local mobile clouds formed by nearby mobile devices and give the mathematical models of the mobile devices and their applications. Secondly, we formulate the scheduling problem in local mobile clouds. After describing the resource discovery scheme and the adaptive, probabilistic scheduling algorithm, we finally validate the performance of the proposed algorithm by simulation experiments.}
}
@article{PAUL201698,
title = {Energy efficient cloud service pricing: A two-timescale optimization approach},
journal = {Journal of Network and Computer Applications},
volume = {64},
pages = {98-112},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2015.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516000400},
author = {Debdeep Paul and Wen-De Zhong and Sanjay K. Bose},
keywords = {Cloud service market, Energy efficiency, Job scheduling, Model predictive control, Pricing},
abstract = {Abstract
This paper considers the scenario of a cloud service market where several Cloud Service Providers (CSP) are in operation and are competing against each other to attract and serve the demands generated by the customers. The competition arises from the fact that the customers (the individuals or organizations) who generate demand for services in the market rationally choose the CSP which offers good quality of services at a lower price. For pricing the services offered by the CSPs under this framework, we provide an analytical framework by considering the operational cost incurred by the CSP to service the given demand, the quality of service (QoS) offered and the prices other CSPs are charging. The pricing strategy we propose strikes a reasonable balance between charging too little which would result in irrationally low business profit and charging too much which would result in customer loss and thereby eventually loss of market share. In addition, the pricing strategy proposed promotes energy efficiency and renewable energy integration using a bi-level optimization strategy. The first level consisting of a Slow Timescale Optimization Procedure (STOP) addresses the economic efficiency related issues for cloud service pricing. The second level involving a Fast Timescale Optimization Procedure (FTOP) performs energy efficient job scheduling. We carry out numerical simulations to validate the proposed pricing strategy and compare it with an oracle benchmark policy, with fair profit sharing among the CSPs. We compare the proposed energy aware scheduling policy with a baseline scheduling policy. We demonstrate the efficiency and effectiveness of the proposed bi-level strategy and discuss the results.}
}
@article{SHIN2015201,
title = {Proton Linear Energy Transfer measurement using Emulsion Cloud Chamber},
journal = {Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms},
volume = {349},
pages = {201-208},
year = {2015},
issn = {0168-583X},
doi = {https://doi.org/10.1016/j.nimb.2014.12.083},
url = {https://www.sciencedirect.com/science/article/pii/S0168583X1500107X},
author = {Jae-ik Shin and Seyjoon Park and Haksoo Kim and Meyoung Kim and Chiyoung Jeong and Sungkoo Cho and Young Kyung Lim and Dongho Shin and Se Byeong Lee and Kunihiro Morishima and Naotaka Naganawa and Osamu Sato and Jungwon Kwak and Sung Hyun Kim and Jung Sook Cho and Jung Keun Ahn and Ji Hyun Kim and Chun Sil Yoon and Sebastien Incerti},
keywords = {Proton therapy, Bragg curve, Linear Energy Transfer (LET), Nuclear emulsion, Volume Pulse Height (VPH)},
abstract = {This study proposes to determine the correlation between the Volume Pulse Height (VPH) measured by nuclear emulsion and Linear Energy Transfer (LET) calculated by Monte Carlo simulation based on Geant4. The nuclear emulsion was irradiated at the National Cancer Center (NCC) with a therapeutic proton beam and was installed at 5.2m distance from the beam nozzle structure with various thicknesses of water-equivalent material (PMMA) blocks to position with specific positions along the Bragg curve. After the beam exposure and development of the emulsion films, the films were scanned by S-UTS developed in Nagoya University. The proton tracks in the scanned films were reconstructed using the ‘NETSCAN’ method. Through this procedure, the VPH can be derived from each reconstructed proton track at each position along the Bragg curve. The VPH value indicates the magnitude of energy loss in proton track. By comparison with the simulation results obtained using Geant4, we found the correlation between the LET calculated by Monte Carlo simulation and the VPH measured by the nuclear emulsion.}
}
@article{KAUR201855,
title = {GreenSched: An intelligent energy aware scheduling for deadline-and-budget constrained cloud tasks},
journal = {Simulation Modelling Practice and Theory},
volume = {82},
pages = {55-83},
year = {2018},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2017.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X17301697},
author = {Tarandeep Kaur and Inderveer Chana},
keywords = {Forward-only Counter Propagation Network (CPN), Cloud computing, Energy efficiency, Scheduling, Supervised learning, Unsupervised learning},
abstract = {The constant growth of the energy crisis within the ICT Sector has persistently gained importance thereby prompting endeavors to curb growing energy demands and associated expenditures. This paper attempts to propose an intelligent energy aware task allocation and resource provisioning technique running in GreenSched model. The GreenSched model tends to exploit the heterogeneity of tasks and multi-core capacity of the varied nodes in the cloud environment and attempts to proactively schedule the deadline-and budget- constrained tasks on identified less energy consuming or energy aware nodes. It implements a Forward-only Counter Propagation Network (CPN) based intelligent scheduler unit that runs a scheduling technique to identify the best nodes for the task allocation process, one with least energy consumption and deadline- and budget -fulfilling capability. The nodes are clustered and classified by comparing their energy consumption values. The proposed algorithm has been implemented using the CloudSim toolkit and Kohonen and CP-ANN Toolbox with the help of MatlabTM platform. The experimental results exhibit that the proposed technique offers reduced energy consumption along with an overall improvement in the performance by meeting the deadline-and-budget constraints imposed by the users.}
}
@article{LONG201438,
title = {A three-phase energy-saving strategy for cloud storage systems},
journal = {Journal of Systems and Software},
volume = {87},
pages = {38-47},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2013.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213002148},
author = {Saiqin Long and Yuelong Zhao and Wei Chen},
keywords = {Energy saving, Cloud storage systems, Cost efficient},
abstract = {In the running process of cloud data center, the idle data nodes will generate a large amount of unnecessary energy consumption. Furthermore, the resource misallocation will also cause a great waste of energy. This paper proposes a three-phase energy-saving strategy named TPES in order to save energy and operational costs for cloud suppliers. The three phases are replica management based on variable replication factor, cluster reconfiguration according to the optimal total costs and state transition based on observed and predicted workloads. These three phases save energy for the system at different levels which enhance the adaptability of our strategy. We evaluate our strategy using the expanded CloudSim toolkit and the results show that the proposed strategy achieves better energy reduction under different conditions in comparison with the existing schemes.}
}
@article{SHEFER2017148,
title = {Numerical study of influence of different dispersed components of crystal cloud on transmission of radiant energy},
journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},
volume = {201},
pages = {148-155},
year = {2017},
issn = {0022-4073},
doi = {https://doi.org/10.1016/j.jqsrt.2017.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0022407317304831},
author = {Olga Shefer},
keywords = {Crystals, Orientation, Light, Polarization, Extinction, Transmission},
abstract = {The calculated results of the transmission of visible and infrared radiation by an atmosphere layer involving ensembles of large preferentially oriented crystals and spherical particles are presented. To calculate extinction characteristics, the physical optics method and the Mie theory are applied. Among all atmospheric particles, both the small particles that are commensurable with the wavelength of the incident radiation and the large plates and the columns are distinguished by the most pronounced dependence of the transmission on spectra of radiant energy. The work illustrates features of influence of parameters of the particle size distribution, particle aspect ratios, orientation and particle refractive index, also polarization state of the incident radiation on the transmission. The predominant effect of the plates on the wavelength dependence of the transmission is shown. A separated and cooperative contributes of the large plates and the small volume shape particles to the common transmission by medium are considered.}
}
@article{ZHANG2014215,
title = {RESCUE: An energy-aware scheduler for cloud environments},
journal = {Sustainable Computing: Informatics and Systems},
volume = {4},
number = {4},
pages = {215-224},
year = {2014},
note = {Special Issue on Energy Aware Resource Management and Scheduling (EARMS)},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2014.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S2210537914000493},
author = {Quan Zhang and Grace Metri and Sudharsan Raghavan and Weisong Shi},
keywords = {Power management of data centers, Energy efficient scheduling, Virtualization, Cloud computing},
abstract = {Cloud computing has become an attractive platform, offering on-demand computing resources and storage capacity for both personal and commercial use. However, the data centers hosting these clouds use a staggering amount of energy, making energy consumption a major expense. For both homogeneous and heterogeneous clouds, energy consumption varies significantly, owing to the heterogeneity of hardware and software. Therefore, to reduce a data center's energy consumption, our approach leverages knowledge of the power consumption behavior of the underlying hardware and the characteristics of workloads in order to increase their overall energy efficiency. Our ultimate goal is to provide a scheduling mechanism that allows cloud providers to reduce the energy consumption of their data centers without needing to replace the underlying hardware, and to do so seamlessly, without impacting clients’ performance requirements. In this paper, we introduce RESCUE, an energy-aware scheduler for heterogeneous cloud environments. RESCUE ranks nodes within the cloud based on their application-specific energy efficiency (ASEE), which implies the correlation between the various hardware and software and the energy efficiency. According to ASEE, RESCUE can assign the whole workload to the most energy-efficient machine while keeping the same performance. We evaluated RESCUE on a private cloud using three benchmarks: BS Seeker, Matrix Stressmark, and TPC-W. We implemented RESCUE with Eucalyptus and compared the energy consumed using RESCUE as the scheduling policy to the other Eucalyptus built-in policies: Round Robin and Greedy. The results show that with a nonaggressive control policy where the machine remains in active mode (ACPI C0 state), RESCUE reduces the overall energy consumption by up to 16.7% on average for BS Seeker and Matrix Stressmark, while for TPC-W, RESCUE saves up to 6.6% of the total energy. Furthermore, with an aggressive control policy that set the idle machines in “sleep” mode (ACPI S3 state), RESCUE-with-sleep can further reduce the total energy consumption by 51.5% for BS Seeker, 48.8% for Matrix Stressmark, and 21.3% for TPC-W compared to RESCUE.}
}
@article{LAWANYASHRI201742,
title = {Energy-aware hybrid fruitfly optimization for load balancing in cloud environments for EHR applications},
journal = {Informatics in Medicine Unlocked},
volume = {8},
pages = {42-50},
year = {2017},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2017.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S2352914817300187},
author = {M. Lawanyashri and Balamurugan Balusamy and S. Subha},
keywords = {Cloud computing, Electronic Health Records (EHR), Load balancing, Fruitfly Optimization Algorithm (FOA), Simulated Annealing (SA), Energy consumption},
abstract = {Cloud computing has gained precise attention from the research community and management of IT, due to its scalable and dynamic capabilities. It is evolving as a vibrant technology to modernize and restructure healthcare organization to provide best services to the consumers. The rising demand for healthcare services and applications in cloud computing leads to the imbalance in resource usage and drastically increases the power consumption resulting in high operating cost. To achieve fast execution time and optimum utilization of the virtual machines, we propose a multi-objective hybrid fruitfly optimization technique based on simulated annealing to improve the convergence rate and optimization accuracy. The proposed approach is used to achieve the optimal resource utilization and reduces the energy consumption and cost in cloud computing environment. The result attained in our proposed technique provides an improved solution. The experimental results show that the proposed algorithm efficiently outperforms compared to the existing load balancing algorithms.}
}
@article{LIU2017427,
title = {Energy-Aware on-chip virtual machine placement for cloud-supported cyber-physical systems},
journal = {Microprocessors and Microsystems},
volume = {52},
pages = {427-437},
year = {2017},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2016.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0141933116300965},
author = {Xuanzhang Liu and Huaxi Gu and Haibo Zhang and Feiyang Liu and Yawen Chen and Xiaoshan Yu},
keywords = {Cyber-physical systems, Virtual machine placement, Network-on-Chip, Ant colony optimization},
abstract = {Recent trends in the design of cyber-physical systems (CPS) are moving towards heterogeneous multi-core architectures with cloud support. In this paper, we propose an energy-aware scheme for virtual machine placement in cloud-supported CPS with Network-on-Chip (NoC) architecture. We formulate the energy-aware on-chip virtual machine placement problem as an optimization problem, and design a heuristic scheme based on ant-colony optimization. We address problems of slow convergence speed and easily falling into stagnation in ant-colony algorithm by employing pheromone diffusion model that makes the proposed scheme more efficient. Simulation results show that our scheme achieves much higher energy efficiency compared with previous schemes with different network sizes and traffic models.}
}
@article{EVANS20142838,
title = {Open-source Cloud-based Energy Calculator/simulator},
journal = {Energy Procedia},
volume = {57},
pages = {2838-2847},
year = {2014},
note = {2013 ISES Solar World Congress},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2014.10.317},
url = {https://www.sciencedirect.com/science/article/pii/S1876610214016841},
author = {R. Evans},
keywords = {photovoltaic, simulation, cloud-based, energy, solar},
abstract = {In this paper we will present a newly written energy calculator built as a project between CICESE and the State Energy Commission of Baja California. The system runs server side and is written in PHP and Python storing its data on a MySQL database. The user interface allows the user to input their geographic location, and electrical energy use history. The user can then choose from a virtual warehouse of photovoltaic systems offered by local installers. Using astronomical algorithms, and weather station data the system generates a list of solar intensity values and calculates the response of chosen photovoltaic. The final values calculated are the cost predictions for the next 20 years. Because of its open-source nature, then system can be easily expanded to include wind power systems, carbon production, and ever gas and water usage. The primary user for this system is the general public with hopes that they will become educated on their energy use, and the potential effects of new photovoltaic installations.}
}
@article{SAAB201538,
title = {Partial mobile application offloading to the cloud for energy-efficiency with security measures},
journal = {Sustainable Computing: Informatics and Systems},
volume = {8},
pages = {38-46},
year = {2015},
note = {Special Issue on Computing for a Greener Water/Energy/Emissions Nexus; edited by Carol J. Miller.andSpecial Issue on Green Mobile Cloud Computing (Green MCC); edited by Danielo G. Gomes, Rafael Tolosana-Calasanz, and Nazim Agoulmine.},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2210537915000396},
author = {Salwa Adriana Saab and Farah Saab and Ayman Kayssi and Ali Chehab and Imad H. Elhajj},
keywords = {Offloading, Mobile cloud computing, Free sequence protocol, Energy efficiency, Power consumption},
abstract = {Mobile applications are becoming computationally intensive nowadays due to the increasing convenience, reliance on, and sophistication of smartphones. Nevertheless, battery lifetime remains a major obstacle that prohibits the large-scale adoption of such apps. Mobile cloud computing is a promising solution whereby apps are partially processed in the cloud to minimize the overall energy consumption of smartphones. However, this will not necessarily save energy if there is no systematic mechanism to evaluate the effect of offloading an app onto the cloud. In this paper, we present a mathematical model that represents this energy consumption optimization problem. We propose an algorithm to dynamically solve the problem while taking security measures into account. We also propose the free sequence protocol (FSP) that allows for the dynamic execution of apps according to their call graph. Our experimental setup consists of an Android smartphone and a Java server in the cloud. The results demonstrate that our approach saves battery lifetime and enhances performance. They also show the effects of workload amount, network type, computation cost, security operations, signal strength, and call graph structure on the optimized overall energy consumption.}
}
@article{ZHOU2018836,
title = {Minimizing SLA violation and power consumption in Cloud data centers using adaptive energy-aware algorithms},
journal = {Future Generation Computer Systems},
volume = {86},
pages = {836-850},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.07.048},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17316059},
author = {Zhou Zhou and Jemal Abawajy and Morshed Chowdhury and Zhigang Hu and Keqin Li and Hongbing Cheng and Abdulhameed A. Alelaiwi and Fangmin Li},
keywords = {Cloud computing, Energy efficiency, CPU intensive task, I/O intensive task, VM deployment, Service Level Agreement, Data center},
abstract = {In this paper, we address the problem of reducing Cloud datacenter high energy consumption with minimal Service Level Agreement (SLA) violation. Although there are many energy-aware resource management solutions for Cloud datacenters, existing approaches focus on minimizing energy consumption while ignoring the SLA violation at the time of virtual machine (VM) deployment. Also, they do not consider the types of application running in the VMs and thus may not really reduce energy consumption with minimal SLA violation under a variety of workloads. In this paper, we propose two novel adaptive energy-aware algorithms for maximizing energy efficiency and minimizing SLA violation rate in Cloud datacenters. Unlike the existing approaches, the proposed energy-aware algorithms take into account the application types as well as the CPU and memory resources during the deployment of VMs. To study the efficacy of the proposed approaches, we performed extensive experimental analysis using real-world workload, which comes from more than a thousand PlanetLab VMs. The experimental results show that, compared with the existing energy-saving techniques, the proposed approaches can effectively decrease the energy consumption in Cloud datacenters while maintaining low SLA violation.}
}
@article{PAUL2016185,
title = {Energy efficiency aware load distribution and electricity cost volatility control for cloud service providers},
journal = {Journal of Network and Computer Applications},
volume = {59},
pages = {185-197},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2015.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1084804515001988},
author = {Debdeep Paul and Wen-De Zhong and Sanjay K. Bose},
keywords = {Energy efficiency, Electricity markets, Internet data centers, Online algorithms, Model predictive control},
abstract = {This paper consider the case of a cloud service provider (CSP) who owns multiple geographically distributed data centers, with collocated sources of renewable energy. We investigate load distribution strategies to minimize electricity cost and increase renewable incorporation subject to compliance with service level agreement (SLA), considering the adverse effects of switching the servers. Our work provides some insights on the performance of different algorithms for geographical load balancing (GLB) in terms of electricity cost, renewable energy integration and number of server switching. Our proposed strategies incorporate a new way of capturing the server switching cost. We show that, instead of modeling switching cost through a linear function, the proposed technique of modeling switching cost through variance achieves a better tradeoff between some important parameters. Since the three major input parameters-electricity price, renewable energy and number of job requests-vary over time, the average cost of electricity per job request may also exhibit dramatic fluctuations. We propose to tackle this volatility by controlling the average cost of electricity per job request through leveraging contracts in the forward electricity market, and determine the optimal amount of electricity to be procured in the forward electricity market. We show that our proposed strategy substantially reduces the variance of the average cost of electricity per job and that this price risk mitigation is achieved with a decrease in the cumulative electricity cost.}
}
@article{BROERING20173507,
title = {Simulation and Evaluation of the Economic Merit of Cloud Energy Storage for Prosumers: The Case of Germany},
journal = {Energy Procedia},
volume = {105},
pages = {3507-3514},
year = {2017},
note = {8th International Conference on Applied Energy, ICAE2016, 8-11 October 2016, Beijing, China},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2017.03.804},
url = {https://www.sciencedirect.com/science/article/pii/S1876610217308792},
author = {Hendrik Broering and Reinhard Madlener},
keywords = {Prosumer household, Storage cloud, Distributed generation, Photovoltaics, Battery storage},
abstract = {This paper investigates the merits of a virtual aggregation of spare capacities from decentralized batteries installed in private households. To this end, we develop a simulation model that enables to take into account the prevailing grid- use tariffs, feed-in tariffs, and other parameters for an economic assessment of the viability of such an “energy storage cloud”. In the illustrative model application, we study the merits for four households in Germany over the period of one month by analyzing three distinct scenarios (one with no grid-use tariffs, one with unidirectional grid-use tariffs, and one with bidirectional grid-use tariffs). Three households are assumed to have hybrid PV-battery systems, whereas the fourth household aims at using the energy storage cloud for increasing its self-supply. We find that below a feed-in tariff of 10 €-ct/kWh, profits can indeed be made. The maximum net profit results in Scenario 1, where feed-in tariffs and grid-use costs are zero, and amounts to around €36 per month.}
}
@article{FELLER201580,
title = {Performance and energy efficiency of big data applications in cloud environments: A Hadoop case study},
journal = {Journal of Parallel and Distributed Computing},
volume = {79-80},
pages = {80-89},
year = {2015},
note = {Special Issue on Scalable Systems for Big Data Management and Analytics},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2015.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0743731515000027},
author = {Eugen Feller and Lavanya Ramakrishnan and Christine Morin},
keywords = {Cloud computing, Hadoop MapReduce, Performance, Energy efficiency, Virtualization},
abstract = {The exponential growth of scientific and business data has resulted in the evolution of the cloud computing environments and the MapReduce parallel programming model. The focus of cloud computing is increased utilization and power savings through consolidation while MapReduce enables large scale data analysis. Hadoop, an open source implementation of MapReduce has gained popularity in the last few years. In this paper, we evaluate Hadoop performance in both the traditional model of collocated data and compute services as well as consider the impact of separating out the services. The separation of data and compute services provides more flexibility in environments where data locality might not have a considerable impact such as virtualized environments and clusters with advanced networks. In this paper, we also conduct an energy efficiency evaluation of Hadoop on physical and virtual clusters in different configurations. Our extensive evaluation shows that: (1) coexisting virtual machines on servers decrease the disk throughput; (2) performance on physical clusters is significantly better than on virtual clusters; (3) performance degradation due to separation of the services depends on the data to compute ratio; (4) application completion progress correlates with the power consumption and power consumption is heavily application specific. Finally, we present a discussion on the implications of using cloud environments for big data analyses.}
}
@article{KARAKOYUNLU2016282,
title = {Exploiting user metadata for energy-aware node allocation in a cloud storage system},
journal = {Journal of Computer and System Sciences},
volume = {82},
number = {2},
pages = {282-309},
year = {2016},
issn = {0022-0000},
doi = {https://doi.org/10.1016/j.jcss.2015.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0022000015001014},
author = {Cengiz Karakoyunlu and John A. Chandy},
keywords = {Energy efficiency, Cloud storage, Cloud systems, Load balancing, Metadata aware placement},
abstract = {Cloud computing has gained popularity in recent years delivering various services as cost-effective platforms. However, the increasing energy consumption needs to be addressed in order to preserve the cost-effectiveness of these systems. In this work, we target the storage infrastructure in a cloud system and introduce several energy efficient storage node allocation methods by exploiting the metadata heterogeneity of cloud users. Our proposed methods preserve load balance on demand and switch inactive nodes into low-energy modes to save energy. We provide a mathematical model to estimate the outcome of proposed methods and conduct theoretical and simulative analyses using real-world workloads.}
}
@article{LIAO20181318,
title = {Energy Consumption Optimization Scheme of Cloud Data Center Based on SDN},
journal = {Procedia Computer Science},
volume = {131},
pages = {1318-1327},
year = {2018},
note = {Recent Advancement in Information and Communication Technology:},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.04.327},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918307075},
author = {Qing Liao and Zun Wang},
keywords = {Cloud data center, software-defined network, energy consumption control, VM migration integration},
abstract = {In response to the mobile Internet, Internet of things and cloud computing technology fast development, the operation of large-scale distributed computing cloud data center construction in the world at the same time, the network data calculation of energy consumption problem is causing extensive concern. And the software-defined Network (SDN) provides a feasible solution to the rigid problem of traditional Network architecture. Based on SDN technology, this paper proposes a method of energy consumption control based on cloud data center. Aiming at server energy saving, the multi-objective optimization model of virtual machine migration integration is established, and the integration mechanism of virtual machine migration based on mixed single-parent genetic algorithm is proposed. The experimental results show that the algorithm can be used to solve the problem of virtual machine migration and integration in data center.}
}
@article{XIAO20141650,
title = {Energy-efficiency enhanced virtual machine scheduling policy for mixed workloads in cloud environments},
journal = {Computers & Electrical Engineering},
volume = {40},
number = {5},
pages = {1650-1665},
year = {2014},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2014.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0045790614000561},
author = {Peng Xiao and Zhigang Hu and Dongbo Liu and Xizheng Zhang and Xilong Qu},
abstract = {Virtualization technology is an effective approach to improving the energy-efficiency in cloud platforms; however, it also introduces many energy-efficiency losses especially when I/O virtualization is involved. In this paper, we present an energy-efficiency enhanced virtual machine (VM) scheduling policy, namely Share-Reclaiming with Collective I/O (SRC-I/O), with aiming at reducing the energy-efficiency losses caused by I/O virtualization. The proposed SRC-I/O scheduler allows VMs to reclaim extra CPU shares in certain conditions so as to increase CPU utilization. Meanwhile, it separates I/O-intensive VMs from CPU-intensive ones and schedules them in a collective manner, so as to reduce the context-switching cost when scheduling mixed workloads. Extensive experiments are conducted on various platforms to investigate the performance of the proposed scheduler. The results indicate that when the system is in presence of mixed workloads, SRC-I/O scheduler outperforms many existing VM schedulers in terms of energy-efficiency and I/O responsiveness.}
}
@article{HSU2014452,
title = {Optimizing Energy Consumption with Task Consolidation in Clouds},
journal = {Information Sciences},
volume = {258},
pages = {452-462},
year = {2014},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2012.10.041},
url = {https://www.sciencedirect.com/science/article/pii/S0020025512007554},
author = {Ching-Hsien Hsu and Kenn D. Slagter and Shih-Chang Chen and Yeh-Ching Chung},
abstract = {Task consolidation is a way to maximize utilization of cloud computing resources. Maximizing resource utilization provides various benefits such as the rationalization of maintenance, IT service customization, QoS and reliable services, etc. However, maximizing resource utilization does not mean efficient energy use. Much of the literature shows that energy consumption and resource utilization in clouds are highly coupled. Consequently, some of the literature aims to decrease resource utilization in order to save energy, while others try to reach a balance between resource utilization and energy consumption. In this paper, we present an energy-aware task consolidation (ETC) technique that minimizes energy consumption. ETC achieves this by restricting CPU use below a specified peak threshold. ETC does this by consolidating tasks amongst virtual clusters. In addition, the energy cost model considers network latency when a task migrates to another virtual cluster. To evaluate the performance of ETC we compare it against MaxUtil. MaxUtil is a recently developed greedy algorithm that aims to maximize cloud computing resources. The simulation results show that ETC can significantly reduce power consumption in a cloud system, with 17% improvement over MaxUtil.}
}
@article{WANG2016287,
title = {Energy-based automatic recognition of multiple spheres in three-dimensional point cloud},
journal = {Pattern Recognition Letters},
volume = {83},
pages = {287-293},
year = {2016},
note = {Efficient Shape Representation, Matching, Ranking, and its Applications},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2016.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167865516301702},
author = {Liang Wang and Chao Shen and Fuqing Duan and Ke Lu},
keywords = {Sphere recognition, 3D point cloud, Energy minimization, Point labeling},
abstract = {The emerging RGB-D sensors make three-dimensional data acquisition more economy and flexible. However, an ensuing great challenge is how to efficiently and effectively understand and apply the huge amount of three-dimensional data. Automatic recognition of primary geometric shapes in three-dimensional point cloud, such as spheres, can provide some abstractions and possibly semantic information to solve the challenge. An energy-based method for automatic recognition of multiple spheres in three-dimensional point cloud is proposed from the point of view of data labeling. It first generates initial sphere models by randomly sampling. Second, it constructs the energy function, and then labels three-dimensional points by minimizing the energy. Third, it refines obtained labels and parameters further. Four, it iterates the above steps until the energy does not decrease. Finally, multiple spheres are recognized from three-dimensional point cloud. Experiments with synthetic and real data validate the proposed method. It outperforms the Hough-based and the RANSAC-based method in accuracy and robustness. More importantly, it alleviates the dependence of existing algorithms on distance thresholds, the requirement of the unknown number and parameters of spheres, and the requirement of a huge sampling number to generate initial models.}
}
@article{LUO20145804,
title = {Hybrid shuffled frog leaping algorithm for energy-efficient dynamic consolidation of virtual machines in cloud data centers},
journal = {Expert Systems with Applications},
volume = {41},
number = {13},
pages = {5804-5816},
year = {2014},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2014.03.039},
url = {https://www.sciencedirect.com/science/article/pii/S0957417414001778},
author = {Jian-ping Luo and Xia Li and Min-rong Chen},
keywords = {Cloud computing, Data center, Resource management, Intelligent algorithm},
abstract = {Cloud computing aims to provide dynamic leasing of server capabilities as scalable virtualized services to end users. However, data centers hosting cloud applications consume vast amounts of electrical energy, thereby contributing to high operational costs and carbon footprints. Green cloud computing solutions that can not only minimize the operational costs but also reduce the environmental impact are necessary. This study focuses on the Infrastructure as a Service model, where custom virtual machines (VMs) are launched in appropriate servers available in a data center. A complete data center resource management scheme is presented in this paper. The scheme can not only ensure user quality of service (through service level agreements) but can also achieve maximum energy saving and green computing goals. Considering that the data center host is usually tens of thousands in size and that using an exact algorithm to solve the resource allocation problem is difficult, the modified shuffled frog leaping algorithm and improved extremal optimization are employed in this study to solve the dynamic allocation problem of VMs. Experimental results demonstrate that the proposed resource management scheme exhibits excellent performance in green cloud computing.}
}
@article{PANNEERSELVAM2018239,
title = {An investigation into the impacts of task-level behavioural heterogeneity upon energy efficiency in Cloud datacentres},
journal = {Future Generation Computer Systems},
volume = {83},
pages = {239-249},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.12.064},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1731960X},
author = {John Panneerselvam and Lu Liu and Yao Lu and Nick Antonopoulos},
keywords = {Energy-aware stragglers, Long-tails, Resource idleness, Task heterogeneity},
abstract = {Cloud datacentre resources and the arriving jobs are addressed to be exhibiting increased level of heterogeneity. A single Cloud job may encompass one to several number of tasks, such tasks usually exhibit increased level of behavioural heterogeneity though they belong to the same job. Such behavioural heterogeneity are usually evident among the level of resource consumption, resource intensiveness, task duration etc. These task behavioural heterogeneity within jobs impose various complications in achieving an effective energy efficient management of the Cloud jobs whilst processing them in the server resources. To this end, this paper investigates the impacts of the task level behavioural heterogeneity upon energy efficiency whilst the tasks within given jobs are executed in Cloud datacentres. Real-life Cloud trace logs have been investigated to exhibit the impacts of task heterogeneity from three different perspectives including the task execution trend and task termination pattern, the presence of few proportions of resource intensive and long running tasks within jobs. Furthermore, the energy implications of such straggling tasks within jobs have been empirically exhibited. Analysis conducted in this study demonstrates that Cloud jobs are extremely heterogeneous and tasks behave distinctly under different execution instances, and the presence of energy-aware long tail stragglers within jobs can significantly incur extravagant level of energy expenditures.}
}
@article{XU2020789,
title = {A balanced virtual machine scheduling method for energy-performance trade-offs in cyber-physical cloud systems},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {789-799},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.08.057},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17318927},
author = {Xiaolong Xu and Xuyun Zhang and Maqbool Khan and Wanchun Dou and Shengjun Xue and Shui Yu},
keywords = {Balanced VM scheduling, Energy, Performance, CPS, Cloud},
abstract = {The cloud computing scheme promises many salient features such as on-demand resource provisioning to users, and it therefore has drawn significant attention from the cyber-physical systems (CPS). An increasing number of CPS have been deployed in cloud platforms, and to accommodate numerous CPS applications, cloud datacenters often consist of a huge number of physical computation and storage nodes, and the number is still increasing. As a result, the electricity power consumption in cloud datacenters is considerable, currently accounting for about 1.3% of the worldwide electricity. How to reduce the energy consumption of datacenters is an economically beneficial but challenging problem. Optimizing virtual machine (VM) scheduling in datacenters by live VM migration is an appealing method to save energy consumption. However, it is still a challenge to conduct VM scheduling in an energy-efficient and performance-guaranteed manner, since VM migration can suffer from severe performance degradation while saving energy. In this paper, we propose a balanced VM scheduling method to achieve trade-offs between energy and performance in cyber-physical cloud systems. Specifically, the problem is formulated via a joint optimization model, and a balanced VM scheduling method is proposed accordingly to determine which VMs and where should be migrated, aiming at both reducing energy consumption and mitigating performance degradation. Both analytical and simulation results demonstrate the effectiveness and efficiency of our method.}
}
@article{BARNES20149444,
title = {Modelling PV Clouding Effects Using a Semi-Markov Process with Application to Energy Storage},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {9444-9449},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.00825},
url = {https://www.sciencedirect.com/science/article/pii/S147466701643106X},
author = {Arthur K. Barnes and Juan C. Balda and Jonathan K. Hayes},
abstract = {Cloud-induced intermittency of photovoltaic (PV) generation forces equipment on the electrical grid to cycle excessively preventing PV from being considered as a reliable or dispatchable source of power. Energy storage units (ESU) are proposed to turn PV power dispatchable. In order to use an ESU most effectively, it must be controlled appropriately by considering cloud-induced effects. To this end, the cloud structure is modeled as a random sequence inferred from clouding data. The proposed model is valid for centralized PV installations and serves to develop not only a control methodology to coordinate an ESU with existing grid equipment but also as a sizing criterion for an ESU. The above methodology is demonstrated on both clouding data collected from a rooftop PV installation that includes a pyranometer.}
}
@article{LI2018887,
title = {Holistic energy and failure aware workload scheduling in Cloud datacenters},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {887-900},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.07.044},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17315650},
author = {Xiang Li and Xiaohong Jiang and Peter Garraghan and Zhaohui Wu},
keywords = {Energy efficiency, Thermal management, Reliability, Failures, Workload scheduling, Cloud computing},
abstract = {The global uptake of Cloud computing has attracted increased interest within both academia and industry resulting in the formation of large-scale and complex distributed systems. This has led to increased failure occurrence within computing systems that induce substantial negative impact upon system performance and task reliability perceived by users. Such systems also consume vast quantities of power, resulting in significant operational costs perceived by providers. Virtualization – a commonly deployed technology within Cloud datacenters – can enable flexible scheduling of virtual machines to maximize system reliability and energy-efficiency. However, existing work address these two objectives separately, providing limited understanding towards studying the explicit trade-offs towards dependable and energy-efficient compute infrastructure. In this paper, we propose two failure-aware energy-efficient scheduling algorithms that exploit the holistic operational characteristics of the Cloud datacenter comprising the cooling unit, computing infrastructure and server failures. By comprehensively modeling the power and failure profiles of a Cloud datacenter, we propose workload scheduling algorithms Ella-W and Ella-B, capable of reducing cooling and compute energy while minimizing the impact of system failures. A novel and overall metric is proposed that combines energy efficiency and reliability to specify the performance of various algorithms. We evaluate our algorithms against Random, MaxUtil, TASA, MTTE and OBFIT under various system conditions of failure prediction accuracy and workload intensity. Evaluation results demonstrate that Ella-W can reduce energy usage by 29.5% and improve task completion rate by 3.6%, while Ella-B reduces energy usage by 32.7% with no degradation to task completion rate.}
}
@article{CHEN2018416,
title = {ERECT: Energy-efficient reactive scheduling for real-time tasks in heterogeneous virtualized clouds},
journal = {Journal of Computational Science},
volume = {28},
pages = {416-425},
year = {2018},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2017.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S1877750317303204},
author = {Huangke Chen and Guipeng Liu and Shu Yin and Xiaocheng Liu and Dishan Qiu},
keywords = {Reactive scheduling, Real-time task, Virtualized cloud, DVFS},
abstract = {High energy consumption in large-scale cloud data centers has become a burning issue, and efficient task and resource scheduling is an attractive way to cut down their energy consumption while providing satisfactory services for the customers. Unfortunately, existing scheduling approaches do not fully exploit the heterogeneity of real-tasks and physical hosts for maximum energy savings, while guaranteeing the timing requirements of real-time tasks. To solve the above problem, in this paper, we firstly develop a novel scheduling architecture that transforms the dynamic scheduling problem into multiple static schedules. Then, we propose an energy-efficient reactive scheduling algorithm, namely ERECT, to schedule the real-time tasks and computing resources in virtualized clouds. The proposed algorithm ERECT fully consider the heterogeneity of the real-time tasks and the hosts. In addition, when adding and deleting the virtual machines (VMs), the optimal operating frequencies and energy efficiencies of heterogeneous hosts are exploited to achieve energy conservation. Finally, in order to demonstrate the effectiveness of our approach, extensive experiments are conducted to compare ERECT with two baseline scheduling algorithms in the context of Google traces. The experimental results show that ERECT outperforms those two existing algorithms in terms of guaranteeing tasks’ deadlines (up to 14.06%) and energy saving (up to 9.81%).}
}
@article{SAENZ2014180,
title = {The role of cloud forest restoration on energy security},
journal = {Ecosystem Services},
volume = {9},
pages = {180-190},
year = {2014},
issn = {2212-0416},
doi = {https://doi.org/10.1016/j.ecoser.2014.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S2212041614000709},
author = {Leonardo Sáenz and Mark Mulligan and Fabio Arjona and Tatiana Gutierrez},
keywords = {Cloud forest, Calima dam, Environmental Firm Energy (EFE), Power Reliability Environmental Charge (PREC), Payments for watershed services (PWS) schemes},
abstract = {The conservation of cloud forests has recently been recognized as important for the optimal operation of hydropower infrastructure. However, large areas of cloud forest have been deforested globally, which may suggest that many tropical dams, downstream of these deforested areas, are currently operating at suboptimal levels. This is the case in a country like Colombia where 55% of pre-colonial cloud forests have disappeared. Incentives like Payments for Watershed Services have tried to involve Colombia׳s energy sector in improved watershed conservation with limited success. Since hydropower companies likely benefit significantly from eco-hydrological services provided by cloud forests, a new generation of incentives for facilitating their engagement in ecosystem protection is desperately needed. Through simulation of the effect of cloud forest restoration on the hydropower output of the Calima dam system, using innovative process based eco-hydrological models and dam operational modeling, we explore the implications of cloud forest restoration for energy security and expansion in Colombia and propose an innovative financial mechanism to help engage energy companies further in improved cloud forest protection in Colombia and beyond.}
}
@article{ROSSI201783,
title = {E-eco: Performance-aware energy-efficient cloud data center orchestration},
journal = {Journal of Network and Computer Applications},
volume = {78},
pages = {83-96},
year = {2017},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.10.024},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516302569},
author = {Fábio D. Rossi and Miguel G. Xavier and César A.F. {De Rose} and Rodrigo N. Calheiros and Rajkumar Buyya},
keywords = {Cloud application performance, Data center, Energy-efficient management.},
abstract = {The high energy consumption of data centers has been a recurring issue in recent research. In cloud environments, several techniques are being used that aim for energy efficiency, ranging from scaling the processors frequency, to the use of sleep states during idle periods and the consolidation of virtual machines. Although these techniques enable a reduction in power consumption, they usually impact application performance. In this paper, we present an orchestration of different energy-savings techniques in order to improve the trade-off between energy consumption and application performance. To this end, we implemented the Energy-Efficient Cloud Orchestrator - e-eco - a management system that acts along with the cloud load balancer deciding which technique to apply during execution. To evaluate e-eco, tests were carried out in a real environment using scale-out applications on a dynamic cloud infrastructure, taking into account transactions per second as a performance metric. In addition to the empirical experiments, we also analyzed the scalability of our approach with an enhanced version of the CloudSim simulator. Results of our evaluations demonstrated that e-eco is able to reduce energy consumption up to 25% compared to power-agnostic approaches at a cost of only 6% of extra SLA violations. When compared to existing power-aware approaches, e-eco achieved the best trade-off between performance and energy-savings. These results showed that our orchestration approach showed a better balance in regard to a more energy-efficient data center with smaller impact on application performance when compared with other works presented in the literature.}
}
@article{NAGATA1994103,
title = {High energy high resolution monochromatic x-ray computed tomography using synchrotron radiation: Nondestructive Characterization of Materials V, Karuizawa (Japan), 27–30 May 1991. pp. 299–307. Edited by T. Kishi, T. Saito, C. Ruud and R. Green. Iketani Science and Technology Foundation (1993)},
journal = {NDT & E International},
volume = {27},
number = {2},
pages = {103},
year = {1994},
issn = {0963-8695},
doi = {https://doi.org/10.1016/0963-8695(94)90344-1},
url = {https://www.sciencedirect.com/science/article/pii/0963869594903441},
author = {Y. Nagata and H. Yamaji and K. Hayashi and K. Kawashima and K. Hydodo and H. Kawata and M. Ando}
}
@article{XIONG201663,
title = {An energy-optimization-based method of task scheduling for a cloud video surveillance center},
journal = {Journal of Network and Computer Applications},
volume = {59},
pages = {63-73},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2015.06.017},
url = {https://www.sciencedirect.com/science/article/pii/S1084804515001459},
author = {Yonghua Xiong and Shaoyun Wan and Jinhua She and Min Wu and Yong He and Keyuan Jiang},
keywords = {Cloud video surveillance (CVS), Energy optimization, Real time, Task scheduling, Bin packing},
abstract = {The number of cloud video surveillance (CVS) systems has been increasing rapidly over the last decade. Since CVS systems are big energy consumers, it is urgent to take the problem of optimizing the energy consumption of CVS systems into consideration. In this study, we build a task scheduling model, and present a method of scheduling that minimizes energy consumption by reducing the number of virtual machines. The optimization problem is first formulated as a multi-dimensional bin-packing problem due to the constrains on the resources (sizes of the bandwidth, the memory, the hard disk, the CPU utilization, etc.). We convert the problem into a one-dimensional bin-packing problem by making use of the relationships between the resources, and solve it using the greedy best-fit search algorithm. This method greatly reduces the computational expense and can be used in a real-time fashion. An experimental system is designed to evaluate the method, and four experiments are carried out to demonstrate the validity of the method. Experimental results show that the method not only largely improved the resource utilization and reduces energy consumption but also the scheduling time was significantly decreased when handling the same number of video tasks. And it is obviously superior to the common approach and First Fit Decreasing (FFD) algorithm.}
}
@article{BAKER201583,
title = {GreeDi: An energy efficient routing algorithm for big data on cloud},
journal = {Ad Hoc Networks},
volume = {35},
pages = {83-96},
year = {2015},
note = {Special Issue on Big Data Inspired Data Sensing, Processing and Networking Technologies},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2015.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1570870515001341},
author = {T. Baker and B. Al-Dawsari and H. Tawfik and D. Reid and Y. Ngoko},
keywords = {Big data, Cloud computing, Routing algorithm, Data centre},
abstract = {The ever-increasing density in cloud computing parties, i.e. users, services, providers and data centres, has led to a significant exponential growth in: data produced and transferred among the cloud computing parties; network traffic; and the energy consumed by the cloud computing massive infrastructure, which is required to respond quickly and effectively to users requests. Transferring big data volume among the aforementioned parties requires a high bandwidth connection, which consumes larger amounts of energy than just processing and storing big data on cloud data centres, and hence producing high carbon dioxide emissions. This power consumption is highly significant when transferring big data into a data centre located relatively far from the users geographical location. Thus, it became high-necessity to locate the lowest energy consumption route between the user and the designated data centre, while making sure the users requirements, e.g. response time, are met. The main contribution of this paper is GreeDi, a network-based routing algorithm to find the most energy efficient path to the cloud data centre for processing and storing big data. The algorithm is, first, formalised by the situation calculus. The linear, goal and dynamic programming approaches are used to model the algorithm. The algorithm is then evaluated against the baseline shortest path algorithm with minimum number of nodes traversed, using a real Italian ISP physical network topology.}
}
@article{WHEELER2017149,
title = {A fragment-cloud model for asteroid breakup and atmospheric energy deposition},
journal = {Icarus},
volume = {295},
pages = {149-169},
year = {2017},
issn = {0019-1035},
doi = {https://doi.org/10.1016/j.icarus.2017.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0019103516307989},
author = {Lorien F. Wheeler and Paul J. Register and Donovan L. Mathias},
abstract = {As asteroids break up during atmospheric entry, they deposit energy that can be seen in flares of light and, if substantial enough, can produce damaging blast waves. Analytic models of asteroid breakup and energy deposition processes are needed in order to assess potential airburst hazards, and to enable inferences about asteroid properties or breakup physics to be made from comparisons with observed meteors. This paper presents a fragment-cloud model (FCM) that is able to represent a broad range of breakup behaviors and the resulting variations in energy deposition in ways that make it a useful tool for both applications. Sensitivity studies are performed to investigate how variations the model's fragmentation parameters affect the energy deposition results for asteroids 20–500m in diameter. The model is also used to match observational data from the Chelyabinsk meteor and infer potential asteroid properties and representative modeling parameter ranges. Results illustrate how the model's fragmentation parameters can introduce different energy deposition features, and how much they affect the overall energy deposition rates, magnitudes, and altitudes that would drive ground damage for risk assessment applications.}
}
@article{ADDIS201475,
title = {Energy-aware joint management of networks and Cloud infrastructures},
journal = {Computer Networks},
volume = {70},
pages = {75-95},
year = {2014},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2014.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S1389128614001649},
author = {Bernardetta Addis and Danilo Ardagna and Antonio Capone and Giuliana Carello},
keywords = {Green ICT, Cloud service, Energy management, Optimization, Mathematical programming, Renewable energy},
abstract = {Fueled by the massive adoption of Cloud services, the CO2 emissions of the Information and Communication Technology (ICT) systems are rapidly increasing. Overall service centers and networks account for 2–4% of global CO2 emissions and it is expected they can reach up to 10% in 5–10years. Service centers and communication networks have been managed independently so far, but the new generation of Cloud systems can be based on a strict integration of service centers and networking infrastructures. Moreover, geographically-distributed service centers are being widely adopted to keep Cloud services close to end users and to guarantee high performance. The geographical distribution of the computing facilities offers many opportunities for optimizing energy consumption and costs by means of a clever distribution of the computational workload exploiting different availability of renewable energy sources, but also different time zones and hourly energy pricing. Energy and cost savings can be pursued by dynamically allocating computing resources to applications at a global level, while communication networks allow to assign flexibly load requests and to move data. Even if in the last years a quite large research effort has been devoted to the energy efficiency of service centers and communication networks, limited work has been done for exploring the opportunities of integrated approaches able to exploit possible synergies between geographically distributed service centers and networks for accessing and interconnecting them. In this paper we propose an optimization framework able to jointly manage the use of brown and green energy in an integrated system and to guarantee quality requirements. We propose an efficient and accurate problem formulation that can be solved for real-size instances in few minutes to optimality. Numerical results, on a set of randomly generated instances and a case study representative of a large Cloud provider, show that the availability of green energy have a big impact on optimal energy management policies and that the contribution of the network is far from being negligible.}
}
@article{LIU20161,
title = {An energy-efficient task scheduling for mobile devices based on cloud assistant},
journal = {Future Generation Computer Systems},
volume = {61},
pages = {1-12},
year = {2016},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16300176},
author = {Tundong Liu and Fufeng Chen and Yingran Ma and Yi Xie},
keywords = {Energy efficiency, Task scheduling, Mobile cloud computing, Cloud assistant, Constrained shortest path problem},
abstract = {Mobile cloud computing is an emerging service model to extend the capability and the battery life of mobile devices. Mostly one network application can be decomposed into fine-grained tasks which consist of sequential tasks and parallel tasks. With the assistance of mobile cloud computing, some tasks could be offloaded to the cloud for speeding up executions and saving energy. However, the task offloading results in some additional cost during the communication between cloud and mobile devices. Therefore, this paper proposes an energy-efficient scheduling of tasks, in which the mobile device offloads appropriate tasks to the cloud via a Wi-Fi access point. The scheduling aims to minimize the energy consumption of mobile device for one application under the constraint of total completion time. This task scheduling problem is reconstructed into a constrained shortest path problem and the LARAC method is applied to get the approximate optimal solution. The proposed energy-efficient strategy decreases 81.93% of energy consumption and 25.70% of time at most, compared with the local strategy. Moreover, the applicability and performance of the proposed strategy are verified in different patterns of applications, where the time constraint, the workload ratio between communication and computation are various.}
}
@article{LIU2020932,
title = {Context-aware collect data with energy efficient in Cyber–physical cloud systems},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {932-947},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.05.029},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17310518},
author = {YuXin Liu and Anfeng Liu and Shuang Guo and Zhetao Li and Young-June Choi and Hiroo Sekiya},
keywords = {Wireless sensor networks, Context-aware sensing, Spatial–temporal correlation, Network lifetime},
abstract = {Cyber–Physical Cloud System is emerging as a promising system that enables a wide range of applications. In many applications, smart grids, sensing operations generate large amount of data. In order to effectively and efficiently collect large amount of data, a Global view of Context-aware Sensing and Collection (GCSC) scheme is proposed for exploiting both local and global of spatial–temporal correlations to perform data collection in cyber–physical cloud system (CPC system). In a GCSC scheme, the size of the representative region varies according to the residual energy of its smart sensor nodes. For areas far from the sink decrease the size of the representative region to keep high accuracy in the collected data, while areas near the Sink increase the size of the representative region to lower energy consumption to ensure efficient energy management. Thus, the accuracy of sensing data and lifetime can be enhanced at same time. Both theoretical analysis and experimental results indicate that the performance of GCSC scheme is better than the performance in previous studies. Compared with previous schemes, GCSC scheme can improve the data accuracy by 7.56%∼23.16% and increase the network lifetime by more than 11%, also increase energy efficiency as much as 12.39%.}
}
@article{KOMAR20161,
title = {Statistical cloud coverage as determined from sunshine duration: a model applicable in daylighting and solar energy forecasting},
journal = {Journal of Atmospheric and Solar-Terrestrial Physics},
volume = {150-151},
pages = {1-8},
year = {2016},
issn = {1364-6826},
doi = {https://doi.org/10.1016/j.jastp.2016.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364682616303352},
author = {Ladislav Kómar and Miroslav Kocifaj},
keywords = {Sunshine duration, Absolute cloud fraction, Illuminance prediction, Poisson distribution},
abstract = {A radiative/luminous energy budget is difficult to predict on a daily or hourly base if cloud coverage is obtained by subjective methods in discrete time points. A simple theoretical model that overcomes this shortcoming through interrelation of absolute cloud fraction and sunshine duration is presented. The latter is measured routinely at the meteorological stations worldwide. The model is based on statistical probability of clear line of sight, where Poisson spatial cloud distribution is analyzed for three different cloud shapes. A validation of the model using long-term measurements show a good correlation between experimentally determined and theoretically predicted data. The absolute cloud fraction obtained this way are a base for daylighting and solar energy applications including simulations of luminance/radiance sky distributions under different meteorological conditions. A simple calculation tool is developed and demonstrated on global horizontal illuminance (GHI).}
}
@article{ARIANYAN2015222,
title = {Novel energy and SLA efficient resource management heuristics for consolidation of virtual machines in cloud data centers},
journal = {Computers & Electrical Engineering},
volume = {47},
pages = {222-240},
year = {2015},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2015.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S004579061500155X},
author = {Ehsan Arianyan and Hassan Taheri and Saeed Sharifian},
keywords = {Cloud computing, Consolidation, Data center, Energy consumption, Resource allocation},
abstract = {Proliferation of IT services provided by cloud service delivery model as well as diverse range of cloud users have led to the establishment of huge energy hungry data centers all around the world. Therefore, cloud providers are confronted with great pressures to reduce their energy consumption as well as their CO2 emissions. In this direction, consolidation is proposed as an effective method of energy saving in cloud data centers. This paper proposes a new holistic cloud resource management procedure as well as novel heuristics based on multi-criteria decision making method for both determination of underloaded hosts and placement of the migrating VMs. The results of simulations using Cloudsim simulator validates the applicability of the proposed policies which shows up to 46%, 99%, and 95% reductions in energy consumption, SLA violation, and number of VM migrations, respectively in comparison with state of the arts.}
}
@article{CHAUDHARI2017145,
title = {Partial inerting of dust clouds using a modified standard minimum ignition energy device},
journal = {Journal of Loss Prevention in the Process Industries},
volume = {48},
pages = {145-150},
year = {2017},
issn = {0950-4230},
doi = {https://doi.org/10.1016/j.jlp.2017.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0950423017301122},
author = {Purvali Chaudhari and Chad V. Mashuga},
keywords = {Minimum ignition energy, Partial inerting, Dust explosion},
abstract = {Partial inerting is an important but underutilized mitigation technique in which minimum ignition energy (MIE) of a dust cloud is increased through inerting, reducing the risk of an accidental dust explosion or more accurately, a dust deflagration. This technique has wide application potential in numerous chemical and general manufacturing industries. The Kühner MIKE3 is the predominant apparatus for measurement of the minimum ignition energy (MIE) of combustible dusts worldwide. The current version of the MIKE3 device is not specifically designed to measure partial inerting minimum ignition energies. The purpose of this work is to demonstrate that a properly designed add on purge device and technique can accurately produce partial inerting MIE results with an existing MIE device. The purge device ensures complete purging of the Hartman dust dispersion tube with the desired gas concentration before experimentation. The same gas is then pulsed into the dispersion tube producing the dust dispersion for ignition testing. This approach leads to uniform testing conditions in the tube with respect to gas concentration which is essential for producing proper measurements. Additionally, experiments show the turbulence generated by the purging technique did not significantly affect the MIE measurements. Therefore, an important finding of this work is that purging the tube before partial inerting MIE testing results in a proper characterization of the relationship between the MIE and oxygen for the dust. The findings therefore demonstrate the need to amend existing or develop new standards for this type of dust testing. The effect of these modifications and techniques are demonstrated by the experimental determination of the partial inerting curve for Niacin (CaRo15) using the Kühner MIKE3 apparatus.}
}
@article{QUARATI2013121,
title = {Hybrid Clouds brokering: Business opportunities, QoS and energy-saving issues},
journal = {Simulation Modelling Practice and Theory},
volume = {39},
pages = {121-134},
year = {2013},
note = {S.I.Energy efficiency in grids and clouds},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2013.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X13000075},
author = {Alfonso Quarati and Andrea Clematis and Antonella Galizia and Daniele D’Agostino},
keywords = {Cloud computing, Energy aware cloud scheduling, QoS in cloud},
abstract = {Hybrid Clouds couple the scalability offered by public Clouds with the greater control supplied by private ones. A (hybrid) Cloud broker acting as an intermediary between users and providers of public Cloud services, may support customers in the selection of the most suitable offers, optionally adding the provisioning of dedicated services with higher levels of quality. The paper presents a Cloud brokering algorithm delivering services with different level of non-functional requirements, to the private or public resources, on the basis of different scheduling criteria. With the objective of maximize user satisfaction and broker’s revenues, the algorithm pursues profit increases by reducing energy costs, through the adoption of energy saving mechanisms. A simulation model is used to evaluate performance in terms of broker’s revenue, user satisfaction and energy behavior of various allocation policies. Simulation results show that differences among policies depend on system loads and that the use of turn on and off techniques greatly improves energy savings at low and medium load rates.}
}
@incollection{AKGUL201641,
title = {Chapter 3 - Software defined things: a green network management for future smart city architectures},
editor = {Mohammad S. Obaidat and Petros Nicopolitidis},
booktitle = {Smart Cities and Homes},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {41-57},
year = {2016},
isbn = {978-0-12-803454-5},
doi = {https://doi.org/10.1016/B978-0-12-803454-5.00003-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128034545000031},
author = {Ö.U. Akgül and B. Canberk},
keywords = {smart city, self-organized networks, software defined network, local indicator of spatial association, self-aware networks, self-controlled networks, energy-aware coverage optimization},
abstract = {The control framework in modern cities highly relies on human-centralized management that dependently brings the latency and failure in many critical real-time applications. The insufficiency of centralized human control mechanism over cities’ resource and function management framework led the evolution of the smart city concept that essentially counts on the communications between different networks. However, the deployment of electronic components that can carry both the decision-making mechanisms and the functional capacity to perform the necessary action is economically impossible to afford. This impossibility brings out an older approach of separating the decision-making and the application parts. The decision-making part can handle the data from different networks and make smart decisions according to the predefined constraints and trusted control resources. The derived decisions are sent over secure channels to the actuators that can perform physical tasks to change its surroundings. Even though the definition presents an illusion of simplicity, the design, implementation, and control of two separated yet correlated network structure are not trivial. The decentralized structure of data networks, for example, Internet of Thing (IoT) network and wireless sensor node (WSN), and ineffective scheduling algorithms result in a challenging durability problem for control frameworks. Self-Organized Network (SON) frameworks enable a self-aware system structure that can adjust network resources according to the user needs. In this chapter, as the main focus is the durability of the actuator network, we proposed a SON-based centralized control scheme. Through this chapter the observed actuator devices are cyber physical devices (CPDs) and the actuator network will be named as CPD network. With the objective of maintaining the highest coverage ratio with the minimum number of CPD devices, we used Local Indicator of Spatial Association (LISA) coefficient and Conflict Ratio for each CPD device. Using a probabilistic approach, the number of minimum active devices to fulfill the user expectations is determined. Using LISA coefficient and Conflict Ratio, the centralized controller determines a schedule for IoT devices. In this study, in order to maintain the connection with the generality, a layered CPD device network is considered where all CPD devices at the same layer are the same. Different CPD devices are considered to be in different layers and the controller can optimize each layer separately.}
}
@article{FANG201479,
title = {On the throughput-energy tradeoff for data transmission between cloud and mobile devices},
journal = {Information Sciences},
volume = {283},
pages = {79-93},
year = {2014},
note = {New Trend of Computational Intelligence in Human-Robot Interaction},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2014.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S0020025514006501},
author = {Weiwei Fang and Yangchun Li and Huijing Zhang and Naixue Xiong and Junyu Lai and Athanasios V. Vasilakos},
keywords = {Mobile cloud computing, Throughput-energy tradeoff, Lyapunov optimization, Dynamic scheduling, Queue stability},
abstract = {Mobile cloud computing has recently emerged as a new computing paradigm promising to improve the capabilities of resource-constrained mobile devices. As the data processing and storage are moved from mobile devices to powerful cloud platforms, data transmission has become an important issue affecting user experiences of mobile applications. One of the challenges is how to optimize the tradeoff between system throughput and energy consumption, which are potentially conflicting objectives. Inspired by the feasibility of transmission scheduling for prefetching-friendly or delay-tolerant applications, we mathematically formulate this problem as a stochastic optimization problem, and design an online control algorithm to balance such an energy-performance tradeoff based on the Lyapunov optimization framework. Our algorithm is able to independently and simultaneously make control decisions on admission and transmission to maximize a joint utility of the average application throughput and energy cost, without requiring any statistical information of traffic arrivals and link bandwidth. Rigorous analysis and extensive simulations have demonstrated both the system stability and the utility optimality achieved by our control algorithm.}
}
@article{MO2017257,
title = {Cloud-based query evaluation for energy-efficient mobile sensing},
journal = {Pervasive and Mobile Computing},
volume = {38},
pages = {257-274},
year = {2017},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2016.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S157411921630431X},
author = {Tianli Mo and Lipyeow Lim and Sougata Sen and Archan Misra and Rajesh Krishna Balan and Youngki Lee},
keywords = {Mobile sensing, Query evaluation, Energy-efficient},
abstract = {In this paper, we reduce the energy overheads of continuous mobile sensing, specifically for the case of context-aware applications that are interested in collective context or events, i.e., events expressed as a set of complex predicates over sensor data from multiple smartphones. We propose a cloud-based query management and optimization framework, called CloQue, that can support thousands of such concurrent queries, executing over a large number of individual smartphones. Our central insight is that the context of different individuals & groups often have significant correlation, and that this correlation can be learned through standard association rule mining on historical data. CloQue’s exploits such correlation to reduce energy overheads via two key innovations: (i) dynamically reordering the order of predicate processing to preferentially select predicates with not just lower sensing cost and higher selectivity, but that maximally reduce the uncertainty about other context predicates; and (ii) intelligently propagating the query evaluation results to dynamically update the confidence values of other correlated context predicates. We present techniques for probabilistic processing of context queries (to save significant energy at the cost of a query fidelity loss) and for query partitioning (to scale CloQue to a large number of users while meeting latency bounds). An evaluation, using real cellphone traces from two different datasets, shows significant energy savings (between 30% and 50% compared with traditional short-circuit systems) with little loss in accuracy (5% at most). In addition, we utilize parallel evaluation to reduce overall latency. The experiments show our approaches save up to 70% latency.}
}
@article{KULATUNGA2017106,
title = {Cooperative in-network computation in energy harvesting device clouds},
journal = {Sustainable Computing: Informatics and Systems},
volume = {16},
pages = {106-116},
year = {2017},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2017.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S2210537917302391},
author = {Chamil Kulatunga and Kriti Bhargava and Dixon Vimalajeewa and Stepan Ivanov},
keywords = {In-network analytics, Cooperative computing, Computation offloading, Energy harvesting, Low-latency applications, Fog computing},
abstract = {The Internet of Things paradigm is creating an environment where the big data originators will be located at the edge of the Internet. Accordingly, data analytic infrastructure is also being relocated to the network edges, to fulfill the philosophy of data gravity, under the umbrella of Fog computing. The extreme edge of the hierarchical infrastructure consists of sensor devices that constitute the wireless sensor networks. The role of these devices has evolved tremendously over the past few years owing to significant improvements in their design and computational capabilities. Sensor devices, today, are not only capable of performing sense and send tasks but also certain kinds of in-network processing. As such, triple optimization of sensing, computing and communication tasks is required to facilitate the implementation of data analytics on the sensor devices. A sensor node may optimally partition a computation task, for instance, and offload sub-tasks to cooperative neighbouring nodes for parallel execution to, in turn, optimize the network resources. This approach is crucial, especially, for energy harvesting sensor devices where the energy profile and, therefore, the computation capability of each device differs depending on the node location and time of day. Accordingly, future in-network computing must capture the energy harvesting information of sensor nodes to jointly optimize the computation and communication within the network. In this paper, we present a theoretical model for computation offloading in micro-solar powered energy harvesting sensor devices. Optimum data partitioning to minimize the total energy consumption has been discussed based on the energy harvesting status of sensor nodes for different scenarios. The simulation results show that our model reduced both energy losses and waste due to energy conversion and overflows respectively compared to a data partitioning algorithm that offloads computation tasks without taking the energy harvesting status of nodes into consideration. Our approach also improves energy balance of a WSN which is an important factor for its long-term autonomous operation.}
}
@article{FAHEEM2019103341,
title = {Energy efficient and reliable data gathering using internet of software-defined mobile sinks for WSNs-based smart grid applications},
journal = {Computer Standards & Interfaces},
volume = {66},
pages = {103341},
year = {2019},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2019.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0920548918303210},
author = {M. Faheem and R. Aslam Butt and Basit Raza and M. Waqar Ashraf and Md.A. Ngadi and V.C. Gungor},
keywords = {Internet of Things, Software-defined networking, Wireless sensor network, Smart grid, Smart cities},
abstract = {The smart grid is an emerging concept that introduces innovative ways to handle the power quality and reliability issues for both service provider and consumers. The key aims of the smart grid (SG) in smart cities (SCs) is to preserve a certain level of residents’ life quality and support the entire spectrum of their economic activities. In this paper, we present a novel Energy Efficient and Reliable Data Gathering Routing Protocol (ODGRP) for wireless sensor networks (WSNs)-based smart grid applications. The developed scheme employs a software-defined centralized controller and multiple mobile sinks for energy efficient and reliable data gathering from WSNs in the SG. The extensive simulation results conducted through the EstiNet 9.0 show that the designed scheme outperforms existing approaches and achieves its defined goals for event-driven applications in the SG.}
}
@article{TAO2014264,
title = {CLPS-GA: A case library and Pareto solution-based hybrid genetic algorithm for energy-aware cloud service scheduling},
journal = {Applied Soft Computing},
volume = {19},
pages = {264-279},
year = {2014},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2014.01.036},
url = {https://www.sciencedirect.com/science/article/pii/S1568494614000568},
author = {Fei Tao and Ying Feng and Lin Zhang and T.W. Liao},
keywords = {Cloud computing, Cloud service, Energy, Genetic algorithm, Pareto solutions, Case library},
abstract = {Since the appearance of cloud computing, computing capacity has been charged as a service through the network. The optimal scheduling of computing resources (OSCR) over the network is a core part for a cloud service center. With the coming of virtualization, the OSCR problem has become more complex than ever. Previous work, either on model building or scheduling algorithms, can no longer offer us a satisfactory resolution. In this paper, a more comprehensive and accurate model for OSCR is formulated. In this model, the cloud computing environment is considered to be highly heterogeneous with processors of uncertain loading information. Along with makespan, the energy consumption is considered as one of the optimization objectives from both economic and ecological perspectives. To provide more attentive services, the model seeks to find Pareto solutions for this bi-objective optimization problem. On the basis of classic multi-objective genetic algorithm, a case library and Pareto solution based hybrid Genetic Algorithm (CLPS-GA) is proposed to solve the model. The major components of CLPS-GA include a multi-parent crossover operator (MPCO), a two-stage algorithm structure, and a case library. Experimental results have verified the effectiveness of CLPS-GA in terms of convergence, stability, and solution diversity.}
}
@article{HOSSAIN201711,
title = {Cyber–physical cloud-oriented multi-sensory smart home framework for elderly people: An energy efficiency perspective},
journal = {Journal of Parallel and Distributed Computing},
volume = {103},
pages = {11-21},
year = {2017},
note = {Special Issue on Scalable Cyber-Physical Systems},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2016.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S074373151630123X},
author = {M. Shamim Hossain and Md. Abdur Rahman and Ghulam Muhammad},
keywords = {Gesture-based appliance control, Energy optimization, Cloud analytics for energy data, Multi-sensory data recognition},
abstract = {The emerging Cyber–Physical Systems (CPSs) provide a number of services ranging from smart homes to elderly care. With a CPS, a user’s (elderly person’s) interactions with smart home appliances are sensed, collected, and shared in physical spaces. This interaction is then delivered to cyberspaces for processing in order to monitor energy efficiency. In this paper, we propose an energy-efficient cyber–physical smart home system for monitoring the elderly that uses the potential of cloud computing and big data technologies. Given that an elderly person may need assistance with the complex activities of maintaining energy efficiency, a smart multimedia-enabled middleware assistant is proposed that enables him/her to observe different energy-efficient processes, control smart home appliances through gestures, receive notifications regarding appliance statuses, and share multimedia messages with a community of interest. For data processing, robust and low-dimensional discriminative features are extracted in a server from the data available via sensors and multimedia. Events are also automatically classified in the server to assist caregiver decision-making. To save energy, an automatic switch on/off control system using speech or gesture is developed. Keywords are detected from the speech and used as control commands. Experimental results show the encouraging potential of deploying this framework at a large scale.}
}
@article{RANJBARI201855,
title = {A learning automata-based algorithm for energy and SLA efficient consolidation of virtual machines in cloud data centers},
journal = {Journal of Parallel and Distributed Computing},
volume = {113},
pages = {55-62},
year = {2018},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S074373151730285X},
author = {Milad Ranjbari and Javad {Akbari Torkestani}},
keywords = {Cloud computing, Resource management, Energy consumption, Service level agreement, Virtual machine migration},
abstract = {Resource management in cloud computing consists of allocating processing resources, storage, and network to a set of software applications. Resource providers focus on performance and utilization of resources considering the constraints of service level agreement. Resource performance is achieved by virtualization techniques, which share infrastructure of the resource provider between different virtual machines. This study proposes a novel algorithm based on learning automata, which improves resource utilization and reduces energy consumption. The proposed algorithm considers changes in the user demanded resources to predict the PM, which may suffer from overload. Due to preventing server overload, the proposed algorithm improves PMs’ utilization, reduces the number of migrations, and shuts down idle servers to reduce the energy consumption of the data center. The proposed algorithm is simulated in CloudSim simulator; the 10-day processor information of a real PlanetLab cloud infrastructure system are used for workload data. Performance of the proposed algorithm is compared with existing algorithms such as DVFS, NPA, and the threshold algorithm in terms of energy consumption and the number of shut down PMs. Simulation results indicate that the proposed algorithm outperforms other algorithms with 175.48 Kwh, 0.00326 in energy consumption, SLA violation respectively.}
}
@article{CANTARA20161,
title = {The energy-momentum tensor and D-term of Q-clouds},
journal = {Nuclear Physics A},
volume = {953},
pages = {1-20},
year = {2016},
issn = {0375-9474},
doi = {https://doi.org/10.1016/j.nuclphysa.2016.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0375947416300835},
author = {Michael Cantara and Manuel Mai and Peter Schweitzer},
keywords = {Energy momentum tensor, -ball, Soliton, Stability, -term},
abstract = {The D-term is, like mass and spin, a fundamental property related to the energy-momentum tensor. Yet it is not known experimentally for any particle. In all theoretical studies so far the D-terms of various particles were found negative. Early works gave rise to the assumption the negative sign could be related to stability. The emerging question is whether it is possible to find a field-theoretical system with a positive D-term. To shed some light on this question we investigate Q-clouds, an extreme parametric limit in the Q-ball system. Q-clouds are classically unstable solutions which delocalize, spread out over all space forming an infinitely dilute gas of free quanta, and are even energetically unstable against tunneling to plane waves. In short, these extremely unstable field configurations provide an ideal candidate system for our purposes. By studying the energy-momentum tensor we show that at any stage of the Q-cloud limit one deals with perfectly well-defined and, when viewed in appropriately scaled coordinates, non-dissipating non-topological solitonic solutions. We investigate in detail their properties, and find new physical interpretations by observing that Q-clouds resemble BPS Skyrmions in certain aspects, and correspond to universal non-perturbative solutions in (complex) |Φ|4 theory. In particular, we show that also Q-cloud solutions have negative D-terms. Our findings do not prove that D-terms must always be negative. But they indicate that it is unlikely to realize a positive D-term in a consistent physical system.}
}
@article{LIU2017226,
title = {Cloud energy storage for residential and small commercial consumers: A business case study},
journal = {Applied Energy},
volume = {188},
pages = {226-236},
year = {2017},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2016.11.120},
url = {https://www.sciencedirect.com/science/article/pii/S0306261916317512},
author = {Jingkun Liu and Ning Zhang and Chongqing Kang and Daniel Kirschen and Qing Xia},
keywords = {Energy storage, Energy internet, Cloud, Business model, Distributed energy storage, Sharing economy, Economies of scale},
abstract = {Energy storage is extensively recognized as a significant potential resource for balancing generation and load in future power systems. Although small residential and commercial consumers of electrical energy can now purchase energy storage systems, many factors, such as cost, policy and control efficiency, limit the spread of distributed energy storage (DES). This paper proposes a new type of DES—cloud energy storage (CES)—that is capable of providing energy storage services at a substantially lower cost. This grid-based storage service enables ubiquitous and on-demand access to a shared pool of grid-scale energy storage resources. It provides users the ability to store and withdraw electrical energy to and from centralized batteries. This paper describes the concept of CES and the control and communication technologies that are required for its implementation and its operating mechanism, as well as its business model. Simulation results that are based on actual power system operating data demonstrate the feasibility and economic benefit of CES.}
}
@article{ZHAO201614,
title = {A new energy-aware task scheduling method for data-intensive applications in the cloud},
journal = {Journal of Network and Computer Applications},
volume = {59},
pages = {14-27},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2015.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1084804515000909},
author = {Qing Zhao and Congcong Xiong and Ce Yu and Chuanlei Zhang and Xi Zhao},
keywords = {Energy aware scheduling, Data-intensive application, SLA violation rate, Data correlation},
abstract = {Maximizing energy efficiency while ensuring the user׳s Service-Level Agreement (SLA) is very important for the purpose of environmental protection and profit maximization for the cloud service providers. In this paper, an energy and deadline aware task scheduling method for data-intensive applications is proposed. In this method, first, the datasets and tasks are modeled as a binary tree by a data correlation clustering algorithm, in which both the data correlations generated from the initial datasets and that from the intermediate datasets have been considered. Hence, the amount of global data transmission can be reduced greatly, which are beneficial to the reduction of SLA violation rate. Second, a “Tree-to-Tree” task scheduling approach based on the calculation of Task Requirement Degree (TRD) is proposed, which can improve energy efficiency of the whole cloud system by reducing the number of active machines, decreasing the global time consumption on data transmission, and optimizing the utilization of its computing resources and network bandwidth. Experiment results show that the power consumption of the cloud system can be reduced efficiently while maintaining a low-level SLA violation rate.}
}
@article{KANEKO2018S775,
title = {Diagnostic accuracy of indocyanine green fluorescence imaging and multidetector row computed tomography for identifying hepatocellular carcinoma with liver explant correlation},
journal = {HPB},
volume = {20},
pages = {S775-S776},
year = {2018},
note = {Abstract of the 13th World Congress of the International Hepato-Pancreato-Biliary Association, 4-7 September 2018, Geneva, Switzerland},
issn = {1365-182X},
doi = {https://doi.org/10.1016/j.hpb.2018.06.2510},
url = {https://www.sciencedirect.com/science/article/pii/S1365182X18338905},
author = {J. Kaneko and M. Kouichi and J. Arita and N. Akamatsu and Y. Sakamoto and N. Kokudo and K. Hasegawa}
}
@article{KITAGAWA201587,
title = {Electron Identification and Energy Measurement with Emulsion Cloud Chamber},
journal = {Physics Procedia},
volume = {80},
pages = {87-89},
year = {2015},
note = {26th International Conference on Nuclear Tracks in Solids (ICNTS26) Kobe, Japan 15th – 19th September 2014},
issn = {1875-3892},
doi = {https://doi.org/10.1016/j.phpro.2015.11.099},
url = {https://www.sciencedirect.com/science/article/pii/S1875389215016168},
author = {Nobuko Kitagawa and Masahiro Komatsu},
keywords = {energy measurement, radiation ;},
abstract = {Charged particles undergo the Multiple Coulomb Scattering (MCS) when passing through a material. Their momentum can be estimated from the distribution of the scattering angle directly. Angle of electrons (or positrons) largely changes because of the energy loss in bremsstrahlung, and they are distinguished from other charged particles by making use of its feature. Electron energy is generally measured by counting of electromagnetic shower (e.m. shower) tracks in Emulsion Cloud Chamber (ECC), so enough absorber material is needed to develop the shower. In the range from sub-GeV to a few GeV, electrons don’t develop noticeable showers. In order to estimate the energy of electrons in this range with a limited material, we established the new method which is based on the scattering angle considering the energy loss in bremsstrahlung. From the Monte Carlo simulation (MC) data, which is generated by electron beam (0.5GeV, 1GeV, 2GeV) exposure to ECC, we derived the correlation between energy and scattering angle in each emulsion layer. We fixed the function and some parameters which 1GeV MC sample would return 1GeV as the center value, and then applied to 0.5GeV and 2GeV sample and confirmed the energy resolution about 50% within two radiation length.}
}
@article{ISMAIL2018248,
title = {EATSVM: Energy-Aware Task Scheduling on Cloud Virtual Machines},
journal = {Procedia Computer Science},
volume = {135},
pages = {248-258},
year = {2018},
note = {The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.08.172},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918314613},
author = {Leila Ismail and Huned Materwala},
keywords = {Cloud Computing, Virtual Machines, Energy-Aware Task Scheduling, Energy Optimization},
abstract = {The pervasive adoption of cloud computing services and applications at a rapid rate makes the underlying data centers exacerbate the problems like carbon footprint and the operational cost, caused by the energy consumption. Various hardware-centric and software-centric approaches are proposed in the literature to reduce the energy consumption of the cloud data centers. Task scheduling algorithms are software-centric approaches to reduce the energy consumption in cloud computing systems. The majority of these algorithms focus on server consolidation leading to idle servers that reduce energy efficiency optimization. In this paper, we propose an Energy-Aware Task Scheduling algorithm on cloud Virtual Machines (EATSVM) that assigns a task to the VM where the increase in energy consumption is the least, considering both active and idle VMs. The algorithm also takes into consideration the increase in the energy consumption of the already running tasks on the VM due to increase in their execution time, while assigning a new task to that VM. We analyze the performance of our algorithm in a heterogeneous cloud environment with increasing number of tasks and compare the energy-savings of our algorithm with that of Energy Conscious Task Consolidation (ECTC) algorithm. Our experimental results demonstrate that EATSVM achieves energy-saving in a heterogeneous cloud-computing environment.}
}
@article{HOSSAIN2020800,
title = {Towards energy-aware cloud-oriented cyber-physical therapy system},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {800-813},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.08.045},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1731885X},
author = {M. Shamim Hossain and Md. Abdur Rahman and Ghulam Muhammad},
keywords = {Cyber-physical therapy system, Big data, Health sensors, Motion tracking devices, Therapeutic kinematic data, Energy efficiency},
abstract = {The Cyber-Physical System (CPS) is an emerging computing technology that involves in sensing, computing, controlling and communication between physical components (e.g., smart sensors, devices, systems and human beings) and cyber components (e.g., cloud and big data centers). The sensing, controlling and interaction have significant promises towards the realization of the current and future therapy system, where cloud resources and data centers are expected to process complex therapeutic heterogeneous big data. Although, the CPS has a great potential for such a sensing and controlling of therapy, however, energy efficiency is crucial for such a therapy system for its sustainability, especially for elderly people who cannot physically optimize energy consumptions. To this end, this article proposes an energy-aware cyber-physical therapy system (T-CPS), which incorporates smart things and devices in both the physical and cyber world for therapy sensing. To provide energy-efficient affordable therapeutic services, the T-CPS framework uses multi-modal sensing for the provision of therapy sensing, therapy playback, annotation, visualization, and energy efficiency. The framework was evaluated by real subjects along with several therapists. Test results show the usefulness of the proposed T-CPS framework.}
}
@article{SIGWELE20171,
title = {Energy-efficient cloud radio access networks by cloud based workload consolidation for 5G},
journal = {Journal of Network and Computer Applications},
volume = {78},
pages = {1-8},
year = {2017},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516302740},
author = {Tshiamo Sigwele and Atm S. Alam and Prashant Pillai and Yim F. Hu},
keywords = {Cloud computing, C-RAN, Energy efficiency, Workload consolidation, Virtualization, 5G},
abstract = {Next-generation cellular systems like fifth generation (5G) are expected to experience tremendous traffic growth. To accommodate such traffic demand, there is a need to increase the network capacity that eventually requires the deployment of more base stations (BSs). Nevertheless, BSs are very expensive and consume a lot of energy. With growing complexity of signal processing, baseband units are now consuming a significant amount of energy. As a result, cloud radio access networks (C-RAN) have been proposed as an energy efficient (EE) architecture that leverages cloud computing technology where baseband processing is performed in the cloud. This paper proposes an energy reduction technique based on baseband workload consolidation using virtualized general purpose processors (GPPs) in the cloud. The rationale for the cloud based workload consolidation model is to switch off idle baseband units (BBUs) to reduce the overall network energy consumption. The power consumption model for C-RAN is also formulated with considering radio side, fronthaul and BS cloud power consumption. Simulation results demonstrate that the proposed scheme achieves an enhanced energy performance compared to the existing distributed long term evolution (LTE) RAN system. The proposed scheme saves up to 80% of energy during low traffic periods and 12% during peak traffic periods compared to baseline LTE system. Moreover, the proposed scheme saves 38% of energy compared to the baseline system on a daily average.}
}
@article{ARIANYAN201743,
title = {Novel fuzzy multi objective DVFS-aware consolidation heuristics for energy and SLA efficient resource management in cloud data centers},
journal = {Journal of Network and Computer Applications},
volume = {78},
pages = {43-61},
year = {2017},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516300169},
author = {Ehsan Arianyan and Hassan Taheri and Vahid Khoshdel},
keywords = {Cloud computing, Data center, Energy consumption, Resource allocation},
abstract = {Cloud computing is an attractive solution for managing IT infrastructures due to its numerous beneficiaries such as automatic optimum resource management as well as modern service delivery models. Cloud computing relies on huge energy hungry data centers to supply resources for diverse range of users with dynamic workloads. Hence, reducing the ever-increasing energy consumption of Cloud data centers as well as their carbon footprints is a crucial issue for Cloud providers. This paper takes advantage of dynamic voltage and frequency scaling method as well as consolidation approach to propose a novel fuzzy multi criteria and objective resource management solution. The extensive evaluation of proposed algorithms using Cloudsim simulator shows notable reductions in energy consumption, SLA violation, and number of migrations in comparison with state of the art.}
}
@incollection{HERATH2019453,
title = {Appendix - Smart Community and City Environmental Responsibility (C2ER) With Green Computing},
editor = {Woodrow W. Clark},
booktitle = {Climate Preservation in Urban Communities Case Studies},
publisher = {Butterworth-Heinemann},
pages = {453-473},
year = {2019},
isbn = {978-0-12-815920-0},
doi = {https://doi.org/10.1016/B978-0-12-815920-0.15001-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128159200150014},
author = {Hemantha S.B. Herath and Tejaswini C. Herath and Athula Ekanayake}
}
@article{HAFFNER201536,
title = {Systematic search for molecular clouds near supernova remnants as sources of very-high-energy γ-ray emission},
journal = {Astroparticle Physics},
volume = {71},
pages = {36-44},
year = {2015},
issn = {0927-6505},
doi = {https://doi.org/10.1016/j.astropartphys.2015.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0927650515000845},
author = {Stephanie Häffner and Christian Stegmann and Ira Jung-Richardt},
keywords = {VHE -ray astronomy, Supernova remnants, Molecular clouds, Cosmic rays, Galactic Ring Survey, H.E.S.S. Galactic Plane Survey},
abstract = {Supernova remnants accelerate particles up to energies of at least 100 TeV as established by observations in very-high-energy γ-ray astronomy. Molecular clouds in their vicinity provide an increased amount of target material for proton-proton interaction and subsequent neutral pion decay into γ-rays of accelerated hadrons escaping the remnant. Therefore, these molecular clouds are potential γ-ray sources. The γ-ray emission from these clouds provides a unique environment to derive information on the propagation of very-high-energy particles through the interstellar medium as well as on the acceleration of hadrons in supernova remnants. Current Imaging Atmospheric Cherenkov Telescope systems are suitable to explore a large parameter space of the propagation properties depending on the age of the supernova remnant and the distance between the remnant and the nearby molecular cloud. In this paper we present our strategy and results of a systematic search for γ-ray emitting molecular clouds near supernova remnants which are potentially detectable with current experiments in the TeV energy range and explore the prospects of future experiments.}
}
@article{HU201498,
title = {An adaptive surface filter for airborne laser scanning point clouds by means of regularization and bending energy},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {92},
pages = {98-111},
year = {2014},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2014.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0924271614000525},
author = {Han Hu and Yulin Ding and Qing Zhu and Bo Wu and Hui Lin and Zhiqiang Du and Yeting Zhang and Yunsheng Zhang},
keywords = {Airborne laser scanning, Point clouds, Filtering, Bending energy, Thin plate spline, DEM},
abstract = {The filtering of point clouds is a ubiquitous task in the processing of airborne laser scanning (ALS) data; however, such filtering processes are difficult because of the complex configuration of the terrain features. The classical filtering algorithms rely on the cautious tuning of parameters to handle various landforms. To address the challenge posed by the bundling of different terrain features into a single dataset and to surmount the sensitivity of the parameters, in this study, we propose an adaptive surface filter (ASF) for the classification of ALS point clouds. Based on the principle that the threshold should vary in accordance to the terrain smoothness, the ASF embeds bending energy, which quantitatively depicts the local terrain structure to self-adapt the filter threshold automatically. The ASF employs a step factor to control the data pyramid scheme in which the processing window sizes are reduced progressively, and the ASF gradually interpolates thin plate spline surfaces toward the ground with regularization to handle noise. Using the progressive densification strategy, regularization and self-adaption, both performance improvement and resilience to parameter tuning are achieved. When tested against the benchmark datasets provided by ISPRS, the ASF performs the best in comparison with all other filtering methods, yielding an average total error of 2.85% when optimized and 3.67% when using the same parameter set.}
}
@article{FERNANDEZCERERO2018160,
title = {SCORE: Simulator for cloud optimization of resources and energy consumption},
journal = {Simulation Modelling Practice and Theory},
volume = {82},
pages = {160-173},
year = {2018},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2018.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X18300030},
author = {Damián Fernández-Cerero and Alejandro Fernández-Montes and Agnieszka Jakóbik and Joanna Kołodziej and Miguel Toro},
keywords = {Data center, Energy saving, Cloud computing, Energy-aware scheduling},
abstract = {Achieving efficiency both in terms of resource utilisation and energy consumption is a complex challenge, especially in large-scale wide-purpose data centers that serve cloud-computing services. Simulation presents an appropriate solution for the development and testing of strategies that aim to improve efficiency problems before their applications in production environments. Various cloud simulators have been proposed to cover different aspects of the operation environment of cloud-computing systems. In this paper, we define the SCORE tool, which is dedicated to the simulation of energy-efficient monolithic and parallel-scheduling models and for the execution of heterogeneous, realistic and synthetic workloads. The simulator has been evaluated through empirical tests. The results of the experiments confirm that SCORE is a performant and reliable tool for testing energy-efficiency, security, and scheduling strategies in cloud-computing environments.}
}
@article{KATSAROS20132077,
title = {A service framework for energy-aware monitoring and VM management in Clouds},
journal = {Future Generation Computer Systems},
volume = {29},
number = {8},
pages = {2077-2091},
year = {2013},
note = {Including Special sections: Advanced Cloud Monitoring Systems & The fourth IEEE International Conference on e-Science 2011 — e-Science Applications and Tools & Cluster, Grid, and Cloud Computing},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2012.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X12002269},
author = {Gregory Katsaros and Josep Subirats and J. Oriol Fitó and Jordi Guitart and Pierre Gilet and Daniel Espling},
keywords = {Monitoring, Cloud, Energy efficiency, Energy consumption},
abstract = {The monitoring of QoS parameters in Services Computing as well as in Clouds has been a functionality provided by all contemporary systems. As the optimization of energy consumption becomes a major concern for system designers and administrators, it can be considered as another QoS metric to be monitored. In this paper, we present a service framework that allows us to monitor the energy consumption of a Cloud infrastructure, calculate its energy efficiency, and evaluate the gathered data in order to put in place an effective virtual machine (VM) management. In that context, a simulation scenario of an eco-driven VM placement policy resulted in a 14% improvement of the infrastructure’s energy efficiency. In total, the proposed approaches and implementations have been validated against a testbed, producing very promising results regarding the prospect of energy efficiency as an important quality factor in Clouds.}
}