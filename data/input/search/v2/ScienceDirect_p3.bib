@article{GHAPANCHI201540,
title = {Predicting software future sustainability: A longitudinal perspective},
journal = {Information Systems},
volume = {49},
pages = {40-51},
year = {2015},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2014.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0306437914001562},
author = {Amir Hossein Ghapanchi},
keywords = {Software adoption, Development sustainability, Dynamic capabilities, OSS},
abstract = {Whereas today׳s organisations have embraced Open Source Software (OSS) applications because of the significant values that these products have to offer, the majority of OSS projects have difficulties sustaining their development activities, and hence experience failure. Even though many researchers have worked on uncovering the influence of the determinants of OSS projects׳ sustainability, there is a lack of research that investigates the longitudinal impact of a project׳s capabilities on its sustainability. Collecting data from 1409 OSS projects in a longitudinal fashion (over a period of 16 months), this paper develops and tests a research model that examines the influences of a project׳s capabilities on its development sustainability. The results demonstrated a temporal persistence in the relationship between sustainability and the speed of defect-removal and functionality-enhancement, whereas the effect that the defect-removal rate and functionality-enhancement rate have on development sustainability was discovered to significantly decrease as the project grows old. These findings have implications for both the OSS research community and OSS practitioners; these are derived and stated.}
}
@article{CHEN201520,
title = {Towards energy-efficient scheduling for real-time tasks under uncertain cloud computing environment},
journal = {Journal of Systems and Software},
volume = {99},
pages = {20-35},
year = {2015},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.08.065},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214001903},
author = {Huangke Chen and Xiaomin Zhu and Hui Guo and Jianghan Zhu and Xiao Qin and Jianhong Wu},
keywords = {Green cloud computing, Uncertain scheduling, Proactive and reactive},
abstract = {Green cloud computing has become a major concern in both industry and academia, and efficient scheduling approaches show promising ways to reduce the energy consumption of cloud computing platforms while guaranteeing QoS requirements of tasks. Existing scheduling approaches are inadequate for real-time tasks running in uncertain cloud environments, because those approaches assume that cloud computing environments are deterministic and pre-computed schedule decisions will be statically followed during schedule execution. In this paper, we address this issue. We introduce an interval number theory to describe the uncertainty of the computing environment and a scheduling architecture to mitigate the impact of uncertainty on the task scheduling quality for a cloud data center. Based on this architecture, we present a novel scheduling algorithm (PRS11Proactive and Reactive Scheduling.) that dynamically exploits proactive and reactive scheduling methods, for scheduling real-time, aperiodic, independent tasks. To improve energy efficiency, we propose three strategies to scale up and down the system's computing resources according to workload to improve resource utilization and to reduce energy consumption for the cloud data center. We conduct extensive experiments to compare PRS with four typical baseline scheduling algorithms. The experimental results show that PRS performs better than those algorithms, and can effectively improve the performance of a cloud data center.}
}
@article{SAMPAIO201430,
title = {Towards high-available and energy-efficient virtual computing environments in the cloud},
journal = {Future Generation Computer Systems},
volume = {40},
pages = {30-43},
year = {2014},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2014.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X14001307},
author = {Altino M. Sampaio and Jorge G. Barbosa},
keywords = {Scheduling, Energy-efficiency, Consolidation, Proactive fault-tolerance, Platform elasticity},
abstract = {Empowered by virtualisation technology, cloud infrastructures enable the construction of flexible and elastic computing environments, providing an opportunity for energy and resource cost optimisation while enhancing system availability and achieving high performance. A crucial requirement for effective consolidation is the ability to efficiently utilise system resources for high-availability computing and energy-efficiency optimisation to reduce operational costs and carbon footprints in the environment. Additionally, failures in highly networked computing systems can negatively impact system performance substantially, prohibiting the system from achieving its initial objectives. In this paper, we propose algorithms to dynamically construct and readjust virtual clusters to enable the execution of users’ jobs. Allied with an energy optimising mechanism to detect and mitigate energy inefficiencies, our decision-making algorithms leverage virtualisation tools to provide proactive fault-tolerance and energy-efficiency to virtual clusters. We conducted simulations by injecting random synthetic jobs and jobs using the latest version of the Google cloud tracelogs. The results indicate that our strategy improves the work per Joule ratio by approximately 12.9% and the working efficiency by almost 15.9% compared with other state-of-the-art algorithms.}
}
@article{RAJEEV2015141,
title = {Dynamic load-shifting program based on a cloud computing framework to support the integration of renewable energy sources},
journal = {Applied Energy},
volume = {146},
pages = {141-149},
year = {2015},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2015.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S0306261915001877},
author = {T. Rajeev and S. Ashok},
keywords = {Intermittent resources, Dynamic renewable factor, Solar rooftop PV, Cloud computing},
abstract = {Demand-side management programs such as load shifting utilise the flexibility in the load consumption pattern of consumers to enable the effective capacity utilisation of renewable energy sources. The locational and temporal characteristics of renewable energy sources cause forecasting and operational challenges in the implementation of such a renewable energy program. In this paper, a dynamic load-shifting program using real-time data in a cloud computing framework is proposed to address the aforementioned issues. A new dynamic renewable factor is proposed to facilitate on-time incentive based load shifting program. The effectiveness of the dynamic load-shifting program was evaluated using simulated case studies. The case study indicates that PV energy utilisation at the consumer side is increased by 18% by the application of the proposed load-shifting program. The study result in Kerala, India, consisting of more than 7.5 million domestic consumers, indicates that demand reduction of 250–300MW at times of peak demand can be achieved by using load shifting in the domestic sector.}
}
@article{MA2012577,
title = {Energy Efficiency on Location Based Applications in Mobile Cloud Computing: A Survey},
journal = {Procedia Computer Science},
volume = {10},
pages = {577-584},
year = {2012},
note = {ANT 2012 and MobiWIS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.06.074},
url = {https://www.sciencedirect.com/science/article/pii/S1877050912004310},
author = {Xiao Ma and Yong Cui and Ivan Stojmenovic},
keywords = {Mobile, Cloud computing, Location based service, Energy-efficiency},
abstract = {With the emergence of mobile cloud computing (MCC), an increasingly number of applications and services becomes available on mobile devices. In the meantime, the constrained battery power of mobile devices makes a serious impact on user experience. As one increasingly prevalent type of applications in mobile cloud environments, location based applications (LBAs) present some inherent limitations surrounding energy. For example, the GPS (Global Positioning System) based positioning mechanism is well-known to be extremely power-hungry. Due to the severity of the issue, considerable researches have been devoted to energy-efficient locating sensing mechanism in the last few years. These efforts toward enhancing energy efficiency have allowed us to provide a comprehensive survey of recent work on low-power design of LBAs.}
}
@article{CALERO2017117,
title = {Puzzling out Software Sustainability},
journal = {Sustainable Computing: Informatics and Systems},
volume = {16},
pages = {117-124},
year = {2017},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2017.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S2210537916301676},
author = {Coral Calero and Mario Piattini},
keywords = {Software sustainability, Software greenability, SWEBOK, Green in software engineering},
abstract = {Software Sustainability is gaining importance and, as occurs with any other new discipline, there are still many misconceptions and misunderstandings surrounding it. In this paper we attempt to clarify the different aspects of software sustainability, from organizational sustainability to software sustainability, exploring the latter in great depth by considering its three dimensions. We also present an overview of the research that has been developed around software sustainability, which was obtained after reviewing the best known workshops and conferences on green and sustainable software and some journals. The results obtained principally address the environmental dimension, and specifically green software design, quality and requirements.}
}
@article{TEREFE201675,
title = {Energy-efficient multisite offloading policy using Markov decision process for mobile cloud computing},
journal = {Pervasive and Mobile Computing},
volume = {27},
pages = {75-89},
year = {2016},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2015.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S1574119215001923},
author = {Mati B. Terefe and Heezin Lee and Nojung Heo and Geoffrey C. Fox and Sangyoon Oh},
keywords = {Multisite, Offloading, MDP, Mobile cloud},
abstract = {Mobile systems, such as smartphones, are becoming the primary platform of choice for a user’s computational needs. However, mobile devices still suffer from limited resources such as battery life and processor performance. To address these limitations, a popular approach used in mobile cloud computing is computation offloading, where resource-intensive mobile components are offloaded to more resourceful cloud servers. Prior studies in this area have focused on a form of offloading where only a single server is considered as the offloading site. Because there is now an environment where mobile devices can access multiple cloud providers, it is possible for mobiles to save more energy by offloading energy-intensive components to multiple cloud servers. The method proposed in this paper differentiates the data- and computation-intensive components of an application and performs a multisite offloading in a data and process-centric manner. In this paper, we present a novel model to describe the energy consumption of a multisite application execution and use a discrete time Markov chain (DTMC) to model fading wireless mobile channels. We adopt a Markov decision process (MDP) framework to formulate the multisite partitioning problem as a delay-constrained, least-cost shortest path problem on a state transition graph. Our proposed Energy-efficient Multisite Offloading Policy (EMOP) algorithm, built on a value iteration algorithm (VIA), finds the efficient solution to the multisite partitioning problem. Numerical simulations show that our algorithm considers the different capabilities of sites to distribute appropriate components such that there is a lower energy cost for data transfer from the mobile to the cloud. A multisite offloading execution using our proposed EMOP algorithm achieved a greater reduction on the energy consumption of mobiles when compared to a single site offloading execution.}
}
@article{BUI2017103,
title = {Energy efficiency for cloud computing system based on predictive optimization},
journal = {Journal of Parallel and Distributed Computing},
volume = {102},
pages = {103-114},
year = {2017},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2016.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S0743731516301708},
author = {Dinh-Mao Bui and YongIk Yoon and Eui-Nam Huh and SungIk Jun and Sungyoung Lee},
keywords = {Energy efficiency, IaaS cloud computing, Predictive analysis, Convex optimization, Gaussian process},
abstract = {In recent years, power consumption has become one of the hottest research trends in computer science and industry. Most of the reasons are related to the operational budget and the environmental issues. In this paper, we would like to propose an energy-efficient solution for orchestrating the resource in cloud computing. In nature, the proposed approach firstly predicts the resource utilization of the upcoming period based on the Gaussian process regression method. Subsequently, the convex optimization technique is engaged to compute an appropriate quantity of physical servers for each monitoring window. This quantity of interest is calculated to ensure that a minimum number of servers can still provide an acceptable quality of service. Finally, a corresponding migrating instruction is issued to stack the virtual machines and turn off the idle physical servers to achieve the objective of energy savings. In order to evaluate the proposed method, we conduct the experiments using synthetic data from 29-day period of Google traces and real workload from the Montage open-source toolkit. Through the evaluation, we show that the proposed approach can achieve a significant result in reducing the energy consumption as well as maintaining the system performance.}
}
@article{CHANTEM2019152,
title = {Sustainable embedded software and systems},
journal = {Sustainable Computing: Informatics and Systems},
volume = {22},
pages = {152-154},
year = {2019},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2019.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S2210537919301830},
author = {Thidapat Chantem and Nan Guan and Duo Liu},
abstract = {Research on sustainable embedded software and systems has gained immense interest from academia and industry alike, as embedded systems have become pervasive and interconnected. A focus has been placed on (i) energy-efficient and sustainable architectures, software, systems, design methodologies, and tools, and (ii) emerging applications and frameworks for Internet of Things, Cyber-Physical Systems, and Smart Cities. In this issue, reducing energy consumption is a recurrent theme, with a focus on processor cores, storage systems, and interconnected bus. Effective thermal management and resilience to soft errors as well as attacks are also key considerations. Finally, since embedded systems often interact with human users, user experience must be optimized.}
}
@article{FARAHAT2023121108,
title = {CAD system for intelligent grading of COVID-19 severity with green computing and low carbon footprint analysis},
journal = {Expert Systems with Applications},
volume = {234},
pages = {121108},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.121108},
url = {https://www.sciencedirect.com/science/article/pii/S095741742301610X},
author = {Ibrahim Shawky Farahat and Waleed Aladrousy and Mohamed Elhoseny and Ahmed Elsaid Tolba and Samir Elmougy},
keywords = {CAD, Neural network, GLCM, HOG, COVID-19, DWT, PCA, SURF},
abstract = {The Coronavirus Disease (COVID-19) caused a lot of mortality. The high mortality rate occurred because of the physicians’ wrong or late identification of COVID-19 severity. So, developing Computer-Aided Design (CAD) systems using Artificial Intelligence (AI) techniques is critical to help physicians correctly identify the severity of COVID-19 in the early stages of the pandemic and then decrease the COVID-19 mortality percentage. In this paper, we develop a new green CAD system using a new hybrid handcrafted feature extraction algorithm and two-stage neural network architecture to grade the COVID-19 patient based on Computed Tomography (CT) scan images as having a moderate, severe, or critical infection. Because the proposed system uses handcrafted feature extraction algorithms, it consumes minimum resources and time than recent works. The proposed system consists of three phases: lesion segmentation, feature extraction, and diagnosis. Firstly, lesions from the CT scan image are manually segmented, and then three schemes are applied to extract salient features from the segmented lesions. These schemes are the Histogram of Oriented Gradients (HOG), Speeded Up Robust Features (SURF), and a new hybrid method that consists of cascading Discrete Wavelet Transform (DWT) and Gray-Level Co-Occurrence Matrix (GLCM). Then, the Cumulative Distribution Function (CDF) is computed for each scheme to extract the statistical markers. In the grading phase, a two-stage neural network approach is used. First, the extracted features are individually trained and tested for each scheme in the first neural network stage, and then the results of the first stage are combined to train and test each patient in the second neural network stage. The performance of the proposed system was assessed on a CT image dataset of 300 COVID-19-positive patients collected from the Cancer Imaging Archive (TCIA) website. The experimental results showed that our proposed system achieved 100% accuracy and kappa when the dataset was partitioned into 80% for training and 20% for testing. Also, it achieved 95.67% ± 0.47, 99.33% ± 0.77, and 100% ± 0 accuracies and 93.48% ± 0.74, 98.997% ± 1.16, and 100% ± 0 kappa values when the data was organized using 2, 4, and 10 folds, respectively. A green complexity algorithm analysis shows that this proposed system takes O(n) time complexity and 1 h and 20 min to train and test all cases. The performed green complexity analysis shows that the proposed system consumes 117.80 g Carbon Dioxide Equivalent (CO2e), 130.80 Wh, and 0.13 tree months for the carbon footprint, the energy needed, and the carbon sequestration, respectively. These results show that the proposed work consumes fewer resources and provides a green CAD system.}
}
@article{PALACINSILVA20184338,
title = {Infusing sustainability into software engineering education: Lessons learned from capstone projects},
journal = {Journal of Cleaner Production},
volume = {172},
pages = {4338-4347},
year = {2018},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2017.06.078},
url = {https://www.sciencedirect.com/science/article/pii/S0959652617312489},
author = {Maria Victoria Palacin-Silva and Ahmed Seffah and Jari Porras},
keywords = {Sustainable development, ICT, Software services, Green.Citizen@ICT, PERCCOM, Educational initiative},
abstract = {Sustainable development (SD) has become a millennium challenge for humanity. It has boosted the integration of sustainable, sound practices across different fields (e.g. e-participation, smart transportation, sustainable agriculture). Information and Communication Technologies (ICT) have strongly supported social transitions in becoming more sustainable and participative over the last two decades. Integrating multi-disciplinary sustainability concepts into the higher education of computer scientists is important in that this ensures that future ICT endeavours will take sustainability concerns into account. This article describes four capstone projects developed by students from the Erasmus Mundus Master Course in Pervasive Computing and Communications for Sustainable Development (PERCCOM), who were enrolled alongside regular students in a traditional software engineering course held at the Lappeenranta University of Technology. The coursework was part of a research project called Green.Citizen@ICT, which aims at investigating the use of ICT and software services for infusing sustainable habits in citizens through the development of applications for SD. This study demonstrates how a sustainable development focus can be integrated into a traditional software engineering course. The goal of this article is to enhance understanding of the integration of sustainability into software engineering education, by providing a detailed example of a master course in which this took place. This course supported the development of ICT competences for building cleaner, greener, and more resource- and energy-efficient cyber-physical systems, while addressing the social and environmental dimensions of sustainable development.}
}
@article{LI2023101869,
title = {Rushing through the clouds, or waiting to die? The effect of the green credit policy on heavily polluting firms},
journal = {The North American Journal of Economics and Finance},
volume = {64},
pages = {101869},
year = {2023},
issn = {1062-9408},
doi = {https://doi.org/10.1016/j.najef.2022.101869},
url = {https://www.sciencedirect.com/science/article/pii/S1062940822002042},
author = {Qian Li and Ruodan Zhou and Jie Xiong and Yanxi Wang},
keywords = {Green credit, Corporate financing, Green management, Pollution, Green innovation},
abstract = {Since the 2012 issuance of the Green Credit Guidelines by the Chinese government, banks have adjusted their credit lines for heavily polluting firms. Using the data of listed companies operating in China from 2010 to 2018, this paper examines the promulgation of the green credit policy as a quasi-natural experiment, empirically tests the effectiveness of this policy on heavily polluting firms, and examines the response of firms to this policy. The paper shows that the green credit policy has reduced corporate external financing and increased internal working capital to overcome financial challenges; and that the response of heavily polluting firms to the policy is mixed, with increases in both illegal pollution and green innovation.}
}
@article{ARROBA2014401,
title = {Server Power Modeling for Run-time Energy Optimization of Cloud Computing Facilities},
journal = {Energy Procedia},
volume = {62},
pages = {401-410},
year = {2014},
note = {6th International Conference on Sustainability in Energy and Buildings, SEB-14},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2014.12.402},
url = {https://www.sciencedirect.com/science/article/pii/S187661021403433X},
author = {Patricia Arroba and José L. Risco-Martín and Marina Zapater and José M. Moya and José L. Ayala and Katzalin Olcoz},
keywords = {Green Data Centers, Sustainable Cloud Computing, Power modeling, Particle Swarm Optimization},
abstract = {As advanced Cloud services are becoming mainstream, the contribution of data centers in the overall power consumption of modern cities is growing dramatically. The average consumption of a single data center is equivalent to the energy consumption of 25.000 households. Modeling the power consumption for these infrastructures is crucial to anticipate the effects of aggressive optimization policies, but accurate and fast power modeling is a complex challenge for high-end servers not yet satisfied by analytical approaches. This work proposes an automatic method, based on Multi-Objective Particle Swarm Optimization, for the identification of power models of enterprise servers in Cloud data centers. Our approach, as opposed to previous procedures, does not only consider the workload consolidation for deriving the power model, but also incorporates other non traditional factors like the static power consumption and its dependence with temperature. Our experimental results shows that we reach slightly better models than classical approaches, but simul- taneously simplifying the power model structure and thus the numbers of sensors needed, which is very promising for a short-term energy prediction. This work, validated with real Cloud applications, broadens the possibilities to derive efficient energy saving techniques for Cloud facilities.}
}
@article{YANG2020985,
title = {A task scheduling algorithm considering game theory designed for energy management in cloud computing},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {985-992},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17304673},
author = {Jiachen Yang and Bin Jiang and Zhihan Lv and Kim-Kwang Raymond Choo},
keywords = {Task scheduling, Game theory, Cloud computing, Optimization},
abstract = {With the increasing popularity of cloud computing products, task scheduling problem has become a hot research topic in this field. The task scheduling problem of cloud computing system is more complex than the traditional distributed system. Based on the analysis of cloud computing in related literature, we established a simplified model for task scheduling system in cloud computing.Different from the previous research of cloud computing task scheduling algorithm, the simplified model in this paper is based on game theory as a mathematical tool. Based on game theory, the task scheduling algorithm considering the reliability of the balanced task is proposed. Based on the balanced scheduling algorithm, the task scheduling model for computing nodes is proposed. In the cooperative game model, game strategy is used for the task in the calculation of rate allocation strategy on the node. Through analysis of experimental results, it is shown that the proposed algorithm has better optimization effect.}
}
@article{SHEIKHI20151007,
title = {A cloud computing framework on demand side management game in smart energy hubs},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {64},
pages = {1007-1016},
year = {2015},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2014.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S0142061514005468},
author = {Aras Sheikhi and Mohammad Rayati and Shahab Bahrami and Ali Mohammad Ranjbar and Sourena Sattari},
keywords = {Cloud computing (CC), Demand side management (DSM), Game theory, Smart Energy Hub (S.E. Hub), Smart grid (SG)},
abstract = {The presence of energy hubs in the future vision of energy networks creates an opportunity for electrical engineers to move toward more efficient energy systems. At the same time, it is envisioned that smart grid can cover the natural gas network in the near future. This paper modifies the classic Energy Hub model to present an upgraded model in the smart environment entitling “Smart Energy Hub”. Supporting real time, two-way communication between utility companies and smart energy hubs, and allowing intelligent infrastructures at both ends to manage power consumption necessitates large-scale real-time computing capabilities to handle the communication and the storage of huge transferable data. To manage communications to large numbers of endpoints in a secure, scalable and highly-available environment, in this paper we provide a cloud computing framework for a group of smart energy hubs. Then, we use game theory to model the demand side management among the smart energy hubs. Simulation results confirm that at the Nash equilibrium, peak to average ratio of the total electricity demand reduces significantly and at the same time the hubs will pay less considerably for their energy bill.}
}
@article{ZAKARYA201713,
title = {Energy efficient computing, clusters, grids and clouds: A taxonomy and survey},
journal = {Sustainable Computing: Informatics and Systems},
volume = {14},
pages = {13-33},
year = {2017},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2017.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2210537917300707},
author = {Muhammad Zakarya and Lee Gillam},
abstract = {Cloud computing continues to play a major role in transforming the IT industry by facilitating elastic on-demand provisioning of computational resources including processors, storage and networks. This is necessarily accompanied by the creation, and refreshes, of large-scale systems including cluster, grids and datacenters from which such resources are provided. These systems consume substantial amounts of energy, with associated costs, leading to significant CO2 emissions. In 2014, these systems consumed 70billion kWh of energy in US; this is 1.8% of the US total energy consumption, and future consumption is expected to continue around this level with approximately 73billion kWh by 2020. The energy bills for major cloud service providers are typically the second largest item in their budgets due to the increased number of computational resources. Energy efficiency in these systems serves the providers interests in saving money to enable reinvestment, reduce supply costs and also reduces CO2 emissions. In this paper, we discuss energy consumption in large scale computing systems, such as scientific high performance computing systems, clusters, grids and clouds, and whether it is possible to decrease energy consumption without detrimental impact on service quality and performance. We discuss a number of approaches, reported in the literature, that claim to improve the energy efficiency of such large scale computing systems, and identify a number of open challenges. Key findings include: (i) in clusters and grids, use of system level efficiency techniques might increase their energy consumption; (ii) in (virtualized) clouds, efficient scheduling and resource allocation can lead to substantially greater economies than consolidation through migration; and (iii) in clusters, switching off idle resources is more energy efficient, however in (production) clouds, performance is affected due to demand fluctuation.}
}
@article{DITTRICH20141436,
title = {Software engineering beyond the project – Sustaining software ecosystems},
journal = {Information and Software Technology},
volume = {56},
number = {11},
pages = {1436-1456},
year = {2014},
note = {Special issue on Software Ecosystems},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2014.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0950584914000652},
author = {Yvonne Dittrich},
keywords = {Software ecosystems, Software product development, Qualitative empirical research},
abstract = {Context
The main part of software engineering methods, tools and technologies has developed around projects as the central organisational form of software development. A project organisation depends on clear bounds regarding scope, participants, development effort and lead-time. What happens when these conditions are not given? The article claims that this is the case for software product specific ecosystems. As software is increasingly developed, adopted and deployed in the form of customisable and configurable products, software engineering as a discipline needs to take on the challenge to support software ecosystems.
Objective
The article provides a holistic understanding of the observed and reported practices as a starting point to device specific support for the development in software ecosystems.
Method
A qualitative interview study was designed based on previous long-term ethnographical inspired research.
Results
The analysis results in a set of common features of product development and evolution despite differences in size, kind of software and business models. Design is distributed and needs to be coordinated across heterogeneous design constituencies that, together with the software, build a product specific socio-technical ecosystem. The technical design has to support the deference of part of the development not only to 3rd-party developers but also to local designers tailoring the software in the use organisation. The technical interfaces that separate the work of different design constituencies are contested and need to be maintained permanently. Development takes place as cycles within cycles – overlaying development cycles with different rhythms to accommodate different evolution drivers.
Conclusion
The reported practices challenge some of the very core assumptions of traditional software engineering, but makes perfect sense, considering that the frame of reference for product development is not a project but continuous innovation across the respective ecosystem. The article provides a number of concrete points for further research.}
}
@article{SARATHCHANDRAMAGURAWALAGE201422,
title = {Energy-efficient and network-aware offloading algorithm for mobile cloud computing},
journal = {Computer Networks},
volume = {74},
pages = {22-33},
year = {2014},
note = {Special Issue on Mobile Computing for Content/Service-Oriented Networking Architecture},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2014.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S1389128614003193},
author = {Chathura M. {Sarathchandra Magurawalage} and Kun Yang and Liang Hu and Jianming Zhang},
keywords = {Mobile cloud computing, Mobile clone, Mobile cloudlet, Offloading algorithm, Energy efficiency},
abstract = {We propose a new system architecture for mobile cloud computing (MCC) that includes a middle layer sitting between mobile devices and their cloud infrastructure or clones. This middle layer is composed of cloudlets and is thus called a cloudlet layer. Cloudlets are deployed next to IEEE 802.11 access points and serve as a localized service point in close proximity to mobile devices to improve the performance of mobile cloud services. On top of this new architecture, an offloading algorithm is proposed with the main aim of deciding whether to offload to a clone or a cloudlet. The decision-making takes into consideration the energy consumption for task execution and the network status while satisfying certain task response time constraints. We also introduce a data caching mechanism at cloudlets to further improve the overall MCC performance. Simulation results demonstrate the effectiveness and efficiency of the proposed system architecture and offloading algorithm in terms of response time and energy consumption.}
}
@article{PATEL2020700,
title = {Energy efficient strategy for placement of virtual machines selected from underloaded servers in compute Cloud},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {32},
number = {6},
pages = {700-708},
year = {2020},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2017.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1319157817302288},
author = {Nimisha Patel and Hiren Patel},
keywords = {Workload consolidation, VM placement, Utilization, Energy efficiency, Underloaded server},
abstract = {Workload consolidation is a phase in Cloud datacenter where tasks are allocated among the available hosts in such a way that a minimal number of hosts is used and users’ need in terms of service level agreement (SLA) is fulfilled. To achieve workload consolidation, hosts are divided among three groups based on their utilization namely overloaded hosts, underloaded host and normal hosts. Detection of over or underloaded host is a challenging issue. Most of the existing researchers propose to use threshold values for such detection. We believe that there is a scope of improvement in existing methods of deciding underloaded hosts and subsequently taking off virtual machines (VMs) from them and placing them on other hosts. In this research, we propose Host Utilization Aware (HUA) Algorithm for underloaded host detection and placing its VMs on other hosts in a dynamic Cloud environment. We compare our proposed mechanism with existing one and with empirical analysis; it is shown that our proposal results into shutting off more number of hosts without compromising user’s workload requirement which leads to an energy-efficient workload consolidation with minimal migration costs and efficient utilization of active hosts.}
}
@article{ZHU2020100375,
title = {Guest editorial: Special issue on data intelligence in sustainable computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {25},
pages = {100375},
year = {2020},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2020.100375},
url = {https://www.sciencedirect.com/science/article/pii/S2210537920300469},
author = {Tao Zhu and Wenjian Luo and Junwei Cao and Hansheng Lei}
}
@article{KARNAMA2019100063,
title = {Organic data centers: A sustainable solution for computing facilities},
journal = {Results in Engineering},
volume = {4},
pages = {100063},
year = {2019},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2019.100063},
url = {https://www.sciencedirect.com/science/article/pii/S2590123019300635},
author = {Ahmad Karnama and Ehsan Bitaraf Haghighi and Ricardo Vinuesa},
abstract = {In the present perspective article we provide an overview of on-going work in the literature and possible future development of organic data centers (ODC). These are defined as the combined operation of a data center and a greenhouse, and given their compatible thermal and operation requirements, ODCs have the potential to provide an excellent solution in terms of sustainability. In particular, we identify possible positive impacts of ODCs on at least 5 of the 17 United Nations (UN) Sustainable Development Goals (SDGs), including SDGs 2 and 13 on zero hunger and climate change, respectively.}
}
@article{ISMAIL2016870,
title = {EATS: Energy-Aware Tasks Scheduling in Cloud Computing Systems},
journal = {Procedia Computer Science},
volume = {83},
pages = {870-877},
year = {2016},
note = {The 7th International Conference on Ambient Systems, Networks and Technologies (ANT 2016) / The 6th International Conference on Sustainable Energy Information Technology (SEIT-2016) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.04.178},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916302113},
author = {Leila Ismail and Abbas Fardoun},
keywords = {Green Computing, Energy Efficiency, Energy Management, Scheduling, Cloud Computing, Performance},
abstract = {The increasing cost in power consumption in data centers, and the corresponding environmental threats have raised a growing demand in energy-efficient computing. Despite its importance, little work was done on introducing models to manage the consumption efficiently. With the growing use of Cloud Computing, this issue becomes very crucial. In a Cloud Computing, the services run in a data center on a set of clusters that are managed by the Cloud computing environment. The services are provided in the form of a Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS). The amount of energy consumed by the underutilized and overloaded computing systems may be substantial. Therefore, there is a need for scheduling algorithms to take into account the power consumption of the Cloud for energy-efficient resource utilization. On the other hand, Cloud computing is seen as crucial for high performance computing; for instance for the purpose of Big Data processing, and that should not be much compromised for the sake of reducing energy consumption. In this work, we derive an energy-aware tasks scheduling (EATS) model, which divides and schedules a big data in the Cloud. The main goal of EATS is to increase the application efficiency and reduce the energy consumption of the underlying resources. The power consumption of a computing server was measured under different working load conditions. Experiments show that the ratio of energy consumption at peak performance compared to an idle state is 1.3. This shows that resources must be utilized correctly without scarifying performance. The results of the proposed approach are very promising and encouraging. Hence, the adoption of such strategies by the cloud providers result in energy saving for data centers.}
}
@article{ALZAMIL201591,
title = {Energy-Aware Profiling for Cloud Computing Environments},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {318},
pages = {91-108},
year = {2015},
note = {Twenty-ninth and thirtieth Annual UK Performance Engineering Workshops (UKPEW)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2015.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S1571066115000626},
author = {Ibrahim Alzamil and Karim Djemame and Django Armstrong and Richard Kavanagh},
keywords = {Cloud Computing, Energy Efficiency, Energy-Aware Profiling, Energy Efficiency Metrics},
abstract = {Cloud Computing has changed the way in which people use the IT resources today. Now, instead of buying their own IT resources, they can use the services offered by Cloud Computing with reasonable costs based on a “pay-per-use” model. However, with the wide adoption of Cloud Computing, the costs for maintaining the Cloud infrastructure have become a vital issue for the providers, especially with the large input of energy costs to underpin these resources. Thus, this paper proposes a system architecture that can be used for profiling the resources usage in terms of the energy consumption. From the profiled data, the application developers can enhance their energy-aware decisions when creating or optimising the applications to be more energy efficient. This paper also presents an adapted existing Cloud architecture to enable energy-aware profiling based on the proposed system. The results of the conducted experiments show energy-awareness at physical host and virtual machine levels.}
}
@article{KUMARREDDY2023,
title = {A Futuristic Green Service Computing Approach for Smart City: A Fog Layered Intelligent Service Management Model for Smart Transport System},
journal = {Computer Communications},
year = {2023},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S014036642300275X},
author = {K. Hemant {Kumar Reddy} and Rajat Subhra Goswami and Diptendu {Sinha Roy}},
keywords = {Vehicular Network, Context Computing, Learning, IoT, IoV},
abstract = {With the widespread adoption of technologies like the Internet of Things (IoT), context awareness, and decentralized computing at the edge of the network, service delivery in smart city parlance has been rapidly evolved. Management of Information and Communication Technologies (ICT) infrastructure for such dynamic environment at scale brings about new challenges. Existing fog layer resource management involves context-sharing and migration for real-time vertical and cross-vertical services. However, improper context migration might affect performance negatively. In this paper, the authors have envisioned improving the Quality of Service (QoS) of smart transportation while employing context-aware computing and Artificial Intelligence, which helps alleviate massive data transfers among Fog nodes and intelligent vehicles in real-time. The proposed Context-Aware Intelligent Transportation System (CAITS) manages the services of intelligent vehicles and manages the road traffic of traditional vehicles in an effective manner, with a three-layered learning model that accounts for on-vehicle, on-co-vehicle, and on-fog-and-vehicle learning by means of a platoon control algorithm as well as federated learning at the Fog level. Simulations are carried out on CloudSim simulator under different scenarios and the results demonstrate that the proposed scheme improves prediction efficacy of contexts at the Fog layer by approximately 8% to 24% than existing models which in turn reflects in reduced service time and energy consumption of EVs and reduces the CO2 of environment.}
}
@article{JUAREZ2018257,
title = {Dynamic energy-aware scheduling for parallel task-based application in cloud computing},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {257-271},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.06.029},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1630214X},
author = {Fredy Juarez and Jorge Ejarque and Rosa M. Badia},
keywords = {Distributed computing, Cloud computing, Green computing, Task-based applications, Energy-aware scheduling, Multi-heuristic resource allocation},
abstract = {Green Computing is a recent trend in computer science, which tries to reduce the energy consumption and carbon footprint produced by computers on distributed platforms such as clusters, grids, and clouds. Traditional scheduling solutions attempt to minimize processing times without taking into account the energetic cost. One of the methods for reducing energy consumption is providing scheduling policies in order to allocate tasks on specific resources that impact over the processing times and energy consumption. In this paper, we propose a real-time dynamic scheduling system to execute efficiently task-based applications on distributed computing platforms in order to minimize the energy consumption. Scheduling tasks on multiprocessors is a well known NP-hard problem and optimal solution of these problems is not feasible, we present a polynomial-time algorithm that combines a set of heuristic rules and a resource allocation technique in order to get good solutions on an affordable time scale. The proposed algorithm minimizes a multi-objective function which combines the energy-consumption and execution time according to the energy-performance importance factor provided by the resource provider or user, also taking into account sequence-dependent setup times between tasks, setup times and down times for virtual machines (VM) and energy profiles for different architectures. A prototype implementation of the scheduler has been tested with different kinds of DAG generated at random as well as on real task-based COMPSs applications. We have tested the system with different size instances and importance factors, and we have evaluated which combination provides a better solution and energy savings. Moreover, we have also evaluated the introduced overhead by measuring the time for getting the scheduling solutions for a different number of tasks, kinds of DAG, and resources, concluding that our method is suitable for run-time scheduling.}
}
@article{GAI2018126,
title = {Energy-aware task assignment for mobile cyber-enabled applications in heterogeneous cloud computing},
journal = {Journal of Parallel and Distributed Computing},
volume = {111},
pages = {126-135},
year = {2018},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517302319},
author = {Keke Gai and Meikang Qiu and Hui Zhao},
keywords = {Energy-aware, Task assignment, Cloud computing, Mobile embedded systems, Cyber-enabled applications, NP-hard},
abstract = {Recent remarkable growth of mobile computing has led to an exceptional hardware upgrade, including the adoption of the multiple core processors. Along with this trend, energy consumptions are becoming greater when the computation capacity or workload grows. As one of the solutions, using cloud computing can mitigate energy costs due to the centralized computation. However, simply offloading the workloads to the remote side cannot efficiently reduce the energy consumptions when the energy costs caused by wireless communications are greater than that of on mobile devices. In this paper, we focus on the energy-saving problem and consider the energy wastes when tasks are assigned to remote cloud servers or heterogeneous core processors. Our solution aims to reduce the total energy cost of the mobile heterogeneous embedded systems by a novel task assignment to heterogeneous cores and mobile clouds. The proposed model is called Energy-Aware Heterogeneous Cloud Management (EA-HCM) model and the main algorithm is Heterogeneous Task Assignment Algorithm (HTA2). Our experimental evaluations have proved that our approach is effective to save energy when deploying heterogeneous embedded systems in mobile cloud systems.}
}
@article{KALAKUL201498,
title = {Integration of life cycle assessment software with tools for economic and sustainability analyses and process simulation for sustainable process design},
journal = {Journal of Cleaner Production},
volume = {71},
pages = {98-109},
year = {2014},
note = {Special Volume: PSE Asia for Cleaner Production},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2014.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S0959652614000353},
author = {Sawitree Kalakul and Pomthong Malakul and Kitipat Siemanond and Rafiqul Gani},
keywords = {Life cycle assessment, Process design, Bioethanol process, Sustainability analysis},
abstract = {The sustainable future of the world challenges engineers to develop chemical process designs that are not only technically and economically feasible but also environmental friendly. Life cycle assessment (LCA) is a tool for identifying and quantifying environmental impacts of the chemical product and/or the process that makes it. It can be used in conjunction with process simulation and economic analysis tools to evaluate the design of any existing and/or new chemical-biochemical process and to propose improvement options in order to arrive at the best design among various alternatives. Although there are several commercial LCA tools, there is still a need for a simple LCA software that can be integrated with process design tools. In this paper, a new LCA software, LCSoft, is developed for evaluation of chemical, petrochemical, and biochemical processes with options for integration with other process design tools such as sustainable design (SustainPro), economic analysis (ECON) and process simulation. The software framework contains four main tools: Tool-1 is for life cycle inventory (LCI) knowledge management that enables easy maintenance and future expansion of the LCI database; Tool-2 is for estimation of environmental impact characterization factors using group contribution+ method (GC)+ in order to calculate environmental impacts for a wide range of chemicals; Tool-3 performs LCA calculations based on a library of models; and, Tool-4 provides interfaces for integration with other tools. To test the software, a bioethanol production process using cassava rhizome is employed as a case study. Results from LCSoft highlight the estimated environmental performance in terms of various aspects such as carbon footprint, resource and energy consumptions, and various environmental impacts.}
}
@article{TOLEDOACEVES2011974,
title = {Tropical montane cloud forests: Current threats and opportunities for their conservation and sustainable management in Mexico},
journal = {Journal of Environmental Management},
volume = {92},
number = {3},
pages = {974-981},
year = {2011},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2010.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S030147971000410X},
author = {Tarin Toledo-Aceves and Jorge A. Meave and Mario González-Espinosa and Neptalí Ramírez-Marcial},
keywords = {Biodiversity, Conservation planning, Deforestation, Environmental services, Multicriteria decision analysis, Prioritisation analysis, Tropical forest management},
abstract = {Tropical montane cloud forests (TMCF) are among the most threatened ecosystems globally in spite of their high strategic value for sustainable development due to the key role played by these forests in hydrological cycle maintenance and as reservoirs of endemic biodiversity. Resources for effective conservation and management programs are rarely sufficient, and criteria must be applied to prioritise TMCF for conservation action. This paper reports a priority analysis of the 13 main regions of TMCF distribution in Mexico, based on four criteria: (1) forest quality, (2) threats to forest permanence, (3) threats to forest integrity, and (4) opportunities for conservation. Due to the diverse socio-environmental conditions of the local communities living in Mexican TMCF regions, their associated social characteristics were also evaluated to provide a background for the planning of conservation actions. A set of indicators was defined for the measurement of each criterion. To assign priority values for subregions within each main region, an international team of 40 participants evaluated all the indicators using multicriteria decision-making analysis. This procedure enabled the identification of 15 subregions of critical priority, 17 of high priority, and 10 of medium priority; three more were not analysed due to lack of information. The evaluation revealed a number of subjects that had hitherto been undetected and that may prove useful for prioritisation efforts in other regions where TMCF is similarly documented and faces equally severe threats. Based on this analysis, key recommendations are outlined to advance conservation objectives in those TMCF areas that are subjected to high pressure on forest resources.}
}
@article{LIU2023129066,
title = {A task matching model of photovoltaic storage system under the energy blockchain environment - based on GA-CLOUD-GS algorithm},
journal = {Energy},
volume = {283},
pages = {129066},
year = {2023},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2023.129066},
url = {https://www.sciencedirect.com/science/article/pii/S036054422302460X},
author = {Jicheng Liu and Yunyuan Lu},
keywords = {Energy blockchain, Photovoltaic, Energy storage, Task matching, Cloud model},
abstract = {Photovoltaic storage system (PVSS) has been spawned with the combined application of photovoltaic (PV), energy storage (ES) and energy blockchain (EB), which has also made important contributions to the energy structure adjustment, energy transaction security and ecological environment protection. The establishment of a reasonable task matching mechanism can further improve the operation efficiency and quality of the system under the EB environment, and this paper consequently constructs a task matching model of PVSS based on GA-CLOUD-GS algorithm. Firstly, the decision-making committee is set up and the index system is determined for the to-be-matched task. Secondly, the Genetic Algorithm (GA) comprehensive weighting method is introduced to integrate the subjective and objective weights to achieve the weight optimization. Thirdly, the cloud model is used to obtain the preference order and priority order of the to-be-matched subjects. Fourthly, the Gale-Shapley (GS) algorithm is used to obtain the task matching results. Finally, the operability, the stability and the effectiveness of the model are separately verified through numerical simulation, sensitivity analysis and comparative analysis. Corresponding suggestions for the task matching of PVSS in the EB environment are also put forward according to the research content.}
}
@article{WU201863,
title = {A multi-model estimation of distribution algorithm for energy efficient scheduling under cloud computing system},
journal = {Journal of Parallel and Distributed Computing},
volume = {117},
pages = {63-72},
year = {2018},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2018.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0743731518300868},
author = {Chu-ge Wu and Ling Wang},
keywords = {Task graph scheduling, Energy efficient scheduling, Cloud computing, Estimation of distribution algorithm, Precedence-constrained parallel application},
abstract = {How to manage the applications under computing systems such as a cloud computing system in a more efficient way is a focus problem. The primary performance goal is to reduce the execution time (makespan) of the application. As the need to cloud computing grows, the environmental influence of data centers attracts much attention. This paper aims at the scheduling of the precedence-constrained parallel application to minimize time and energy consumption efficiently. A multi-model estimation of distribution (mEDA) algorithm is adopted to determine both task processing permutation and voltage supply levels (VSLs). Specific operators to decrease execution time and energy consumption are designed. An improvement operator is also designed to enhance the diversity of the non-dominated solutions. The proposed algorithm is compared with the standard heuristic methods and a parallel bi-objective genetic algorithm (bGA). The comparative results show the Pareto solution set by the proposed algorithm is able to dominate a large proportion of those solutions by both the heuristic methods and the bGA.}
}
@incollection{BIRON202085,
title = {3 - Metrics of Sustainability in Plastics: Indicators, Standards, Software},
editor = {Michel Biron},
booktitle = {A Practical Guide to Plastics Sustainability},
publisher = {William Andrew Publishing},
pages = {85-111},
year = {2020},
series = {Plastics Design Library},
isbn = {978-0-12-821539-5},
doi = {https://doi.org/10.1016/B978-0-12-821539-5.00003-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128215395000033},
author = {Michel Biron},
keywords = {Acidification, carbon footprint, disposal, eco-design, eco-profile, energy, environmental impact, GHG, GWP, index, LCA, management, ozone, pollution, water},
abstract = {Plastics synthesis, processing, use, and disposal—as do all human activities—consume resources and energy, pollute and compromise the future of the planet by global warming, atmospheric ozone depletion, and accumulation of pollutants often under organic forms, which is particularly harmful for human, animal, vegetal, and aquatic life. It is essential to evaluate different solutions with efficient and unbiased methods, preferably standardized, allowing to compare the whole life from resource use up to waste disposal. Methods are very diverse and may be globally or regionally applied, from general purpose or a detailed level, from voluntary or mandatory application. Laws, regulations and trends are rapidly evolving. The provided information is only a quick glance needing a more deeply study before application to the problem of the reader. Examined specific tools for sustainability management include indicators, standards, and software concerning environment management systems, life cycle inventory, life cycle assessment, life cycle impact assessment (LCIA), incorporation of eco-design (ECD), or sustainable design in the life cycle. This chapter also broaches general purpose and specific standards linked to the environment, Environmental assessment of sites and organizations (EASO), environmental labels and declarations, environmental performance, risk management, quality management systems, and environmental product declaration (EPD). Environmental indicators are examined more or less in depth such as energy consumption, CO2 and other greenhouse gases (GHG), global warming potential (GWP), water footprint, toxicity, unwanted emissions, ozone depletion, photochemical oxidation, acidification, eutrophication, and other diverse indicators. Synthetic Indexes, for example Eco-Profiling System (EPS), CML-IA, resulting from environmental indicator integration are discussed. Clarification concerning some terms, databases, and software regarding environmental management complete this brief landscape of sustainability tools. Social and societal aspects, as well as regulatory requirements, are not taken into account.}
}
@article{TULA201774,
title = {A computer-aided software-tool for sustainable process synthesis-intensification},
journal = {Computers & Chemical Engineering},
volume = {105},
pages = {74-95},
year = {2017},
note = {Process Intensification},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2017.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0098135417300017},
author = {Anjan Kumar Tula and Deenesh K. Babi and Jack Bottlaender and Mario R. Eden and Rafiqul Gani},
keywords = {Process synthesis, Process intensification},
abstract = {Currently, the process industry is moving towards the design of innovative, more sustainable processes that show improvements in both economic and environmental factors. The design space of unit operations that can be combined to generate process flowsheet alternatives considering known unit operations as well as reported hybrid/intensified unit operations is large and can be difficult to manually navigate in order to determine the best process flowsheet for the production of a desired chemical product. Therefore, it is beneficial to utilize computer-aided methods and tools to enumerate, analyze and determine within the design space, the more sustainable processes. In this paper, an integrated computer-aided software-tool that searches the design space for hybrid/intensified more sustainable process options is presented. Embedded within the software architecture are process synthesis and intensification methods that operate at multiple scales, namely, unit operation, task and phenomena. First a base case process flowsheet (if it is not already available) is generated through process synthesis considering only known unit operations. The generated or supplied base case is then analyzed in order to identify process bottlenecks/limitations (hot-spots) that are translated into design targets. Next, phenomena-based synthesis is performed to identify process flowsheets that match the design targets through the use of hybrid/intensified unit operations. As these process flowsheets satisfy all process constraints while also matching the design targets, they are therefore more sustainable than the base case. The application of the software-tool to the production of biodiesel is presented, highlighting the main features of the computer-aided, multi-stage, multi-scale methods that are able to determine more sustainable designs.}
}
@article{ZHANG20229,
title = {GSIP: Green Semantic Segmentation of Large-Scale Indoor Point Clouds},
journal = {Pattern Recognition Letters},
volume = {164},
pages = {9-15},
year = {2022},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2022.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0167865522003075},
author = {Min Zhang and Pranav Kadam and Shan Liu and C.-C. Jay Kuo},
keywords = {Point cloud, Semantic segmentation, Indoor scene understanding, Green learning, unsupervised learning},
abstract = {An efficient solution to semantic segmentation of large-scale indoor scene point clouds is proposed in this work. It is named GSIP (Green Segmentation of Indoor Point clouds) and its performance is evaluated on a representative large-scale benchmark — the Stanford 3D Indoor Segmentation (S3DIS) dataset. GSIP has two novel components: 1) a room-style data pre-processing method that selects a proper subset of points for further processing, and 2) a new feature extractor which is extended from PointHop. For the former, sampled points of each room form an input unit. For the latter, the weaknesses of PointHop’s feature extraction when extending it to large-scale point clouds are identified and fixed with a simpler processing pipeline. As compared with PointNet, which is a pioneering deep-learning-based solution, GSIP is green since it has significantly lower computational complexity and a much smaller model size. Furthermore, experiments show that GSIP outperforms PointNet in segmentation performance for the S3DIS dataset.}
}
@article{WANG201491,
title = {A new multi-objective bi-level programming model for energy and locality aware multi-job scheduling in cloud computing},
journal = {Future Generation Computer Systems},
volume = {36},
pages = {91-101},
year = {2014},
note = {Special Section: Intelligent Big Data Processing Special Section: Behavior Data Security Issues in Network Information Propagation Special Section: Energy-efficiency in Large Distributed Computing Architectures Special Section: eScience Infrastructure and Applications},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2013.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X13002689},
author = {Xiaoli Wang and Yuping Wang and Yue Cui},
keywords = {Energy aware, Data locality, Multi-job scheduling, Cloud computing, MapReduce},
abstract = {How to reduce power consumption of data centers has received worldwide attention. By combining the energy-aware data placement policy and locality-aware multi-job scheduling scheme, we propose a new multi-objective bi-level programming model based on MapReduce to improve the energy efficiency of servers. First, the variation of energy consumption with the performance of servers is taken into account; second, data locality can be adjusted dynamically according to current network state; last but not least, considering that task-scheduling strategies depend directly on data placement policies, we formulate the problem as an integer bi-level programming model. In order to solve the model efficiently, specific-design encoding and decoding methods are introduced. Based on these, a new effective multi-objective genetic algorithm based on MOEA/D is proposed. As there are usually tens of thousands of tasks to be scheduled in the cloud, this is a large-scale optimization problem and a local search operator is designed to accelerate convergent speed of the proposed algorithm. Finally, numerical experiments indicate the effectiveness of the proposed model and algorithm.}
}
@article{MAHMOUDI2019171,
title = {Accessibility with time and resource constraints: Computing hyper-prisms for sustainable transportation planning},
journal = {Computers, Environment and Urban Systems},
volume = {73},
pages = {171-183},
year = {2019},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0198971518302710},
author = {Monirehalsadat Mahmoudi and Ying Song and Harvey J. Miller and Xuesong Zhou},
keywords = {Resource hyper-prisms, Space-time prisms, Accessibility, Sustainable transportation, Dynamic programming},
abstract = {Accessibility is the ease of obtaining desired destinations, activities, or services in an environment. A common accessibility measure in basic and applied transportation science is the space-time prism (STP) and the network-time prisms (NTPs): these are the envelopes of all possible paths between two locations and times in planar space and transportation networks, respectively. STPs and NTPs focus on time as the scarce resource limiting accessibility. However, other resource constraints can constrain space-time accessibility, such as limits or “budgets” for energy, emissions, or monetary expenses. This paper extends NTPs to include other resource constraints in addition to time. Network-based resource hyper-prisms (RHPs) incorporate other resource constraints into NTP, capturing the trade-offs between time and other resources in determining space-time accessibility. We conceptualize RHPs as a constrained optimization problem and develop a forward and backward resource-dependent time-dependent dynamic programming to determine the boundaries of a RHP given time and other resource budgets. We illustrate our approach using the Chicago sketch network (with 933 nodes and 2967 links) for the use case of an individual with an internal combustion engine vehicle and a carbon emission budget and using portions of Washington, D.C. and Baltimore networks (with 12,145 nodes and 30,697 links) for the use case of siting electric vehicle charging stations to maximize regional accessibility.}
}
@article{VENKATARAMAN2017327,
title = {Development of a multidisciplinary approach to compute sustainability index for manufacturing plants - Singapore perspective},
journal = {Energy Procedia},
volume = {143},
pages = {327-335},
year = {2017},
note = {Leveraging Energy Technologies and Policy Options for Low Carbon Cities},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2017.12.692},
url = {https://www.sciencedirect.com/science/article/pii/S1876610217364561},
author = {NARAYANASWAMY VENKATARAMAN and KANESAN MUTHUSAMY},
keywords = {Sustainability, Manufactuirng, Index, Resource, Management},
abstract = {The purpose and objectives of this paper is to determine the determinants for computing sustainable footprint for a typical semiconductor manufacturing facility and subsequently to benchmark the sustainability footprint with other semiconductor manufacturing environment. Sustainability index studies have been used by different agencies mostly for public listed companies. Suitable checklist was used to determine the sustainability index of an organization and the results were compared with other similar organization. Using one approach, sustainability index was computed and compared with the other similar organization. By computing the sustainability index for a manufacturing organization, it will help the organization to identify the areas to improve for more sustainable operations. Sustainability index is a function of wellbeing, management, resource and compliance. By using Analytical Hierarchic Process (AHP) model a simple Sustainability index formula was developed for this study SI = (0.375*Wellbeing +0.25*Compliance+0.25*Resource+0.125*Management)/5, Using a structured questionnaire and giving a scoring for each construct, SI for a manufacturing company was computed. For one of the company, Sustainability Index was computed as 80%. Benchmarking can be done with similar industrial sector and will also help shareholders and other interested parties to know better of the organization in terms of their ability to be sustainable. Organizations with low sustainable index will be preferred and will be better recognized in the market. This paper has attempted to define sustainable index and also a method to compute sustainability Index (SI) for a manufacturing organization in Singapore.}
}
@article{IBRAHIM2018551,
title = {An Integer Linear Programming model and Adaptive Genetic Algorithm approach to minimize energy consumption of Cloud computing data centers},
journal = {Computers & Electrical Engineering},
volume = {67},
pages = {551-565},
year = {2018},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2018.02.028},
url = {https://www.sciencedirect.com/science/article/pii/S0045790617319808},
author = {Huda Ibrahim and Raafat O. Aburukba and Khaled El-Fakih},
keywords = {Cloud computing, Task scheduling, Optimization, Integer Linear Programming, Energy consumption, Genetic algorithm, Cloud data centers},
abstract = {Cloud computing infrastructures are designed to support the accessibility and availability of various services to consumers over the Internet. Data centers hosting Cloud applications consume massive amount of power, contributing to high carbon footprints to the environment. Hence, solutions are needed to minimize the energy consumption. This paper focuses on the development of a dynamic task scheduling algorithm by proposing an Integer Linear Programming (ILP) model that minimizes the energy consumption in a Cloud data center. Furthermore, an Adaptive Genetic Algorithm (GA) is proposed to reflect the dynamic nature of the Cloud environment and to provide a near optimal scheduling solution that minimizes the energy consumption. The proposed adaptive GA is validated by simulating the Cloud infrastructure and conducting a set of performance and quality evaluation study in this environment. The results demonstrate that the proposed solution offers performance gains with regards to response time and in reducing energy consumption.}
}
@article{ZHU201766,
title = {A three-dimensional virtual resource scheduling method for energy saving in cloud computing},
journal = {Future Generation Computer Systems},
volume = {69},
pages = {66-74},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.10.034},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16306586},
author = {Wei Zhu and Yi Zhuang and Long Zhang},
keywords = {Resource scheduling power control, Data center, Virtualization, Cloud computing},
abstract = {Cloud computing is growing in popularity among computing paradigms, but in practice the energy consumption of the cloud data centers is very high. In this paper, we build the resource model of the cloud data center and the dynamic power model of the physical machine, and then propose a three-dimensional virtual resource scheduling method for energy saving in cloud computing (TVRSM), in which the process of virtual resource scheduling are divided into three stages: virtual resource allocation, virtual resource scheduling and virtual resource optimization. For the different objective of each stage, we design three different algorithms, respectively. The simulation results prove that the TVRSM is able to efficiently allocate and manage the virtual resources in the cloud data center. And compared with other traditional algorithms, the TVRSM can effectively reduce the energy consumption of the cloud data center and significantly minimize the amount of violations of Service Level Agreement (SLA).}
}
@article{GOMES201537,
title = {Introduction to special issue on Green Mobile Cloud Computing (Green MCC)},
journal = {Sustainable Computing: Informatics and Systems},
volume = {8},
pages = {37},
year = {2015},
note = {Special Issue on Computing for a Greener Water/Energy/Emissions Nexus; edited by Carol J. Miller.andSpecial Issue on Green Mobile Cloud Computing (Green MCC); edited by Danielo G. Gomes, Rafael Tolosana-Calasanz, and Nazim Agoulmine.},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2015.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2210537915000529},
author = {Danielo G. Gomes and Rafael Tolosana-Calasanz and Nazim Agoulmine}
}
@article{LI2018591,
title = {Scheduling parallel tasks with energy and time constraints on multiple manycore processors in a cloud computing environment},
journal = {Future Generation Computer Systems},
volume = {82},
pages = {591-605},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17300298},
author = {Keqin Li},
keywords = {Cloud computing, Energy constrained scheduling, Manycore processor, Parallel tasks, Performance evaluation, Precedence constraint, Simulation, Time constrained scheduling},
abstract = {When multiple manycore processors in a data center for cloud computing are shared by a large number parallel tasks simultaneously, we are facing the problem of allocating the cores to the tasks and scheduling the tasks, such that the system performance is optimized or the energy consumption is minimized. Furthermore, such core allocation and task scheduling should be conducted with energy constraints or performance constraints. The problems of energy and time constrained scheduling of precedence constrained parallel tasks on multiple manycore processors in a cloud computing environment are defined as optimization problems. Lower bounds for optimal solutions are generalized from a single parallel computing system to multiple parallel computing systems. Our approach in this paper is to design and analyze the performance of heuristic algorithms that employ the equal-speed method. Pre-power-determination algorithms and post-power-determination algorithms are developed for both energy and time constrained scheduling of precedence constrained parallel tasks on multiple manycore processors with continuous or discrete speed levels. The performance of these algorithms are evaluated analytically and experimentally. Our main strategy is to embed the equal-speed method into our algorithms, which not only makes our analysis possible, but also yields good performance of our algorithms.}
}
@article{JIANG2018119,
title = {Self-adaptive resource allocation for energy-aware virtual machine placement in dynamic computing cloud},
journal = {Journal of Network and Computer Applications},
volume = {120},
pages = {119-129},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S1084804518302352},
author = {Han-Peng Jiang and Wei-Mei Chen},
keywords = {Cloud computing, Data center networks, Resource allocation, Bursty workload, Live migration},
abstract = {Cloud computing is a type of Internet-based computing that provides shared computing resources and data on demand. To support the massive cloud services, a data center is built with thousands of servers and switches connected by a communication network called a data center network (DCN). Along with the development of virtualization, the data center manager conducts virtual machine (VM) resizing and live migrations to adjust the allocation of VMs and improve the server utilization. However, compared to VM resizing, live migrations can negatively impact the performance of the system depending on the amount of transferred data and the path length. In this paper, we propose an online resource allocation algorithm using VM consolidation to achieve energy efficiency and reduce service-level agreement (SLA) violations of data centers while considering the power usage of servers, the number of migrations, and the path length of migrations in DCNs. Compared to the state-of-the-art mechanism, the proposed algorithm successfully reduces the power consumption, the number of migrations, and the path length of migrations for a dynamic cloud service.}
}
@article{BOSSUET2014196,
title = {Sustainable electronics: On the trail of reconfigurable computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {4},
number = {3},
pages = {196-202},
year = {2014},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2014.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S2210537914000365},
author = {Lilian Bossuet},
keywords = {Sustainable electronics, Reconfigurable architecture, FPGA, Obsolescence reduction},
abstract = {The electronics industry today is not yet green and/or sustainable. Indeed, the microelectronics industry is a consumer of primary materials, chemical products, water and energy. The manufacture of electronic products and their disposal at the end of their lives results in large quantities of waste products of varying degrees of toxicity that are difficult to deal with. Due to their high replacement rate, the lifespan of electronic products is spectacularly short. To reduce the environmental impact of electronic products the usual reduce-reuse-recycle (3R) trilogy appears to be insufficient. To achieve the objective of sustainable electronics, in this paper we suggest adding a fourth R for reconfigure. We recommend the use of the reconfiguration capacities of reconfigurable circuits such as FPGAs to reduce the functional obsolescence of electronic products by updating hardware. This paper is a survey of the sustainability of microelectronic. It presents some examples of pioneer works to illustrate the architecture of sustainable reconfigurable computing systems.}
}
@article{TESFATSION2014205,
title = {A combined frequency scaling and application elasticity approach for energy-efficient cloud computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {4},
number = {4},
pages = {205-214},
year = {2014},
note = {Special Issue on Energy Aware Resource Management and Scheduling (EARMS)},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2014.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S2210537914000481},
author = {S.K. Tesfatsion and E. Wadbro and J. Tordsson},
keywords = {Cloud computing, Energy-efficiency, Quality-of-service, Virtualization, Frequency scaling, Application elasticity},
abstract = {Energy management has become increasingly necessary in large-scale cloud data centers to address high operational costs and carbon footprints to the environment. In this work, we combine three management techniques that can be used to control cloud data centers in an energy-efficient manner: changing the number of virtual machines, the number of cores, and scaling the CPU frequencies. We present a feedback controller that determines an optimal configuration to minimize energy consumption while meeting performance objectives. The controller can be configured to accomplish these goals in a stable manner, without causing large oscillations in the resource allocations. To meet the needs of individual applications under different workload conditions, the controller parameters are automatically adjusted at runtime based on a system model that is learned online. The potential of the proposed approach is evaluated in a video encoding scenario. The results show that our combined approach achieves up to 34% energy savings compared to the constituent approaches—core change, virtual machine change, and CPU frequency change policies, while meeting the performance target.}
}
@article{PEAN2017124,
title = {Presentation of the PyDEF post-treatment Python software to compute publishable charts for defect energy formation},
journal = {Chemical Physics Letters},
volume = {671},
pages = {124-130},
year = {2017},
issn = {0009-2614},
doi = {https://doi.org/10.1016/j.cplett.2017.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0009261417300015},
author = {Emmanuel Péan and Julien Vidal and Stéphane Jobic and Camille Latouche},
abstract = {In this paper we present a new software, Python for Defect Energy Formation (PyDEF), especially dedicated to the calculation of defect formation energy including its various corrections as developed by the theoretical community through the years. This program offers an intuitive graphical user interface which allows one to easily compute the corrected formation energy of any defect using theoretical calculation results. PyDEF is particularly suited for semiconductor materials as it includes finite size error corrections due to spurious intercell interactions as it is able to plot the formation energy of the different charge states and to determine the more stable ones as a function of the Fermi energy. Moreover PyDEF is able to plot Density Of States (DOS) with various parameters such as the projection on atoms or atomic species allowing a more comprehensive representation of defect-related electronic states. This software is developed in such a way that even non specialist or coder can use it and easily and quickly obtain reliable results.}
}
@article{LIU20161,
title = {Multi-device task offloading with time-constraints for energy efficiency in mobile cloud computing},
journal = {Future Generation Computer Systems},
volume = {64},
pages = {1-14},
year = {2016},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16300905},
author = {Kaiyang Liu and Jun Peng and Heng Li and Xiaoyong Zhang and Weirong Liu},
keywords = {Mobile cloud computing, Energy efficiency, Time constraints, Convex optimization, Task offloading},
abstract = {Nowadays, in order to deal with the increasingly complex applications on mobile devices, mobile cloud offloading techniques have been studied extensively to meet the ever-increasing energy requirements. In this study, an offloading decision method is investigated to minimize the energy consumption of mobile device with an acceptable time delay and communication quality. In general, mobile devices can execute a sequence of tasks in parallel. In the proposed offloading decision method, only parts of the tasks are offloaded for task characteristics to save the energy of multi-devices. The issue of the offloading decision is formulated as an NP-hard 0–1 nonlinear integer programming problem with time deadline and transmission error rate constraints. Through decision-variable relaxation from the integer to the real domain, this problem can be transformed as a continuous convex optimization. Based on Lagrange duality and the Karush–Kuhn–Tucker condition, a solution with coupled terms is derived to determine the priority of tasks for offloading. Then, an iterative decoupling algorithm with high efficiency is proposed to obtain near-optimal offloading decisions for energy saving. Simulation results demonstrate that considerable energy can be saved via the proposed method in various mobile cloud scenarios.}
}
@article{FERNANDES2016854,
title = {A virtual machine scheduler based on CPU and I/O-bound features for energy-aware in high performance computing clouds},
journal = {Computers & Electrical Engineering},
volume = {56},
pages = {854-870},
year = {2016},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2016.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0045790616302270},
author = {Felipe Fernandes and David Beserra and Edward David Moreno and Bruno Schulze and Raquel Coelho Gomes Pinto},
keywords = {Green cloud computing, HPC, VM scheduler, Energy-aware},
abstract = {A Virtual Machine (VM) scheduler for homogeneous High Performance Computing (HPC) cloud environments is presented in this paper. This scheduler considers each VM workload type (CPU or I/O-bound) to decide on its allocation. Scheduler is able to reduce energy consumption, as well as SLA violations on this cloud environment, avoiding performance losses by allocating simultaneously VMs which run different types of tasks. The scheduler method was validated through simulations conducted with the CloudSim framework. Two synthetic benchmarks representing both workload types were run previously in VMs in order to obtain basic data to design the scheduler. Thus, it was possible to implement a scheduling method that employs a VM allocation policy based on features of each application. Results showed that knowing the specifications and characteristics of environment may contribute to a better usage of resources, leading to an increased level of services availability and, finally, reducing problems caused by competition in resource usage.}
}
@article{CONDORIFERNANDEZ2018289,
title = {Characterizing the contribution of quality requirements to software sustainability},
journal = {Journal of Systems and Software},
volume = {137},
pages = {289-305},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2017.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0164121217302984},
author = {Nelly Condori-Fernandez and Patricia Lago},
keywords = {Sustainability, Software-intensive systems, Quality requirements, Survey},
abstract = {Background
Since sustainability became a challenge in software engineering, researchers mainly from requirements engineering and software architecture communities have contributed to defining the basis of the notion of sustainability-aware software.
Problem
Despite these valuable efforts, the assessment and design based on the notion of sustainability as a software quality is still poorly understood. There is no consensus on which sustainability requirements should be considered.
Aim and Method
To fill this gap, a survey was designed with a double objective: i) determine to which extent quality requirements contribute to the sustainability of software-intensive systems; and ii) identify direct dependencies among the sustainability dimensions. The survey involved different target audiences (e.g. software architects, ICT practitioners with expertise in Sustainability). We evaluated the perceived importance/relevance of each sustainability dimension, and the perceived usefulness of exploiting a sustainability model in different software engineering activities.
Results
Most respondents considered modifiability as relevant for addressing both technical and environmental sustainability. Functional correctness, availability, modifiability, interoperability and recoverability favor positively the endurability of software systems. This study has also identified security, satisfaction, and freedom from risk as very good contributors to social sustainability. Satisfaction was also considered by the respondents as a good contributor to economic sustainability.}
}
@article{SARAGIH2016668,
title = {Strategy Competitive for Creating Sustainable Growth in Software Development in Indonesia: A Conceptual Model},
journal = {Procedia - Social and Behavioral Sciences},
volume = {219},
pages = {668-675},
year = {2016},
note = {3rd Global Conference on Business and Social Sciences (GCBSS-2016) on “Contemporary Issues in Management and Social Sciences Research”, Kuala Lumpur, Malaysia},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2016.05.049},
url = {https://www.sciencedirect.com/science/article/pii/S1877042816301094},
author = {Romat Saragih and Grisna Anggadwita},
keywords = {Competitive Strategies, Conceptual Model, Innovation, Software Development, Sustainable Growth.},
abstract = {Every company is trying to achieve a competitive advantage and maintain sustainable business growth. Software development industries in Indonesia have a high growth potential. In line with technological developments, the need for software particularly applications has increased to support the activities of the government, education, business, or society. This paper attempts to describe the actual conditions of software development industries in Indonesia and also proposed a conceptual model by identifying the factors that influence software development industries to achieve the sustainable growth. The model developed is expected to be a reference in the software development industries, particularly in developing countries.}
}
@article{CLOTET2018550,
title = {Structural Parameters of the Proximal Femur by 3-Dimensional Dual-Energy X-ray Absorptiometry Software: Comparison With Quantitative Computed Tomography},
journal = {Journal of Clinical Densitometry},
volume = {21},
number = {4},
pages = {550-562},
year = {2018},
issn = {1094-6950},
doi = {https://doi.org/10.1016/j.jocd.2017.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1094695017300173},
author = {Jordi Clotet and Yves Martelli and Silvana {Di Gregorio} and Luis Miguel {del Río Barquero} and Ludovic Humbert},
keywords = {3D Modeling, bone densitometry, DXA, hip structure analysis, QCT},
abstract = {Structural parameters of the proximal femur evaluate the strength of the bone and its susceptibility to fracture. These parameters are computed from dual-energy X-ray absorptiometry (DXA) or from quantitative computed tomography (QCT). The 3-dimensional (3D)-DXA software solution provides 3D models of the proximal femur shape and bone density from anteroposterior DXA scans. In this paper, we present and evaluate a new approach to compute structural parameters using 3D-DXA software. A cohort of 60 study subjects (60.9 ± 14.7 yr) with DXA and QCT examinations was collected. 3D femoral models obtained by QCT and 3D-DXA software were aligned using rigid registration techniques for comparison purposes. Geometric, cross-sectional, and volumetric structural parameters were computed at the narrow neck, intertrochanteric, and lower shaft regions for both QCT and 3D-DXA models. The accuracy of 3D-DXA structural parameters was evaluated in comparison with QCT. Correlation coefficients (r) between geometric parameters computed by QCT and 3D-DXA software were 0.86 for the femoral neck axis length and 0.71 for the femoral neck shaft angle. Correlation coefficients ranged from 0.86 to 0.96 for the cross-sectional parameters and from 0.84 to 0.97 for the volumetric structural parameters. Our study demonstrated that accurate estimates of structural parameters for the femur can be obtained from 3D-DXA models. This provides clinicians with 3D indexes related to the femoral strength from routine anteroposterior DXA scans, which could potentially improve osteoporosis management and fracture prevention.}
}
@article{BIBRI2017449,
title = {ICT of the new wave of computing for sustainable urban forms: Their big data and context-aware augmented typologies and design concepts},
journal = {Sustainable Cities and Society},
volume = {32},
pages = {449-474},
year = {2017},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S2210670716302475},
author = {Simon Elias Bibri and John Krogstie},
keywords = {Sustainable urban forms, Smart sustainable cities, Big data analytics, Context-aware computing, Typologies and design concepts, Technologies and applications, ICT of the new wave of computing},
abstract = {Undoubtedly, sustainable development has inspired a generation of scholars and practitioners in different disciplines into a quest for the immense opportunities created by the development of sustainable urban forms for human settlements that will enable built environments to function in a more constructive and efficient way. However, there are still significant challenges that need to be addressed and overcome. The issue of such forms has been problematic and difficult to deal with, particularly in relation to the evaluation and improvement of their contribution to the goals of sustainable development. As it is an urban world where the informational and physical landscapes are increasingly being merged, sustainable urban forms need to embrace and leverage what current and future ICT has to offer as innovative solutions and sophisticated methods so as to thrive—i.e. advance their contribution to sustainability. The need for ICT of the new wave of computing to be embedded in such forms is underpinned by the recognition that urban sustainability applications are deemed of high relevance to the contemporary research agenda of computing and ICT. To unlock and exploit the underlying potential, the field of sustainable urban planning is required to extend its boundaries and broaden its horizons beyond the ambit of the built form of cities to include technological innovation opportunities. This paper explores and substantiates the real potential of ICT of the new wave of computing to evaluate and improve the contribution of sustainable urban forms to the goals of sustainable development. This entails merging big data and context-aware technologies and their applications with the typologies and design concepts of sustainable urban forms to achieve multiple hitherto unrealized goals. In doing so, this paper identifies models of smart sustainable city and their technologies and applications and models of sustainable urban form and their design concepts and typologies. In addition, it addresses the question of how these technologies and applications can be amalgamated with these design concepts and typologies in ways that ultimately evaluate and improve the contribution of sustainable urban forms to the goals of sustainable development. The overall aim of this paper suits a mix of three methodologies: literature review, thematic analysis, and secondary (qualitative) data analysis to achieve different but related objectives. The study identifies four technologies and two classes of applications pertaining to models of smart sustainable city as well as three design concepts and four typologies related to models of sustainable urban form. Finally, this paper proposes a Matrix to help scholars and planners in understanding and analyzing how and to what extent the contribution of sustainable urban forms to sustainability can be improved through ICT of the new wave of computing as to the underlying novel technologies and their applications, as well as a data-centric approach into investigating and evaluating this contribution and a simulation method for strategically optimizing it.}
}
@article{SILVA2019329,
title = {Computational sustainability and the PHESS platform: Using affective computing as social indicators},
journal = {Future Generation Computer Systems},
volume = {92},
pages = {329-341},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17328856},
author = {Fábio Silva and Cesar Analide},
keywords = {Intelligent environments, Affective computing, Internet of things, Computational sustainability},
abstract = {The use of ubiquitous devices on intelligent environment enables opportunities to solve complex problems and react to changes quicker. Namely the use of computational resources to assist the management of environment through predicament of parameters based on sustainable indicators applied to social indicators and intelligent environments. This paper considers a computational sustainability platform which manages contexts supported by principles of computational sustainability and the assurance of sustainable scenarios. An application case study based on the definition of social indicators based on mood analysis demonstrates the application of the platform and some of its innovative functionalities. It uses different types of indicators from classical sustainability dimensions in order to demonstrate the platform. Context gathering and predicative services are used based on these indicators obtained from the environment over public services, sensors networks and ubiquitous devices which are used to create indicators based on the fusion of data.}
}
@article{SVOGOR201930,
title = {An extensible framework for software configuration optimization on heterogeneous computing systems: Time and energy case study},
journal = {Information and Software Technology},
volume = {105},
pages = {30-42},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2018.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0950584918301666},
author = {Ivan Švogor and Ivica Crnković and Neven Vrček},
keywords = {Cyber–physical systems, Software components, Power consumption, Execution time, Robot experiment, Heterogeneous computing, Component based software},
abstract = {Context: Application of component based software engineering methods to heterogeneous computing (HC) enables different software configurations to realize the same function with different non–functional properties (NFP). Finding the best software configuration with respect to multiple NFPs is a non–trivial task. Objective: We propose a Software Component Allocation Framework (SCAF) with the goal to acquire a (sub–) optimal software configuration with respect to multiple NFPs, thus providing performance prediction of a software configuration in its early design phase. We focus on the software configuration optimization for the average energy consumption and average execution time. Method: We validated SCAF through its instantiation on a real–world demonstrator and a simulation. Firstly, we verified the correctness of our model through comparing the performance prediction of six software configurations to the actual performance, obtained through extensive measurements with a confidence interval of 95%. Secondly, to demonstrate how SCAF scales up, we performed software configuration optimization on 55 generated use–cases (with solution spaces ranging from 1030 to 3070) and benchmark the results against best performing random configurations. Results: The performance of a configuration as predicted by our framework matched the configuration implemented and measured on a real–world platform. Furthermore, by applying the genetic algorithm and simulated annealing to the weight function given in SCAF, we obtain sub–optimal software configurations differing in performance at most 7% and 13% from the optimal configuration (respectfully). Conclusion: SCAF is capable of correctly describing a HC platform and reliably predict the performance of software configuration in the early design phase. Automated in the form of an Eclipse plugin, SCAF allows software architects to model architectural constraints and preferences, acting as a multi–criterion software architecture decision support system. In addition to said, we also point out several interesting research directions, to further investigate and improve our approach.}
}
@article{STAVRINIDES2019216,
title = {An energy-efficient, QoS-aware and cost-effective scheduling approach for real-time workflow applications in cloud computing systems utilizing DVFS and approximate computations},
journal = {Future Generation Computer Systems},
volume = {96},
pages = {216-226},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.02.019},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18327353},
author = {Georgios L. Stavrinides and Helen D. Karatza},
keywords = {Quality of Service, Energy efficiency, Real-time workflows, Per-core DVFS, Approximate computations, Scheduling},
abstract = {Green cloud computing attracts significant attention from both academia and industry. One of the major challenges involved, is to provide a high level of Quality of Service (QoS) in a cost-effective way for the end users and in an energy-efficient manner for the cloud providers. Towards this direction, this paper presents an energy-efficient, QoS-aware and cost-effective scheduling strategy for real-time workflow applications in cloud computing systems. The proposed approach utilizes per-core Dynamic Voltage and Frequency Scaling (DVFS) on the underlying heterogeneous multi-core processors, as well as approximate computations, in order to fill in schedule gaps. At the same time, it takes into account the effects of input error on the processing time of the component tasks. Our goal is to provide timeliness and energy efficiency by trading off result precision, while keeping the result quality of the completed jobs at an acceptable standard and the monetary cost required for the execution of the jobs at a reasonable level. The proposed scheduling heuristic is compared to two other baseline policies, under the impact of various QoS requirements. The simulation experiments reveal that our approach outperforms the other examined policies, providing promising results.}
}
@article{JEONG201315,
title = {High availability and efficient energy consumption for cloud computing service with grid infrastructure},
journal = {Computers & Electrical Engineering},
volume = {39},
number = {1},
pages = {15-23},
year = {2013},
note = {Special issue on Recent Advanced Technologies and Theories for Grid and Cloud Computing and Bio-engineering},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2012.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0045790612000456},
author = {Young-Sik Jeong and Jong Hyuk Park},
abstract = {The main services in cloud computing are SaaS (Software as a Service), PaaS (Platform as a Service) and IaaS (Infrastructure as a Service). Among these services, server virtualization falls into IaaS which is a service for lowering server maintenance costs. Generally, the primary aim of server virtualization has been to improve system performance by replacing multiple servers with a single server with better performance. But it carries the problem of increased cost, needed for the installation of new servers for server virtualization. In this paper, grid infrastructure is used for server virtualization in which existing servers are used rather than bringing in new servers. Server virtualization service is provided using scheduling algorithms for distributed servers or resources in grid computing. To overcome potential performance limitations that come from using existing servers, mathematical models of Meta and Sleep Servers under the grid infrastructure environment are used to provide server virtualization service with high availability.}
}
@article{HOFMANN201565,
title = {Sustainability through flexibility: Building complex simulation programs for distributed computing systems},
journal = {Simulation Modelling Practice and Theory},
volume = {58},
pages = {65-78},
year = {2015},
note = {Special Issue on TECHNIQUES AND APPLICATIONS FOR SUSTAINABLE ULTRASCALE COMPUTING SYSTEMS},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2015.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X15000829},
author = {Michael Hofmann and Gudula Rünger},
keywords = {Scientific computing, Distributed simulations, Data coupling, Parallel computing},
abstract = {Complex simulation programs in science and engineering are often built up from a diverse set of existing applications. The large variety of application codes and their high computational demands lead to an increasing utilization of distributed computing systems. Furthermore, the need for developing sustainable simulation programs, especially with regard to ever increasing data sizes, requires a profound flexibility such that application codes and hardware resources can be easily replaced or extended. In this article, we propose a methodology for building complex simulation programs for distributed computing systems. A software library specifically designed to support a client–server-based development of simulation program components is presented. An application example for the simulation and optimization of lightweight structures in mechanical engineering is used to demonstrate the approach.}
}
@article{MALEKLOO20189,
title = {An energy efficient and SLA compliant approach for resource allocation and consolidation in cloud computing environments},
journal = {Sustainable Computing: Informatics and Systems},
volume = {17},
pages = {9-24},
year = {2018},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2018.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2210537917302019},
author = {Mohammad-Hossein Malekloo and Nadjia Kara and May {El Barachi}},
keywords = {Green cloud computing, Virtual machine placement, Virtual machine consolidation, Multi-objective optimization},
abstract = {Cloud computing is a promising paradigm that enables a “computing-as-a-service” model, in which a dynamic pool of virtualized computational resources (e.g. CPU) can be leased and released on demand. With the increased demand for cloud computing infrastructures and the explosion in data center sizes, energy efficiency becomes an important issue to consider. Green cloud computing is an area that focuses on the design of energy efficient data centers, in order to achieve cost savings and minimize negative impacts on the environment. One of the main green cloud computing strategies used for the reduction of energy consumption consists in maximizing the utilization of a number of physical machines (PMs) and turning off or suspending unused servers. This strategy is typically achieved using two types of algorithms: Virtual Machines (VMs) placement and VMs consolidation algorithms. VMs’ placement is a process of dynamically placing VMs onto PMs while satisfying specific VM-to-PM mapping rules. VMs’ consolidation optimizes the resource utilization and groups dispersed VMs on a minimal number of active PMs, based on live migration techniques. Both approaches are time and resource consuming, and are categorized as NP-hard optimization problems. Moreover, reducing energy consumption by means of resource consolidation may reduce the system’s availability and reliability, and lead to SLA violations. Therefore, there is a need for multi-objective optimization approaches that can strike a balance between energy consumption and the system’s ability to meet QoS and SLA requirements. In this work, we propose an energy-aware and QoS-aware multi-objective Ant Colony Optimization (MACO) approach for VM placement and consolidation. Our approach aims at achieving a trade-off between energy efficiency, system performance, and SLA-compliance. The proposed approach was implemented and tested in small to mid-size data center settings, simulated using cloudSim, and was compared with a number of heuristic and meta-heuristic approaches, using eight performance metrics. The results show that our approach outperforms the other tested approaches in terms of energy savings, reduction of resource wastage in term of CPU, reduction of communication cost in term of energy induced by traffic load exchanged between VMs, and minimization of the number of VM migrations and SLA violations – thus demonstrating an ability to balance energy efficiency with system performance and QoS requirements.}
}
@article{ABUSHARKH2017199,
title = {An evergreen cloud: Optimizing energy efficiency in heterogeneous cloud computing architectures},
journal = {Vehicular Communications},
volume = {9},
pages = {199-210},
year = {2017},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2017.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S2214209616300717},
author = {Mohamed {Abu Sharkh} and Abdallah Shami},
keywords = {Cloud computing, Energy efficiency, Scalability, Virtualization, Network and systems monitoring and measurements},
abstract = {In a heterogeneous Cloud network scenario where a Cloud computing data center serves mobile Cloud computing requests, Cloud providers are expected to implement more innovative and effective solutions for a list of long standing challenges. Energy efficiency in the Cloud data center is one of the more pressing issues near the top of that list. Cloud providers are in constant pursuit of a system that satisfies client demands for resources, maximizes availability and other service level agreement metrics while minimizing energy consumption and, in turn, minimizing Cloud providers' cost. In this work, we introduce a novel mathematical optimization model to solve the problem of energy efficiency in a cloud data center. Next, we offer a solution based on VM migration that tackles this problem and minimizes energy efficiency in comparison to other common solutions. This solution includes a novel proposed technique to be integrated in any consolidation-based energy efficiency solution. This technique depends on dynamic idleness prediction (DIP) using machine learning classifiers. Moreover, we offer a robust energy efficiency scheduling solution that does not depend on live migration. This technique, termed Smart VM Over Provision (SVOP), offers a major advantage to cloud providers in the cases when live migration of VMs is not preferred due to its effects on performance. We evaluate the aforementioned solutions in terms of a number of critical metrics, namely, energy used per server, energy used per served request, acceptance rate, and the number of migrations performed.}
}
@article{MALAKUTI20151,
title = {Introduction to special issue on Software Engineering Aspects of Green Computing (SEAGC)},
journal = {Sustainable Computing: Informatics and Systems},
volume = {7},
pages = {1},
year = {2015},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2015.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2210537915000153},
author = {Somayeh Malakuti and Wolfgang Lohmann and Mehmet Aksit}
}
@article{ALDOSSARY2019442,
title = {Energy-aware cost prediction and pricing of virtual machines in cloud computing environments},
journal = {Future Generation Computer Systems},
volume = {93},
pages = {442-459},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.10.027},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18310288},
author = {Mohammad Aldossary and Karim Djemame and Ibrahim Alzamil and Alexandros Kostopoulos and Antonis Dimakis and Eleni Agiatzidou},
keywords = {Cloud computing, Energy efficiency, Cost estimation, Workload prediction, Energy prediction, Pricing schemes},
abstract = {With the increasing cost of electricity, Cloud providers consider energy consumption as one of the major cost factors to be maintained within their infrastructure. Consequently, various proactive and reactive management mechanisms are used to efficiently manage the cloud resources and reduce the energy consumption and cost. These mechanisms support energy-awareness at the level of Physical Machines (PM) as well as Virtual Machines (VM) to make corrective decisions. This paper introduces a novel Cloud system architecture that facilitates an energy aware and efficient cloud operation methodology and presents a cost prediction framework to estimate the total cost of VMs based on their resource usage and power consumption. The evaluation on a Cloud testbed show that the proposed energy-aware cost prediction framework is capable of predicting the workload, power consumption and estimating total cost of the VMs with good prediction accuracy for various Cloud application workload patterns. Furthermore, a set of energy-based pricing schemes are defined, intending to provide the necessary incentives to create an energy-efficient and economically sustainable ecosystem. Further evaluation results show that the adoption of energy-based pricing by cloud and application providers creates additional economic value to both under different market conditions.}
}
@article{VAFAMEHR201840,
title = {Energy-aware cloud computing},
journal = {The Electricity Journal},
volume = {31},
number = {2},
pages = {40-49},
year = {2018},
issn = {1040-6190},
doi = {https://doi.org/10.1016/j.tej.2018.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1040619017302804},
author = {Ali Vafamehr and Mohammad E. Khodayar},
keywords = {Cloud computing, Cloud providers, Data center, Energy market},
abstract = {Cloud computing, as a trending model for the information technology, provides unique features and opportunities including scalability, broad accessibility and dynamic provision of computing resources with limited capital investments. This paper presents the criteria, assets, and models for energy-aware cloud computing practices and envisions a market structure that addresses the impact of the quality and price of energy supply on the quality and cost of cloud computing services. Energy management practices for cloud providers at the macro and micro levels to improve the cost and reliability of cloud services are presented.}
}
@article{CHOUDHARY2016132,
title = {A Critical Analysis of Energy Efficient Virtual Machine Placement Techniques and its Optimization in a Cloud Computing Environment},
journal = {Procedia Computer Science},
volume = {78},
pages = {132-138},
year = {2016},
note = {1st International Conference on Information Security & Privacy 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916000247},
author = {Ankita Choudhary and Shilpa Rana and K.J. Matahai},
keywords = {Energy efficiency, Virtualization, Dynamic consolidation, Virtual Machine Placement, Live Migration},
abstract = {Infrastructure-as-a-service cloud computing providers with on-demand infrastructures have become a promising alternative to the rising cost of ownership for computing infrastructures in many enterprises. Many of the touted gains in the cloud model come from resource multiplexing through virtualization technology that allows cloud-scale datacenters to improve resource utilization and energy efficiency. This paper provides a critical analysis on the basis of literature review of the state-of-the-art research on energy efficient dynamic allocation of virtual machines to hosts in a datacenter as per variable workload demands of different application running on the virtual machines and literature review suggests that further optimization of the virtual machine placement can be done using live migration. So, this paper proposes a technique for optimizing virtual machine placement by live migration using dynamic threshold values ensuring a deadlock free resource allocation focusing on multidimensional resources. The goal is to improve the overall utilization of computing resources thus reducing the energy consumption of datacenter.}
}
@article{PROCACCIANTI20152,
title = {A systematic literature review on energy efficiency in cloud software architectures},
journal = {Sustainable Computing: Informatics and Systems},
volume = {7},
pages = {2-10},
year = {2015},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2014.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S2210537914000900},
author = {Giuseppe Procaccianti and Patricia Lago and Stefano Bevini},
keywords = {Cloud computing, Energy efficiency, Green software, Software architecture},
abstract = {Cloud-based software architectures introduce more complexity and require new competences for migration, maintenance, and evolution. Although cloud computing is often considered as an energy-efficient technology, the implications of cloud-based software on energy efficiency lack scientific evidence. At the same time, energy efficiency is becoming a crucial requirement for cloud service provisioning, as energy costs significantly contribute to the Total Cost of Ownership (TCO) of a data center. In this paper, we present the results of a systematic literature review that investigates cloud software architectures addressing energy efficiency as a primary concern. The aim is to provide an analysis of the state-of-the-art in the field of energy-efficient software architectures.}
}
@article{VARGA2018354,
title = {Deadline scheduling algorithm for sustainable computing in Hadoop environment},
journal = {Computers & Security},
volume = {76},
pages = {354-366},
year = {2018},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2017.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0167404818300038},
author = {Mihai Varga and Alina Petrescu-Nita and Florin Pop},
keywords = {Scheduling, Distributed systems, Deadline scheduling, Hadoop, Energy efficiency, Sustainable computing},
abstract = {Cloud computing is popular choice for processing and analyzing large amounts of data. Organizations can easily manage and deploy powerful clusters that run different software environments and enable distributed processing. Scheduling is an important part of distributed computing that allows users to leverage the available resources for a faster computation time. In this paper we propose a generic scheduling algorithm that takes deadline constraints into consideration. We develop a cost model that estimates the remaining work load which allows the scheduler to properly prioritize jobs according to their upcoming deadlines. The cost model works with generic abstract resources requests such as virtual cores, memory and containers and determines the remaining running time based on the completed tasks. We validate the cost model and measure the performance of the scheduler by running several experiments on a cluster on Amazon EC2 and our algorithm performs as expected under different scenarios.}
}
@article{BENKHELIFA20151159,
title = {User Profiling for Energy Optimisation in Mobile Cloud Computing},
journal = {Procedia Computer Science},
volume = {52},
pages = {1159-1165},
year = {2015},
note = {The 6th International Conference on Ambient Systems, Networks and Technologies (ANT-2015), the 5th International Conference on Sustainable Energy Information Technology (SEIT-2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.151},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915009515},
author = {Elhadj Benkhelifa and Thomas Welsh and Loai Tawalbeh and Yaser Jararweh and Anas Basalamah},
keywords = {Mobile-Cloud-Computing, Energy, Profiling, Optimisation, Smartphone, Networks.},
abstract = {Both mobile and cloud computing are two areas which are rapidly expanding in terms of use case and functionality.Both mobile and cloud computing are two areas which are rapidly expanding in terms of use case and functionality. This paper reviews current work in energy consumption of mobile cloud computing and then proposes a system whereby user applications may be profiled for their resource consumption locally and then if augmentation is required, they may negotiate with an external cloud for optimum energy consumption. Such a system is particularly useful for cloudlets which contain constrained resources so may need to choose between a number of clients. Whilst mobile computing enables a variety of feature rich functionality for users in a non-fixed location, cloud computing is revolutionising the way in which computing resources are being provisioned, used and optimised for both service providers and end users. These two fields are being combined in order to provide greater functionality for mobile devices in a number of different ways. Augmentation of mobile resources from the cloud has been shown as one way in which the energy consumption and power of mobile devices may be considerably enhanced. However, due to the resource constrained nature of the devices, in particular their power source and communication interfaces, there is often a fine line where offloading of these resources is economical.}
}
@article{KHAYYAM2013971,
title = {Intelligent battery energy management and control for vehicle-to-grid via cloud computing network},
journal = {Applied Energy},
volume = {111},
pages = {971-981},
year = {2013},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2013.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S030626191300528X},
author = {Hamid Khayyam and Jemal Abawajy and Bahman Javadi and Andrzej Goscinski and Alex Stojcevski and Alireza Bab-Hadiashar},
keywords = {Intelligent battery energy management, Intelligent scheduling, Fuzzy logic prediction, Cloud computing, Vehicle to grid, Battery energy management and control},
abstract = {Plug-in Electric Vehicles (PEVs) provide new opportunities to reduce fuel consumption and exhaust emission. PEVs need to draw and store energy from an electrical grid to supply propulsive energy for the vehicle. As a result, it is important to know when PEVs batteries are available for charging and discharging. Furthermore, battery energy management and control is imperative for PEVs as the vehicle operation and even the safety of passengers depend on the battery system. Thus, scheduling the grid power electricity with parking lots would be needed for efficient charging and discharging of PEV batteries. This paper aims to propose a new intelligent battery energy management and control scheduling service charging that utilize Cloud computing networks. The proposed intelligent vehicle-to-grid scheduling service offers the computational scalability required to make decisions necessary to allow PEVs battery energy management systems to operate efficiently when the number of PEVs and charging devices are large. Experimental analyses of the proposed scheduling service as compared to a traditional scheduling service are conducted through simulations. The results show that the proposed intelligent battery energy management scheduling service substantially reduces the required number of interactions of PEV with parking lots and grid as well as predicting the load demand calculated in advance with regards to their limitations. Also it shows that the intelligent scheduling service charging using Cloud computing network is more efficient than the traditional scheduling service network for battery energy management and control.}
}
@article{SHARMA201666,
title = {Reliability and energy efficiency in cloud computing systems: Survey and taxonomy},
journal = {Journal of Network and Computer Applications},
volume = {74},
pages = {66-85},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516301746},
author = {Yogesh Sharma and Bahman Javadi and Weisheng Si and Daniel Sun},
keywords = {Cloud computing, Virtualization, Reliability, Energy efficiency, Resource failure, Failure correlation},
abstract = {With the popularity of cloud computing, it has become crucial to provide on-demand services dynamically according to the user's requirements. Reliability and energy efficiency are two key challenges in cloud computing systems (CCS) that need careful attention and investigation. The recent survey articles are either focused on the reliability techniques or energy efficiency methods in cloud computing. This paper presents a thorough review of existing techniques for reliability and energy efficiency and their trade-off in cloud computing. We also discuss the classifications on resource failures, fault tolerance mechanisms and energy management mechanisms in cloud systems. Moreover, various challenges and research gaps in trade-off between reliability and energy efficiency are identified for future research and developments.}
}
@article{ABBAS2018204,
title = {Systems thinking for developing sustainable complex smart cities based on self-regulated agent systems and fog computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {19},
pages = {204-213},
year = {2018},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2018.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2210537918300295},
author = {Hosny Abbas and Samir Shaheen and Mohamed Elhoseny and Amit Kumar Singh and Majid Alkhambashi},
keywords = {Smart cities, Systems thinking, Future smart applications, Macro-Micro management, Self-Regulating multi-agent systems, Fog computing},
abstract = {As the gap between digital and physical worlds getting dwindled as a result of the dramatic advance getting achieved in information and communication technology (ICT), feasible, efficient, reliable, and secure smart cities are becoming a reality. Future smart cities will be characterized by their high distribution, openness, heterogeneity, complexity, unpredictable/uncertain/dynamic work environments, and their large-scale nature. These challenging characteristics require a transition from the traditional parts thinking paradigm which studies systems by breaking them down into their separate elements to the emerging systems thinking paradigm which represents a holistic approach focuses on the way that a system's constituent parts interrelate and how systems work over time and within the context of larger systems. In this article, we first study smart cities from systems thinking perspective and then introduce self-regulating agent systems and fog computing as promising technological paradigms for developing future large-scale complex smart cities applications. Preliminary simulation results to test the performance of the proposed framework are provided. The results show that self-regulated agent systems can give high performance if an appropriate self-regulation model is used. A complete architecture for building future complex smart cities based on the systems thinking paradigm and using self-regulating MAS integrated with fog computing for implementation is currently under preparation.}
}
@article{LEYH2014386,
title = {Sustainability management and its software support in selected Italian enterprises},
journal = {Computers in Industry},
volume = {65},
number = {3},
pages = {386-392},
year = {2014},
note = {ICT for Sustainability in Industry},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2014.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0166361514000219},
author = {Christian Leyh and Matteo Rossetto and Mario Demez},
keywords = {Sustainability management, ERP systems, Environmental management information systems, EMIS, Multiple-case study},
abstract = {Sustainability is a very important factor in long-term entrepreneurial success. Company-wide sustainability management is mandatory and requires software support if it is to be conducted efficiently. This paper aims to investigate the approaches and instruments that selected Italian enterprises have implemented for company-wide sustainability management. We conducted a multiple-case study of 30 selected companies. The results show that the selection and deployment of sustainability instruments differ from enterprise to enterprise. However, all of the enterprises studied exhibited substantial uncertainty about the extent of possible future governmental regulations that would necessitate adaptations to existing systems, causing high costs and requiring large resource deployments. This is why software support of sustainability instruments is often managed using Excel-based solutions. The absence of governmental regulations is clearly constraining the technological development and enhancement of enterprise-wide software support for sustainability management instruments.}
}
@article{KE2017497,
title = {Cloud computing platform for real-time measurement and verification of energy performance},
journal = {Applied Energy},
volume = {188},
pages = {497-507},
year = {2017},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2016.12.034},
url = {https://www.sciencedirect.com/science/article/pii/S0306261916317974},
author = {Ming-Tsun Ke and Chia-Hung Yeh and Cheng-Jie Su},
keywords = {Real-time energy performance, Measurement and verification, Cloud computing, Particle swarm optimization},
abstract = {Nations worldwide are vigorously promoting policies to improve energy efficiency. The use of measurement and verification (M&V) procedures to quantify energy performance is an essential topic in this field. Currently, energy performance M&V is accomplished via a combination of short-term on-site measurements and engineering calculations. This requires extensive amounts of time and labor and can result in a discrepancy between actual energy savings and calculated results. In addition, the M&V period typically lasts for periods as long as several months or up to a year, the failure to immediately detect abnormal energy performance not only decreases energy performance, results in the inability to make timely correction, and misses the best opportunity to adjust or repair equipment and systems. In this study, a cloud computing platform for the real-time M&V of energy performance is developed. On this platform, particle swarm optimization and multivariate regression analysis are used to construct accurate baseline models. Instantaneous and automatic calculations of the energy performance and access to long-term, cumulative information about the energy performance are provided via a feature that allows direct uploads of the energy consumption data. Finally, the feasibility of this real-time M&V cloud platform is tested for a case study involving improvements to a cold storage system in a hypermarket. Cloud computing platform for real-time energy performance M&V is applicable to any industry and energy conservation measure. With the M&V cloud platform, real-time and long-term energy performances can be obtained. By tracking fluctuations in energy performance, real-time monitoring or correction of the operating performance of equipment or system can help to maintain good energy performance. Thus, real-time energy management can be accomplished based on the above attributes. In addition, the cloud computing platform developed in this research can improve our national M&V level. Specifically, it helps government in promoting energy efficiency programs and the development of energy service industries.}
}
@article{DEALFONSO2013704,
title = {An economic and energy-aware analysis of the viability of outsourcing cluster computing to a cloud},
journal = {Future Generation Computer Systems},
volume = {29},
number = {3},
pages = {704-712},
year = {2013},
note = {Special Section: Recent Developments in High Performance Computing and Security},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2012.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X12001720},
author = {Carlos {de Alfonso} and Miguel Caballer and Fernando Alvarruiz and Germán Moltó},
keywords = {Cloud computing, Cluster computing, Green computing, Cost analysis},
abstract = {This paper compares the total cost of ownership of a physical cluster with the cost of a virtual cloud-based cluster. For that purpose, cost models for both a physical cluster and a cluster on a cloud have been developed. The model for the physical cluster takes into account previous works and incorporates a more detailed study of the costs related to energy consumption and the usage of energy-saving strategies. The model for the cluster on a cloud considers pricing options offered by Amazon EC2, such as reserving instances on a long-term basis, and also considers using tools for powering nodes on and off on demand, in order to avoid the costs associated to keeping idle nodes running. Using these cost models, a comparison is made of physical clusters with cloud clusters of a similar size and performance. The results show that cloud clusters are an interesting option for start-ups and other organizations with a high degree of uncertainty with respect to the computational requirements, while physical clusters are still more economically viable for organizations with a high usage rate.}
}
@article{SULPIZIO2008263,
title = {Discriminating the long distance dispersal of fine ash from sustained columns or near ground ash clouds: The example of the Pomici di Avellino eruption (Somma-Vesuvius, Italy)},
journal = {Journal of Volcanology and Geothermal Research},
volume = {177},
number = {1},
pages = {263-276},
year = {2008},
note = {Explosive volcanism in the central Mediterranean area during the late Quaternary - linking sources and distal archives},
issn = {0377-0273},
doi = {https://doi.org/10.1016/j.jvolgeores.2007.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0377027307003629},
author = {Roberto Sulpizio and Rosanna Bonasia and Pierfrancesco Dellino and Mauro A. {Di Vito} and Luigi {La Volpe} and Daniela Mele and Giovanni Zanchetta and Laura Sadori},
keywords = {Pomici di Avellino eruption, ash dispersal, atmosphere dynamics, volcanic hazard, tephra layers},
abstract = {Ash samples from tephra layers correlated with the Pomici di Avellino (Avellino Pumice) eruption of Somma-Vesuvius were collected in distal archives and their composition and particle morphology investigated in order to infer their behaviour of transportation and deposition. Differences in composition and particle morphologies were recognised for ash particles belonging to the magmatic Plinian and final phreatomagmatic phases of the eruption. The ash particles were dispersed in opposite directions during the two different phases of the eruption, and these directions are also different from that of coarse-grained fallout deposits. In particular, ash generated during magmatic phase and injected in the atmosphere to form a sustained column shows a prevailing SE dispersion, while ash particles generated during the final phreatomagmatic phase and carried by pyroclastic density currents show a general NW dispersion. These opposite dispersions indicate an ash dispersal influenced by both high and low atmosphere dynamics. In particular, the magmatic ash dispersal was first driven by stratospheric wind towards NE and then the falling particles encountered a variable wind field during their settling, which produced the observed preferential SE dispersal. The wind field encountered by the rising ash clouds that accompanied the pyroclastic density currents of the final phreatomagmatic phase was different with respect to that encountered by the magmatic ash, and produced a NW dispersal. These data demonstrate how ash transportation and deposition are greatly influenced by both high and low atmosphere dynamics. In particular, fine-grained particles transported in ash clouds of small-scale pyroclastic density currents may be dispersed over distances and cover areas comparable with those injected into the stratosphere by Plinian, sustained columns. This is a point not completely addressed by present day mitigation plans in case of renewal of activity at Somma-Vesuvius, and can yield important information also for other volcanoes potentially characterised by explosive activity.}
}
@article{YANG201711,
title = {Cloud computing-based energy optimization control framework for plug-in hybrid electric bus},
journal = {Energy},
volume = {125},
pages = {11-26},
year = {2017},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2017.02.102},
url = {https://www.sciencedirect.com/science/article/pii/S0360544217302840},
author = {Chao Yang and Liang Li and Sixiong You and Bingjie Yan and Xian Du},
keywords = {Plug-in hybrid electric bus, Energy optimization control framework, Driving conditions clustering, Energy management, Stochastic receding horizon control},
abstract = {Considering the complicated characteristics of traffic flow in city bus route and the nonlinear vehicle dynamics, optimal energy management integrated with clustering and recognition of driving conditions in plug-in hybrid electric bus is still a challenging problem. Motivated by this issue, this paper presents an innovative energy optimization control framework based on the cloud computing for plug-in hybrid electric bus. This framework, which includes offline part and online part, can realize the driving conditions clustering in offline part, and the energy management in online part. In offline part, utilizing the operating data transferred from a bus to the remote monitoring center, K-means algorithm is adopted to cluster the driving conditions, and then Markov probability transfer matrixes are generated to predict the possible operating demand of the bus driver. Next in online part, the current driving condition is real-time identified by a well-trained support vector machine, and Markov chains-based driving behaviors are accordingly selected. With the stochastic inputs, stochastic receding horizon control method is adopted to obtain the optimized energy management of hybrid powertrain. Simulations and hardware-in-loop test are carried out with the real-world city bus route, and the results show that the presented strategy could greatly improve the vehicle fuel economy, and as the traffic flow data feedback increases, the fuel consumption of every plug-in hybrid electric bus running in a specific bus route tends to be a stable minimum.}
}
@article{MOGANARANGAN201655,
title = {A novel algorithm for reducing energy-consumption in cloud computing environment: Web service computing approach},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {28},
number = {1},
pages = {55-67},
year = {2016},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2014.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S1319157815000816},
author = {N. Moganarangan and R.G. Babukarthik and S. Bhuvaneswari and M.S. {Saleem Basha} and P. Dhavachelvan},
keywords = {ACO ant colony optimization, CS cuckoo search, VSF voltage scaling factor, EcPSO extended compact particle swarm optimization},
abstract = {Cloud computing slowly gained an important role in scientific application, on-demand facility of virtualized resources is provided as a service with the help of virtualization without any additional waiting time. Energy consumption is reduced for job scheduling problems based on makespan constraint which in turn leads to significant decrease in the energy cost. Additionally, there is an increase in complexity for scheduling problems mainly because the application is not based on makespan constraint. In this paper we propose a new Hybrid algorithm combining the benefits of ACO and cuckoo search algorithm. It is focused on the voltage scaling factor for reduction of energy consumption. Performance of the Hybrid algorithm is considerably increased from 45 tasks onward when compared to ACO. Energy consumed by Hybrid algorithm is measured and energy improvement is evaluated up to 35 tasks. Energy consumption is the same as ACO algorithm because as the number of tasks increases (45 to 70) there is a considerable decrease in the energy consumption rate. Makespan of Hybrid algorithm based on number of tasks is compared with ACO algorithm. Further we have analyzed the energy consumption for a number of processors and its improvement rate – up to 6 processors, energy consumption is considerably reduced and the energy consumption tends to be in steady state with further increase in the number of processors.}
}
@article{LOOMBA201547,
title = {Energy-aware collaborative sensing for multiple applications in mobile cloud computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {8},
pages = {47-59},
year = {2015},
note = {Special Issue on Computing for a Greener Water/Energy/Emissions Nexus; edited by Carol J. Miller.andSpecial Issue on Green Mobile Cloud Computing (Green MCC); edited by Danielo G. Gomes, Rafael Tolosana-Calasanz, and Nazim Agoulmine.},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2015.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S2210537915000384},
author = {Radhika Loomba and Lei Shi and Brendan Jennings and Roy Friedman and John Kennedy and Joe Butler},
keywords = {Mobile cloud, Collaborative sensing, Information aggregation, Frequent pattern mining, Optimization, Human mobility},
abstract = {Modern mobile handsets and the myriad of wearable devices connected to them offer a wide range of sensing capabilities. The ubiquity of such sensing devices offers the potential to realise novel applications based on collaborative sensing, in which application logic makes use of sensor input from a number of handsets, typically distributed across a defined physical area. Such applications will be enabled by mobile cloud computing, with the devices transferring raw or pre-processed sensed data to application logic hosted in the cloud. This results in a trade-off between the quality of the sensed data received by applications and the energy required to transfer data from the mobile handsets. We address this trade-off by considering a scheme in which a collaborative sensing middleware mediates between multiple applications requiring sensed data and the mobile handsets located within a particular physical area. We present and evaluate an algorithm which seeks to maximise the degree to which sensed data transferred from a given mobile device can be served to more than one application. We show that this algorithm leads to better overall performance in terms of energy used than an algorithm which does not aggregate sensed information between applications.}
}
@article{WEN2016144,
title = {Energy-aware dynamical hosts and tasks assignment for cloud computing},
journal = {Journal of Systems and Software},
volume = {115},
pages = {144-156},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216000236},
author = {Yean-Fu Wen},
keywords = {Energy efficiency, Load balance, Performance, Scheduling, Threshold},
abstract = {One feature of MapReduce is to split user request into multiple tasks and then process around multiple datacenters for cloud computing. This study addresses an energy efficiency problem of dynamic cloud hosts (CHs) and task assignments as well as a subset of CH power-on or suspended schedules by controlling the range between the power-on and suspended thresholds for high-energy efficiency. A dynamical CHs and tasks assignment scheme is proposed to reduce the overall system energy consumption. The main concept of the proposed scheme entails setting the thresholds to satisfy the constant and variable traffic loads, nodal load balance, migration overhead, basic required power, and processing power. The reason is the established energy consumption required for initialing power-on and variable rates to keep working. This work evaluates the proposed scheme and compares it with the CHs and tasks assignment schemes to show how the proposed scheme achieves energy efficiency. The simulation results show that the proposed scheme obtains the lowest energy consumption under the tolerable responding time constraints even though the request traffic load is varying. The average improvement rate is 16.3% to balance the number of active hosts and migration overhead as well as 4.8% for task schedule.}
}
@article{MONDAL201725,
title = {P2NoC: Power- and Performance-aware NoC Architectures for Sustainable Computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {16},
pages = {25-37},
year = {2017},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S221053791630230X},
author = {Hemanta Kumar Mondal and Sri Harsha Gade and Raghav Kishore and Sujay Deb},
keywords = {Low power design, Sustainable computing platforms, Power management, On-chip interconnection networks, Power gating, Network performance evaluation},
abstract = {Communication performance over distant nodes and high power consumption are major challenges for efficient Network-on-Chip (NoC) architectures. Wireless NoCs, by augmenting wired topologies with low latency wireless links, overcome performance limitations of conventional NoCs. However, NoC routers and Wireless Interfaces (WIs) consume significant amount of leakage power. The usage of routers in NoC is application dependent and for most applications, performance requirement can be achieved without operating all resources all the time. Similarly, WIs transmitting data over shared channel can be selectively turned off when they are not active. Exploiting these, we propose Power- and Performance-aware NoC (P2NoC) architecture that power gates router elements and WIs depending upon their utilization to reduce leakage power. P2NoC works based on hybrid two-level router utilization estimate; pre-computed and runtime to provide coarse and fine estimate of utilization to maximize power saving while keeping overheads and performance impact to a minimum. We also propose deadlock-free seamless bypass routing strategy with P2NoC to avoid adverse impacts of power gating. P2NoC saves up to 92.20% and 68.23% of leakage power in base and hybrid routers respectively with only 7% area overhead. Based on utilization, P2NoC also reduces total average packet energy consumption by 49% with negligible performance degradation. The proposed solution provides a flexible sustainable computing platform that can be optimized for a wide range of application scenarios.}
}
@article{CHEN2023197,
title = {Developing an intelligent cloud attention network to support global urban green spaces mapping},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {198},
pages = {197-209},
year = {2023},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2023.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0924271623000655},
author = {Yang Chen and Qihao Weng and Luliang Tang and Lei Wang and Hanfa Xing and Qinhuo Liu},
keywords = {Urban green spaces, Urbanization, Sustainable development goals, Cloud removal, Cloud attention intelligent network, Harmonized Landsat-8 and Sentinel-2 data},
abstract = {Urban green spaces (UGS) play an important role in understanding of urban ecosystems, climate, environment, and public health concerns. Satellite derived UGS maps provide an efficient and effective tool for urban studies and contribute to targets and indicators of the sustainable development goals, at the global level, set by the United Nations. However, clouds create a challenging issue in optical satellite image processing, leading to significant uncertainty in UGS mapping. In this study, we propose an automatic UGS mapping method by integrating satellite images with crowdsourced geospatial data while aiming to reduce the uncertainty caused by cloud contamination. The proposed method consists of three parts: (1) auxiliary data pre-processing module; (2) cloud attention intelligent network (CAI-net); and (3) non-cloud scenes classification module. The auxiliary data pre-processing module was used to convert crowdsourcing geospatial data into auxiliary maps. The CAI-net was proposed to retrieve detailed UGS classes within clouds from satellite image patches and auxiliary maps, while non-cloud scenes classification module was used to extract UGS from satellite image patches. The proposed method was applied to generate spatial continuous global UGS map products, considering the uncertainty caused by cloud contamination. The results show the proposed method yielded a high-quality global UGS map with average overall accuracy as high as 92.96% when satellite images had cloud coverage ranging from 0% to 50%. The geospatial AI, specifically CAI-net, can provide more accurate UGS mapping regardless of different geographical and climatic conditions of the study areas, which is especially significant for humid tropical and subtropical regions with frequent clouds and rains.}
}
@article{CUPIAL201564,
title = {Optimisation of the Machinery Park with the Use of OTR-7 Software in Context of Sustainable Agriculture},
journal = {Agriculture and Agricultural Science Procedia},
volume = {7},
pages = {64-69},
year = {2015},
note = {Farm Machinery and Processes Management in Sustainable Agriculture, 7th International Scientific Symposium},
issn = {2210-7843},
doi = {https://doi.org/10.1016/j.aaspro.2015.12.034},
url = {https://www.sciencedirect.com/science/article/pii/S2210784315300346},
author = {Michał Cupiał and Anna Szeląg-Sikora and Marcin Niemiec},
keywords = {machinery park, sustainable agriculture, optimisation, agricultural technology, agricultural software.},
abstract = {The paper presents possibilities for the use of OTR-7 software (Organizer of Agricultural Technology) for optimization of the machinery park equipment in sustainable agriculture. The applied algorithms enable selection of the relevant technical equipment which enables performance of the planned field work. Due to the use of the specialised software, desired economic effects and competitive advantage can be obtained and the risk related to the purchase of expensive equipment can be minimized.}
}
@article{DUAN2017142,
title = {Energy-aware scheduling of virtual machines in heterogeneous cloud computing systems},
journal = {Future Generation Computer Systems},
volume = {74},
pages = {142-150},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16300292},
author = {Hancong Duan and Chao Chen and Geyong Min and Yu Wu},
keywords = {Cloud computing, Resource allocation, Energy efficiency, Fractal prediction model, Resource-intensive applications},
abstract = {With the rapid development of cloud computing, how to reduce energy consumption as well as maintain high computation capacity has become a timely and important challenge. Existing Virtual Machines (VMs) scheduling schemes have mainly focused on enhancing the cluster resource utilization and reducing power consumption by improving the legacy “bin-packing” algorithm. However, different resource-intensive applications running on VMs in realistic scenarios have significant effects on the system performance and energy consumption. Furthermore, instantaneous peak loads may lead to a scheduling error, which can significantly impede the energy efficiency of scheduling algorithms. In this paper, we propose a new scheduling approach named PreAntPolicy that consists of a prediction model based on fractal mathematics and a scheduler on the basis of an improved ant colony algorithm. The prediction model determines whether to trigger the execution of the scheduler by virtue of load trend prediction, and the scheduler is responsible for resource scheduling while minimizing energy consumption under the premise of guaranteeing the Quality-of-Service (QoS). Through extensive analysis and simulation experiments using real workload traces from the compute clusters of Google, the performance results demonstrate that the proposed approach exhibits excellent energy efficiency and resource utilization. Moreover, this approach offers an effective dynamic capacity provisioning model for resource-intensive applications in a heterogeneous computing environment and can reduce the consumption of system resources and energy when scheduling is triggered by instantaneous peak loads.}
}
@article{SUBIRATS201570,
title = {Assessing and forecasting energy efficiency on Cloud computing platforms},
journal = {Future Generation Computer Systems},
volume = {45},
pages = {70-94},
year = {2015},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2014.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X14002428},
author = {Josep Subirats and Jordi Guitart},
keywords = {Cloud computing, Energy efficiency, Ecological efficiency, Forecasting, Green computing, IaaS provider},
abstract = {IaaS providers have become interested in optimising their infrastructure energy efficiency. To do so, their VM placement algorithms need to know the current and future energy efficiency at different levels (Virtual Machine, node, infrastructure and service levels) and for potential actions such as service deployment or VM deployment, migration or cancellation. This publication provides a mathematical formulation for the previous aspects, as well as the design of a CPU utilisation estimator used to calculate the aforementioned forecasts. The correct adjustment of the estimators’ configuration parameters has been proved to lead to considerable precision improvements. When running Web workloads, estimators focused on noise filtering provide the best precision even if they react slowly to changes, whereas reactive predictors are desirable for batch workloads. Furthermore, the precision when running batch workloads partially depends on each execution. Finally, it has been observed that the forecasts precision degradation as such forecasts are performed for a longer time period in the future is smaller when running web workloads.}
}
@article{TIAN20181230,
title = {Confidentiality preservation in user-side integrated energy system management for cloud computing},
journal = {Applied Energy},
volume = {231},
pages = {1230-1245},
year = {2018},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2018.09.068},
url = {https://www.sciencedirect.com/science/article/pii/S0306261918313722},
author = {Nianfeng Tian and Tao Ding and Yongheng Yang and Qinglai Guo and Hongbin Sun and Frede Blaabjerg},
keywords = {Cloud computing, Energy hub, Integrated energy management, Information masking},
abstract = {Under the development of information and communication technologies, this paper discusses a cloud-based user-side integrated energy management to improve the energy utilization efficiency in a smart community, for which a two-level model is proposed that relies on an energy hub and load aggregators. Furthermore, to address the issue of preserving confidentiality for the cloud service, an information-masking mechanism is designed based on linear mapping functions, whose information-masking requirements and processes are specified accordingly. Numerical results demonstrate the effectiveness of the proposed model and of the method for cloud computing.}
}
@article{ESFANDIARPOOR201574,
title = {Structure-aware online virtual machine consolidation for datacenter energy improvement in cloud computing},
journal = {Computers & Electrical Engineering},
volume = {42},
pages = {74-89},
year = {2015},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2014.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S004579061400233X},
author = {Sina Esfandiarpoor and Ali Pahlavan and Maziar Goudarzi},
keywords = {Cloud computing, Consolidation, Datacenter, Energy efficiency, Service-level agreements, Virtual machine},
abstract = {The necessity and significance of improving the energy efficiency of cloud implementations have increased due to the rapid growth and proliferation of cloud computing services around the world. Virtual machines (VMs) comprise the backend of most, if not all, cloud computing services. Several VMs are often consolidated on a physical machine to efficiently utilize its resources. In this paper, we take into account the cooling and network structure of the datacenter host ing the physical machines when consolidating the VMs so that fewer racks and routers are employed, without compromising the service-level agreements; consequently, idle routing and cooling equipment can be turned off in order to reduce the energy consumption. Our experimental results on four benchmarks show that the proposed techniques improve energy consumption of servers, network equipment, and cooling systems by 2.5%, 18.8%, and 28.2% respectively compared to state of the art, resulting in a total of 14.7% energy improvement on average in the entire datacenter.}
}
@article{GU201889,
title = {Greening cloud data centers in an economical way by energy trading with power grid},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {89-101},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.12.029},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16308330},
author = {Chonglin Gu and Longxiang Fan and Wenbin Wu and Hejiao Huang and Xiaohua Jia},
keywords = {Green, Cloud, Data Center, Renewable Energy, Energy Trading},
abstract = {In this paper, we mainly study the issues of green scheduling for cloud data centers in an economical way by energy trading with the power grid. The data centers can be powered by the self-generated wind or solar energy, or by the energy purchased from the renewable power plant. The renewable energy can be used to power the data centers directly, or stored into ESDs (Energy Storage Devices) for later use, or sell back to the power grid to finance part of the high energy expenditure of the data centers. It is hard to make decisions on the usage of each type of energy considering dynamic resource demand of different types of requests, time-varying and location-varying electricity prices, and intermittent supply of renewable energy in each time slot. We focus on two optimization problems: (1) Minimizing total energy cost through scheduling of requests, servers, and the usage of different energy sources. (2) Minimizing total carbon emissions within the budget of energy cost. We formulate each problem as an optimization problem during the whole period of time. Our simulation is based on traces from real world. Experiment results show that our scheduling methods can significantly reduce the carbon emissions for cloud data centers.}
}
@article{LIU2015161,
title = {Tradeoff between energy and user experience for multimedia cloud computing},
journal = {Computers & Electrical Engineering},
volume = {47},
pages = {161-172},
year = {2015},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2015.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0045790615001445},
author = {Yunchang Liu and Chunlin Li and Zhiyong Yang},
keywords = {Quality of experience, Energy, Resource provisioning, Multimedia cloud},
abstract = {Cloud computing provides an effective approach to deliver multimedia services to end users with the desired user quality of experience (QoE). However, cloud-based multimedia applications require many of servers and consume huge energy. To reduce energy consumption, a multimedia service provider (MSP) should balance the energy and QoE. In this paper, a theoretic model is developed to explore the trade-off between energy consumption and QoE for multimedia cloud. Based on objective factor, a QoE quantifying model is proposed. Employing Lyapunov Optimization techniques, an optimal control framework is designed and analyzed to make energy and QoE decisions in MSPs. An approximate online algorithm (EUE-RP) is proposed with the explicitly provable performance upper bound. Extensive experiments have been conducted to verify the effectiveness of EUE-RP algorithm in the practical settings. The algorithm can guarantee desired QoE and reduce energy consumption, even without any information about the future fluctuation of user demands.}
}
@article{MAO2018233,
title = {A multi-resource task scheduling algorithm for energy-performance trade-offs in green clouds},
journal = {Sustainable Computing: Informatics and Systems},
volume = {19},
pages = {233-241},
year = {2018},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2018.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S2210537918300064},
author = {Li Mao and Yin Li and Gaofeng Peng and Xiyao Xu and Weiwei Lin},
keywords = {Energy-performance, Green cloud, Multi-resource, Task scheduling, Time greedy},
abstract = {Previous studies on task scheduling for cloud computing mostly focused on either energy saving or upgrading performance only. However, with the development of cloud computing, users’ demand becomes more and more diversified and difficult to meet with some previous studies’ ideas. In this paper, we first introduce two good-quality algorithms: a time-aware algorithm and an energy-aware algorithm, which are designed for task scheduling in a heterogeneous environment. Secondly, based on the two algorithms, we propose to combine them and design a new algorithm named Energy-Performance Trade-Off Multi-Resource Cloud Task Scheduling Algorithm (namely ETMCTSA). Users can flexibly manage and control the energy and performance of a cloud system via tuning the probability parameterαof the algorithm. Thus, it realizes the goal of focusing on reducing energy consumption or saving time according to users’ will. We conducted the simulated experiments based on MultiRECloudSim and evaluated ETMCTSA with several other task scheduling algorithms. The experimental results indicate that with a pre-specified α, users can tune ETMCTSA inclining to be more energy efficient or more time efficient.}
}
@article{HEIDARI2023100859,
title = {A green, secure, and deep intelligent method for dynamic IoT-edge-cloud offloading scenarios},
journal = {Sustainable Computing: Informatics and Systems},
volume = {38},
pages = {100859},
year = {2023},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2023.100859},
url = {https://www.sciencedirect.com/science/article/pii/S2210537923000148},
author = {Arash Heidari and Nima Jafari Navimipour and Mohammad Ali Jabraeil Jamali and Shahin Akbarpour},
keywords = {Green Offloading, Deep Learning, IoT, Smart Edge, Blockchain},
abstract = {To fulfill people's expectations for smart and user-friendly Internet of Things (IoT) applications, the quantity of processing is fast expanding, and task latency constraints are becoming extremely rigorous. On the other hand, the limited battery capacity of IoT objects severely affects the user experience. Energy Harvesting (EH) technology enables green energy to offer a continuous energy supply for IoT objects. It provides a solid assurance for the proper functioning of resource-constrained IoT objects when combined with the maturation of edge platforms and the development of parallel computing. The Markov Decision Process (MDP) and Deep Learning (DL) are used in this work to solve dynamic online/offline IoT-edge offloading scenarios. The suggested system may be used in both offline and online contexts and meets the user's quality of service expectations. Also, we investigate a blockchain scenario in which edge and cloud could work toward task offloading to address the tradeoff between limited processing power and high latency while ensuring data integrity during the offloading process. We provide a double Q-learning solution to the MDP issue that maximizes the acceptable offline offloading methods. During exploration, Transfer Learning (TL) is employed to quicken convergence by reducing pointless exploration. Although the recently promoted Deep Q-Network (DQN) may address this space complexity issue by replacing the huge Q-table in standard Q-learning with a Deep Neural Network (DNN), its learning speed may still be insufficient for IoT apps. In light of this, our work introduces a novel learning algorithm known as deep Post-Decision State (PDS)-learning, which combines the PDS-learning approach with the classic DQN. The system component in the proposed system can be dynamically chosen and modified to decrease object energy usage and delay. On average, the proposed technique outperforms multiple benchmarks in terms of delay by 4.5%, job failure rate by 5.7%, cost by 4.6%, computational overhead by 6.1%, and energy consumption by 3.9%.}
}
@article{KONG2011241,
title = {Software-based tool path evaluation for environmental sustainability},
journal = {Journal of Manufacturing Systems},
volume = {30},
number = {4},
pages = {241-247},
year = {2011},
note = {Selected Papers of 39th North American Manufacturing Research Conference},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2011.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278612511000707},
author = {Daeyoung Kong and Seungchoun Choi and Yusuke Yasui and Sushrut Pavanaskar and David Dornfeld and Paul Wright},
keywords = {CNC machining, Greenhouse gas emissions, Tool-path evaluation, Energy consumption},
abstract = {Currently available life cycle assessment (LCA) tools provide only a rough estimation of the environmental impact of different manufacturing operations (e.g. energy consumption). To address this limitation, a web-based and application programming interface (API) based process analysis software tools were developed to estimate the energy consumption of a computer numerically controlled (CNC) machine tool operation and to evaluate its environmental impact as a first step towards sustainable manufacturing analysis. Acceleration/deceleration of machine tool axes and the direction of axes movement were considered to estimate the total energy demand and processing time of the machine tool operation. Several tool path generation schemes were tested to analyze the energy consumption and resulting green house gas emission of CNC machine tool operation. It showed that tool path generation schemes affect the amount of energy and the processing time required to machine the same part, and location of the machining resulted in different amount and characteristics of green house gas emission.}
}
@article{SHARMA2019620,
title = {Failure-aware energy-efficient VM consolidation in cloud computing systems},
journal = {Future Generation Computer Systems},
volume = {94},
pages = {620-633},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.11.052},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1831700X},
author = {Yogesh Sharma and Weisheng Si and Daniel Sun and Bahman Javadi},
keywords = {Cloud computing, Failures, Reliability, Energy consumption, Checkpointing, VM consolidation, VM migration, Failure prediction, Bag of Tasks},
abstract = {VM consolidation is an important technique used in cloud computing systems to improve energy efficiency. It migrates the running VMs from under utilized physical resources to other resources in order to reduce the energy consumption. But in a cloud computing environment with failure prone resources, focusing solely on energy efficiency has adverse effects. If the reliability factor of resources is ignored then the running VMs may get consolidated to unreliable physical resources. This will cause more failures and recreations of VMs, thus increasing the energy consumption. To solve this problem, this paper proposes a failure-aware VM consolidation mechanism, which takes the occurrence of failures and the hazard rate of physical resources into consideration before performing VM consolidation. We proposed a failure prediction technique based on exponential smoothing to trigger two fault tolerance mechanisms (VM migration and VM checkpointing). A simulation based evaluation of the proposed VM consolidation mechanism was conducted by using real failure traces. The results demonstrate that by using the combination of checkpointing and VM migration with the proposed failure-aware VM consolidation mechanism, the energy consumption of cloud computing system is reduced by 34% and reliability is improved by 12% while decreasing the occurrence of failures by 14%.}
}
@article{DEROUICHE2019387,
title = {FCA-based Energy Aware-data Placement Strategy for Intensive Workflow in Cloud Computing.},
journal = {Procedia Computer Science},
volume = {159},
pages = {387-397},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.193},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919313754},
author = {Rihab Derouiche and Zaki Brahmi and Mohamed Mohsen Gammoudi},
keywords = {data placement, intensive workflow, Cloud Computing, FCA, energy, communication, granularity, network},
abstract = {Intensive workflows require a lot of computational resources and massive data movement between Storage and Computing servers hosting these datasets and tasks. Moving these datasets among these servers may increase the execution time, generate a high energy consumption by communication devices and a significant data movement cost. Thus, we need a good data placement strategy (DPS) to minimize the data movement between these servers, the communication energy consumption and the workflow execution time and cost. In this paper, we propose a data placement strategy based on the Formal Concept Analysis approach that considers the original datasets, the different communication levels (switches, routers) and the granularity of used resources in data center. It aims at grouping the maximum of datasets and tasks in a minimal number of Storage computing Servers (SC) as close as possible to each other. Simulations show that our strategy can greatly reduce the energy consumed by communication devices, the volume of data movement as well as the execution time and cost of the workflow.}
}
@article{MEKALA2019227,
title = {Energy-efficient virtual machine selection based on resource ranking and utilization factor approach in cloud computing for IoT},
journal = {Computers & Electrical Engineering},
volume = {73},
pages = {227-244},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2018.11.021},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618315611},
author = {Mahammad Shareef Mekala and P Viswanathan},
keywords = {Cloud computing, Resource requirement rate, CRB Ranking, Processing element cost, Task categorization, VM Migration},
abstract = {IoT leads to abrupt variations producing an immense number of data streams for storage, which is a considerable task in the heterogeneous cloud computing environment. Extant techniques consider task deadlines for virtual machine (VM) allocation and migration. This creates a resource famine leading to haphazard and numerous VM migrations, high energy consumption and unbalanced resource utilization. To solve this issue, an energy-efficient resource ranking and utilization factor-based virtual machine selection (ERVS) approach is proposed. ERVS encompasses the resource requirement rate for task classification, comprehensive resource balance ranking, processing element cost and the resource utilization square model for migration. It evaluates overloaded and underloaded hosts and types of VM by predicting CPU utilization rate and energy consumption. Based on this, tasks are sorted and VMs are optimally assigned, which enhances the resource utilization rate, reducing the number of live VM migrations. The experiments evaluate the ability of the proposed approach to diminish energy consumption without violation of service level agreements.}
}
@article{GALLAGHER201926,
title = {IntelliMaV: A cloud computing measurement and verification 2.0 application for automated, near real-time energy savings quantification and performance deviation detection},
journal = {Energy and Buildings},
volume = {185},
pages = {26-38},
year = {2019},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2018.12.034},
url = {https://www.sciencedirect.com/science/article/pii/S037877881832927X},
author = {Colm V. Gallagher and Kevin Leahy and Peter O’Donovan and Ken Bruton and Dominic T.J. O’Sullivan},
keywords = {Energy efficiency, M&V 2.0, Performance verification, Machine learning, Cloud computing},
abstract = {Energy conservation measures (ECMs) are implemented in all sectors with the objective of improving the efficiency with which energy is consumed. Measurement and verification (M&V) is required to verify the performance of every ECM to ensure its successful implementation and operation. The methodologies implemented to achieve this are currently evolving to a more dynamic state, known as measurement and verification 2.0, through the use of automated and advanced analytics. The primary barrier to the adoption of M&V 2.0 practices are the tools available to practitioners. This paper aims to populate the knowledge gap in the industrial buildings sector by presenting a novel cloud computing-based application, IntelliMaV, that applies advanced machine learning techniques on large datasets to automatically verify the performance of ECMs in near real-time. Additionally, a performance deviation detection system is incorporated, ensuring persistence of savings beyond the typical period of analysis in M&V. IntelliMaV allows M&V practitioners to quantify energy savings with minimum levels of uncertainty by applying powerful analytics to data readily available in industrial facilities. The use of a cloud computing-based architecture reduces the resources required on-site and decreases the time required to train the baseline energy model through the use of parallel processing. The robust nature of the application ensures it is applicable across the broad spectrum of ECMs in the industrial buildings sector. A case study carried out in a large biomedical manufacturing facility demonstrates the ease of use of the application and the benefits realised through its adoption. The energy savings from an ECM were calculated to be 2,353,225 kWh/yr with 25.5% uncertainty at a 90% confidence interval.}
}
@article{JARARWEH2018262,
title = {Energy efficient dynamic resource management in cloud computing based on logistic regression model and median absolute deviation},
journal = {Sustainable Computing: Informatics and Systems},
volume = {19},
pages = {262-274},
year = {2018},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2018.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2210537918300118},
author = {Yaser Jararweh and Manar Bani Issa and Mustafa Daraghmeh and Mahmoud Al-Ayyoub and Mohammad A. Alsmirat},
keywords = {Cloud computing, Resource management, Energy efficiency, Dynamic consolidation, Host detection algorithm, Logistic regression, Median absolute deviation},
abstract = {The unprecedented trend of using public cloud computing services by increasing number of customers motivates cloud services providers to optimize their resources usage and management to the limit. This is including managing cloud user’s virtual machines (VM) running on one or more of the thousands of hosting servers or physical machines (PMs) of the cloud datacenters. The cloud service providers are mainly concerned on answering the two main questions that dramatically impact their infrastructure usage and utilization; Where to initially place the VMs and where to move them in case we need to move them. Along with the VM consolidation technique, VMs migration will help in protecting the physical servers from being overloaded or reduce the number of active physical servers for better resources utilization and energy saving. Efficiently detecting overloaded servers will help in improving the cloud system performance and reduce the total operational costs which will provide competitiveness for the cloud provider in the market. In this work, we are proposing a general host overloading detection algorithm based on logistic regression model and median absolute derivation. The proposed algorithm is scalable and can be used with any VM placement and migration algorithms. An extensive evaluation procedure is used with dynamic workload to proof the efficiency of the proposed algorithm. The archived results show that the proposed algorithm outperforms all other known host status prediction techniques.}
}
@article{KLINE2019322,
title = {GreenChip: A tool for evaluating holistic sustainability of modern computing systems},
journal = {Sustainable Computing: Informatics and Systems},
volume = {22},
pages = {322-332},
year = {2019},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2017.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2210537917300823},
author = {Donald Kline and Nikolas Parshook and Xiaoyu Ge and Erik Brunvand and Rami Melhem and Panos K. Chrysanthis and Alex K. Jones},
keywords = {Sustainable computing, Life cycle assessment, Indifference analysis, Embodied energy},
abstract = {There is mounting evidence that manufacturing energy and environmental costs are a growing factor in the overall energy footprint of computing systems. The quantification of these impacts requires the evaluation of both the manufacturing and use phase energy/environmental costs of major integrated circuit (IC) components, including processing units, memory, and storage. In particular, expansions of memory and cache can potentially increase manufacturing costs beyond what can be recovered through use phase advantages for reasonable usage patterns. With this holistic view of sustainability in mind, we provide evaluations of the environmental impacts of memory and cache options for Parsec and SPEC multi-program workloads. Using indifference point analysis, we determine which architectural decisions are the most sustainable in the context of these workloads for various usage scenarios. Through a form of break even analysis, we show the impact of upgrading to a new technology node. Our analysis of current processor trends indicates that upgrading may require upwards of 10 years of service time to break even, and that designing systems with smaller cache and main memory sizes may provide an overall positive environmental trend without dramatically reducing performance.}
}
@article{CASTANE201356,
title = {E-mc2: A formal framework for energy modelling in cloud computing},
journal = {Simulation Modelling Practice and Theory},
volume = {39},
pages = {56-75},
year = {2013},
note = {S.I.Energy efficiency in grids and clouds},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2013.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X13000816},
author = {Gabriel G. Castañé and Alberto Núñez and Pablo Llopis and Jesús Carretero},
keywords = {Cloud computing systems, Energy aware models, Modelling cloud systems},
abstract = {Due to energy crisis of the last years, energy waste and sustainability have been brought both into public attention, and under industry and scientific scrutiny. Thus, obtaining high-performance at a reduced cost in cloud environments as reached a turning point where computing power is no longer the most important concern. However, the emphasis is shifting to manage energy efficiently, whereas providing techniques for measuring energy requirements in cloud systems becomes of capital importance. Currently there are different methods for measuring energy consumption in computer systems. The first consists in using power meter devices, which measure the aggregated power use of a machine. Another method involves directly instrumenting the motherboard with multimeters in order to obtain each power connector’s voltage and current, thus obtaining real-time power consumption. These techniques provide a very accurate results, but they are not suitable for large-scale environments. On the contrary, simulation techniques provide good scalability for performing experiments of energy consumption in cloud environments. In this paper we propose E-mc2, a formal framework integrated into the iCanCloud simulation platform for modelling the energy requirements in cloud computing systems.}
}
@article{ZHOU20161,
title = {Special issue on green networking, computing, and software systems},
journal = {Journal of Network and Computer Applications},
volume = {59},
pages = {1-3},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2015.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S1084804515002647},
author = {Zhang Bing Zhou and Wendong Xiao and Jucheng Yang and Faming Gong}
}
@article{GARCIAMIRELES2018108,
title = {Interactions between environmental sustainability goals and software product quality: A mapping study},
journal = {Information and Software Technology},
volume = {95},
pages = {108-129},
year = {2018},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2017.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0950584917303142},
author = {Gabriel Alberto García-Mireles and Mª Ángeles Moraga and Félix García and Coral Calero and Mario Piattini},
keywords = {Environmental sustainability, Greenability, Interaction, Software product quality, ISO/IEC 25010},
abstract = {Context
Sustainability is considered as either a quality requirement or a quality characteristic that should be included in software when environmental protection concerns are being taken into account. However, addressing sustainability in software projects might have an impact on the quality of the software product delivered. Conflicting goals between sustainability and particular software product characteristics should be studied when developing application software, since achieving users’ requirements can be a hindrance in the quest to meet sustainability goals.
Objective
This paper aims to provide an overview of the approaches found in the literature for dealing with interactions between software product quality and sustainability in the context of application software.
Method
A systematic mapping study is conducted to identify practices for managing interactions between software quality characteristics and sustainability. The selected papers are classified according to the quality characteristic considered and their influence on sustainability.
Results
Most of the 66 selected papers focused on validating current technologies concerning their support for sustainability (46%%). The interaction between performance efficiency and energy efficiency is what is reported most and there is a fairly positive interaction. In addition, reliability and usability point to a positive interaction with energy efficiency, while security shows a conflicting interaction with energy efficiency. Functional suitability and maintainability can present both positive and negative interaction, with different goals derived from environmental sustainability.
Conclusions
Interactions between software quality and sustainability have been addressed within an explorative approach. There is a need for additional research work to characterize the impact of interaction on both software quality and sustainability. Furthermore, proposals should be validated in industrial settings.}
}
@article{SINGH2020100371,
title = {Special issue on networking technologies for sustainable computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {25},
pages = {100371},
year = {2020},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2019.100371},
url = {https://www.sciencedirect.com/science/article/pii/S221053791930397X},
author = {Pradeep Kumar Singh and Bharat Bhargava and Pao Ann Hsuing and Wei-Chiang Hong}
}
@incollection{MARTINGARIN2020235,
title = {10 - IoT and cloud computing for building energy efficiency},
editor = {Fernando Pacheco-Torgal and Erik Rasmussen and Claes-Goran Granqvist and Volodymyr Ivanov and Arturas Kaklauskas and Stephen Makonin},
booktitle = {Start-Up Creation (Second Edition)},
publisher = {Woodhead Publishing},
edition = {Second Edition},
pages = {235-265},
year = {2020},
series = {Woodhead Publishing Series in Civil and Structural Engineering},
isbn = {978-0-12-819946-6},
doi = {https://doi.org/10.1016/B978-0-12-819946-6.00010-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128199466000102},
author = {A. Martín-Garín and J.A. Millán-García and A. Baïri and M. Gabilondo and A. Rodríguez},
keywords = {Building and environmental monitoring, Digitization, Energy efficiency, Internet of things, Low-power wide-area network, Open-source platform},
abstract = {Improving the energy efficiency of buildings is one of the pressing problems that society faces. On the other hand, the acquisition of real-time data of the variables that affect energy consumption is another challenge in the building sector. The high cost of this type of devices, the dearth of instrumentation for the measurement of specific variables, and the lack of interoperability between them represent important barriers that limit the mass deployment of monitoring systems for the improvement of energy efficiency. This chapter deals with the implementation in a case study of a cost-effective, low-power, and long-range Internet of things (IoT) device for real-time monitoring. Due to the great impact that air leakages have on buildings energy demand, this variable has been taken as object of monitoring. To bridge the gap, an Arduino MKR FOX 1200-based device has been developed, which uses the low-power wide-area network Sigfox technology and the SDP810 differential pressure sensor. Then, the monitored data are gathered in the cloud via Google Spreadsheets and shown through an implemented dashboard with Data Studio. This research has shown that the development of open source–based devices supported by IoT technologies fits monitoring requirements in buildings. Energy efficiency of buildings has been the main aim of this work; nevertheless, the presented methodology could be scaled for multiple fields with smart requirements such as agriculture, mobility, healthcare, or safety management.}
}
@article{GAMALIELSSON2014128,
title = {Sustainability of Open Source software communities beyond a fork: How and why has the LibreOffice project evolved?},
journal = {Journal of Systems and Software},
volume = {89},
pages = {128-145},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2013.11.1077},
url = {https://www.sciencedirect.com/science/article/pii/S0164121213002744},
author = {Jonas Gamalielsson and Björn Lundell},
keywords = {Open Source software, Fork, Community evolution},
abstract = {Many organisations are dependent upon long-term sustainable software systems and associated communities. In this paper we consider long-term sustainability of Open Source software communities in Open Source software projects involving a fork. There is currently a lack of studies in the literature that address how specific Open Source software communities are affected by a fork. We report from a study aiming to investigate the developer community around the LibreOffice project, which is a fork from the OpenOffice.org project. In so doing, our analysis also covers the OpenOffice.org project and the related Apache OpenOffice project. The results strongly suggest a long-term sustainable LibreOffice community and that there are no signs of stagnation in the LibreOffice project 33 months after the fork. Our analysis provides details on developer communities for the LibreOffice and Apache OpenOffice projects and specifically concerning how they have evolved from the OpenOffice.org community with respect to project activity, developer commitment, and retention of committers over time. Further, we present results from an analysis of first hand experiences from contributors in the LibreOffice community. Findings from our analysis show that Open Source software communities can outlive Open Source software projects and that LibreOffice is perceived by its community as supportive, diversified, and independent. The study contributes new insights concerning challenges related to long-term sustainability of Open Source software communities.}
}
@incollection{RICCIARDI2013267,
title = {Chapter 10 - Green Data center Infrastructures in the Cloud Computing Era},
editor = {Mohammad S. Obaidat and Alagan Anpalagan and Isaac Woungang},
booktitle = {Handbook of Green Information and Communication Systems},
publisher = {Academic Press},
pages = {267-293},
year = {2013},
isbn = {978-0-12-415844-3},
doi = {https://doi.org/10.1016/B978-0-12-415844-3.00010-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780124158443000103},
author = {Sergio Ricciardi and Francesco Palmieri and Jordi Torres-Viñals and Beniamino {Di Martino} and Germán Santos-Boada and Josep Solé-Pareta}
}