
@inbook{doi:https://doi.org/10.1002/9781118305393.ch16,
author = {Kumar, Saurabh and Buyya, Rajkumar},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781118305393},
title = {Green Cloud Computing and Environmental Sustainability},
booktitle = {Harnessing Green It},
chapter = {16},
pages = {315-339},
doi = {https://doi.org/10.1002/9781118305393.ch16},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118305393.ch16},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118305393.ch16},
year = {2012},
keywords = {Cloud computing, Green IT/computing, Resource allocation and provisioning, Energy efficiency, Carbon footprint, Infrastructure-as-a-service (IaaS), Software-as-a-service (SaaS), Platform-as-a-service (PaaS)},
abstract = {Summary Cloud computing is a highly scalable and cost-effective infrastructure for running HPC, enterprise and Web applications. However, the growing demand of Cloud infrastructure has drastically increased the energy consumption of data centers, which has become a critical issue. High energy consumption not only translates to high operational cost, which reduces the profit margin of Cloud providers, but also leads to high carbon emissions which is not environmentally friendly. Hence, energy-efficient solutions are required to minimize the impact of Cloud computing on the environment. In order to design such solutions, deep analysis of Cloud is required with respect to their power efficiency. Thus, in this chapter, we discuss various elements of Clouds which contribute to the total energy consumption and how it is addressed in the literature. We also discuss the implication of these solutions for future research directions to enable green Cloud computing. The chapter also explains the role of Cloud users in achieving this goal.}
}@article{https://doi.org/10.1002/cpe.3092,
author = {Chen, Jinjun and Liu, Jianxun},
title = {Special issue: 2011 international conference on cloud and green computing (CGC2011)},
journal = {Concurrency and Computation: Practice and Experience},
volume = {25},
number = {18},
pages = {2433-2434},
keywords = {CGC2011, cloud computing, green computing},
doi = {https://doi.org/10.1002/cpe.3092},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3092},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3092},
year = {2013}
}

@inbook{doi:https://doi.org/10.1002/9781119785873.ch12,
author = {Meenal, Agrawal and Ankita, Jain},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781119785873},
title = {Study on Green Cloud Computing—A Review},
booktitle = {Machine Learning Approach for Cloud Data Analytics in IoT},
chapter = {12},
pages = {307-322},
doi = {https://doi.org/10.1002/9781119785873.ch12},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119785873.ch12},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119785873.ch12},
year = {2021},
keywords = {                                                       C                    loud computing                , green cloud computing, energy consumption, green information, green computing},
abstract = {Summary Cloud computing is evolving as an important information communication technology. Though computing becomes progressively pervasive, the energy consumption attributable to computing is climbing that marked the foundation of Green Computing. In other words, Green Cloud Computing (GCC) is data center architecture of an internet whose objective is to decrease the power consumption of data center and simultaneously secure the performance from users' point of view. One important feature of Green Computing is saving energy or reduction of carbon footprints. It enables wide range of online monitoring, live virtual machine migration, and VM placement optimization. This type of system responds to the period of top use and alters the accessibility of assets dependent on them expanding or contracting the cloud varying. The paper reviews the comprehensive literature on GCC and comes out with research gaps to further explore this field having lots of research potential.}
}@article{https://doi.org/10.1002/cpe.5425,
author = {Zheng, Xianghan and Rong, Chunming and Badarch, Tuyatsetseg},
title = {Foreword to the special issue of green cloud computing: Methodology and practice},
journal = {Concurrency and Computation: Practice and Experience},
volume = {31},
number = {23},
pages = {e5425},
doi = {https://doi.org/10.1002/cpe.5425},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5425},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.5425},
note = {e5425 CPE-19-0582},
year = {2019}
}
@article{https://doi.org/10.1002/spe.2585,
author = {Yousefipour, Amin and Rahmani, Amir Masoud and Jahanshahi, Mohsen},
title = {Energy and cost-aware virtual machine consolidation in cloud computing},
journal = {Software: Practice and Experience},
volume = {48},
number = {10},
pages = {1758-1774},
keywords = {cost, cloud computing, power consumption, virtual machine, VM consolidation, VM placement},
doi = {https://doi.org/10.1002/spe.2585},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2585},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2585},
note = { SPE-17-0279.R1},
abstract = {Summary Cloud computing has become an essential part of the computational world, offering a variety of server capabilities as scalable virtualized services. Big data centers that deliver cloud computing services contain thousands of computational nodes that consume a significant amount of energy. By introducing the virtual machine (VM), virtualization technology is trying to overcome this problem. One impressive technique for minimizing the total number of active physical servers that lead to improved energy consumption is VM consolidation. To optimize the consolidation process, effective VM placement can be used. In this paper, we first present a mathematical model aimed at reducing power consumption and costs by employing an effective VM consolidation in the cloud data center. Subsequently, we propose a genetic algorithm–based meta-heuristic algorithm, namely, energy and cost-aware VM consolidation for resolving the problem. Finally, we compare our proposed model with the well-known first fit, first fit decreasing, and permutation pack algorithms. The experimental results show that our proposed model reduced power consumption and costs when compared with the three demonstrated algorithms.},
year = {2018}
}
@article{https://doi.org/10.1002/dac.5046,
author = {Souri, Alireza and Piuri, Vincenzo and Shojafar, Mohammad and Al-Masri, Eyhab and Kumari, Saru},
title = {Green energy-efficient computing solutions in Internet of Things communications},
journal = {International Journal of Communication Systems},
volume = {35},
number = {1},
pages = {e5046},
doi = {https://doi.org/10.1002/dac.5046},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.5046},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/dac.5046},
year = {2022}
}
@article{https://doi.org/10.1002/spe.2850,
author = {Malik, Saif U. R. and Akram, Hina and Gill, Sukhpal Singh and Pervaiz, Haris and Malik, Hassan},
title = {EFFORT: Energy efficient framework for offload communication in mobile cloud computing},
journal = {Software: Practice and Experience},
volume = {51},
number = {9},
pages = {1896-1909},
keywords = {cloud computing, cloud service providers, energy consumption, IoT, Internet spoofing, offload communication},
doi = {https://doi.org/10.1002/spe.2850},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2850},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2850},
abstract = {Summary There is an abundant expansion in the race of technology, specifically in the production of data, because of the smart devices, such as mobile phones, smart cards, sensors, and Internet of Things (IoT). Smart phones and devices have undergone an enormous evolution in a way that they can be used. More and more new applications, such as face recognition, augmented reality, online interactive gaming, and natural language processing are emerging and attracting the users. Such applications are generally data intensive or compute intensive, which demands high resource and energy consumption. Mobile devices are known for the resource scarcity, having limited computational power and battery life. The tension between compute/data intensive application and resource constrained mobile devices hinders the successful adaption of emerging paradigms. In the said perspective, the objective of this article is to study the role of computation offloading in mobile cloud computing to supplement mobile platforms ability in executing complex applications. This article proposes a systematic approach (EFFORT) for offload communication in the cloud. The proposed approach provides a promising solution to partially solve energy consumption issue for communication-intensive applications in a smartphone. The experimental study shows that our proposed approach outperforms its counterparts in terms of energy consumption and fast processing of smartphone devices. The battery consumption was reduced to 19\% and the data usage was reduced to 16\%.},
year = {2021}
}
@article{https://doi.org/10.1002/itl2.254,
author = {G, Thanmayatejaswi and Ch, Dileep Chakravarthy and Varma, G. P. S. and Mekala, M. S.},
title = {Efficient task optimization algorithm for green computing in cloud},
journal = {Internet Technology Letters},
volume = {6},
number = {1},
pages = {e254},
keywords = {cloud computing, energy optimization, Hadoop system, measurement decision system},
doi = {https://doi.org/10.1002/itl2.254},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/itl2.254},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/itl2.254},
abstract = {Cloud infrastructure assets are accessed by all hooked heterogeneous network servers and applications to maintain entail reliability towards global subscribers with high performance and low cost is a tedious challenging task. Most of the extant techniques are considered limited constraints like task deadline, which leads Service Level Agreement (SLA) violation. In this manuscript, we develop Hadoop based Task Scheduling (HTS) algorithm which considers a task deadline time, completion time, migration time and future resource availability of each virtual machine. The Intelligent System (IS) enabled with adaptive neural computation method to assess all above attributes. Specifically, the result of Prophecy Resource Availability (PRA) method has been used to assess the status of each Virtual Machine (VM), which helps to streamline the resource wastage and increases the response time with low SLA violation rate.},
year = {2023}
}
@article{https://doi.org/10.1049/iet-wss.2015.0050,
author = {De, Debashis and Mukherjee, Anwesha and Ray, Anindita and Roy, Deepsubhra Guha and Mukherjee, Suchismita},
title = {Architecture of green sensor mobile cloud computing},
journal = {IET Wireless Sensor Systems},
volume = {6},
number = {4},
pages = {109-120},
keywords = {mobile computing, cloud computing, software architecture, macrocell base station, microcell base station, sensor data transmission, home node base station, mobile device, sensor data, mobile network, green sensor mobile cloud computing},
doi = {https://doi.org/10.1049/iet-wss.2015.0050},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-wss.2015.0050},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1049/iet-wss.2015.0050},
abstract = {This study presents an architecture of green sensor mobile cloud computing which integrates sensor network and mobile network with cloud computing. In the proposed scheme, the sensor data are transmitted to the cloud through a mobile device. To develop the proposed architecture both the indoor and outdoor region are considered. For indoor region light weight access point and home node base station are used by the mobile device for sensor data transmission to the cloud, whereas for outdoor region macrocell and microcell base stations are used. Simulation results present that using home node base station the power consumption at indoor region can be reduced by ∼10\% than the light weight access point, and using microcell base station at outdoor region the power consumption can be reduced by ∼30\% than the macrocell base station. Hence, using home node base station and microcell base station green sensor mobile cloud computing can be obtained at indoor and outdoor regions, respectively. In this study, an experimental analysis of the proposed architecture is also performed.},
year = {2016}
}
@article{https://doi.org/10.1002/cpe.4461,
author = {Siddiqa, Ayesha and Qureshi, Faisal Fayyaz and Shah, Munam Ali and Iqbal, Rahat and Wahid, Abdul and Chang, Victor},
title = {CCN: A novel energy efficient greedy routing protocol for green computing},
journal = {Concurrency and Computation: Practice and Experience},
volume = {31},
number = {23},
pages = {e4461},
keywords = {broken edges, content centric mobile ad hoc network (CC-MANET), energy efficiency, green computing, mobility, routing table (RT)},
doi = {https://doi.org/10.1002/cpe.4461},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4461},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.4461},
note = {e4461 CPE-17-0316.R1},
abstract = {Summary We proposed a novel Energy Efficient Greedy Routing Protocol (EEGRP) in CCN for MANETs to achieve the gaps in the existing infrastructure of Green Cloud Computing. Initially, the consumer node broadcasts the interest packet; each relay node verifies if it is already satisfied, and then it drops the packet. Otherwise, the provider node selects shortest path to unicast data packet within minimum delay. Each relay node receives a data packet, stores its content in content store, and forwards it to next node according to path mention in the hop-count field. If the data packet custodian node does not find path mention in the hop-count field, then it searches the routing table entries to choose the second best path to unicast the data packet. EEGRP is implemented in three scenarios using ns2 and compare its performance with AIRDrop routing protocol on bases of three performance parameters like packet delivery ratio, delay, and energy consumption. EEGRP achieves high PDR with minimum delay and less energy consumption as compared to AIRDrop. Therefore, EEGRP is feasible to use on green computing and cloud technology. This can save energy issue to secure energy for Green Computing and Cloud before moving to full-scale virtualization and Cloud services.},
year = {2019}
}

@inbook{doi:https://doi.org/10.1002/9781119821878.ch2,
author = {Balamurugan, N.M. and Rathish babu, TKS and Maithili, K and Adimoolam, M.},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781119821878},
title = {Energy Optimized Techniques in Cloud and Fog Computing},
booktitle = {Hybrid Intelligent Approaches for Smart Energy},
chapter = {2},
pages = {27-47},
doi = {https://doi.org/10.1002/9781119821878.ch2},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119821878.ch2},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119821878.ch2},
year = {2022},
keywords = {Cloud computing, fog computing, energy optimization, public cloud, private cloud, context aware service, edge computing, grid computing},
abstract = {Summary In the world, many applications have been utilized with distributed manner and as a result, resources have been effectively utilized irrespective of different places. In distributed computing various subsections have been introduced like grid computing, cloud computing, and fog/edge computing. In cloud computing various services are introduced and are Infrastructure as a Service (IaaS), Software as Service (SaaS), Platform as a Service (PaaS), Security as a Service (SECaaS), and so on. Even though major advantages have been affluently available from cloud computing, the processing and computation has to be carried out remotely in a distributed manner. On the other hand, fog computing plays inevitable latency and bandwidth reduced distributed services are provided. Even though both cloud computing and fog computing provide various services using distributed resources, it is important to realize how energy is consumed and what percentage of consumption is used for what services. In this chapter, how energy is optimized and what techniques are available in cloud and fog computing are discussed.}
}
@inbook{doi:https://doi.org/10.1002/9781119821878.ch3,
author = {Mishra, Praveen and Sivaram, M. and Arvindhan, M. and Daniel, A. and Ranjan, Raju},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781119821878},
title = {Energy-Efficient Cloud Computing Techniques for Next Generation},
booktitle = {Hybrid Intelligent Approaches for Smart Energy},
chapter = {3},
pages = {49-66},
doi = {https://doi.org/10.1002/9781119821878.ch3},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119821878.ch3},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119821878.ch3},
year = {2022},
keywords = {Energy efficiency, data center, network, servers, cloud computing, cloud management system, appliances},
abstract = {Summary In recent decades, massive growth has led to high use of natural resources in global economization and acceleration in global transition. In the meantime, computer technology has become a standard human social lifestyle feature. The I.T. sector's energy use has also risen significantly as machine and I.T. services are widely attractive. Cloud computing is probably the most thrilling I.C.T. platform and nearly every web user has used it directly or indirectly. Its ultra-scale size contains enormous data centers with several thousand additional server support equipment. The proportion of electricity used by infrastructures is 1.1\% to 1.5\% of the entire electricity production. It can expand even further. We also discern recent cloud computing advances in terms of the energy efficiency of the networks. In the literature and expertise covering servers, networks, cloud management platforms, and computers, including end-user apps, we discuss government-of-the-art strategies. This chapter defines the profits and trade-offs when adopting energy conservation measures and ultimately adopting challenges and outlines recommendations for analysis in the future.}
}@article{https://doi.org/10.1002/sys.21393,
author = {Biran, Yahav and Collins, George and Dubow, Joel},
title = {Cloud Computing Cost and Energy Optimization through Federated Cloud SoS},
journal = {Systems Engineering},
volume = {20},
number = {3},
pages = {280-293},
keywords = {systems thinking, architectural design, system integration, environmental compatibility, information & communications, energy, infrastructure & resource management},
doi = {https://doi.org/10.1002/sys.21393},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sys.21393},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sys.21393},
abstract = {ABSTRACT The two most significant differentiators among contemporary cloud computing service providers have increased green energy use and data center resource utilization. This paper addresses these two issues from a system's architectural optimization viewpoint. The proposed approach herein allows multiple cloud providers to utilize their individual computing resources in three ways by: (1) cutting the number of datacenters needed, (2) scheduling available datacenter grid energy via aggregators to reduce costs and power outages, and lastly by (3) utilizing, where appropriate, more renewable, and carbon-free energy sources. Altogether our proposed approach creates an alternative paradigm for a federated cloud system-of-systems (SoS) approach. The proposed paradigm employs a novel control methodology that is tuned to obtain both financial and environmental advantages. It also supports dynamic expansion and contraction of computing capabilities for handling sudden variations in service demand as well as for maximizing usage of time-varying green energy supplies. Herein we analyze the core SoS requirements, concept synthesis, and functional architecture with an eye on avoiding inadvertent cascading conditions. We suggest a physical architecture that diminishes unwanted outcomes while encouraging desirable results. Finally, in our approach, the constituent cloud services retain their independent ownership, objectives, funding, and sustainability means.},
year = {2017}
}
@article{https://doi.org/10.1002/spe.2603,
author = {Arroba, Patricia and Risco-Martín, José L. and Moya, José M. and Ayala, José L.},
title = {Heuristics and metaheuristics for dynamic management of computing and cooling energy in cloud data centers},
journal = {Software: Practice and Experience},
volume = {48},
number = {10},
pages = {1775-1804},
keywords = {cloud computing, energy efficiency, metaheuristics, thermal management},
doi = {https://doi.org/10.1002/spe.2603},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2603},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2603},
note = { spe.2603},
abstract = {Summary Data centers handle impressive high figures in terms of energy consumption, and the growing popularity of cloud applications is intensifying their computational demand. Moreover, the cooling needed to keep the servers within reliable thermal operating conditions also has an impact on the thermal distribution of the data room, thus affecting to servers' power leakage. Optimizing the energy consumption of these infrastructures is a major challenge to place data centers on a more scalable scenario. Thus, understanding the relationship between power, temperature, consolidation, and performance is crucial to enable an energy-efficient management at the data center level. In this research, we propose novel power and thermal-aware strategies and models to provide joint cooling and computing optimizations from a local perspective based on the global energy consumption of metaheuristic-based optimizations. Our results show that the combined awareness from both metaheuristic and best fit decreasing algorithms allow us to describe the global energy into faster and lighter optimization strategies that may be used during runtime. This approach allows us to improve the energy efficiency of the data center, considering both computing and cooling infrastructures, in up to a 21.74\% while maintaining quality of service.},
year = {2018}
}
@article{https://doi.org/10.1002/ett.3434,
author = {Verma, Jitendra Kumar and Kumar, Sushil and Kaiwartya, Omprakash and Cao, Yue and Lloret, Jaime and Katti, C. P. and Kharel, Rupak},
title = {Enabling green computing in cloud environments: Network virtualization approach toward 5G support},
journal = {Transactions on Emerging Telecommunications Technologies},
volume = {29},
number = {11},
pages = {e3434},
doi = {https://doi.org/10.1002/ett.3434},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.3434},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ett.3434},
note = {e3434 ett.3434},
abstract = {Abstract Virtualization technology has revolutionized the mobile network and widely used in fifth-generation innovation. It is a way of computing that allows dynamic leasing of server capabilities in the form of services like Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS). The proliferation of these services among the users led to the establishment of large-scale cloud data centers that consume an enormous amount of electrical energy and results into high metered bill cost and carbon footprint. In this paper, we propose three heuristic models, namely, median migration time, smallest void detection, and maximum fill technique, that can reduce energy consumption with minimal variation in service-level agreements negotiated. Specifically, we derive the cost of running cloud data center, cost optimization problem, and resource utilization optimization problem. Power consumption model is developed for cloud computing environment focusing on linear relationship between power consumption and resource utilization. A virtual machine (VM) migration technique is considered, focusing on synchronization-oriented shorter stop-and-copy phase. The complete operational steps as algorithms are developed for energy-aware heuristic models including median migration time, smallest void detection, and maximum fill technique. To evaluate the proposed heuristic models, we conduct experimentations using PlanetLab server data often in ten days and synthetic workload data collected randomly from the similar number of VMs employed in PlanetLab servers. Through evaluation process, we deduce that the proposed approaches can significantly reduce the energy consumption, total VM migration, and host shutdown while maintaining high system performance.},
year = {2018}
}
@article{https://doi.org/10.1002/ett.4095,
author = {Gu, Xiaohui and Zhang, Guoan and Cao, Yujie},
title = {Cooperative mobile edge computing-cloud computing in Internet of vehicle: Architecture and energy-efficient workload allocation},
journal = {Transactions on Emerging Telecommunications Technologies},
volume = {32},
number = {8},
pages = {e4095},
keywords = {Cloud computing, Energy-latency tradeoff, Internet of vehicles, Mobile edge computing, Workload allocation},
doi = {https://doi.org/10.1002/ett.4095},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.4095},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ett.4095},
abstract = {Abstract With the increasing number of vehicles, the generating vehicular data exceeds the capacity of mobile edge computing (MEC). Therefore, studying the interaction and collaboration of edge computing and cloud computing is of significance to provide vehicular users with low-latency high-rate services. This paper first proposes a MEC-cloud computing collaboration architecture for Internet of vehicles, then designs the interconnection/interaction framework between MEC and cloud computing. We consider reducing computation delay and power consumption, and formulate an energy-efficient workload allocation problem with load balancing and dynamic voltage frequency scaling technology, to obtain the optimal workload allocations of MEC and cloud computing. We then present the overall distribution optimization algorithm to solve this problem. The simulation and numerical results show that by saving communication bandwidth and reducing transmission delay, MEC significantly enhances the performance of cloud computing. Besides, the proposed workload balance scheme is better than the benchmark schemes in terms of power consumption and latency.},
year = {2021}
}

@inbook{doi:https://doi.org/10.1002/9781118640708.ch16,
author = {Valentini, Giorgio L. and Khan, Samee U. and Bouvry, Pascal},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781118640708},
title = {Energy-Efficient Resource Utilization in Cloud Computing},
booktitle = {Large Scale Network‐Centric Distributed Systems},
chapter = {16},
pages = {377-408},
doi = {https://doi.org/10.1002/9781118640708.ch16},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118640708.ch16},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118640708.ch16},
year = {2013},
keywords = {cloud computing, complementarity approach, energy consumption, energy models, energy-conscious task consolidation (ECTC), mathematical model, MaxUtil, resource utilization, task consolidation algorithms},
abstract = {Summary In Cloud computing, energy consumption and resource utilization are strongly coupled. Specifically, resources with a low utilization rate still consume an unacceptable amount of energy compared to the energy consumption of a fully utilized or sufficiently loaded Cloud computing. To increase resource utilization, task consolidation is an effective technique, greatly enabled by virtualization technologies, which facilitate the concurrent execution of several tasks and, in turn, reduce energy consumption. The authors use two energy-conscious heuristics for task consolidation: MaxUtil, which aims to maximize resource utilization, and Energy-Conscious Task Consolidation (ECTC) which explicitly takes into account both active and idle energy consumption. ECTC computes the energy consumption based on an objective function derived from findings reported in the literature. The chapter deals with the Cloud computing, energy models, and task consolidation algorithms. It describes the complementarity approach and the related mathematical model. The chapter finally summarizes the simulation results and discussions.}
}@article{https://doi.org/10.1002/cpe.3176,
author = {Tian, Wenhong and Yeo, Chee Shin},
title = {Minimizing total busy time in offline parallel scheduling with application to energy efficiency in cloud computing},
journal = {Concurrency and Computation: Practice and Experience},
volume = {27},
number = {9},
pages = {2470-2488},
keywords = {parallel job scheduling, multiple identical machines, offline scheduling, total busy time},
doi = {https://doi.org/10.1002/cpe.3176},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3176},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3176},
abstract = {Summary Our paper considers the following fundamental scheduling problem. There are n deterministic jobs to be scheduled offline on multiple identical machines, which have bounded capacities. Each job is associated with a start-time, an end-time, a process time, and demand for machine capacity. The goal is to schedule all of the jobs non-preemptively in their start-time-end-time windows, subject to machine capacity constraints such that the total busy time of the machines is minimized. We refer to this problem as minimizing the total busy time for the scheduling of multiple identical machines (MinTBT). This problem has important applications in power-aware scheduling for Cloud computing, optical network design, customer service systems, and other related areas. Scheduling to minimize busy times is already NP-hard in the special case where all jobs have the same process time and can be scheduled in a fixed time interval. One best-known result for this problem is a 5-approximation algorithm for special instances using first-fit-decreasing algorithm. In this paper, we propose and prove a 3-approximation algorithm, modified first-fit-decreasing-earliest for the general case and obtain more results for special cases. We then show how our results are applied in cloud computing to improve the energy efficiency. Copyright © 2013 John Wiley \& Sons, Ltd.},
year = {2015}
}
@article{https://doi.org/10.1002/cpe.4942,
author = {Zhou, Zhou and Yu, Junyang and Li, Fangmin and Yang, Fei},
title = {Virtual machine migration algorithm for energy efficiency optimization in cloud computing},
journal = {Concurrency and Computation: Practice and Experience},
volume = {30},
number = {24},
pages = {e4942},
keywords = {cloud computing, energy consumption management, VM migration, VM selection},
doi = {https://doi.org/10.1002/cpe.4942},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4942},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.4942},
note = {e4942 CPE-18-0870.R1},
abstract = {Summary Cloud computing has gained more and more attention from industrial and academic circle since it offers pay-as-you-go model, and business applications based on the cloud are also increasing. These applications meet the requirement of users while at the same time triggering the problem of high energy consumption in data centers. To deal with the problem, we propose a new algorithm named EEOM (Energy Efficiency Optimization of VM Migrations). Under considering CPU and memory factors, the key three steps for EEOM algorithm, including trigger time, VM selection, and host location, are optimized. EEOM algorithm takes use of the virtualization technology and migrates some VMs on the lightly loaded host and heavily loaded host to other hosts. The idle hosts are switched to low-power mode or shut down so as to save energy consumption. The experimental results show that, as compared with Double Threshold (DT) algorithm, the EEOM algorithm saves 7\% energy consumption and reduces 13\% SLA violations.},
year = {2018}
}
@article{https://doi.org/10.1049/smc2.12049,
author = {Su, Wenwei and Shi, Yan},
title = {Distributed energy sharing algorithm for Micro Grid energy system based on cloud computing},
journal = {IET Smart Cities},
volume = {n/a},
number = {n/a},
pages = {},
keywords = {Data Structures, Artificial Intelligence, Data Analytics and Machine Learning, building management systems},
doi = {https://doi.org/10.1049/smc2.12049},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/smc2.12049},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1049/smc2.12049},
abstract = {Abstract The reduction of adverse environmental effects and the socioeconomic advantages of renewable energy systems promote greater integration of distributed energy systems into the traditional electrical networks. A new type of sharing economy is emerging with the sharing of energy resources to reduce transaction costs by using platform services in the cloud. Given the obstacles posed by the legacy system and various forms of renewable energy integration, Distributed Energy and Micro Grids (DE-MG) are an efficient means of raising the quality of energy services. Rules for microgrid scalability, maintaining a budget, and security can make this difficult. Consumers are better at receiving the best renewable energy allotment price using a cloud-based Peer-to-Peer (P2P) network. The main objective is to lower the daily energy cost of microgrid power in commercial buildings. In the proposed work, cloud-based P2P for peer-Multi Agent System (p-MAS) optimization techniques are used to reduce system peak and integrated Demand Response (DR) with Energy Management System (EMS) in a commercial MG. To fill knowledge gaps about how various power market architectures and individual decision-making processes impact local interactions and market outcomes, cloud-based P2P for Modelling Leveraging Agents (MLA) is used for bill calculation. A performance measure is finally created for cost evaluation and reliability to measure the social benefits of cloud-based P2P models for exchanging energy. For various price environments and resource types, a comparison between the proposed cloud-based P2P model with an existing P2P model for exchanging energy is provided. The primary use of a distributed P2P model for exchanging power in a microgrid is to reduce electricity costs and increase grid environment reliability.}
}

