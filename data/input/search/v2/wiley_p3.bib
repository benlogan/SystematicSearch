@article{https://doi.org/10.1049/iet-net.2017.0105,
author = {Kallam, Suresh and Madda, Rajasekhara Babu and Chen, Chi-Yuan and Patan, Rizwan and Cheelu, Dhanaraj},
title = {Low energy aware communication process in IoT using the green computing approach},
journal = {IET Networks},
volume = {7},
number = {4},
pages = {258-264},
keywords = {Internet of Things, telecommunication power management, energy conservation, green computing, wireless sensor networks, low energy aware communication process, green computing approach, Internet of Things, ubiquitous network, IoT sensor devices, battery-operated devices, intelligent transmission, sensor management, energy reduction, energy-efficient communication energy, communication overhead reduction},
doi = {https://doi.org/10.1049/iet-net.2017.0105},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-net.2017.0105},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1049/iet-net.2017.0105},
abstract = {The Internet of Things (IoT) is a ubiquitous network that interconnects and integrates the devices and cyberspace to enable the smart objects. It lays a platform to collect, process, and to analyse the data for monitoring and controlling the cyber–physical world by using IoT sensor devices. These sensor devices can be wired or wireless that connects to IoT. The wireless devices are battery-operated devices, unlike wired devices. The energy reduction is critical for battery-operated devices. The smart devices need an intelligent transmission that increases the life of the devices. There are difficulties in sensor management with regard to energy reduction by applying the energy-efficient communication energy saved over IoT devices communication. Finally, the low energy aware communication process can enhance device life time in IoT. Least energy aware communication technique is a promising paradigm for IoT is reduced 30\% communication overhead.},
year = {2018}
}

@inbook{doi:https://doi.org/10.1002/9781118821930.ch25,
author = {Marinescu, Dan C.},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781118821930},
title = {Cloud Energy Consumption},
booktitle = {Encyclopedia of Cloud Computing},
chapter = {25},
pages = {301-314},
doi = {https://doi.org/10.1002/9781118821930.ch25},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118821930.ch25},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118821930.ch25},
year = {2016},
keywords = {energy optimization, power usage effectiveness, energy proportional system, cloud delivery models, cloud resource management, carbon footprint, economy of scale, information and communication technology ecosystem},
abstract = {Summary Cloud computing is also considered as a realization of the 'green computing' ideal, an IT infrastructure with a considerably smaller carbon footprint than the traditional ones. It has the potential to reduce the energy consumption for computing and data storage, thus shrinking the carbon footprint for IT-related activities. This chapter examines cloud energy consumption and its relationship with other aspects of cloud resource management. It discusses energy use and ecological impact of large data centers, and outlines cloud resource management policies for energy optimization, energy proportional systems, energy-aware load balancing, and server consolidation.}
}
@inbook{doi:https://doi.org/10.1002/9781119792642.ch33,
author = {Singh, Chandan Deep and Kaur, Harleen},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781119792642},
title = {Intelligent Computing for Green Sustainability},
booktitle = {Handbook of Intelligent Computing and Optimization for Sustainable Development},
chapter = {33},
pages = {693-751},
doi = {https://doi.org/10.1002/9781119792642.ch33},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119792642.ch33},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119792642.ch33},
year = {2022},
keywords = {                                                                                               S                                        ustainable development                                , green engineering,                                                                                                AMT                                                                                    , advanced maintenance,                                                                                                ISM                                                                                    ,                                                                                                MDEMATEL                                                                                    , manufacturing performance},
abstract = {Summary Nowadays, all manufacturing firms are facing more and more pressure for a “greener” and more environment-friendly manufacturing. Therefore, the manufacturing firms have had to bring changes in their manufacturing processes as to able to cope up with the community and concerned government. The sustainability and the environmental factors nowadays are one of the most important topics for manufacturing, management, and strategic business and decision for developing a new product. Recent developments in industry suggest another way of achieving excellence in production, that is, industry regulators and professional bodies must encourage innovation in a broad range of high-tech production facilities with environment in mind. Success of the industry depends upon production facilities and the competitive advantage that the industry gains because of better quality and reliability. This advantage leads to increase in the sales and the creation of a sound customer base for greater market share, which eventually leads to more profit, growth and expansion. A firm's processes must possess operating advantages in the form of competitive priorities to outperform its competitors.}
}@article{https://doi.org/10.1002/cpe.3084,
author = {Deng, Kefeng and Ren, Kaijun and Song, Junqiang and Yuan, Dong and Xiang, Yang and Chen, Jinjun},
title = {A clustering based coscheduling strategy for efficient scientific workflow execution in cloud computing},
journal = {Concurrency and Computation: Practice and Experience},
volume = {25},
number = {18},
pages = {2523-2539},
keywords = {cloud computing, scientific workflow, coscheduling, data placement, data staging},
doi = {https://doi.org/10.1002/cpe.3084},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3084},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3084},
abstract = {SUMMARY Due to its advantages of cost-effectiveness, on-demand provisioning and easy for sharing, cloud computing has grown in popularity with the research community for deploying scientific applications such as workflows. Although such interests continue growing and scientific workflows are widely deployed in collaborative cloud environments that consist of a number of data centers, there is an urgent need for exploiting strategies which can place application datasets across globally distributed data centers and schedule tasks according to the data layout to reduce both latency and makespan for workflow execution. In this paper, by utilizing dependencies among datasets and tasks, we propose an efficient data and task coscheduling strategy that can place input datasets in a load balance way and meanwhile, group the mostly related datasets and tasks together. Moreover, data staging is used to overlap task execution with data transmission in order to shorten the start time of tasks. We build a simulation environment on Tianhe supercomputer for evaluating the proposed strategy and run simulations by random and realistic workflows. The results demonstrate that the proposed strategy can effectively improve scheduling performance while reducing the total volume of data transfer across data centers. Concurrency and Computation: Practice and Experience, 2013.© 2013 Wiley Periodicals, Inc.},
year = {2013}
}
@article{https://doi.org/10.1049/joe.2014.0239,
author = {Thankappan Nair, Rajeev and Sankar, Ashok},
title = {Dynamic pricing based on a cloud computing framework to support the integration of renewable energy sources},
journal = {The Journal of Engineering},
volume = {2014},
number = {12},
pages = {680-687},
keywords = {distributed power generation, demand side management, power engineering computing, cloud computing, renewable energy sources, load flow, pricing, dynamic pricing, cloud computing framework, renewable energy sources, electric grid, bidirectional energy flow, price based demand side management programme, dynamic renewable factor, consumer oriented pricing, photovoltaic penetration, distribution system, voltage stability, India},
doi = {https://doi.org/10.1049/joe.2014.0239},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/joe.2014.0239},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1049/joe.2014.0239},
abstract = {Integration of renewable energy sources into the electric grid in the domestic sector results in bidirectional energy flow from the supply side of the consumer to the grid. Traditional pricing methods are difficult to implement in such a situation of bidirectional energy flow and they face operational challenges on the application of price-based demand side management programme because of the intermittent characteristics of renewable energy sources. In this study, a dynamic pricing method using real-time data based on a cloud computing framework is proposed to address the aforementioned issues. The case study indicates that the dynamic pricing captures the variation of energy flow in the household. The dynamic renewable factor introduced in the model supports consumer oriented pricing. A new method is presented in this study to determine the appropriate level of photovoltaic (PV) penetration in the distribution system based on voltage stability aspect. The load flow study result for the electric grid in Kerala, India, indicates that the overvoltage caused by various PV penetration levels up to 33\% is within the voltage limits defined for distribution feeders. The result justifies the selected level of penetration.},
year = {2014}
}
@article{https://doi.org/10.1002/ett.4851,
author = {S., Soundararajan and Shanmugam, Vimal and D., Karunkuzhali and S., Pradeep Kumar},
title = {Hybrid Pelican and Archimedes optimization algorithm fostered energy aware task scheduling in heterogeneous virtualized cloud computing},
journal = {Transactions on Emerging Telecommunications Technologies},
volume = {n/a},
number = {n/a},
pages = {e4851},
doi = {https://doi.org/10.1002/ett.4851},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.4851},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ett.4851},
abstract = {Abstract Energy reduction is a key issue of virtualized cloud computing (CC) schemes, because it provide significant benefits, like lower operating costs, improving system effectiveness, securing the environment. Energy-efficient task scheduling is a feasible mode to attain these objectives. Nevertheless, it is difficult to match cloud resources to user requests in a way that improves performance while meeting a user-defined deadline for energy consumption reduction. Therefore, hybrid Pelican and Archimedes optimization algorithm fostered energy-aware task scheduling in heterogeneous virtualized cloud computing (TS-HVCC-Hyb-POA-AOA) is proposed in this article. A hybrid Pelican and Archimedes optimization algorithm (Hyb-POA-AOA) is used to lessen the task duration and the consumption of power in the cloud. For evaluation, the cloud environment uses the provided environment hybrid Pelican and Archimedes optimization algorithm for execute a few common workloads at the simulated data center. The performance metrics, like makespan right skewed analysis, makespan left skewed analysis, energy consumption right skewed analysis, energy consumption left skewed analysis, availability and resource utilization is considered. The performance of the proposed TS-HVCC-Hyb-POA-AOA method provides 23.69\%, 29.50\%, and 36.78\% higher resource utilization; 38.23\%, 31.35\%, and 26.19\% lower consumption of energy left skewed analysis and 34.52\%, 30.28\%, and 23.54\% lower makespan for right skewed analysis compared with existing methods such as; task scheduling in heterogeneous cloud environment with gray wolf optimization algorithm (TS-HVCC-GWOA), hybrid whale optimization approach and differential evolution optimization for multiple objective virtual machine programming at cloud services (TS-HVCC-WOA), energy and performance planning in TasterkHeterek virtualized cloud computing using particle swarm optimization algorithm (TS-HVCC-PSOA).}
}
@article{https://doi.org/10.1002/cpe.5960,
author = {Cudennec, Loïc},
title = {Adaptive message passing polling for energy efficiency: Application to software-distributed shared memory over heterogeneous computing resources},
journal = {Concurrency and Computation: Practice and Experience},
volume = {32},
number = {24},
pages = {e5960},
keywords = {energy efficiency, heterogeneous computing, high-performance embedded computing},
doi = {https://doi.org/10.1002/cpe.5960},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5960},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.5960},
abstract = {Summary Autonomous vehicles, smart manufacturing, heterogeneous systems, and new high-performance embedded computing (HPEC) applications can benefit from the reuse of code coming from the high-performance computing world. However, unlike for HPC, energy efficiency is critical in embedded systems, especially when running on battery power. Code base from HPC mostly relies on the message passing interface (MPI) message passing runtime to deal with distributed systems. MPI has been designed primarily for performance and not for energy efficiency. One drawback is the way messages are received, in an energy-consuming busy-wait fashion. In this work, we study a simple approach in which receiving processes are put to sleep instead of constantly polling. We implement this strategy at the user level to be transparent to the MPI runtime and the application. Experiments are conducted with OpenMPI, MPICH, and MPC, using a video processing application and a software-distributed shared memory system deployed over two heterogeneous platforms, including the Christmann RECS|Box Antares Microserver. Results show significant energy savings. In some particular cases involving process colocation, we also observe better performance using our strategy which can be explained by a better sharing of the computing resource.},
year = {2020}
}
@article{https://doi.org/10.1002/ett.3305,
author = {Mansouri, Kamel and Alti, Adel and Roose, Philippe and Laborie, Sébastien},
title = {Dynamic semantic-based green bio-inspired approach for optimizing energy and cloud services qualities},
journal = {Transactions on Emerging Telecommunications Technologies},
volume = {29},
number = {5},
pages = {e3305},
doi = {https://doi.org/10.1002/ett.3305},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ett.3305},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ett.3305},
note = {e3305 ett.3305},
abstract = {Abstract Currently, everybody can access and leverage existing services on the Cloud from a wide variety of mobile devices at any time and from anywhere (at home, at work, in the car, etc). The massive use of new heterogeneous mobile devices and technologies for discovering and deploying cloud services has led a trade-off between costs and improved quality of services (eg, fast response time, low cost, improved security, the reduction of energy consumption, and considerable emissions of carbon). This trade-off has led most cloud service providers to call for new intelligent, faster, and energy-saving solutions. This paper aims to propose a new approach based on Semantic Web technologies and Ant Colony Optimization algorithm, which intends to reduce the energy consumption of a wide variety of cloud services. Our approach is generic and, therefore, offers to customers a flexible infrastructure where they can easily perform their preferences. The effectiveness and energy saving of our proposal have been validated and evaluated through multiple experiments on random and real-world data sets.},
year = {2018}
}
@article{https://doi.org/10.1049/iet-cps.2017.0100,
author = {Huang, Lina and Liu, Yi and Wu, Jun and Li, Gaolei and Li, Jianhua},
title = {Software-defined dynamic QoS provisioning for smart metering in energy Internet using fog computing and network calculus},
journal = {IET Cyber-Physical Systems: Theory \& Applications},
volume = {3},
number = {3},
pages = {142-149},
keywords = {quality of service, software defined networking, Internet, telecommunication power management, cloud computing, metering, smart meters, smart metering, software-defined dynamic QoS provisioning, energy Internet, fog computing, NC, quality of services, software-defined networks, SDN controller, network calculus, smart meters, base stations, edge services, bandwidth utilisation},
doi = {https://doi.org/10.1049/iet-cps.2017.0100},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/iet-cps.2017.0100},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1049/iet-cps.2017.0100},
abstract = {Energy Internet (EI) is a revolution of power systems due to its flexible energy control. The smart meters are the key components in EI which perform real-time monitoring and require high demands on quality of services (QoSs). Besides, due to the great performance on resolving device-interconnecting and realising overall network control, software-defined networks (SDNs) are considered as a trend for future EI. However, most existing software-defined EI have all the data processed at SDN controller which makes it difficult to realise fine-grained and deep edge computation and control. Meanwhile, most existing QoS provisioning cannot provide satisfying service for EI because various metering data from smart meters require different time-variant QoS guarantees. To address above challenges, the authors propose a software-defined dynamic QoS provisioning for smart metering in EI using fog computing and network calculus (NC). First, a software-defined EI architecture, where fogs are deployed on smart meters and base stations to realise edge services, is proposed to perform deep edge control in EI. Second, the software-defined dynamic QoS provisioning based on NC theory is proposed to guarantee QoS. Simulations of latency as well as bandwidth utilisation show the advantages of the proposed scheme.},
year = {2018}
}
@article{https://doi.org/10.1002/cpe.4463,
author = {Chen, Xing and Lin, Junxin and Lin, Bing and Xiang, Tao and Zhang, Ying and Huang, Gang},
title = {Self-learning and self-adaptive resource allocation for cloud-based software services},
journal = {Concurrency and Computation: Practice and Experience},
volume = {31},
number = {23},
pages = {e4463},
keywords = {cloud computing, resource allocation, software adaptation},
doi = {https://doi.org/10.1002/cpe.4463},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4463},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.4463},
note = {e4463 CPE-17-0360},
abstract = {Summary In the presence of scale, dynamism, uncertainty, and elasticity, cloud engineers face several challenges when allocating resources for cloud-based software services. They should allocate appropriate resources in order to guarantee good quality of services as well as low cost of resources. Self-adaptive ability is needed in this process because engineers' intervention is difficult. Traditional self-adaptive resource allocation methods are policy-driven. Thus, cloud engineers usually have to develop separate sets of rules for each systems in order to allocate resources effectively, which leads to high administrative cost and implementation complexity. Machine learning has made great achievements in many fields, and it can be also applied to resource allocation. In this paper, we present a self-learning and self-adaptive approach to resource allocation for cloud-based software services. For a given cloud-based software service, its QoS model is firstly trained on history data, which is capable to predict the QoS value as output by using the information on workload and allocated resources as inputs. Then, on-line decision-making on resource allocation can be carried out automatically based on genetic algorithm, which is aimed to search reasonable resource allocation plan by using the QoS model. We evaluate our approach on RUBiS benchmark, demonstrating the accuracy of the QoS model over 90\% and the improvement of resource utilization by 10\%-30\%.},
year = {2019}
}
@article{https://doi.org/10.1002/spe.3248,
author = {Buyya, Rajkumar and Ilager, Shashikant and Arroba, Patricia},
title = {Energy-efficiency and sustainability in new generation cloud computing: A vision and directions for integrated management of data centre resources and workloads},
journal = {Software: Practice and Experience},
volume = {n/a},
number = {n/a},
pages = {},
keywords = {Cloud computing, cooling systems, energy efficiency, integrated resource management, learning-centric management, thermal awareness},
doi = {https://doi.org/10.1002/spe.3248},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3248},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.3248},
abstract = {Abstract Cloud computing has become a critical infrastructure for modern society, like electric power grids and roads. As the backbone of the modern economy, it offers subscription-based computing services anytime, anywhere, on a pay-as-you-go basis. Its use is growing exponentially with the continued development of new classes of applications driven by a huge number of emerging networked devices. However, the success of Cloud computing has created a new global energy challenge, as it comes at the cost of vast energy usage. Currently, data centres hosting Cloud services world-wide consume more energy than most countries. Globally, by 2025, they are projected to consume 20\% of global electricity and emit up to 5.5\% of the world's carbon emissions. In addition, a significant part of the energy consumed is transformed into heat which leads to operational problems, including a reduction in system reliability and the life expectancy of devices, and escalation in cooling requirements. Therefore, for the future generations of Cloud computing to address the environmental and operational consequences of such significant energy usage, they must become energy-efficient and environmentally sustainable while continuing to deliver high-quality services. In this article, we propose a vision for learning-centric approach for the integrated management of new generation Cloud computing environments to reduce their energy consumption and carbon footprint while delivering service quality guarantees. In this article, we identify the dimensions and key issues of integrated resource management and our envisioned approaches to address them. We present a conceptual architecture for energy-efficient new generation Clouds and early results on the integrated management of resources and workloads that evidence its potential benefits towards energy efficiency and sustainability.}
}
@article{https://doi.org/10.1002/dac.4379,
author = {Khorsand, Reihaneh and Ramezanpour, Mohammadreza},
title = {An energy-efficient task-scheduling algorithm based on a multi-criteria decision-making method in cloud computing},
journal = {International Journal of Communication Systems},
volume = {33},
number = {9},
pages = {e4379},
keywords = {best-worst method (BWM), cloud computing, energy consumption, multi-criteria decision making, TOPSIS method},
doi = {https://doi.org/10.1002/dac.4379},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dac.4379},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/dac.4379},
note = {e4379 IJCS-19-0734.R2},
abstract = {Summary The massive growth of cloud computing has led to huge amounts of energy consumption and carbon emissions by a large number of servers. One of the major aspects of cloud computing is its scheduling of many task requests submitted by users. Minimizing energy consumption while ensuring the user's QoS preferences is very important to achieving profit maximization for the cloud service providers and ensuring the user's service level agreement (SLA). Therefore, in addition to implementing user's tasks, cloud data centers should meet the different criteria in applying the cloud resources by considering the multiple requirements of different users. Mapping of user requests to cloud resources for processing in a distributed environment is a well-known NP-hard problem. To resolve this problem, this paper proposes an energy-efficient task-scheduling algorithm based on best-worst (BWM) and the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) methodology. The main objective of this paper is to determine which cloud scheduling solution is more important to select. First, a decision-making group identify the evaluation criteria. After that, a BWM process is applied to assign the importance weights for each criterion, because the selected criteria have varied importance. Then, TOPSIS uses these weighted criteria as inputs to evaluate and measure the performance of each alternative. The performance of the proposed and existing algorithms is evaluated using several benchmarks in the CloudSim toolkit and statistical testing through ANOVA, where the evaluation metrics include the makespan, energy consumption, and resource utilization.},
year = {2020}
}
@article{https://doi.org/10.1002/isd2.12114,
author = {Dawadi, Babu R. and Rawat, Danda B. and Joshi, Shashidhar R. and Keitsch, Martina M.},
title = {Towards energy efficiency and green network infrastructure deployment in Nepal using software defined IPv6 network paradigm},
journal = {THE ELECTRONIC JOURNAL OF INFORMATION SYSTEMS IN DEVELOPING COUNTRIES},
volume = {86},
number = {1},
pages = {e12114},
keywords = {energy, green networking, internet service providers, rural ICT, SoDIP6},
doi = {https://doi.org/10.1002/isd2.12114},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/isd2.12114},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/isd2.12114},
note = {e12114 ISD-RA--0254.R3},
abstract = {Abstract The use of information and communication technology (ICT) has resulted in significant impacts on social welfare, economic growth, transparency, and good governance in developing countries like Nepal. Due to the diverse geographic and economic situations, ICT network and service expansions throughout Nepal have been becoming quite challenging. Private network operators mostly have confined their services to urban areas. Nepal Telecommunications Authority (NTA) collects 2\% royalty form Internet Service Providers (ISPs) and Telecom Operators as Rural Telecommunications Disbursement Fund (RTDF) to enhance ICT services to rural Nepal. Broadband expansion projects initiated by utilizing RTDF to expand ICT infrastructure throughout Nepal are expected to have considerable societal and economical transformations in the rural communities of Nepal. This paper not only presents the current ICT deployment scenario of Nepal but also studies design, analysis, and evaluation of green networking that leverages both software defined networking (SDN), and Internet Protocol version 6 (IPv6)—aka Software Defined IPv6 (SoDIP6)—for energy efficient networking, robust services, and sustainable ICT ecosystem for developing nations like Nepal. We evaluate the SoDIP6 network by considering a typical ISP with end access networks and present benefits and recommendations. Experimental results show that the proposed SoDIP6 network help significantly reduce the energy consumption and carbon footprint leading to overall economic benefits to service providers and the society. Furthermore, energy-saving practices through SoDIP6 networks and some policy directions to the government to focus on green networking considering sensitivity of climate change and global warming impact in the mountainous and developing countries like Nepal are presented.},
year = {2020}
}
@article{https://doi.org/10.1002/cpe.7825,
author = {Yokoyama, André M. and Ferro, Mariza and de Paula, Felipe B. and Vieira, Vitor G. and Schulze, Bruno},
title = {Investigating hardware and software aspects in the energy consumption of machine learning: A green AI-centric analysis},
journal = {Concurrency and Computation: Practice and Experience},
volume = {n/a},
number = {n/a},
pages = {e7825},
keywords = {algorithm, ARM, artificial intelligence, CO2$$ C{O}_2 $$, energy, green AI, machine learning},
doi = {https://doi.org/10.1002/cpe.7825},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.7825},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.7825},
abstract = {Summary Much has been discussed about artificial intelligence's negative environmental impacts due to its power-hungry Machine Learning algorithms and CO2\$\$ C{O}\_2 \$\$ emissions linked to this. This work discusses three direct impacts of AI on energy consumption associated with computation: the software, the hardware, and the energy source's carbon intensity. We present an up-to-date revision of the literature and assess it through experiments. For hardware, we evaluate the use of ARM-based single-board computers for training Machine Learning algorithms. An experimental setup was developed training the algorithm XGBoost and its cost-effectiveness (energy consumption, acquisition cost, and execution time) compared with the X86-64 and GPU architectures and other algorithms. In addition, the CO2\$\$ C{O}\_2 \$\$ is estimated for these experiments and compared for three energy sources. The results show that this type of architecture can become a viable and greener alternative, not only for inference but also for training these algorithms. Finally, we evaluated low precision for training Random Forest algorithms with different datasets for the software aspect. Results show that is possible energy reduction with no decrease in accuracy.}
}
@article{https://doi.org/10.1002/cpe.3086,
author = {Mach, Werner and Schikuta, Erich},
title = {Toward an economic and energy-aware cloud cost model},
journal = {Concurrency and Computation: Practice and Experience},
volume = {25},
number = {18},
pages = {2471-2487},
keywords = {cloud computing, cost model, business strategies},
doi = {https://doi.org/10.1002/cpe.3086},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3086},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3086},
abstract = {SUMMARYThis paper represents an economic cost model for cloud computing aiming at comprising all kinds of cost of a commercial environment. To extend conventional state-of-the-art models considering only fixed cost, we developed a concise but comprehensive analytical model, which includes also variable cost allowing for the development and evaluation of business strategies for cloud environments. These strategies can be used for both cloud providers and cloud consumers. The major goal of our model is to comprise all important economic fundamentals and methods. Thus, this new model supports the decision-making process to be applied with business cases and enables cloud consumers and cloud providers to define their own business strategies and to analyze the respective impact on their business. On the basis of this model, also, the energy efficiency of cloud systems can be evaluated according to chosen business models. Copyright © 2013 John Wiley \& Sons, Ltd.},
year = {2013}
}

@inbook{doi:https://doi.org/10.1002/9781118342015.ch10,
author = {Luo, Haoting and Khargharia, Bithika and Hariri, Salim and Al-Nashif, Youssif},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781118342015},
title = {Autonomic Green Computing in Large-Scale Data Centers},
booktitle = {Energy‐Efficient Distributed Computing Systems},
chapter = {10},
pages = {271-299},
doi = {https://doi.org/10.1002/9781118342015.ch10},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118342015.ch10},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118342015.ch10},
year = {2012},
keywords = {autonomic green computing in large-scale data centers, autonomic computing, active control of heterogeneous behaviors, techniques contributing to optimizing EPE for data centers, promoting green as cost savings, with autonomic green computing},
abstract = {Summary This chapter contains sections titled: Introduction Related Technologies and Techniques Autonomic Green Computing: A Case Study Conclusion and Future Directions References}
}
@inbook{doi:https://doi.org/10.1002/9781118801338.ch9,

publisher = {John Wiley & Sons, Ltd},
isbn = {9781118801338},
title = {Green Mobile Clouds: Making Mobile Devices More Energy Efficient},
booktitle = {Mobile Clouds},
chapter = {9},
pages = {131-157},
doi = {https://doi.org/10.1002/9781118801338.ch9},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118801338.ch9},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118801338.ch9},
year = {2014},
keywords = {green networks, energy efficiency, mobile cloud scenarios for energy-efficient operation, cooperative techniques, cooperative download, cooperative streaming, performance comparison, local exchange of information},
abstract = {Summary Green communications has gained a lot of interest lately and the question here is how mobile clouds can help to improve the energy efficiency of mobile devices. In this chapter the energy-savingix potential of mobile clouds is demonstrated. A particular scenario is chosen for this purpose, namely a cooperative download case where users retrieve a desired content in a collaborative manner. The effect on download speed is also investigated. Several cooperative strategies for the mobile cloud are studied and their energy–saving performance is compared.}
}@article{https://doi.org/10.1002/cpe.3692,
author = {Magoulès, Frédéric and Ahamed, Abal-Kassim Cheik and Suzuki, Atsushi},
title = {Green computing on graphics processing units},
journal = {Concurrency and Computation: Practice and Experience},
volume = {28},
number = {16},
pages = {4305-4325},
keywords = {Green computing, GPU, CUDA, Alinea, Cusp, linear algebra, sparse matrix–vector product, iterative methods, conjugate gradient, compressed sparse row format},
doi = {https://doi.org/10.1002/cpe.3692},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.3692},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3692},
note = { cpe.3692},
abstract = {Summary To answer the question ‘How much energy is consumed for a numerical simulation running on Graphic Processing Unit?’, an experimental protocol is here established. The current provided to a graphic processing unit (GPU) during computation is directly measured using amperometric clamps. Signal processing on the intensity of the current of the power supplied to a GPU, with noise reduction technique, gives precise timing of GPU states, which allow establishing an energy consumption model of the GPU. Energy consumption of each operation, memory copy, vector addition, and element wise product is precisely measured to tune and validate the energy consumption model. The accuracy of the proposed energy consumption model compared to measurements is finally illustrated on a conjugate gradient method for a problem discretized by a finite element method. Copyright © 2015 John Wiley \& Sons, Ltd.},
year = {2016}
}

@inbook{doi:https://doi.org/10.1002/9781119695868.ch4,
author = {Sharifzadeha, Mahdi and Malekpoura, Hossein and Shojab, Ehsan},
publisher = {John Wiley & Sons, Ltd},
isbn = {9781119695868},
title = {Cloud Computing and Its Impact on Industry 4.0},
booktitle = {Industry 4.0 Vision for Energy and Materials},
chapter = {4},
pages = {99-120},
doi = {https://doi.org/10.1002/9781119695868.ch4},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119695868.ch4},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119695868.ch4},
year = {2022},
keywords = {Cloud computing, IaaS, PaaS, SaaS, Public Cloud, Private Cloud, Hybrid Cloud, Community Cloud, Grid computing, Edge Computing, Fog computing},
abstract = {In this chapter, an overview of cloud computing is presented. We try to define the term, describe its main characteristics, outline the types of services provided by cloud technology, and detail how it is related to new concepts such as edge and fog computing. To this end, we check various definitions presented by companies, academics, and analyst firms and study the historical evolution of cloud computing. Cloud computing describes a model for on-demand delivery of computing power based on pay-per-use business models. Virtualization and dynamic scalability on demand are the main features of the cloud. Here, software, platform, and infrastructure are often provided in as a service manner, for which multitenancy and resource pooling, on-demand usage, elasticity, broad network access, measured usage, and resiliency are the main common characteristics. Infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS) are three constitutive layers of a cloud. There are four deployment models for cloud computing: public, private, hybrid, and community. In this chapter, the main advantages and disadvantages of this technology are given, and the motivations of organizations for acquiring cloud computing services are discussed. Finally, the relationship between cloud computing and several close technologies such as grid, edge, and fog computing are presented and discussed.}
}@article{https://doi.org/10.1002/spe.2942,
author = {Cao, Kun and Wei, Tongquan and Chen, Mingsong and Li, Keqin and Weng, Jian and Tan, Wuzheng},
title = {Exploring reliable edge-cloud computing for service latency optimization in sustainable cyber-physical systems},
journal = {Software: Practice and Experience},
volume = {51},
number = {11},
pages = {2225-2237},
keywords = {cyber-physical systems, edge-cloud computing, energy, reliability, service latency minimization},
doi = {https://doi.org/10.1002/spe.2942},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2942},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2942},
abstract = {Abstract In recent years, the advance in information technology has promoted a wide span of emerging cyber-physical systems (CPS) applications such as autonomous automobile systems, healthcare monitoring, and process control systems. For these CPS applications, service latency management is extraordinarily important for the sake of providing high quality-of-experience to terminal users. Edge-cloud computing, integrating both edge computing and cloud computing, is regarded as a promising computation paradigm to achieve low service latency for terminal users in CPS. However, existing latency-aware edge-cloud computing methods dedicated for CPS fail to jointly consider energy budgets and reliability requirements, which may greatly degrade the sustainability of CPS applications. In this article, we explore the problem of minimizing service latency of edge-cloud computing coupled CPS under the constraints of energy budgets and reliability requirements. We propose a two-stage approach composed of static and dynamic service latency optimization. At static stage, Monte-Carlo simulation with integer-linear-programming technique is adopted to find the optimal computation offloading mapping and task backup number. At dynamic stage, a backup-adaptive dynamic mechanism is developed to avoid redundant data transmissions and executions for achieving additional energy savings and service latency enhancement. Experimental results show that our solution is able to reduce system service latency by up to 18.3\% compared with representative baseline solutions.},
year = {2021}
}

